{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UW2BMd5GVok2"
      },
      "source": [
        "# **LOADING DATASET IN PYTHON**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5IwDgYUUphM"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Model\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHzpKY8GVubT"
      },
      "outputs": [],
      "source": [
        "# Initialize an empty list to store the image data\n",
        "image_data_list = []\n",
        "\n",
        "# Loop through the images and convert them to NumPy arrays\n",
        "for i in range(31):\n",
        "  # Construct the file name for the current image\n",
        "  image_file = f'/content/drive/MyDrive/balloons_ms/balloons_ms/balloons_ms_{i+1:02d}.png'\n",
        "\n",
        "  # Open the image and convert it to a NumPy array\n",
        "  image = Image.open(image_file)\n",
        "  image_data = np.array(image)\n",
        "\n",
        "  # Append the image data to the list\n",
        "  image_data_list.append(image_data)\n",
        "\n",
        "# Stack the image data into a 3D array\n",
        "image_data = np.stack(image_data_list, axis=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKYYI1bBV7v8",
        "outputId": "c022f67f-cd39-49f0-9e3b-fee9560e8120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(512, 512, 31)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "BSTRqjZEnriw",
        "outputId": "e57cf585-f882-4af4-a957-feb1957e029b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac70ecff10>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(image_data[:,:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "togpGHavV_Ul"
      },
      "source": [
        "# **GROUND TRUTH DATASET**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMcuhTVnWCqF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "gt_data=[]\n",
        "\n",
        "for j in range(15):\n",
        "\n",
        "  for i in range(15):\n",
        "    if j==0 & i==0:\n",
        "      gt_dataset=image_data[0:63,0:63,0:31]\n",
        "\n",
        "  # Extract a ROI from the image\n",
        "    gt_dataset=image_data[j*32:j*32+64,i*32:i*32+64,0:31]\n",
        "    gt_data.append(gt_dataset)\n",
        "# Stack the image data into a 3D array\n",
        "gt_dataset = np.stack(gt_data, axis=2)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb1fYTy5QoOC"
      },
      "outputs": [],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "gt_data=[]\n",
        "\n",
        "for j in range(8):\n",
        "\n",
        "  for i in range(8):\n",
        "    if j==0 & i==0:\n",
        "      gt_dataset=image_data[0:63,0:63,0:31]\n",
        "\n",
        "  # Extract a ROI from the image\n",
        "    gt_dataset=image_data[j*64:j*64+64,i*64:i*64+64,0:31]\n",
        "    gt_data.append(gt_dataset)\n",
        "# Stack the image data into a 3D array\n",
        "gt_dataset = np.stack(gt_data, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1Fg5bhDAblD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "ljpwAWyDAbvG",
        "outputId": "e5203bd9-c5f6-4b25-8260-949570ecd31e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 64, 31)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 64 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "patches=np.asarray(gt_data)\n",
        "print(patches.shape)\n",
        "plt.figure(figsize=(6,6))\n",
        "for i in range(64):\n",
        "  plt.subplot(8,8,i+1)\n",
        "  plt.imshow(patches[i,:,:,1])\n",
        "  plt.axis('off')\n",
        "plt.savefig('patches.png',dpi=400)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbNHN835Abzv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtpgTJeKAb5H"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKpDnjMRUqYt",
        "outputId": "bb2b7cb0-ef27-477b-b796-e762369a86bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64, 64, 31)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gt_dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TeMKUjaWHXU"
      },
      "outputs": [],
      "source": [
        "image_transposed = np.transpose(gt_dataset, (2, 0, 1, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caQWo2MvWI4F",
        "outputId": "c2bcc248-cfd4-4ce8-d161-b0a01e30d64c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64, 64, 31)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hogKmQCCWKSs",
        "outputId": "0c54dc43-4c38-4df0-b981-55033c947cfb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64, 31)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image_transposed[1].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "T9gs-36Oy6jM",
        "outputId": "d022fa95-970f-4de7-a9e8-8e15dfbc6678"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac6e4092b0>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(image_transposed[40][:,:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-0cVpIeWQlO"
      },
      "source": [
        "# **HI RESOLUTION RGB**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Wr9m0zEWTpF",
        "outputId": "46e192a8-1898-461e-c90b-5f2c5824a466"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 89ms/step\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = layers.Input(shape=(64, 64, 31))\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer = layers.Conv2D(3, kernel_size=3, padding='same', activation='relu')(input_layer)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model(input_layer, conv_layer)\n",
        "\n",
        "# Compile the model\n",
        "HR_RGB = model.predict(image_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGsBrnGQWXfU",
        "outputId": "7f038959-f307-4a99-d103-7d24d909184f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64, 64, 3)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "HR_RGB.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQDq_Q38Wai9",
        "outputId": "e1336d12-8467-4923-9540-20e5bdeff0ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "HR_RGB[0][:,:,2].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "Jcm63f2brE4C",
        "outputId": "4bdf5f42-a5e5-4158-d6cd-80228eaae11c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac6e386040>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(HR_RGB[40][:,:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8d6I1zkpWdhF"
      },
      "source": [
        "# **LOW RESOLUTION HYPER-SPECTRAL IMAGES**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2F5UDFbWiQt"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layer\n",
        "input_layer = layers.Input(shape=(64, 64, 31))\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer = layers.Conv2D(31, kernel_size=3, strides=8, padding='same', activation='relu')(input_layer)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model(input_layer, conv_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV7umExZWkfk",
        "outputId": "62d6ad4b-ca7a-41f6-f95f-5d250aabee78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 13ms/step\n"
          ]
        }
      ],
      "source": [
        "LRHSI = model.predict(image_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vS6jQckRWof0",
        "outputId": "941a1c89-2469-4511-af2a-b04aa0a5c6f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(8, 8, 31)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LRHSI[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytVLcIuJUqdl",
        "outputId": "03515af8-3000-43a9-b79a-f8b61785d490"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 8, 8, 31)"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LRHSI.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "K6KOhNeSUqgc",
        "outputId": "21b74090-2a55-4b58-92be-bbb360b68a7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fac72a1a280>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.imshow(LRHSI[40][:,:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeBPJMTcUqkd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jYlke3AoUqqt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5i8YcAqdUqtd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5Ji4LXAUqzr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-XlOipfUq3L"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5py-vtmUq59"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gITpKw2KUsJm"
      },
      "source": [
        "# **CNN MODEL WITH ACCURACY 80% AND LOSS OF 600 IN 29_12_2022**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZAGUZFcUq8F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m3sRqevqUq-I",
        "outputId": "c14c0b92-5b17-4db5-e5e2-2e3bba25e788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 1s 107ms/step - loss: 36.7451 - accuracy: 7.0123e-04 - val_loss: 13.3558 - val_accuracy: 1.3021e-04\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 31.3606 - accuracy: 6.8088e-04 - val_loss: 14.4259 - val_accuracy: 1.4106e-04\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 28.7447 - accuracy: 0.0127 - val_loss: 13.4934 - val_accuracy: 0.0601\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 26.5593 - accuracy: 0.1422 - val_loss: 11.9224 - val_accuracy: 0.4301\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 24.3598 - accuracy: 0.1830 - val_loss: 10.7594 - val_accuracy: 0.3714\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 22.5559 - accuracy: 0.1502 - val_loss: 10.0351 - val_accuracy: 0.3714\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 20.8368 - accuracy: 0.1480 - val_loss: 9.3084 - val_accuracy: 0.3767\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 19.5008 - accuracy: 0.0615 - val_loss: 8.5086 - val_accuracy: 0.0275\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 18.3451 - accuracy: 0.0892 - val_loss: 7.7819 - val_accuracy: 0.3620\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 17.4438 - accuracy: 0.0978 - val_loss: 7.1813 - val_accuracy: 0.0902\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 16.6270 - accuracy: 0.0199 - val_loss: 6.6818 - val_accuracy: 0.1611\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 15.8979 - accuracy: 0.1462 - val_loss: 6.3411 - val_accuracy: 0.4455\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 15.2728 - accuracy: 0.1998 - val_loss: 6.0319 - val_accuracy: 0.4254\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 14.7699 - accuracy: 0.2040 - val_loss: 5.5828 - val_accuracy: 0.4288\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 14.4049 - accuracy: 0.2324 - val_loss: 5.1834 - val_accuracy: 0.4291\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 13.9356 - accuracy: 0.2346 - val_loss: 4.6088 - val_accuracy: 0.4303\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 13.2028 - accuracy: 0.2269 - val_loss: 4.0987 - val_accuracy: 0.4304\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 12.2111 - accuracy: 0.2347 - val_loss: 3.9736 - val_accuracy: 0.4217\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 11.6081 - accuracy: 0.2069 - val_loss: 3.9735 - val_accuracy: 5.6424e-04\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 11.3535 - accuracy: 0.3276 - val_loss: 3.8351 - val_accuracy: 0.0608\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 11.0941 - accuracy: 0.2828 - val_loss: 3.6189 - val_accuracy: 0.4353\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 10.9197 - accuracy: 0.4321 - val_loss: 3.4723 - val_accuracy: 0.4507\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.7680 - accuracy: 0.4804 - val_loss: 3.4559 - val_accuracy: 0.4549\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.6504 - accuracy: 0.4307 - val_loss: 3.3852 - val_accuracy: 0.4629\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.6129 - accuracy: 0.4361 - val_loss: 3.3845 - val_accuracy: 0.5032\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.5539 - accuracy: 0.4399 - val_loss: 3.3221 - val_accuracy: 0.4784\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.4769 - accuracy: 0.4589 - val_loss: 3.3659 - val_accuracy: 0.5032\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 10.3755 - accuracy: 0.4565 - val_loss: 3.3449 - val_accuracy: 0.4901\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 10.3639 - accuracy: 0.4769 - val_loss: 3.5114 - val_accuracy: 0.5083\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.3881 - accuracy: 0.4893 - val_loss: 3.3486 - val_accuracy: 0.5558\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 10.4301 - accuracy: 0.5101 - val_loss: 3.5293 - val_accuracy: 0.6204\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.4043 - accuracy: 0.5153 - val_loss: 3.3575 - val_accuracy: 0.6252\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 10.4043 - accuracy: 0.5288 - val_loss: 3.2691 - val_accuracy: 0.6011\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 10.2760 - accuracy: 0.5697 - val_loss: 3.2726 - val_accuracy: 0.6189\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.2493 - accuracy: 0.5809 - val_loss: 3.3540 - val_accuracy: 0.6363\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.2233 - accuracy: 0.5887 - val_loss: 3.2579 - val_accuracy: 0.5889\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.2205 - accuracy: 0.6095 - val_loss: 3.2578 - val_accuracy: 0.6042\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.1838 - accuracy: 0.6149 - val_loss: 3.3418 - val_accuracy: 0.6006\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.1628 - accuracy: 0.6093 - val_loss: 3.2589 - val_accuracy: 0.6213\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 10.1754 - accuracy: 0.6127 - val_loss: 3.2362 - val_accuracy: 0.5715\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.1618 - accuracy: 0.6129 - val_loss: 3.3691 - val_accuracy: 0.6373\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.0889 - accuracy: 0.6135 - val_loss: 3.0544 - val_accuracy: 0.6502\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.8948 - accuracy: 0.6032 - val_loss: 2.8757 - val_accuracy: 0.6824\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 9.5387 - accuracy: 0.6050 - val_loss: 2.8002 - val_accuracy: 0.6271\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 9.3089 - accuracy: 0.5935 - val_loss: 2.9364 - val_accuracy: 0.5862\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 9.1985 - accuracy: 0.5941 - val_loss: 2.7775 - val_accuracy: 0.5931\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 9.0425 - accuracy: 0.6148 - val_loss: 2.7420 - val_accuracy: 0.5640\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.9379 - accuracy: 0.6153 - val_loss: 2.6911 - val_accuracy: 0.6135\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.9086 - accuracy: 0.6147 - val_loss: 2.8334 - val_accuracy: 0.6279\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.8247 - accuracy: 0.6482 - val_loss: 2.7630 - val_accuracy: 0.6414\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.7747 - accuracy: 0.6389 - val_loss: 2.6921 - val_accuracy: 0.6309\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.7423 - accuracy: 0.6491 - val_loss: 2.7516 - val_accuracy: 0.6243\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.7445 - accuracy: 0.6643 - val_loss: 2.6504 - val_accuracy: 0.6275\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.7908 - accuracy: 0.6447 - val_loss: 2.7476 - val_accuracy: 0.6498\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.8017 - accuracy: 0.6513 - val_loss: 2.6445 - val_accuracy: 0.6557\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.9134 - accuracy: 0.6547 - val_loss: 2.7870 - val_accuracy: 0.6349\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.8423 - accuracy: 0.6837 - val_loss: 2.7028 - val_accuracy: 0.6279\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 8.7550 - accuracy: 0.6792 - val_loss: 2.7145 - val_accuracy: 0.5966\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 8.8327 - accuracy: 0.6754 - val_loss: 2.8167 - val_accuracy: 0.6589\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 8.7923 - accuracy: 0.6811 - val_loss: 2.7048 - val_accuracy: 0.6379\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.7003 - accuracy: 0.6905 - val_loss: 2.6334 - val_accuracy: 0.6059\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.6756 - accuracy: 0.6534 - val_loss: 2.7447 - val_accuracy: 0.6489\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.6562 - accuracy: 0.7045 - val_loss: 2.6681 - val_accuracy: 0.6468\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.6550 - accuracy: 0.7055 - val_loss: 2.7458 - val_accuracy: 0.6448\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.6575 - accuracy: 0.6977 - val_loss: 2.6485 - val_accuracy: 0.6345\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.6348 - accuracy: 0.7016 - val_loss: 2.6129 - val_accuracy: 0.6408\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.7177 - accuracy: 0.6944 - val_loss: 2.8693 - val_accuracy: 0.6386\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.7449 - accuracy: 0.7085 - val_loss: 2.6634 - val_accuracy: 0.6252\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 8.7639 - accuracy: 0.7038 - val_loss: 2.6532 - val_accuracy: 0.6178\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.6679 - accuracy: 0.7098 - val_loss: 2.7704 - val_accuracy: 0.6392\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 8.6908 - accuracy: 0.7087 - val_loss: 2.6627 - val_accuracy: 0.6373\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.6638 - accuracy: 0.7105 - val_loss: 2.7591 - val_accuracy: 0.6267\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.6382 - accuracy: 0.7030 - val_loss: 2.6280 - val_accuracy: 0.6419\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.6250 - accuracy: 0.7012 - val_loss: 2.7572 - val_accuracy: 0.6267\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.6417 - accuracy: 0.7010 - val_loss: 2.6487 - val_accuracy: 0.6723\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.6166 - accuracy: 0.7126 - val_loss: 2.5752 - val_accuracy: 0.6549\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.6191 - accuracy: 0.7207 - val_loss: 2.8653 - val_accuracy: 0.6556\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.6522 - accuracy: 0.7051 - val_loss: 2.6064 - val_accuracy: 0.6312\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.6310 - accuracy: 0.7083 - val_loss: 2.6900 - val_accuracy: 0.6528\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.6044 - accuracy: 0.7091 - val_loss: 2.7178 - val_accuracy: 0.6223\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.5802 - accuracy: 0.7039 - val_loss: 2.6103 - val_accuracy: 0.6460\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.5739 - accuracy: 0.7293 - val_loss: 2.6522 - val_accuracy: 0.6534\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.5936 - accuracy: 0.7168 - val_loss: 2.6170 - val_accuracy: 0.6535\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.6319 - accuracy: 0.7255 - val_loss: 2.7657 - val_accuracy: 0.6352\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.6465 - accuracy: 0.7178 - val_loss: 2.5865 - val_accuracy: 0.6563\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5974 - accuracy: 0.7183 - val_loss: 2.6937 - val_accuracy: 0.6530\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.5639 - accuracy: 0.7104 - val_loss: 2.6429 - val_accuracy: 0.6118\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.5618 - accuracy: 0.7233 - val_loss: 2.6241 - val_accuracy: 0.6599\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5542 - accuracy: 0.7155 - val_loss: 2.6581 - val_accuracy: 0.6506\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5624 - accuracy: 0.7153 - val_loss: 2.6563 - val_accuracy: 0.6501\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.5712 - accuracy: 0.7293 - val_loss: 2.6360 - val_accuracy: 0.6261\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5716 - accuracy: 0.7199 - val_loss: 2.6610 - val_accuracy: 0.6533\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5531 - accuracy: 0.7250 - val_loss: 2.6268 - val_accuracy: 0.6535\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 8.5415 - accuracy: 0.7256 - val_loss: 2.7030 - val_accuracy: 0.6436\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.5407 - accuracy: 0.7287 - val_loss: 2.7280 - val_accuracy: 0.6391\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.5641 - accuracy: 0.7285 - val_loss: 2.5872 - val_accuracy: 0.6226\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 8.5507 - accuracy: 0.7291 - val_loss: 2.6483 - val_accuracy: 0.6374\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.5572 - accuracy: 0.7259 - val_loss: 2.5462 - val_accuracy: 0.6152\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.6255 - accuracy: 0.7366 - val_loss: 2.9062 - val_accuracy: 0.6553\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.6399 - accuracy: 0.7273 - val_loss: 2.5751 - val_accuracy: 0.6442\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.5745 - accuracy: 0.7245 - val_loss: 2.5617 - val_accuracy: 0.6436\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5628 - accuracy: 0.7125 - val_loss: 2.7847 - val_accuracy: 0.6515\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.5728 - accuracy: 0.7312 - val_loss: 2.5800 - val_accuracy: 0.6555\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5787 - accuracy: 0.7260 - val_loss: 2.6017 - val_accuracy: 0.6450\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.5434 - accuracy: 0.7294 - val_loss: 2.6001 - val_accuracy: 0.6452\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.5576 - accuracy: 0.7393 - val_loss: 2.6863 - val_accuracy: 0.6528\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5515 - accuracy: 0.7263 - val_loss: 2.5920 - val_accuracy: 0.6384\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5237 - accuracy: 0.7162 - val_loss: 2.5674 - val_accuracy: 0.6213\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 8.5093 - accuracy: 0.7405 - val_loss: 2.5688 - val_accuracy: 0.6240\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 8.5131 - accuracy: 0.7347 - val_loss: 2.5926 - val_accuracy: 0.6424\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.4954 - accuracy: 0.7381 - val_loss: 2.6676 - val_accuracy: 0.6436\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.5062 - accuracy: 0.7326 - val_loss: 2.5893 - val_accuracy: 0.6549\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5195 - accuracy: 0.7388 - val_loss: 2.6491 - val_accuracy: 0.6438\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4995 - accuracy: 0.7409 - val_loss: 2.5812 - val_accuracy: 0.6435\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 8.4985 - accuracy: 0.7380 - val_loss: 2.6160 - val_accuracy: 0.6494\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.4929 - accuracy: 0.7433 - val_loss: 2.5801 - val_accuracy: 0.6587\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4879 - accuracy: 0.7379 - val_loss: 2.5863 - val_accuracy: 0.6622\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5021 - accuracy: 0.7448 - val_loss: 2.7766 - val_accuracy: 0.6662\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.5039 - accuracy: 0.7440 - val_loss: 2.5376 - val_accuracy: 0.6152\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.5369 - accuracy: 0.7403 - val_loss: 2.5721 - val_accuracy: 0.6828\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5093 - accuracy: 0.7351 - val_loss: 2.6346 - val_accuracy: 0.6833\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 8.4843 - accuracy: 0.7364 - val_loss: 2.5637 - val_accuracy: 0.6391\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.4782 - accuracy: 0.7421 - val_loss: 2.6116 - val_accuracy: 0.6506\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.4678 - accuracy: 0.7310 - val_loss: 2.5894 - val_accuracy: 0.6873\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.4778 - accuracy: 0.7419 - val_loss: 2.6438 - val_accuracy: 0.6498\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4805 - accuracy: 0.7434 - val_loss: 2.6418 - val_accuracy: 0.6723\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.4612 - accuracy: 0.7519 - val_loss: 2.5721 - val_accuracy: 0.6502\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 8.4721 - accuracy: 0.7492 - val_loss: 2.5516 - val_accuracy: 0.6723\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.4637 - accuracy: 0.7495 - val_loss: 2.6403 - val_accuracy: 0.6574\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.4582 - accuracy: 0.7455 - val_loss: 2.5142 - val_accuracy: 0.6313\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.4593 - accuracy: 0.7498 - val_loss: 2.6685 - val_accuracy: 0.6913\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.4871 - accuracy: 0.7472 - val_loss: 2.5604 - val_accuracy: 0.6601\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.5360 - accuracy: 0.7512 - val_loss: 2.8163 - val_accuracy: 0.6387\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5552 - accuracy: 0.7473 - val_loss: 2.6466 - val_accuracy: 0.6370\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 8.5113 - accuracy: 0.7478 - val_loss: 2.5735 - val_accuracy: 0.6732\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.4818 - accuracy: 0.7578 - val_loss: 2.5292 - val_accuracy: 0.6225\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4689 - accuracy: 0.7459 - val_loss: 2.6395 - val_accuracy: 0.6589\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.4695 - accuracy: 0.7551 - val_loss: 2.6867 - val_accuracy: 0.6743\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4536 - accuracy: 0.7539 - val_loss: 2.6255 - val_accuracy: 0.6479\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.4465 - accuracy: 0.7531 - val_loss: 2.5315 - val_accuracy: 0.6700\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4549 - accuracy: 0.7539 - val_loss: 2.5493 - val_accuracy: 0.6473\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4355 - accuracy: 0.7522 - val_loss: 2.5647 - val_accuracy: 0.6677\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4294 - accuracy: 0.7581 - val_loss: 2.5823 - val_accuracy: 0.6514\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4265 - accuracy: 0.7567 - val_loss: 2.6113 - val_accuracy: 0.6829\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.4248 - accuracy: 0.7546 - val_loss: 2.6526 - val_accuracy: 0.6437\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.4306 - accuracy: 0.7476 - val_loss: 2.6027 - val_accuracy: 0.6316\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.4316 - accuracy: 0.7476 - val_loss: 2.6222 - val_accuracy: 0.6576\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4463 - accuracy: 0.7535 - val_loss: 2.5802 - val_accuracy: 0.6512\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.4393 - accuracy: 0.7514 - val_loss: 2.5822 - val_accuracy: 0.6685\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 8.4624 - accuracy: 0.7570 - val_loss: 2.5837 - val_accuracy: 0.6571\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 8.4921 - accuracy: 0.7467 - val_loss: 2.6657 - val_accuracy: 0.6385\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 8.4692 - accuracy: 0.7501 - val_loss: 2.5136 - val_accuracy: 0.6483\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.4566 - accuracy: 0.7521 - val_loss: 2.5942 - val_accuracy: 0.6582\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4234 - accuracy: 0.7534 - val_loss: 2.6943 - val_accuracy: 0.6478\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.4309 - accuracy: 0.7593 - val_loss: 2.6597 - val_accuracy: 0.6570\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 8.4186 - accuracy: 0.7461 - val_loss: 2.5740 - val_accuracy: 0.6174\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 8.4183 - accuracy: 0.7413 - val_loss: 2.6078 - val_accuracy: 0.6531\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4006 - accuracy: 0.7524 - val_loss: 2.5683 - val_accuracy: 0.6538\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.4033 - accuracy: 0.7544 - val_loss: 2.5244 - val_accuracy: 0.6449\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.4625 - accuracy: 0.7518 - val_loss: 2.8498 - val_accuracy: 0.7186\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.5961 - accuracy: 0.7472 - val_loss: 2.6147 - val_accuracy: 0.6237\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.5517 - accuracy: 0.7552 - val_loss: 2.7219 - val_accuracy: 0.6446\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 8.6111 - accuracy: 0.7411 - val_loss: 2.5108 - val_accuracy: 0.6416\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.5474 - accuracy: 0.7535 - val_loss: 2.7913 - val_accuracy: 0.6384\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.4432 - accuracy: 0.7559 - val_loss: 2.5186 - val_accuracy: 0.6489\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.9673 - accuracy: 0.6883 - val_loss: 2.4286 - val_accuracy: 0.5895\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 7.6577 - accuracy: 0.7369 - val_loss: 2.5555 - val_accuracy: 0.6375\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.5903 - accuracy: 0.7222 - val_loss: 2.4638 - val_accuracy: 0.6496\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.5057 - accuracy: 0.7191 - val_loss: 2.4449 - val_accuracy: 0.6774\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.4536 - accuracy: 0.6602 - val_loss: 2.5078 - val_accuracy: 0.6873\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.3869 - accuracy: 0.6991 - val_loss: 2.3074 - val_accuracy: 0.6683\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.3454 - accuracy: 0.7385 - val_loss: 2.5084 - val_accuracy: 0.6608\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2742 - accuracy: 0.7550 - val_loss: 2.2616 - val_accuracy: 0.6430\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2717 - accuracy: 0.7550 - val_loss: 2.3788 - val_accuracy: 0.6417\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2537 - accuracy: 0.7510 - val_loss: 2.3632 - val_accuracy: 0.6928\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2429 - accuracy: 0.7550 - val_loss: 2.3352 - val_accuracy: 0.6877\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2332 - accuracy: 0.7479 - val_loss: 2.3379 - val_accuracy: 0.6752\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2360 - accuracy: 0.7613 - val_loss: 2.3293 - val_accuracy: 0.6744\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2371 - accuracy: 0.7620 - val_loss: 2.3137 - val_accuracy: 0.6915\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2285 - accuracy: 0.7592 - val_loss: 2.4139 - val_accuracy: 0.6768\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2706 - accuracy: 0.7675 - val_loss: 2.2904 - val_accuracy: 0.6944\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.2483 - accuracy: 0.7569 - val_loss: 2.2572 - val_accuracy: 0.6752\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2900 - accuracy: 0.7509 - val_loss: 2.5787 - val_accuracy: 0.7069\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2957 - accuracy: 0.7536 - val_loss: 2.3036 - val_accuracy: 0.6942\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.2472 - accuracy: 0.7575 - val_loss: 2.3397 - val_accuracy: 0.6930\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.2325 - accuracy: 0.7541 - val_loss: 2.3779 - val_accuracy: 0.7139\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2263 - accuracy: 0.7588 - val_loss: 2.3601 - val_accuracy: 0.6958\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2279 - accuracy: 0.7530 - val_loss: 2.4035 - val_accuracy: 0.6996\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.2259 - accuracy: 0.7601 - val_loss: 2.3007 - val_accuracy: 0.6923\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2247 - accuracy: 0.7549 - val_loss: 2.2579 - val_accuracy: 0.6840\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2214 - accuracy: 0.7582 - val_loss: 2.3993 - val_accuracy: 0.7037\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2114 - accuracy: 0.7626 - val_loss: 2.2815 - val_accuracy: 0.6933\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.2234 - accuracy: 0.7587 - val_loss: 2.4086 - val_accuracy: 0.6995\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2281 - accuracy: 0.7605 - val_loss: 2.3295 - val_accuracy: 0.6808\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2201 - accuracy: 0.7487 - val_loss: 2.3154 - val_accuracy: 0.6701\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2157 - accuracy: 0.7502 - val_loss: 2.2764 - val_accuracy: 0.7002\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2052 - accuracy: 0.7647 - val_loss: 2.2938 - val_accuracy: 0.6975\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2182 - accuracy: 0.7602 - val_loss: 2.3034 - val_accuracy: 0.6785\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2120 - accuracy: 0.7592 - val_loss: 2.4838 - val_accuracy: 0.6849\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2858 - accuracy: 0.7568 - val_loss: 2.2320 - val_accuracy: 0.7023\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2665 - accuracy: 0.7562 - val_loss: 2.3000 - val_accuracy: 0.7046\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2127 - accuracy: 0.7623 - val_loss: 2.3099 - val_accuracy: 0.6793\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2280 - accuracy: 0.7572 - val_loss: 2.4479 - val_accuracy: 0.6772\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.2404 - accuracy: 0.7490 - val_loss: 2.2876 - val_accuracy: 0.6837\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2497 - accuracy: 0.7581 - val_loss: 2.2582 - val_accuracy: 0.7063\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2329 - accuracy: 0.7576 - val_loss: 2.3273 - val_accuracy: 0.6840\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2224 - accuracy: 0.7598 - val_loss: 2.3036 - val_accuracy: 0.7066\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2338 - accuracy: 0.7510 - val_loss: 2.3182 - val_accuracy: 0.6563\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.2260 - accuracy: 0.7628 - val_loss: 2.3331 - val_accuracy: 0.6825\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2132 - accuracy: 0.7562 - val_loss: 2.2513 - val_accuracy: 0.6758\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2617 - accuracy: 0.7588 - val_loss: 2.4357 - val_accuracy: 0.6938\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2162 - accuracy: 0.7534 - val_loss: 2.3106 - val_accuracy: 0.6933\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2187 - accuracy: 0.7501 - val_loss: 2.3220 - val_accuracy: 0.6530\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1925 - accuracy: 0.7575 - val_loss: 2.3006 - val_accuracy: 0.6866\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.2078 - accuracy: 0.7548 - val_loss: 2.3203 - val_accuracy: 0.7025\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1763 - accuracy: 0.7626 - val_loss: 2.2818 - val_accuracy: 0.6967\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1659 - accuracy: 0.7590 - val_loss: 2.3723 - val_accuracy: 0.7023\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2090 - accuracy: 0.7589 - val_loss: 2.2253 - val_accuracy: 0.6828\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2275 - accuracy: 0.7552 - val_loss: 2.3176 - val_accuracy: 0.6839\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2624 - accuracy: 0.7608 - val_loss: 2.2754 - val_accuracy: 0.6821\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 7.2152 - accuracy: 0.7572 - val_loss: 2.3375 - val_accuracy: 0.6763\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1952 - accuracy: 0.7608 - val_loss: 2.3012 - val_accuracy: 0.6703\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1848 - accuracy: 0.7468 - val_loss: 2.2995 - val_accuracy: 0.6770\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1843 - accuracy: 0.7564 - val_loss: 2.3335 - val_accuracy: 0.6895\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1927 - accuracy: 0.7620 - val_loss: 2.2274 - val_accuracy: 0.6882\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2237 - accuracy: 0.7530 - val_loss: 2.3035 - val_accuracy: 0.6987\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2204 - accuracy: 0.7580 - val_loss: 2.2796 - val_accuracy: 0.7086\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2147 - accuracy: 0.7531 - val_loss: 2.4769 - val_accuracy: 0.6942\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1993 - accuracy: 0.7610 - val_loss: 2.3053 - val_accuracy: 0.6930\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1777 - accuracy: 0.7577 - val_loss: 2.2725 - val_accuracy: 0.6923\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1910 - accuracy: 0.7559 - val_loss: 2.2838 - val_accuracy: 0.7013\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.2080 - accuracy: 0.7614 - val_loss: 2.2505 - val_accuracy: 0.7038\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2977 - accuracy: 0.7555 - val_loss: 2.6500 - val_accuracy: 0.6964\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2814 - accuracy: 0.7581 - val_loss: 2.2458 - val_accuracy: 0.6883\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2153 - accuracy: 0.7609 - val_loss: 2.3836 - val_accuracy: 0.7118\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2249 - accuracy: 0.7555 - val_loss: 2.2551 - val_accuracy: 0.7006\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2015 - accuracy: 0.7606 - val_loss: 2.4454 - val_accuracy: 0.6931\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2189 - accuracy: 0.7577 - val_loss: 2.2217 - val_accuracy: 0.7074\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2177 - accuracy: 0.7511 - val_loss: 2.4360 - val_accuracy: 0.6873\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1973 - accuracy: 0.7611 - val_loss: 2.2610 - val_accuracy: 0.6972\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1835 - accuracy: 0.7576 - val_loss: 2.3144 - val_accuracy: 0.7021\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1690 - accuracy: 0.7602 - val_loss: 2.3061 - val_accuracy: 0.6940\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.1674 - accuracy: 0.7615 - val_loss: 2.3821 - val_accuracy: 0.6811\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1810 - accuracy: 0.7585 - val_loss: 2.2624 - val_accuracy: 0.6964\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1855 - accuracy: 0.7602 - val_loss: 2.3644 - val_accuracy: 0.6817\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1682 - accuracy: 0.7578 - val_loss: 2.2664 - val_accuracy: 0.6861\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1574 - accuracy: 0.7560 - val_loss: 2.2901 - val_accuracy: 0.6815\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1756 - accuracy: 0.7594 - val_loss: 2.3816 - val_accuracy: 0.6764\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1962 - accuracy: 0.7619 - val_loss: 2.3128 - val_accuracy: 0.6908\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2067 - accuracy: 0.7563 - val_loss: 2.2246 - val_accuracy: 0.6984\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2080 - accuracy: 0.7618 - val_loss: 2.4865 - val_accuracy: 0.6954\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.2200 - accuracy: 0.7637 - val_loss: 2.2633 - val_accuracy: 0.6952\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2277 - accuracy: 0.7584 - val_loss: 2.2608 - val_accuracy: 0.6936\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1786 - accuracy: 0.7596 - val_loss: 2.2722 - val_accuracy: 0.7029\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1597 - accuracy: 0.7544 - val_loss: 2.3551 - val_accuracy: 0.6957\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1467 - accuracy: 0.7588 - val_loss: 2.2864 - val_accuracy: 0.6914\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1489 - accuracy: 0.7586 - val_loss: 2.4056 - val_accuracy: 0.7095\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1494 - accuracy: 0.7563 - val_loss: 2.2489 - val_accuracy: 0.6873\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1412 - accuracy: 0.7615 - val_loss: 2.3201 - val_accuracy: 0.7012\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.1482 - accuracy: 0.7587 - val_loss: 2.2797 - val_accuracy: 0.6912\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1517 - accuracy: 0.7594 - val_loss: 2.2905 - val_accuracy: 0.6995\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1391 - accuracy: 0.7633 - val_loss: 2.3049 - val_accuracy: 0.6932\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1387 - accuracy: 0.7613 - val_loss: 2.3605 - val_accuracy: 0.6938\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1429 - accuracy: 0.7611 - val_loss: 2.2497 - val_accuracy: 0.7085\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.1519 - accuracy: 0.7605 - val_loss: 2.2848 - val_accuracy: 0.6927\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1415 - accuracy: 0.7593 - val_loss: 2.2715 - val_accuracy: 0.6845\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1737 - accuracy: 0.7632 - val_loss: 2.2836 - val_accuracy: 0.7036\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1871 - accuracy: 0.7599 - val_loss: 2.3833 - val_accuracy: 0.7067\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.1641 - accuracy: 0.7604 - val_loss: 2.3859 - val_accuracy: 0.6960\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1561 - accuracy: 0.7623 - val_loss: 2.2227 - val_accuracy: 0.6960\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2136 - accuracy: 0.7536 - val_loss: 2.3209 - val_accuracy: 0.7010\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.1617 - accuracy: 0.7646 - val_loss: 2.3254 - val_accuracy: 0.7030\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 7.1567 - accuracy: 0.7599 - val_loss: 2.4018 - val_accuracy: 0.6926\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1837 - accuracy: 0.7624 - val_loss: 2.2715 - val_accuracy: 0.7032\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1404 - accuracy: 0.7584 - val_loss: 2.2770 - val_accuracy: 0.6884\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1552 - accuracy: 0.7614 - val_loss: 2.3954 - val_accuracy: 0.7099\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2025 - accuracy: 0.7632 - val_loss: 2.3350 - val_accuracy: 0.7074\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1523 - accuracy: 0.7614 - val_loss: 2.2565 - val_accuracy: 0.6974\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.1679 - accuracy: 0.7630 - val_loss: 2.2913 - val_accuracy: 0.6994\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1418 - accuracy: 0.7613 - val_loss: 2.2670 - val_accuracy: 0.7066\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1783 - accuracy: 0.7645 - val_loss: 2.4755 - val_accuracy: 0.7020\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2219 - accuracy: 0.7608 - val_loss: 2.2766 - val_accuracy: 0.6945\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.2367 - accuracy: 0.7554 - val_loss: 2.5188 - val_accuracy: 0.6755\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2213 - accuracy: 0.7544 - val_loss: 2.2591 - val_accuracy: 0.6965\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2588 - accuracy: 0.7662 - val_loss: 2.2345 - val_accuracy: 0.6990\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2271 - accuracy: 0.7627 - val_loss: 2.4118 - val_accuracy: 0.7082\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2158 - accuracy: 0.7582 - val_loss: 2.3286 - val_accuracy: 0.6983\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1874 - accuracy: 0.7502 - val_loss: 2.2954 - val_accuracy: 0.7006\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1453 - accuracy: 0.7671 - val_loss: 2.3167 - val_accuracy: 0.7197\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1637 - accuracy: 0.7629 - val_loss: 2.2621 - val_accuracy: 0.7155\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1501 - accuracy: 0.7604 - val_loss: 2.3476 - val_accuracy: 0.7044\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1295 - accuracy: 0.7676 - val_loss: 2.2753 - val_accuracy: 0.7107\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1428 - accuracy: 0.7622 - val_loss: 2.3464 - val_accuracy: 0.7125\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1353 - accuracy: 0.7668 - val_loss: 2.3185 - val_accuracy: 0.7030\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1257 - accuracy: 0.7631 - val_loss: 2.2970 - val_accuracy: 0.6987\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1266 - accuracy: 0.7582 - val_loss: 2.3008 - val_accuracy: 0.7052\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1269 - accuracy: 0.7610 - val_loss: 2.2426 - val_accuracy: 0.6955\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1253 - accuracy: 0.7644 - val_loss: 2.2866 - val_accuracy: 0.6998\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1503 - accuracy: 0.7661 - val_loss: 2.4571 - val_accuracy: 0.6953\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 7.1791 - accuracy: 0.7500 - val_loss: 2.3146 - val_accuracy: 0.6883\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1635 - accuracy: 0.7668 - val_loss: 2.2550 - val_accuracy: 0.6945\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1522 - accuracy: 0.7583 - val_loss: 2.3608 - val_accuracy: 0.7050\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1462 - accuracy: 0.7640 - val_loss: 2.2514 - val_accuracy: 0.6967\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1331 - accuracy: 0.7659 - val_loss: 2.3154 - val_accuracy: 0.6927\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1158 - accuracy: 0.7710 - val_loss: 2.2775 - val_accuracy: 0.6897\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1122 - accuracy: 0.7598 - val_loss: 2.3315 - val_accuracy: 0.7057\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1196 - accuracy: 0.7663 - val_loss: 2.3547 - val_accuracy: 0.6947\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1123 - accuracy: 0.7618 - val_loss: 2.3373 - val_accuracy: 0.6926\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1213 - accuracy: 0.7597 - val_loss: 2.2635 - val_accuracy: 0.7046\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1566 - accuracy: 0.7672 - val_loss: 2.4562 - val_accuracy: 0.6981\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1707 - accuracy: 0.7683 - val_loss: 2.2432 - val_accuracy: 0.6961\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1422 - accuracy: 0.7633 - val_loss: 2.2843 - val_accuracy: 0.7038\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1478 - accuracy: 0.7670 - val_loss: 2.2560 - val_accuracy: 0.7009\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.1450 - accuracy: 0.7617 - val_loss: 2.2884 - val_accuracy: 0.7059\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1195 - accuracy: 0.7641 - val_loss: 2.3531 - val_accuracy: 0.7056\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1079 - accuracy: 0.7652 - val_loss: 2.2970 - val_accuracy: 0.6902\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1216 - accuracy: 0.7588 - val_loss: 2.2447 - val_accuracy: 0.7085\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1437 - accuracy: 0.7709 - val_loss: 2.3640 - val_accuracy: 0.7076\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1322 - accuracy: 0.7542 - val_loss: 2.2690 - val_accuracy: 0.7094\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1432 - accuracy: 0.7691 - val_loss: 2.3541 - val_accuracy: 0.7013\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1669 - accuracy: 0.7529 - val_loss: 2.2869 - val_accuracy: 0.6611\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.1754 - accuracy: 0.7667 - val_loss: 2.3596 - val_accuracy: 0.7046\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1471 - accuracy: 0.7565 - val_loss: 2.2830 - val_accuracy: 0.7088\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1079 - accuracy: 0.7615 - val_loss: 2.3292 - val_accuracy: 0.7073\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0996 - accuracy: 0.7658 - val_loss: 2.2567 - val_accuracy: 0.6996\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0948 - accuracy: 0.7669 - val_loss: 2.3315 - val_accuracy: 0.6973\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.0862 - accuracy: 0.7676 - val_loss: 2.3076 - val_accuracy: 0.6946\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.0883 - accuracy: 0.7654 - val_loss: 2.3259 - val_accuracy: 0.7051\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0909 - accuracy: 0.7706 - val_loss: 2.2762 - val_accuracy: 0.6947\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0955 - accuracy: 0.7677 - val_loss: 2.3319 - val_accuracy: 0.7001\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.0841 - accuracy: 0.7671 - val_loss: 2.2855 - val_accuracy: 0.6977\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0931 - accuracy: 0.7678 - val_loss: 2.3109 - val_accuracy: 0.7009\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1057 - accuracy: 0.7646 - val_loss: 2.2785 - val_accuracy: 0.7031\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 7.1052 - accuracy: 0.7676 - val_loss: 2.3858 - val_accuracy: 0.6921\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1020 - accuracy: 0.7676 - val_loss: 2.2635 - val_accuracy: 0.6883\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0938 - accuracy: 0.7701 - val_loss: 2.2588 - val_accuracy: 0.6947\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0865 - accuracy: 0.7681 - val_loss: 2.2639 - val_accuracy: 0.7003\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1133 - accuracy: 0.7688 - val_loss: 2.2436 - val_accuracy: 0.7025\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0934 - accuracy: 0.7666 - val_loss: 2.2991 - val_accuracy: 0.7083\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0843 - accuracy: 0.7676 - val_loss: 2.2803 - val_accuracy: 0.6916\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0850 - accuracy: 0.7706 - val_loss: 2.2922 - val_accuracy: 0.6864\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0918 - accuracy: 0.7672 - val_loss: 2.3079 - val_accuracy: 0.6947\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0930 - accuracy: 0.7680 - val_loss: 2.3965 - val_accuracy: 0.6873\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1524 - accuracy: 0.7687 - val_loss: 2.3105 - val_accuracy: 0.6932\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1290 - accuracy: 0.7685 - val_loss: 2.2387 - val_accuracy: 0.6890\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1634 - accuracy: 0.7696 - val_loss: 2.3794 - val_accuracy: 0.6965\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.1612 - accuracy: 0.7630 - val_loss: 2.2690 - val_accuracy: 0.6887\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1971 - accuracy: 0.7706 - val_loss: 2.4544 - val_accuracy: 0.7143\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1493 - accuracy: 0.7592 - val_loss: 2.2625 - val_accuracy: 0.6636\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1527 - accuracy: 0.7625 - val_loss: 2.2892 - val_accuracy: 0.6996\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1351 - accuracy: 0.7646 - val_loss: 2.2584 - val_accuracy: 0.7039\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1058 - accuracy: 0.7644 - val_loss: 2.3875 - val_accuracy: 0.7034\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1005 - accuracy: 0.7749 - val_loss: 2.3105 - val_accuracy: 0.6995\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0938 - accuracy: 0.7642 - val_loss: 2.2744 - val_accuracy: 0.7004\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0941 - accuracy: 0.7678 - val_loss: 2.2371 - val_accuracy: 0.6962\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1121 - accuracy: 0.7663 - val_loss: 2.3543 - val_accuracy: 0.7014\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1832 - accuracy: 0.7685 - val_loss: 2.2858 - val_accuracy: 0.6989\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.2619 - accuracy: 0.7624 - val_loss: 2.6194 - val_accuracy: 0.7031\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 66ms/step - loss: 7.1970 - accuracy: 0.7662 - val_loss: 2.2316 - val_accuracy: 0.7047\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.1186 - accuracy: 0.7512 - val_loss: 2.2590 - val_accuracy: 0.6951\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 7.1308 - accuracy: 0.7669 - val_loss: 2.3455 - val_accuracy: 0.6955\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1994 - accuracy: 0.7654 - val_loss: 2.3221 - val_accuracy: 0.6920\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 7.1704 - accuracy: 0.7644 - val_loss: 2.2854 - val_accuracy: 0.6843\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1538 - accuracy: 0.7698 - val_loss: 2.2695 - val_accuracy: 0.6718\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1212 - accuracy: 0.7696 - val_loss: 2.2868 - val_accuracy: 0.6886\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1019 - accuracy: 0.7671 - val_loss: 2.2696 - val_accuracy: 0.6951\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1094 - accuracy: 0.7684 - val_loss: 2.3018 - val_accuracy: 0.6859\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1005 - accuracy: 0.7655 - val_loss: 2.2850 - val_accuracy: 0.6732\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1037 - accuracy: 0.7694 - val_loss: 2.3459 - val_accuracy: 0.6883\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0976 - accuracy: 0.7658 - val_loss: 2.3159 - val_accuracy: 0.6975\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 7.0880 - accuracy: 0.7737 - val_loss: 2.3185 - val_accuracy: 0.6952\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0885 - accuracy: 0.7715 - val_loss: 2.2929 - val_accuracy: 0.6819\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0971 - accuracy: 0.7688 - val_loss: 2.3065 - val_accuracy: 0.6871\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.0810 - accuracy: 0.7695 - val_loss: 2.3020 - val_accuracy: 0.6861\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1123 - accuracy: 0.7708 - val_loss: 2.2601 - val_accuracy: 0.6868\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1290 - accuracy: 0.7662 - val_loss: 2.4319 - val_accuracy: 0.6883\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1304 - accuracy: 0.7667 - val_loss: 2.2617 - val_accuracy: 0.6782\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1158 - accuracy: 0.7666 - val_loss: 2.3674 - val_accuracy: 0.6945\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1249 - accuracy: 0.7691 - val_loss: 2.2450 - val_accuracy: 0.6935\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1571 - accuracy: 0.7704 - val_loss: 2.3590 - val_accuracy: 0.6909\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1485 - accuracy: 0.7649 - val_loss: 2.4035 - val_accuracy: 0.7072\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1517 - accuracy: 0.7676 - val_loss: 2.3436 - val_accuracy: 0.7116\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1278 - accuracy: 0.7649 - val_loss: 2.2805 - val_accuracy: 0.6883\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1054 - accuracy: 0.7693 - val_loss: 2.2792 - val_accuracy: 0.6826\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1526 - accuracy: 0.7635 - val_loss: 2.2790 - val_accuracy: 0.6833\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1654 - accuracy: 0.7678 - val_loss: 2.5185 - val_accuracy: 0.6877\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1515 - accuracy: 0.7674 - val_loss: 2.2779 - val_accuracy: 0.6815\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2686 - accuracy: 0.7690 - val_loss: 2.2449 - val_accuracy: 0.7066\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1630 - accuracy: 0.7733 - val_loss: 2.2860 - val_accuracy: 0.6966\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1419 - accuracy: 0.7735 - val_loss: 2.4882 - val_accuracy: 0.6900\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0989 - accuracy: 0.7686 - val_loss: 2.3452 - val_accuracy: 0.6874\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0917 - accuracy: 0.7728 - val_loss: 2.2124 - val_accuracy: 0.6899\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0977 - accuracy: 0.7687 - val_loss: 2.2834 - val_accuracy: 0.6898\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1081 - accuracy: 0.7716 - val_loss: 2.2862 - val_accuracy: 0.7006\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1137 - accuracy: 0.7728 - val_loss: 2.3931 - val_accuracy: 0.6959\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1196 - accuracy: 0.7722 - val_loss: 2.2775 - val_accuracy: 0.6926\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0835 - accuracy: 0.7685 - val_loss: 2.2709 - val_accuracy: 0.6863\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.0857 - accuracy: 0.7665 - val_loss: 2.3216 - val_accuracy: 0.6860\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0904 - accuracy: 0.7695 - val_loss: 2.2624 - val_accuracy: 0.6847\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0861 - accuracy: 0.7676 - val_loss: 2.3047 - val_accuracy: 0.6855\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.0851 - accuracy: 0.7690 - val_loss: 2.3666 - val_accuracy: 0.6804\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0835 - accuracy: 0.7729 - val_loss: 2.2295 - val_accuracy: 0.6924\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0853 - accuracy: 0.7694 - val_loss: 2.3419 - val_accuracy: 0.7009\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0653 - accuracy: 0.7715 - val_loss: 2.3009 - val_accuracy: 0.6875\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0800 - accuracy: 0.7705 - val_loss: 2.2566 - val_accuracy: 0.6909\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0939 - accuracy: 0.7667 - val_loss: 2.3147 - val_accuracy: 0.6890\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1060 - accuracy: 0.7718 - val_loss: 2.3694 - val_accuracy: 0.6896\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1287 - accuracy: 0.7719 - val_loss: 2.3240 - val_accuracy: 0.6938\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1059 - accuracy: 0.7708 - val_loss: 2.2719 - val_accuracy: 0.6916\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0822 - accuracy: 0.7677 - val_loss: 2.2394 - val_accuracy: 0.6908\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0977 - accuracy: 0.7684 - val_loss: 2.3819 - val_accuracy: 0.6813\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0899 - accuracy: 0.7709 - val_loss: 2.2656 - val_accuracy: 0.6923\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0762 - accuracy: 0.7717 - val_loss: 2.3062 - val_accuracy: 0.6823\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0747 - accuracy: 0.7676 - val_loss: 2.3280 - val_accuracy: 0.6902\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0730 - accuracy: 0.7692 - val_loss: 2.3676 - val_accuracy: 0.6885\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0712 - accuracy: 0.7655 - val_loss: 2.2418 - val_accuracy: 0.6878\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0982 - accuracy: 0.7712 - val_loss: 2.3544 - val_accuracy: 0.6857\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0738 - accuracy: 0.7730 - val_loss: 2.3787 - val_accuracy: 0.6895\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0812 - accuracy: 0.7698 - val_loss: 2.2490 - val_accuracy: 0.6950\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0656 - accuracy: 0.7682 - val_loss: 2.2855 - val_accuracy: 0.6899\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0640 - accuracy: 0.7703 - val_loss: 2.2445 - val_accuracy: 0.6877\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0712 - accuracy: 0.7674 - val_loss: 2.3118 - val_accuracy: 0.6931\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0581 - accuracy: 0.7747 - val_loss: 2.3550 - val_accuracy: 0.6941\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0546 - accuracy: 0.7757 - val_loss: 2.3055 - val_accuracy: 0.6932\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0568 - accuracy: 0.7710 - val_loss: 2.2609 - val_accuracy: 0.6807\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0754 - accuracy: 0.7727 - val_loss: 2.3114 - val_accuracy: 0.6887\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0592 - accuracy: 0.7720 - val_loss: 2.4491 - val_accuracy: 0.6859\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.0728 - accuracy: 0.7729 - val_loss: 2.3293 - val_accuracy: 0.6899\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.0786 - accuracy: 0.7697 - val_loss: 2.2525 - val_accuracy: 0.6808\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1641 - accuracy: 0.7687 - val_loss: 2.3241 - val_accuracy: 0.6971\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 7.1597 - accuracy: 0.7707 - val_loss: 2.3658 - val_accuracy: 0.6675\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1057 - accuracy: 0.7659 - val_loss: 2.4544 - val_accuracy: 0.6807\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 7.1315 - accuracy: 0.7667 - val_loss: 2.3215 - val_accuracy: 0.6746\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1033 - accuracy: 0.7675 - val_loss: 2.2688 - val_accuracy: 0.6867\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1727 - accuracy: 0.7739 - val_loss: 2.8821 - val_accuracy: 0.6965\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 7.2747 - accuracy: 0.7656 - val_loss: 2.2908 - val_accuracy: 0.6935\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.2099 - accuracy: 0.7657 - val_loss: 2.2909 - val_accuracy: 0.7058\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.2173 - accuracy: 0.7693 - val_loss: 2.5810 - val_accuracy: 0.7005\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1678 - accuracy: 0.7635 - val_loss: 2.2926 - val_accuracy: 0.7024\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1005 - accuracy: 0.7645 - val_loss: 2.2794 - val_accuracy: 0.6982\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0972 - accuracy: 0.7646 - val_loss: 2.3122 - val_accuracy: 0.6881\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0981 - accuracy: 0.7717 - val_loss: 2.3793 - val_accuracy: 0.7024\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0860 - accuracy: 0.7710 - val_loss: 2.3157 - val_accuracy: 0.6979\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0775 - accuracy: 0.7717 - val_loss: 2.2815 - val_accuracy: 0.6957\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0505 - accuracy: 0.7739 - val_loss: 2.2731 - val_accuracy: 0.6816\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0651 - accuracy: 0.7726 - val_loss: 2.3037 - val_accuracy: 0.6950\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 7.0785 - accuracy: 0.7701 - val_loss: 2.2809 - val_accuracy: 0.6900\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1094 - accuracy: 0.7724 - val_loss: 2.5726 - val_accuracy: 0.6906\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1583 - accuracy: 0.7665 - val_loss: 2.3056 - val_accuracy: 0.6931\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1544 - accuracy: 0.7718 - val_loss: 2.3709 - val_accuracy: 0.6829\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1280 - accuracy: 0.7689 - val_loss: 2.5971 - val_accuracy: 0.6781\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1343 - accuracy: 0.7718 - val_loss: 2.2753 - val_accuracy: 0.6930\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0859 - accuracy: 0.7664 - val_loss: 2.3067 - val_accuracy: 0.6779\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0777 - accuracy: 0.7725 - val_loss: 2.2835 - val_accuracy: 0.6919\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0597 - accuracy: 0.7724 - val_loss: 2.3743 - val_accuracy: 0.6837\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0694 - accuracy: 0.7721 - val_loss: 2.2958 - val_accuracy: 0.6940\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 7.0351 - accuracy: 0.7682 - val_loss: 2.2769 - val_accuracy: 0.6848\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 7.0307 - accuracy: 0.7700 - val_loss: 2.2979 - val_accuracy: 0.6911\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0323 - accuracy: 0.7738 - val_loss: 2.2863 - val_accuracy: 0.6875\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0307 - accuracy: 0.7717 - val_loss: 2.2804 - val_accuracy: 0.7045\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0320 - accuracy: 0.7732 - val_loss: 2.4001 - val_accuracy: 0.6937\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0408 - accuracy: 0.7738 - val_loss: 2.2755 - val_accuracy: 0.6950\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0411 - accuracy: 0.7720 - val_loss: 2.2593 - val_accuracy: 0.6827\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.0896 - accuracy: 0.7705 - val_loss: 2.3001 - val_accuracy: 0.6907\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1368 - accuracy: 0.7729 - val_loss: 2.6623 - val_accuracy: 0.6938\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.2407 - accuracy: 0.7668 - val_loss: 2.2791 - val_accuracy: 0.6885\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1669 - accuracy: 0.7709 - val_loss: 2.4158 - val_accuracy: 0.6548\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.1809 - accuracy: 0.7543 - val_loss: 2.2665 - val_accuracy: 0.6955\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.2086 - accuracy: 0.7658 - val_loss: 2.3007 - val_accuracy: 0.6597\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1205 - accuracy: 0.7726 - val_loss: 2.3826 - val_accuracy: 0.6960\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.1126 - accuracy: 0.7610 - val_loss: 2.2409 - val_accuracy: 0.6870\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.1810 - accuracy: 0.7718 - val_loss: 2.4469 - val_accuracy: 0.6945\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.1220 - accuracy: 0.7730 - val_loss: 2.3553 - val_accuracy: 0.6868\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 7.0787 - accuracy: 0.7690 - val_loss: 2.2815 - val_accuracy: 0.6930\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.0761 - accuracy: 0.7703 - val_loss: 2.2944 - val_accuracy: 0.6863\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0584 - accuracy: 0.7717 - val_loss: 2.3074 - val_accuracy: 0.6972\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0396 - accuracy: 0.7730 - val_loss: 2.3217 - val_accuracy: 0.6934\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0318 - accuracy: 0.7738 - val_loss: 2.2993 - val_accuracy: 0.6901\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 7.0382 - accuracy: 0.7703 - val_loss: 2.2718 - val_accuracy: 0.6840\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 7.0356 - accuracy: 0.7738 - val_loss: 2.2771 - val_accuracy: 0.6862\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 7.0469 - accuracy: 0.7736 - val_loss: 2.2679 - val_accuracy: 0.6957\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 7.0384 - accuracy: 0.7708 - val_loss: 2.3757 - val_accuracy: 0.6952\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0447 - accuracy: 0.7727 - val_loss: 2.2452 - val_accuracy: 0.6867\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0695 - accuracy: 0.7678 - val_loss: 2.3869 - val_accuracy: 0.6996\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0625 - accuracy: 0.7716 - val_loss: 2.2780 - val_accuracy: 0.6812\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.0589 - accuracy: 0.7705 - val_loss: 2.4075 - val_accuracy: 0.6778\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 7.0517 - accuracy: 0.7678 - val_loss: 2.2529 - val_accuracy: 0.6797\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 7.0436 - accuracy: 0.7719 - val_loss: 2.3781 - val_accuracy: 0.6826\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0397 - accuracy: 0.7710 - val_loss: 2.2710 - val_accuracy: 0.6874\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0472 - accuracy: 0.7712 - val_loss: 2.3205 - val_accuracy: 0.6854\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0402 - accuracy: 0.7680 - val_loss: 2.3720 - val_accuracy: 0.6929\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0469 - accuracy: 0.7745 - val_loss: 2.2764 - val_accuracy: 0.6914\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.0256 - accuracy: 0.7728 - val_loss: 2.3397 - val_accuracy: 0.6841\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 7.0398 - accuracy: 0.7750 - val_loss: 2.2603 - val_accuracy: 0.6829\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.0283 - accuracy: 0.7744 - val_loss: 2.3845 - val_accuracy: 0.6785\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0413 - accuracy: 0.7767 - val_loss: 2.2993 - val_accuracy: 0.6845\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 7.0406 - accuracy: 0.7726 - val_loss: 2.2975 - val_accuracy: 0.6831\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.0619 - accuracy: 0.7698 - val_loss: 2.3359 - val_accuracy: 0.6940\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 7.1162 - accuracy: 0.7748 - val_loss: 2.3941 - val_accuracy: 0.7048\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 7.1442 - accuracy: 0.7665 - val_loss: 2.2723 - val_accuracy: 0.6871\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "# Upsample the second input image\n",
        "upsampled = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Combine the two input images using a convolutional layer\n",
        "combined = layers.Conv2D(31, kernel_size=1, activation='relu')(upsampled)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(combined)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer = layers.Conv2D(31, kernel_size=1, activation='relu')(pool3)\n",
        "# Define the model\n",
        "modelnew = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "# Compile the model\n",
        "modelnew.compile(optimizer='adam',\n",
        "loss='mean_absolute_error',\n",
        "metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = modelnew.fit([a, b], c, epochs=500, batch_size=None, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "ZQFrwzYHc9LK",
        "outputId": "268b5cdf-1215-4aeb-a5ee-f46e2c25fbd8"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# Extract the accuracy and loss values from the history object\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the first graph in the first subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(acc, label='Training accuracy')\n",
        "plt.plot(val_acc, label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Plot the second graph in the second subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOsB-KNBc91c",
        "outputId": "80fa4b96-9325-423f-ac25-ee05171f5b44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 8670.0576 - accuracy: 0.0201 - val_loss: 5416.9541 - val_accuracy: 0.0027\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 6072.5415 - accuracy: 0.0333 - val_loss: 4367.8940 - val_accuracy: 0.0036\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 4640.7524 - accuracy: 0.0238 - val_loss: 3373.9226 - val_accuracy: 0.0045\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 3863.6816 - accuracy: 0.0034 - val_loss: 2537.7271 - val_accuracy: 0.0046\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 3060.4277 - accuracy: 0.0664 - val_loss: 2253.0215 - val_accuracy: 0.0322\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 2716.2256 - accuracy: 0.1877 - val_loss: 1965.8236 - val_accuracy: 0.1806\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 2501.8606 - accuracy: 0.3089 - val_loss: 1809.7433 - val_accuracy: 0.3616\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 2391.6372 - accuracy: 0.3459 - val_loss: 1722.8462 - val_accuracy: 0.5323\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 2286.2905 - accuracy: 0.3667 - val_loss: 1596.7922 - val_accuracy: 0.5307\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 2197.3140 - accuracy: 0.3771 - val_loss: 1534.8091 - val_accuracy: 0.5029\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 2138.3662 - accuracy: 0.3982 - val_loss: 1479.8547 - val_accuracy: 0.5621\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 2078.0876 - accuracy: 0.4080 - val_loss: 1484.8289 - val_accuracy: 0.5725\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 2045.8007 - accuracy: 0.3878 - val_loss: 1411.7010 - val_accuracy: 0.5569\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1998.0251 - accuracy: 0.4137 - val_loss: 1384.2845 - val_accuracy: 0.6064\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1968.8951 - accuracy: 0.4327 - val_loss: 1364.6766 - val_accuracy: 0.5867\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1952.4285 - accuracy: 0.4393 - val_loss: 1344.1183 - val_accuracy: 0.6101\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1927.8311 - accuracy: 0.4274 - val_loss: 1317.0505 - val_accuracy: 0.6415\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1904.3474 - accuracy: 0.4329 - val_loss: 1295.8607 - val_accuracy: 0.6544\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1893.2745 - accuracy: 0.4323 - val_loss: 1262.0551 - val_accuracy: 0.6394\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1708.7952 - accuracy: 0.4326 - val_loss: 1196.4857 - val_accuracy: 0.6185\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1473.7208 - accuracy: 0.5599 - val_loss: 1031.1140 - val_accuracy: 0.6881\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1352.2195 - accuracy: 0.5541 - val_loss: 967.4840 - val_accuracy: 0.6939\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1279.5615 - accuracy: 0.6231 - val_loss: 824.2108 - val_accuracy: 0.7304\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1062.9581 - accuracy: 0.6137 - val_loss: 776.4709 - val_accuracy: 0.7023\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 976.1771 - accuracy: 0.6575 - val_loss: 728.4963 - val_accuracy: 0.7454\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 936.4212 - accuracy: 0.6416 - val_loss: 699.2744 - val_accuracy: 0.7347\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 908.9893 - accuracy: 0.6793 - val_loss: 683.4692 - val_accuracy: 0.7390\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 899.0364 - accuracy: 0.6982 - val_loss: 660.6019 - val_accuracy: 0.7399\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 887.4464 - accuracy: 0.7005 - val_loss: 661.0914 - val_accuracy: 0.7325\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 877.5563 - accuracy: 0.7035 - val_loss: 654.7977 - val_accuracy: 0.7293\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 875.4340 - accuracy: 0.7029 - val_loss: 646.3931 - val_accuracy: 0.7316\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 863.5920 - accuracy: 0.6989 - val_loss: 646.4030 - val_accuracy: 0.7379\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 862.4791 - accuracy: 0.7016 - val_loss: 646.0212 - val_accuracy: 0.7617\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 858.4511 - accuracy: 0.6884 - val_loss: 642.6149 - val_accuracy: 0.7560\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 857.7344 - accuracy: 0.6969 - val_loss: 636.1888 - val_accuracy: 0.7509\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 857.0989 - accuracy: 0.7032 - val_loss: 633.0995 - val_accuracy: 0.7196\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 858.5982 - accuracy: 0.6877 - val_loss: 648.3270 - val_accuracy: 0.7455\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 854.5480 - accuracy: 0.6909 - val_loss: 639.4134 - val_accuracy: 0.7622\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 855.6406 - accuracy: 0.6988 - val_loss: 629.1396 - val_accuracy: 0.7490\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 846.9453 - accuracy: 0.6990 - val_loss: 629.6221 - val_accuracy: 0.7623\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 845.2253 - accuracy: 0.7022 - val_loss: 626.8268 - val_accuracy: 0.7500\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 848.9418 - accuracy: 0.7040 - val_loss: 627.8330 - val_accuracy: 0.7426\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 844.7897 - accuracy: 0.7051 - val_loss: 623.2347 - val_accuracy: 0.7637\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 832.4122 - accuracy: 0.7050 - val_loss: 618.6938 - val_accuracy: 0.7432\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 834.6828 - accuracy: 0.7070 - val_loss: 635.1412 - val_accuracy: 0.7585\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 848.8167 - accuracy: 0.7003 - val_loss: 629.0389 - val_accuracy: 0.7602\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 832.7226 - accuracy: 0.7044 - val_loss: 619.6960 - val_accuracy: 0.7644\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 837.2673 - accuracy: 0.7066 - val_loss: 620.9962 - val_accuracy: 0.7570\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 833.0997 - accuracy: 0.7113 - val_loss: 631.4440 - val_accuracy: 0.7648\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 829.6509 - accuracy: 0.7081 - val_loss: 619.2751 - val_accuracy: 0.7560\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 825.8532 - accuracy: 0.7145 - val_loss: 613.7883 - val_accuracy: 0.7575\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 821.8668 - accuracy: 0.7063 - val_loss: 620.2513 - val_accuracy: 0.7616\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 821.6484 - accuracy: 0.7104 - val_loss: 610.6954 - val_accuracy: 0.7583\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 831.7573 - accuracy: 0.7078 - val_loss: 690.1864 - val_accuracy: 0.7636\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 851.0656 - accuracy: 0.7138 - val_loss: 618.2593 - val_accuracy: 0.7602\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 831.0880 - accuracy: 0.7143 - val_loss: 622.4561 - val_accuracy: 0.7296\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 825.9422 - accuracy: 0.7092 - val_loss: 615.3525 - val_accuracy: 0.7630\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 830.6780 - accuracy: 0.7153 - val_loss: 637.1711 - val_accuracy: 0.7717\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 819.6341 - accuracy: 0.7157 - val_loss: 611.3389 - val_accuracy: 0.7614\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 813.5117 - accuracy: 0.7128 - val_loss: 608.8521 - val_accuracy: 0.7525\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 811.2958 - accuracy: 0.7137 - val_loss: 610.0468 - val_accuracy: 0.7545\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 814.6221 - accuracy: 0.7189 - val_loss: 608.0027 - val_accuracy: 0.7572\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 817.1314 - accuracy: 0.7147 - val_loss: 606.7636 - val_accuracy: 0.7653\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 809.7198 - accuracy: 0.7214 - val_loss: 606.6585 - val_accuracy: 0.7668\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 811.7631 - accuracy: 0.7206 - val_loss: 611.9612 - val_accuracy: 0.7684\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 808.3376 - accuracy: 0.7181 - val_loss: 609.5520 - val_accuracy: 0.7706\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 816.8428 - accuracy: 0.7180 - val_loss: 610.7805 - val_accuracy: 0.7693\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 814.1032 - accuracy: 0.7152 - val_loss: 605.4586 - val_accuracy: 0.7722\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 808.7811 - accuracy: 0.7195 - val_loss: 602.7296 - val_accuracy: 0.7746\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 804.6707 - accuracy: 0.7201 - val_loss: 601.1746 - val_accuracy: 0.7794\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 800.2064 - accuracy: 0.7218 - val_loss: 607.2418 - val_accuracy: 0.7701\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 804.9052 - accuracy: 0.7265 - val_loss: 603.4666 - val_accuracy: 0.7655\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 803.4387 - accuracy: 0.7172 - val_loss: 604.1995 - val_accuracy: 0.7717\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 803.2421 - accuracy: 0.7256 - val_loss: 601.4792 - val_accuracy: 0.7770\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 804.0558 - accuracy: 0.7298 - val_loss: 598.6666 - val_accuracy: 0.7740\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 803.3168 - accuracy: 0.7266 - val_loss: 600.7192 - val_accuracy: 0.7534\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 800.2706 - accuracy: 0.7187 - val_loss: 598.0952 - val_accuracy: 0.7693\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 805.1689 - accuracy: 0.7195 - val_loss: 610.5557 - val_accuracy: 0.7738\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 800.6385 - accuracy: 0.7300 - val_loss: 597.3409 - val_accuracy: 0.7789\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 795.0909 - accuracy: 0.7278 - val_loss: 597.0710 - val_accuracy: 0.7704\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 793.5707 - accuracy: 0.7299 - val_loss: 597.2278 - val_accuracy: 0.7764\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 793.5909 - accuracy: 0.7222 - val_loss: 601.2619 - val_accuracy: 0.7705\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 795.7181 - accuracy: 0.7314 - val_loss: 594.8876 - val_accuracy: 0.7773\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 790.8035 - accuracy: 0.7294 - val_loss: 597.5995 - val_accuracy: 0.7736\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 790.5783 - accuracy: 0.7251 - val_loss: 597.8365 - val_accuracy: 0.7743\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 793.5618 - accuracy: 0.7338 - val_loss: 595.5018 - val_accuracy: 0.7766\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 790.3376 - accuracy: 0.7325 - val_loss: 617.6030 - val_accuracy: 0.7735\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 797.6092 - accuracy: 0.7237 - val_loss: 594.9448 - val_accuracy: 0.7748\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 789.4249 - accuracy: 0.7256 - val_loss: 595.7471 - val_accuracy: 0.7740\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 786.8220 - accuracy: 0.7332 - val_loss: 592.3354 - val_accuracy: 0.7741\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 785.5989 - accuracy: 0.7281 - val_loss: 593.8071 - val_accuracy: 0.7738\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 788.5115 - accuracy: 0.7340 - val_loss: 592.9433 - val_accuracy: 0.7749\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 786.6813 - accuracy: 0.7327 - val_loss: 594.4568 - val_accuracy: 0.7748\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 785.3143 - accuracy: 0.7364 - val_loss: 597.8749 - val_accuracy: 0.7809\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 790.8851 - accuracy: 0.7375 - val_loss: 593.7827 - val_accuracy: 0.7774\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 791.1820 - accuracy: 0.7389 - val_loss: 590.3549 - val_accuracy: 0.7741\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 787.6915 - accuracy: 0.7339 - val_loss: 595.0807 - val_accuracy: 0.7862\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 785.3292 - accuracy: 0.7423 - val_loss: 605.0954 - val_accuracy: 0.7768\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 785.2942 - accuracy: 0.7378 - val_loss: 590.3932 - val_accuracy: 0.7729\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 780.6195 - accuracy: 0.7377 - val_loss: 594.3115 - val_accuracy: 0.7759\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 788.0115 - accuracy: 0.7382 - val_loss: 590.3163 - val_accuracy: 0.7822\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 782.1212 - accuracy: 0.7308 - val_loss: 590.2293 - val_accuracy: 0.7836\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 778.3885 - accuracy: 0.7349 - val_loss: 587.3712 - val_accuracy: 0.7727\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 779.0082 - accuracy: 0.7374 - val_loss: 594.0615 - val_accuracy: 0.7804\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 784.6209 - accuracy: 0.7207 - val_loss: 594.3368 - val_accuracy: 0.7764\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 778.7595 - accuracy: 0.7351 - val_loss: 590.5277 - val_accuracy: 0.7846\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 782.0032 - accuracy: 0.7400 - val_loss: 590.7002 - val_accuracy: 0.7803\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 782.2103 - accuracy: 0.7390 - val_loss: 596.1285 - val_accuracy: 0.7824\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 785.9188 - accuracy: 0.7390 - val_loss: 586.5414 - val_accuracy: 0.7838\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 776.9319 - accuracy: 0.7388 - val_loss: 587.7833 - val_accuracy: 0.7894\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 775.0709 - accuracy: 0.7403 - val_loss: 590.8345 - val_accuracy: 0.7761\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 775.7996 - accuracy: 0.7400 - val_loss: 584.7620 - val_accuracy: 0.7892\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 775.3837 - accuracy: 0.7435 - val_loss: 588.5045 - val_accuracy: 0.7875\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 773.0292 - accuracy: 0.7415 - val_loss: 589.3326 - val_accuracy: 0.7899\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 775.6908 - accuracy: 0.7386 - val_loss: 593.1082 - val_accuracy: 0.7828\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 776.4001 - accuracy: 0.7386 - val_loss: 585.8123 - val_accuracy: 0.7814\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 773.1740 - accuracy: 0.7451 - val_loss: 586.9768 - val_accuracy: 0.7870\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 777.1660 - accuracy: 0.7425 - val_loss: 587.7442 - val_accuracy: 0.7885\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 781.9367 - accuracy: 0.7420 - val_loss: 583.6751 - val_accuracy: 0.7903\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 779.3127 - accuracy: 0.7467 - val_loss: 589.3462 - val_accuracy: 0.7886\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 773.7589 - accuracy: 0.7405 - val_loss: 589.7229 - val_accuracy: 0.7910\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 770.3482 - accuracy: 0.7476 - val_loss: 585.5240 - val_accuracy: 0.7944\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 774.0720 - accuracy: 0.7442 - val_loss: 584.6212 - val_accuracy: 0.7851\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 791.0171 - accuracy: 0.7414 - val_loss: 630.7696 - val_accuracy: 0.7946\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 809.2704 - accuracy: 0.7443 - val_loss: 589.7394 - val_accuracy: 0.7842\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 779.3793 - accuracy: 0.7446 - val_loss: 584.8363 - val_accuracy: 0.7835\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 770.3443 - accuracy: 0.7387 - val_loss: 583.6453 - val_accuracy: 0.7965\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 766.4167 - accuracy: 0.7392 - val_loss: 582.8775 - val_accuracy: 0.7883\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 766.9975 - accuracy: 0.7466 - val_loss: 581.1721 - val_accuracy: 0.7862\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 766.1523 - accuracy: 0.7468 - val_loss: 584.6168 - val_accuracy: 0.7970\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 765.6772 - accuracy: 0.7481 - val_loss: 586.2203 - val_accuracy: 0.7949\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 767.8292 - accuracy: 0.7463 - val_loss: 580.6609 - val_accuracy: 0.7934\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 767.7663 - accuracy: 0.7478 - val_loss: 591.2469 - val_accuracy: 0.7953\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 772.6038 - accuracy: 0.7484 - val_loss: 582.3607 - val_accuracy: 0.7894\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 766.1295 - accuracy: 0.7466 - val_loss: 579.5906 - val_accuracy: 0.7968\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 775.7480 - accuracy: 0.7441 - val_loss: 621.7606 - val_accuracy: 0.7966\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 802.9365 - accuracy: 0.7447 - val_loss: 591.7003 - val_accuracy: 0.7977\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 789.0630 - accuracy: 0.7465 - val_loss: 605.4525 - val_accuracy: 0.7928\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 770.8331 - accuracy: 0.7411 - val_loss: 591.1390 - val_accuracy: 0.8004\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 768.5884 - accuracy: 0.7437 - val_loss: 578.3318 - val_accuracy: 0.7960\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 762.2126 - accuracy: 0.7496 - val_loss: 581.2806 - val_accuracy: 0.7969\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 759.5660 - accuracy: 0.7485 - val_loss: 580.9713 - val_accuracy: 0.7959\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 762.9639 - accuracy: 0.7451 - val_loss: 580.0733 - val_accuracy: 0.7926\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 762.0972 - accuracy: 0.7468 - val_loss: 578.4125 - val_accuracy: 0.7933\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 760.4640 - accuracy: 0.7453 - val_loss: 580.1248 - val_accuracy: 0.7872\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 760.5531 - accuracy: 0.7414 - val_loss: 578.4356 - val_accuracy: 0.7955\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 759.0559 - accuracy: 0.7473 - val_loss: 578.8155 - val_accuracy: 0.7892\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 759.3923 - accuracy: 0.7483 - val_loss: 580.0313 - val_accuracy: 0.7936\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 760.1768 - accuracy: 0.7507 - val_loss: 576.6130 - val_accuracy: 0.7941\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 760.9552 - accuracy: 0.7519 - val_loss: 608.7777 - val_accuracy: 0.7946\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 788.5364 - accuracy: 0.7513 - val_loss: 584.5951 - val_accuracy: 0.7936\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 780.7128 - accuracy: 0.7374 - val_loss: 584.1427 - val_accuracy: 0.7962\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 775.6644 - accuracy: 0.7437 - val_loss: 582.1768 - val_accuracy: 0.7928\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 774.3267 - accuracy: 0.7389 - val_loss: 584.5849 - val_accuracy: 0.8022\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 762.9104 - accuracy: 0.7476 - val_loss: 578.6166 - val_accuracy: 0.7958\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 761.0182 - accuracy: 0.7484 - val_loss: 588.4465 - val_accuracy: 0.7911\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 760.7280 - accuracy: 0.7521 - val_loss: 577.0960 - val_accuracy: 0.7942\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 756.4134 - accuracy: 0.7515 - val_loss: 580.5232 - val_accuracy: 0.7925\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 758.4768 - accuracy: 0.7504 - val_loss: 582.5234 - val_accuracy: 0.8001\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 757.2753 - accuracy: 0.7461 - val_loss: 573.5446 - val_accuracy: 0.7948\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 752.9451 - accuracy: 0.7549 - val_loss: 574.0148 - val_accuracy: 0.7968\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 753.6153 - accuracy: 0.7522 - val_loss: 576.7819 - val_accuracy: 0.7931\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 753.3641 - accuracy: 0.7527 - val_loss: 577.2159 - val_accuracy: 0.7939\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 756.6967 - accuracy: 0.7516 - val_loss: 573.6643 - val_accuracy: 0.7914\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 754.7856 - accuracy: 0.7515 - val_loss: 574.8412 - val_accuracy: 0.7962\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 753.1212 - accuracy: 0.7505 - val_loss: 574.1425 - val_accuracy: 0.7903\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 751.0602 - accuracy: 0.7536 - val_loss: 575.2941 - val_accuracy: 0.7957\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 753.2981 - accuracy: 0.7488 - val_loss: 572.9160 - val_accuracy: 0.7955\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 752.0675 - accuracy: 0.7506 - val_loss: 576.2717 - val_accuracy: 0.7866\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 754.4993 - accuracy: 0.7498 - val_loss: 576.0107 - val_accuracy: 0.7867\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 755.1330 - accuracy: 0.7495 - val_loss: 579.7069 - val_accuracy: 0.7922\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 754.4704 - accuracy: 0.7486 - val_loss: 575.7532 - val_accuracy: 0.7889\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 753.1278 - accuracy: 0.7528 - val_loss: 574.8154 - val_accuracy: 0.7933\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 753.0845 - accuracy: 0.7532 - val_loss: 571.1339 - val_accuracy: 0.7891\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.1512 - accuracy: 0.7541 - val_loss: 575.5848 - val_accuracy: 0.7951\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 749.4481 - accuracy: 0.7540 - val_loss: 572.4786 - val_accuracy: 0.7990\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 749.0709 - accuracy: 0.7522 - val_loss: 573.3177 - val_accuracy: 0.7956\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 751.1718 - accuracy: 0.7541 - val_loss: 574.6557 - val_accuracy: 0.8004\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 752.1102 - accuracy: 0.7530 - val_loss: 572.8863 - val_accuracy: 0.7983\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 749.3182 - accuracy: 0.7554 - val_loss: 577.7823 - val_accuracy: 0.7949\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 749.8156 - accuracy: 0.7508 - val_loss: 573.4977 - val_accuracy: 0.7946\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 748.5872 - accuracy: 0.7517 - val_loss: 572.2876 - val_accuracy: 0.7950\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 748.5648 - accuracy: 0.7524 - val_loss: 573.8660 - val_accuracy: 0.7952\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 749.5132 - accuracy: 0.7528 - val_loss: 576.2435 - val_accuracy: 0.7974\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 751.1114 - accuracy: 0.7577 - val_loss: 581.9596 - val_accuracy: 0.7898\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 751.5689 - accuracy: 0.7509 - val_loss: 572.9227 - val_accuracy: 0.7965\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 750.9179 - accuracy: 0.7554 - val_loss: 577.7584 - val_accuracy: 0.7898\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 747.5878 - accuracy: 0.7500 - val_loss: 568.8211 - val_accuracy: 0.7958\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 747.3375 - accuracy: 0.7574 - val_loss: 579.9400 - val_accuracy: 0.7815\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 751.5097 - accuracy: 0.7540 - val_loss: 570.1011 - val_accuracy: 0.8013\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.2841 - accuracy: 0.7504 - val_loss: 569.7990 - val_accuracy: 0.7842\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 746.5408 - accuracy: 0.7565 - val_loss: 573.6661 - val_accuracy: 0.8005\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.4017 - accuracy: 0.7508 - val_loss: 577.2167 - val_accuracy: 0.7956\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 745.7606 - accuracy: 0.7564 - val_loss: 567.9084 - val_accuracy: 0.7929\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 747.9794 - accuracy: 0.7542 - val_loss: 572.0062 - val_accuracy: 0.8004\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 743.4734 - accuracy: 0.7580 - val_loss: 573.8382 - val_accuracy: 0.7865\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 747.2992 - accuracy: 0.7511 - val_loss: 581.3707 - val_accuracy: 0.7792\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 759.6941 - accuracy: 0.7485 - val_loss: 584.4798 - val_accuracy: 0.7948\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 748.8861 - accuracy: 0.7553 - val_loss: 567.8993 - val_accuracy: 0.7910\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 741.6610 - accuracy: 0.7555 - val_loss: 569.0074 - val_accuracy: 0.7921\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 741.4108 - accuracy: 0.7573 - val_loss: 568.3640 - val_accuracy: 0.7886\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.9591 - accuracy: 0.7573 - val_loss: 565.3500 - val_accuracy: 0.7869\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 739.3701 - accuracy: 0.7518 - val_loss: 567.4229 - val_accuracy: 0.7932\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.8633 - accuracy: 0.7564 - val_loss: 566.3400 - val_accuracy: 0.7956\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 741.4495 - accuracy: 0.7542 - val_loss: 568.3093 - val_accuracy: 0.7953\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 742.1182 - accuracy: 0.7591 - val_loss: 565.4414 - val_accuracy: 0.7885\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 739.6675 - accuracy: 0.7566 - val_loss: 567.0693 - val_accuracy: 0.7957\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 744.2911 - accuracy: 0.7574 - val_loss: 571.1578 - val_accuracy: 0.7868\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 742.8468 - accuracy: 0.7552 - val_loss: 569.9815 - val_accuracy: 0.7991\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 747.9525 - accuracy: 0.7543 - val_loss: 583.9362 - val_accuracy: 0.7947\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 746.5804 - accuracy: 0.7546 - val_loss: 569.7584 - val_accuracy: 0.7948\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 742.2632 - accuracy: 0.7533 - val_loss: 565.9838 - val_accuracy: 0.7888\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 741.8163 - accuracy: 0.7570 - val_loss: 567.1071 - val_accuracy: 0.7962\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.6923 - accuracy: 0.7548 - val_loss: 579.0447 - val_accuracy: 0.7911\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 749.4700 - accuracy: 0.7544 - val_loss: 567.8375 - val_accuracy: 0.7978\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 756.4334 - accuracy: 0.7527 - val_loss: 577.2916 - val_accuracy: 0.7810\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 742.9614 - accuracy: 0.7541 - val_loss: 567.4209 - val_accuracy: 0.7990\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.8734 - accuracy: 0.7582 - val_loss: 574.0670 - val_accuracy: 0.7987\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 744.2377 - accuracy: 0.7587 - val_loss: 567.0032 - val_accuracy: 0.7958\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 753.6034 - accuracy: 0.7582 - val_loss: 595.4719 - val_accuracy: 0.7714\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 759.5026 - accuracy: 0.7587 - val_loss: 567.1531 - val_accuracy: 0.7920\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.9691 - accuracy: 0.7546 - val_loss: 572.9504 - val_accuracy: 0.7903\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 754.3653 - accuracy: 0.7566 - val_loss: 585.9163 - val_accuracy: 0.7853\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 748.4558 - accuracy: 0.7570 - val_loss: 564.6578 - val_accuracy: 0.7917\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 738.7715 - accuracy: 0.7550 - val_loss: 566.5442 - val_accuracy: 0.7876\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 737.4802 - accuracy: 0.7572 - val_loss: 567.6192 - val_accuracy: 0.7956\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 738.1606 - accuracy: 0.7585 - val_loss: 571.0101 - val_accuracy: 0.7942\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.2292 - accuracy: 0.7538 - val_loss: 564.8019 - val_accuracy: 0.7763\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 736.7899 - accuracy: 0.7604 - val_loss: 564.4546 - val_accuracy: 0.7981\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 733.8528 - accuracy: 0.7565 - val_loss: 562.2789 - val_accuracy: 0.7913\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.8506 - accuracy: 0.7609 - val_loss: 564.7028 - val_accuracy: 0.7988\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 734.5361 - accuracy: 0.7591 - val_loss: 567.6048 - val_accuracy: 0.7940\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 738.1646 - accuracy: 0.7612 - val_loss: 568.4209 - val_accuracy: 0.7921\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 741.2596 - accuracy: 0.7550 - val_loss: 565.0725 - val_accuracy: 0.7900\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.2309 - accuracy: 0.7561 - val_loss: 568.7856 - val_accuracy: 0.7878\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 736.9431 - accuracy: 0.7566 - val_loss: 566.4775 - val_accuracy: 0.7885\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.4642 - accuracy: 0.7603 - val_loss: 563.7483 - val_accuracy: 0.7987\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 733.8375 - accuracy: 0.7600 - val_loss: 564.9531 - val_accuracy: 0.7944\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 733.7567 - accuracy: 0.7608 - val_loss: 562.1513 - val_accuracy: 0.7954\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.7527 - accuracy: 0.7610 - val_loss: 569.2300 - val_accuracy: 0.7910\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.7239 - accuracy: 0.7600 - val_loss: 566.0125 - val_accuracy: 0.7844\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 736.5066 - accuracy: 0.7606 - val_loss: 565.5693 - val_accuracy: 0.7885\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 742.0142 - accuracy: 0.7570 - val_loss: 589.0737 - val_accuracy: 0.7877\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 744.8187 - accuracy: 0.7592 - val_loss: 573.9550 - val_accuracy: 0.7876\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 736.4526 - accuracy: 0.7610 - val_loss: 564.6506 - val_accuracy: 0.7876\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.6530 - accuracy: 0.7587 - val_loss: 561.9229 - val_accuracy: 0.7885\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.7037 - accuracy: 0.7597 - val_loss: 562.0956 - val_accuracy: 0.7980\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.2521 - accuracy: 0.7592 - val_loss: 562.8370 - val_accuracy: 0.7988\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 731.9502 - accuracy: 0.7610 - val_loss: 563.9955 - val_accuracy: 0.7933\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.6570 - accuracy: 0.7628 - val_loss: 580.6281 - val_accuracy: 0.7945\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.8430 - accuracy: 0.7567 - val_loss: 564.8330 - val_accuracy: 0.7933\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 736.2589 - accuracy: 0.7616 - val_loss: 560.7911 - val_accuracy: 0.7850\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.6990 - accuracy: 0.7609 - val_loss: 567.2220 - val_accuracy: 0.7988\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 734.1388 - accuracy: 0.7554 - val_loss: 562.8121 - val_accuracy: 0.7951\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 733.6411 - accuracy: 0.7597 - val_loss: 561.6714 - val_accuracy: 0.7983\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.0825 - accuracy: 0.7550 - val_loss: 562.1348 - val_accuracy: 0.7986\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 732.2648 - accuracy: 0.7621 - val_loss: 559.9926 - val_accuracy: 0.7971\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.9189 - accuracy: 0.7619 - val_loss: 565.4597 - val_accuracy: 0.7933\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.9365 - accuracy: 0.7602 - val_loss: 567.1742 - val_accuracy: 0.7933\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 731.2987 - accuracy: 0.7627 - val_loss: 568.3153 - val_accuracy: 0.7950\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 736.6135 - accuracy: 0.7617 - val_loss: 565.8060 - val_accuracy: 0.7948\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.2148 - accuracy: 0.7605 - val_loss: 561.0715 - val_accuracy: 0.7931\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 730.1908 - accuracy: 0.7578 - val_loss: 560.1892 - val_accuracy: 0.7841\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.5861 - accuracy: 0.7608 - val_loss: 561.0748 - val_accuracy: 0.7981\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.8970 - accuracy: 0.7624 - val_loss: 574.8895 - val_accuracy: 0.7955\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 747.6770 - accuracy: 0.7587 - val_loss: 566.8781 - val_accuracy: 0.7918\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 760.6044 - accuracy: 0.7565 - val_loss: 621.9604 - val_accuracy: 0.7853\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 758.9252 - accuracy: 0.7575 - val_loss: 597.6604 - val_accuracy: 0.7849\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 757.6718 - accuracy: 0.7551 - val_loss: 566.1896 - val_accuracy: 0.7966\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 734.2979 - accuracy: 0.7551 - val_loss: 572.3202 - val_accuracy: 0.8005\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.9764 - accuracy: 0.7619 - val_loss: 559.1880 - val_accuracy: 0.7997\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.4000 - accuracy: 0.7638 - val_loss: 558.5751 - val_accuracy: 0.7976\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.4371 - accuracy: 0.7630 - val_loss: 557.9662 - val_accuracy: 0.7891\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 732.9179 - accuracy: 0.7594 - val_loss: 568.8173 - val_accuracy: 0.7946\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 739.0969 - accuracy: 0.7559 - val_loss: 593.7931 - val_accuracy: 0.7993\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 749.5806 - accuracy: 0.7594 - val_loss: 561.6827 - val_accuracy: 0.7934\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 741.9909 - accuracy: 0.7586 - val_loss: 565.8906 - val_accuracy: 0.7892\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 735.2003 - accuracy: 0.7582 - val_loss: 560.4260 - val_accuracy: 0.8005\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.2286 - accuracy: 0.7623 - val_loss: 570.9894 - val_accuracy: 0.7833\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 738.2277 - accuracy: 0.7555 - val_loss: 561.0284 - val_accuracy: 0.8048\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 731.8354 - accuracy: 0.7606 - val_loss: 568.7112 - val_accuracy: 0.7869\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.7141 - accuracy: 0.7601 - val_loss: 564.6520 - val_accuracy: 0.7991\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 737.4169 - accuracy: 0.7609 - val_loss: 559.2843 - val_accuracy: 0.7931\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 739.8090 - accuracy: 0.7616 - val_loss: 561.7797 - val_accuracy: 0.7950\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 746.9011 - accuracy: 0.7613 - val_loss: 569.6000 - val_accuracy: 0.7889\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 738.1486 - accuracy: 0.7565 - val_loss: 560.4930 - val_accuracy: 0.7965\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.4915 - accuracy: 0.7622 - val_loss: 588.0284 - val_accuracy: 0.8059\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.7498 - accuracy: 0.7601 - val_loss: 557.8852 - val_accuracy: 0.7984\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 734.5327 - accuracy: 0.7632 - val_loss: 563.7057 - val_accuracy: 0.7980\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.0002 - accuracy: 0.7628 - val_loss: 563.6398 - val_accuracy: 0.7995\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.6713 - accuracy: 0.7629 - val_loss: 570.7253 - val_accuracy: 0.7975\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 735.9609 - accuracy: 0.7638 - val_loss: 558.3063 - val_accuracy: 0.7969\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.9056 - accuracy: 0.7607 - val_loss: 557.8187 - val_accuracy: 0.7996\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 729.1258 - accuracy: 0.7633 - val_loss: 556.9221 - val_accuracy: 0.7950\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.7302 - accuracy: 0.7632 - val_loss: 556.9443 - val_accuracy: 0.7992\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 727.1158 - accuracy: 0.7639 - val_loss: 559.4186 - val_accuracy: 0.7956\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 727.4126 - accuracy: 0.7647 - val_loss: 555.9855 - val_accuracy: 0.8029\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.4030 - accuracy: 0.7639 - val_loss: 563.3395 - val_accuracy: 0.7987\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.7587 - accuracy: 0.7659 - val_loss: 582.9597 - val_accuracy: 0.7860\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 747.1080 - accuracy: 0.7595 - val_loss: 586.0318 - val_accuracy: 0.8061\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 747.1140 - accuracy: 0.7569 - val_loss: 566.9502 - val_accuracy: 0.7815\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 740.3047 - accuracy: 0.7618 - val_loss: 561.0714 - val_accuracy: 0.8069\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 736.7015 - accuracy: 0.7607 - val_loss: 576.2007 - val_accuracy: 0.8022\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 743.2311 - accuracy: 0.7622 - val_loss: 565.1873 - val_accuracy: 0.7998\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.8287 - accuracy: 0.7617 - val_loss: 557.3344 - val_accuracy: 0.8005\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 738.0303 - accuracy: 0.7612 - val_loss: 562.3216 - val_accuracy: 0.8005\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 731.5674 - accuracy: 0.7641 - val_loss: 556.4410 - val_accuracy: 0.7960\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 727.4389 - accuracy: 0.7617 - val_loss: 562.6286 - val_accuracy: 0.7973\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.4410 - accuracy: 0.7661 - val_loss: 562.6851 - val_accuracy: 0.8010\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.4365 - accuracy: 0.7651 - val_loss: 554.8713 - val_accuracy: 0.8026\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 729.1934 - accuracy: 0.7669 - val_loss: 561.0531 - val_accuracy: 0.8006\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.5828 - accuracy: 0.7637 - val_loss: 559.0562 - val_accuracy: 0.7891\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.4794 - accuracy: 0.7595 - val_loss: 560.9590 - val_accuracy: 0.8014\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.4759 - accuracy: 0.7637 - val_loss: 557.3723 - val_accuracy: 0.8028\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 726.3634 - accuracy: 0.7634 - val_loss: 557.5358 - val_accuracy: 0.8040\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.7215 - accuracy: 0.7655 - val_loss: 555.9274 - val_accuracy: 0.8020\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.3705 - accuracy: 0.7683 - val_loss: 561.0595 - val_accuracy: 0.8026\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.6325 - accuracy: 0.7637 - val_loss: 556.4929 - val_accuracy: 0.8042\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.6176 - accuracy: 0.7665 - val_loss: 555.9984 - val_accuracy: 0.8036\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.5890 - accuracy: 0.7654 - val_loss: 563.6082 - val_accuracy: 0.8007\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 727.7270 - accuracy: 0.7665 - val_loss: 558.6074 - val_accuracy: 0.8017\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.7766 - accuracy: 0.7677 - val_loss: 560.7745 - val_accuracy: 0.7982\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.5630 - accuracy: 0.7620 - val_loss: 556.0597 - val_accuracy: 0.7997\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 726.8478 - accuracy: 0.7661 - val_loss: 561.4268 - val_accuracy: 0.8005\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.5168 - accuracy: 0.7656 - val_loss: 556.3527 - val_accuracy: 0.8078\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.8739 - accuracy: 0.7660 - val_loss: 557.5856 - val_accuracy: 0.8016\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 726.6656 - accuracy: 0.7682 - val_loss: 554.8427 - val_accuracy: 0.8017\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.5872 - accuracy: 0.7663 - val_loss: 557.6454 - val_accuracy: 0.7989\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.7254 - accuracy: 0.7644 - val_loss: 555.3787 - val_accuracy: 0.8065\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 733.0331 - accuracy: 0.7641 - val_loss: 564.0986 - val_accuracy: 0.8050\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 737.1108 - accuracy: 0.7625 - val_loss: 565.5773 - val_accuracy: 0.8018\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 737.3889 - accuracy: 0.7635 - val_loss: 558.9159 - val_accuracy: 0.8005\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 741.7411 - accuracy: 0.7569 - val_loss: 568.5991 - val_accuracy: 0.8054\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.3519 - accuracy: 0.7639 - val_loss: 565.3312 - val_accuracy: 0.8075\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 729.6723 - accuracy: 0.7654 - val_loss: 559.5082 - val_accuracy: 0.8102\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.5047 - accuracy: 0.7669 - val_loss: 558.4781 - val_accuracy: 0.8054\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.4326 - accuracy: 0.7621 - val_loss: 557.5337 - val_accuracy: 0.8078\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 727.3016 - accuracy: 0.7667 - val_loss: 559.3836 - val_accuracy: 0.8054\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.2153 - accuracy: 0.7644 - val_loss: 555.9155 - val_accuracy: 0.8081\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.2445 - accuracy: 0.7669 - val_loss: 554.9561 - val_accuracy: 0.8048\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 724.5400 - accuracy: 0.7689 - val_loss: 554.8339 - val_accuracy: 0.8066\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.8588 - accuracy: 0.7669 - val_loss: 560.0115 - val_accuracy: 0.8047\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 731.6045 - accuracy: 0.7664 - val_loss: 554.2318 - val_accuracy: 0.8052\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 725.3747 - accuracy: 0.7703 - val_loss: 556.3860 - val_accuracy: 0.8057\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 724.7754 - accuracy: 0.7681 - val_loss: 556.0209 - val_accuracy: 0.8039\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.3054 - accuracy: 0.7682 - val_loss: 561.8318 - val_accuracy: 0.8054\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 732.0752 - accuracy: 0.7675 - val_loss: 554.6266 - val_accuracy: 0.8030\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 729.8277 - accuracy: 0.7628 - val_loss: 576.2711 - val_accuracy: 0.8068\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 729.1396 - accuracy: 0.7666 - val_loss: 553.5433 - val_accuracy: 0.8060\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 722.9595 - accuracy: 0.7688 - val_loss: 554.2355 - val_accuracy: 0.8008\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.5309 - accuracy: 0.7681 - val_loss: 552.6155 - val_accuracy: 0.8053\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.9764 - accuracy: 0.7677 - val_loss: 552.5047 - val_accuracy: 0.8039\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.7283 - accuracy: 0.7685 - val_loss: 553.0994 - val_accuracy: 0.8101\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.7963 - accuracy: 0.7685 - val_loss: 559.0064 - val_accuracy: 0.8080\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 724.2834 - accuracy: 0.7677 - val_loss: 552.3006 - val_accuracy: 0.8029\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 724.7399 - accuracy: 0.7699 - val_loss: 553.6088 - val_accuracy: 0.8091\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.2147 - accuracy: 0.7660 - val_loss: 554.6851 - val_accuracy: 0.8028\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 723.8594 - accuracy: 0.7664 - val_loss: 552.2120 - val_accuracy: 0.8112\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.0892 - accuracy: 0.7698 - val_loss: 554.4935 - val_accuracy: 0.8065\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.3206 - accuracy: 0.7659 - val_loss: 554.5126 - val_accuracy: 0.8021\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 721.6401 - accuracy: 0.7700 - val_loss: 553.8337 - val_accuracy: 0.8066\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.4755 - accuracy: 0.7691 - val_loss: 552.0753 - val_accuracy: 0.8058\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.4938 - accuracy: 0.7676 - val_loss: 553.6490 - val_accuracy: 0.8079\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.7906 - accuracy: 0.7704 - val_loss: 556.6519 - val_accuracy: 0.8063\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.6004 - accuracy: 0.7695 - val_loss: 559.3809 - val_accuracy: 0.8117\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.2893 - accuracy: 0.7670 - val_loss: 554.8183 - val_accuracy: 0.8075\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.2399 - accuracy: 0.7689 - val_loss: 553.0616 - val_accuracy: 0.8078\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.5499 - accuracy: 0.7659 - val_loss: 552.0349 - val_accuracy: 0.8063\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.5391 - accuracy: 0.7678 - val_loss: 555.5385 - val_accuracy: 0.8095\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 727.8914 - accuracy: 0.7680 - val_loss: 565.1186 - val_accuracy: 0.8069\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.8119 - accuracy: 0.7656 - val_loss: 572.3541 - val_accuracy: 0.8088\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.6957 - accuracy: 0.7680 - val_loss: 556.3518 - val_accuracy: 0.8067\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 723.0018 - accuracy: 0.7664 - val_loss: 554.3468 - val_accuracy: 0.8074\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.3075 - accuracy: 0.7684 - val_loss: 561.0346 - val_accuracy: 0.8107\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.0553 - accuracy: 0.7642 - val_loss: 574.1655 - val_accuracy: 0.8110\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 739.8229 - accuracy: 0.7684 - val_loss: 591.1838 - val_accuracy: 0.8090\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 755.0068 - accuracy: 0.7652 - val_loss: 582.3524 - val_accuracy: 0.8130\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 735.2479 - accuracy: 0.7666 - val_loss: 560.6548 - val_accuracy: 0.8032\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.4486 - accuracy: 0.7673 - val_loss: 560.4959 - val_accuracy: 0.8106\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 724.6708 - accuracy: 0.7698 - val_loss: 553.6497 - val_accuracy: 0.8095\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 723.5580 - accuracy: 0.7676 - val_loss: 554.3632 - val_accuracy: 0.8069\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.2471 - accuracy: 0.7688 - val_loss: 551.6702 - val_accuracy: 0.8137\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.5145 - accuracy: 0.7673 - val_loss: 552.3713 - val_accuracy: 0.8086\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.5458 - accuracy: 0.7679 - val_loss: 550.6674 - val_accuracy: 0.8094\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.0657 - accuracy: 0.7710 - val_loss: 551.3555 - val_accuracy: 0.8096\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.3672 - accuracy: 0.7696 - val_loss: 552.8491 - val_accuracy: 0.8076\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 721.8049 - accuracy: 0.7664 - val_loss: 554.4953 - val_accuracy: 0.8130\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.4278 - accuracy: 0.7730 - val_loss: 558.7982 - val_accuracy: 0.8103\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.6255 - accuracy: 0.7660 - val_loss: 553.7522 - val_accuracy: 0.8129\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.4158 - accuracy: 0.7695 - val_loss: 551.0598 - val_accuracy: 0.8130\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.9329 - accuracy: 0.7717 - val_loss: 551.4843 - val_accuracy: 0.8111\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.8527 - accuracy: 0.7700 - val_loss: 550.9209 - val_accuracy: 0.8131\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.6089 - accuracy: 0.7718 - val_loss: 551.8415 - val_accuracy: 0.8091\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.1310 - accuracy: 0.7688 - val_loss: 555.2510 - val_accuracy: 0.8102\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.2999 - accuracy: 0.7689 - val_loss: 551.4227 - val_accuracy: 0.8104\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.2994 - accuracy: 0.7729 - val_loss: 559.7151 - val_accuracy: 0.8124\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.2308 - accuracy: 0.7669 - val_loss: 556.2814 - val_accuracy: 0.8141\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.5472 - accuracy: 0.7712 - val_loss: 552.4343 - val_accuracy: 0.8102\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.4407 - accuracy: 0.7714 - val_loss: 555.7574 - val_accuracy: 0.8085\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.1036 - accuracy: 0.7692 - val_loss: 554.0166 - val_accuracy: 0.8110\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.2177 - accuracy: 0.7673 - val_loss: 569.5317 - val_accuracy: 0.8142\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 736.7360 - accuracy: 0.7691 - val_loss: 557.3984 - val_accuracy: 0.8144\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 723.7445 - accuracy: 0.7707 - val_loss: 555.0124 - val_accuracy: 0.8119\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.9576 - accuracy: 0.7705 - val_loss: 552.6274 - val_accuracy: 0.8091\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.9393 - accuracy: 0.7678 - val_loss: 552.7895 - val_accuracy: 0.8130\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.1992 - accuracy: 0.7716 - val_loss: 551.1298 - val_accuracy: 0.8116\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.8670 - accuracy: 0.7692 - val_loss: 551.3659 - val_accuracy: 0.8111\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.3372 - accuracy: 0.7722 - val_loss: 552.2825 - val_accuracy: 0.8118\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.0179 - accuracy: 0.7716 - val_loss: 549.7609 - val_accuracy: 0.8115\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.9442 - accuracy: 0.7715 - val_loss: 551.7103 - val_accuracy: 0.8103\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.3176 - accuracy: 0.7709 - val_loss: 550.8787 - val_accuracy: 0.8155\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.0602 - accuracy: 0.7715 - val_loss: 550.7166 - val_accuracy: 0.8105\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.9548 - accuracy: 0.7689 - val_loss: 551.4733 - val_accuracy: 0.8096\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 721.4818 - accuracy: 0.7692 - val_loss: 552.5061 - val_accuracy: 0.8130\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.0342 - accuracy: 0.7688 - val_loss: 572.2737 - val_accuracy: 0.8125\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.8677 - accuracy: 0.7706 - val_loss: 551.5594 - val_accuracy: 0.8145\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.5038 - accuracy: 0.7722 - val_loss: 560.7977 - val_accuracy: 0.8125\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 728.4586 - accuracy: 0.7720 - val_loss: 554.0244 - val_accuracy: 0.8122\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.1338 - accuracy: 0.7713 - val_loss: 552.4002 - val_accuracy: 0.8160\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.7692 - accuracy: 0.7713 - val_loss: 551.6967 - val_accuracy: 0.8133\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.6160 - accuracy: 0.7705 - val_loss: 551.2748 - val_accuracy: 0.8147\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.0118 - accuracy: 0.7706 - val_loss: 558.6055 - val_accuracy: 0.8138\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 729.2557 - accuracy: 0.7712 - val_loss: 561.3697 - val_accuracy: 0.8168\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.7472 - accuracy: 0.7668 - val_loss: 580.3966 - val_accuracy: 0.8162\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.0187 - accuracy: 0.7686 - val_loss: 555.6014 - val_accuracy: 0.8176\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.7603 - accuracy: 0.7692 - val_loss: 550.6768 - val_accuracy: 0.8105\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.1574 - accuracy: 0.7719 - val_loss: 550.4162 - val_accuracy: 0.8147\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.1696 - accuracy: 0.7736 - val_loss: 557.2460 - val_accuracy: 0.8141\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 730.9052 - accuracy: 0.7739 - val_loss: 573.3430 - val_accuracy: 0.8142\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 726.0788 - accuracy: 0.7703 - val_loss: 553.3295 - val_accuracy: 0.8174\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 724.4429 - accuracy: 0.7730 - val_loss: 555.3614 - val_accuracy: 0.8154\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 718.5258 - accuracy: 0.7743 - val_loss: 552.8862 - val_accuracy: 0.8129\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.9122 - accuracy: 0.7719 - val_loss: 554.1738 - val_accuracy: 0.8134\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.1467 - accuracy: 0.7732 - val_loss: 552.7438 - val_accuracy: 0.8155\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.8724 - accuracy: 0.7722 - val_loss: 553.7211 - val_accuracy: 0.8139\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.1031 - accuracy: 0.7720 - val_loss: 551.0480 - val_accuracy: 0.8147\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 722.3939 - accuracy: 0.7747 - val_loss: 555.9930 - val_accuracy: 0.8129\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.2081 - accuracy: 0.7696 - val_loss: 552.8340 - val_accuracy: 0.8146\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 726.1484 - accuracy: 0.7692 - val_loss: 607.0003 - val_accuracy: 0.8144\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 753.2354 - accuracy: 0.7691 - val_loss: 560.3052 - val_accuracy: 0.8205\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.8922 - accuracy: 0.7696 - val_loss: 558.7864 - val_accuracy: 0.8134\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.8612 - accuracy: 0.7711 - val_loss: 549.9337 - val_accuracy: 0.8103\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 718.2376 - accuracy: 0.7753 - val_loss: 554.2528 - val_accuracy: 0.8128\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.6000 - accuracy: 0.7721 - val_loss: 550.4943 - val_accuracy: 0.8112\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 721.9508 - accuracy: 0.7764 - val_loss: 555.7073 - val_accuracy: 0.8124\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.1832 - accuracy: 0.7723 - val_loss: 558.4526 - val_accuracy: 0.8133\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 724.2173 - accuracy: 0.7726 - val_loss: 562.0770 - val_accuracy: 0.8145\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.1987 - accuracy: 0.7728 - val_loss: 551.5513 - val_accuracy: 0.8163\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.3816 - accuracy: 0.7757 - val_loss: 552.9001 - val_accuracy: 0.8139\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.2747 - accuracy: 0.7733 - val_loss: 549.9789 - val_accuracy: 0.8102\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.1656 - accuracy: 0.7718 - val_loss: 549.6451 - val_accuracy: 0.8165\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.1960 - accuracy: 0.7727 - val_loss: 554.9136 - val_accuracy: 0.8170\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.6262 - accuracy: 0.7727 - val_loss: 553.3370 - val_accuracy: 0.8209\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.7734 - accuracy: 0.7741 - val_loss: 552.1797 - val_accuracy: 0.8133\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.4894 - accuracy: 0.7728 - val_loss: 556.2909 - val_accuracy: 0.8132\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.2388 - accuracy: 0.7704 - val_loss: 558.0402 - val_accuracy: 0.8206\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.9563 - accuracy: 0.7739 - val_loss: 552.2781 - val_accuracy: 0.8158\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 728.4299 - accuracy: 0.7752 - val_loss: 576.4846 - val_accuracy: 0.8147\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 746.7163 - accuracy: 0.7703 - val_loss: 583.2524 - val_accuracy: 0.8145\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 735.9834 - accuracy: 0.7729 - val_loss: 561.2371 - val_accuracy: 0.8140\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 737.5826 - accuracy: 0.7715 - val_loss: 587.8487 - val_accuracy: 0.8111\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 737.9564 - accuracy: 0.7724 - val_loss: 561.8369 - val_accuracy: 0.8195\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 727.0067 - accuracy: 0.7695 - val_loss: 554.9324 - val_accuracy: 0.8183\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.9893 - accuracy: 0.7721 - val_loss: 551.6484 - val_accuracy: 0.8211\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.7172 - accuracy: 0.7734 - val_loss: 552.3463 - val_accuracy: 0.8176\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.7542 - accuracy: 0.7735 - val_loss: 552.8625 - val_accuracy: 0.8155\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.4399 - accuracy: 0.7745 - val_loss: 583.3762 - val_accuracy: 0.8201\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.7720 - accuracy: 0.7714 - val_loss: 551.2225 - val_accuracy: 0.8148\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 717.9482 - accuracy: 0.7723 - val_loss: 550.6339 - val_accuracy: 0.8153\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.8079 - accuracy: 0.7736 - val_loss: 561.9995 - val_accuracy: 0.8166\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.4047 - accuracy: 0.7734 - val_loss: 552.0951 - val_accuracy: 0.8175\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.3328 - accuracy: 0.7723 - val_loss: 548.8013 - val_accuracy: 0.8179\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 715.2915 - accuracy: 0.7752 - val_loss: 547.5049 - val_accuracy: 0.8175\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.2154 - accuracy: 0.7756 - val_loss: 549.1204 - val_accuracy: 0.8156\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.7260 - accuracy: 0.7741 - val_loss: 548.6658 - val_accuracy: 0.8146\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.5880 - accuracy: 0.7747 - val_loss: 548.0196 - val_accuracy: 0.8174\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.1520 - accuracy: 0.7740 - val_loss: 549.0546 - val_accuracy: 0.8176\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.9874 - accuracy: 0.7761 - val_loss: 554.6648 - val_accuracy: 0.8159\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.6926 - accuracy: 0.7727 - val_loss: 550.0401 - val_accuracy: 0.8205\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.4460 - accuracy: 0.7731 - val_loss: 553.4414 - val_accuracy: 0.8138\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.2838 - accuracy: 0.7724 - val_loss: 547.7714 - val_accuracy: 0.8221\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.7175 - accuracy: 0.7750 - val_loss: 547.7867 - val_accuracy: 0.8184\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.9011 - accuracy: 0.7757 - val_loss: 551.4455 - val_accuracy: 0.8156\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 716.6540 - accuracy: 0.7751 - val_loss: 550.6537 - val_accuracy: 0.8196\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.2808 - accuracy: 0.7733 - val_loss: 556.4649 - val_accuracy: 0.8137\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.7296 - accuracy: 0.7706 - val_loss: 559.4918 - val_accuracy: 0.8134\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 718.4487 - accuracy: 0.7766 - val_loss: 550.9319 - val_accuracy: 0.8235\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 717.7304 - accuracy: 0.7757 - val_loss: 550.9507 - val_accuracy: 0.8154\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.9093 - accuracy: 0.7717 - val_loss: 553.8893 - val_accuracy: 0.8154\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 718.9388 - accuracy: 0.7740 - val_loss: 552.8082 - val_accuracy: 0.8155\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.1679 - accuracy: 0.7738 - val_loss: 552.0769 - val_accuracy: 0.8162\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.0155 - accuracy: 0.7753 - val_loss: 551.5239 - val_accuracy: 0.8150\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.0421 - accuracy: 0.7745 - val_loss: 562.4956 - val_accuracy: 0.8150\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.2502 - accuracy: 0.7750 - val_loss: 565.2228 - val_accuracy: 0.8217\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 723.1169 - accuracy: 0.7768 - val_loss: 563.9576 - val_accuracy: 0.8141\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 722.3374 - accuracy: 0.7737 - val_loss: 568.8096 - val_accuracy: 0.8172\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 728.9157 - accuracy: 0.7716 - val_loss: 551.5709 - val_accuracy: 0.8173\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 729.7609 - accuracy: 0.7740 - val_loss: 563.4100 - val_accuracy: 0.8151\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 724.1832 - accuracy: 0.7742 - val_loss: 552.5986 - val_accuracy: 0.8211\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.7538 - accuracy: 0.7730 - val_loss: 550.1404 - val_accuracy: 0.8147\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.7552 - accuracy: 0.7741 - val_loss: 546.4098 - val_accuracy: 0.8146\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.3304 - accuracy: 0.7763 - val_loss: 547.5967 - val_accuracy: 0.8161\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.7478 - accuracy: 0.7747 - val_loss: 546.0745 - val_accuracy: 0.8187\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.9653 - accuracy: 0.7739 - val_loss: 548.3731 - val_accuracy: 0.8219\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.4840 - accuracy: 0.7752 - val_loss: 547.0834 - val_accuracy: 0.8183\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.7582 - accuracy: 0.7745 - val_loss: 546.7151 - val_accuracy: 0.8190\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.5470 - accuracy: 0.7756 - val_loss: 546.9188 - val_accuracy: 0.8157\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.8682 - accuracy: 0.7747 - val_loss: 546.7969 - val_accuracy: 0.8166\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 713.2808 - accuracy: 0.7716 - val_loss: 546.9340 - val_accuracy: 0.8173\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 712.3614 - accuracy: 0.7745 - val_loss: 547.3902 - val_accuracy: 0.8200\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.3751 - accuracy: 0.7762 - val_loss: 548.1202 - val_accuracy: 0.8176\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 721.9005 - accuracy: 0.7757 - val_loss: 569.5706 - val_accuracy: 0.8159\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 732.0234 - accuracy: 0.7764 - val_loss: 552.8613 - val_accuracy: 0.8166\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 725.3834 - accuracy: 0.7747 - val_loss: 566.5591 - val_accuracy: 0.8164\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 740.6807 - accuracy: 0.7735 - val_loss: 560.2324 - val_accuracy: 0.8146\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.8171 - accuracy: 0.7703 - val_loss: 553.4747 - val_accuracy: 0.8235\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.0706 - accuracy: 0.7739 - val_loss: 553.2308 - val_accuracy: 0.8144\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.6350 - accuracy: 0.7729 - val_loss: 554.5249 - val_accuracy: 0.8170\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 717.7894 - accuracy: 0.7766 - val_loss: 549.3243 - val_accuracy: 0.8132\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 721.5309 - accuracy: 0.7738 - val_loss: 555.0077 - val_accuracy: 0.8183\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 721.0163 - accuracy: 0.7745 - val_loss: 547.5474 - val_accuracy: 0.8167\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.3487 - accuracy: 0.7749 - val_loss: 548.8068 - val_accuracy: 0.8242\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.9109 - accuracy: 0.7749 - val_loss: 549.4153 - val_accuracy: 0.8189\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.6172 - accuracy: 0.7723 - val_loss: 551.3008 - val_accuracy: 0.8179\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.0403 - accuracy: 0.7769 - val_loss: 548.8884 - val_accuracy: 0.8190\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 714.0478 - accuracy: 0.7751 - val_loss: 565.2448 - val_accuracy: 0.8168\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.2465 - accuracy: 0.7751 - val_loss: 546.9119 - val_accuracy: 0.8159\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.1816 - accuracy: 0.7744 - val_loss: 548.1163 - val_accuracy: 0.8172\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.5906 - accuracy: 0.7741 - val_loss: 560.2696 - val_accuracy: 0.8166\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 717.5888 - accuracy: 0.7765 - val_loss: 547.7982 - val_accuracy: 0.8166\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 717.0692 - accuracy: 0.7742 - val_loss: 563.5745 - val_accuracy: 0.8199\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 726.1888 - accuracy: 0.7749 - val_loss: 549.5571 - val_accuracy: 0.8156\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.2427 - accuracy: 0.7742 - val_loss: 558.1880 - val_accuracy: 0.8219\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.2366 - accuracy: 0.7759 - val_loss: 559.7113 - val_accuracy: 0.8179\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.6401 - accuracy: 0.7731 - val_loss: 547.1597 - val_accuracy: 0.8180\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.8621 - accuracy: 0.7753 - val_loss: 546.5673 - val_accuracy: 0.8161\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.3265 - accuracy: 0.7732 - val_loss: 546.9473 - val_accuracy: 0.8241\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 714.5229 - accuracy: 0.7745 - val_loss: 547.0642 - val_accuracy: 0.8186\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.1951 - accuracy: 0.7754 - val_loss: 545.8779 - val_accuracy: 0.8163\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.7499 - accuracy: 0.7773 - val_loss: 546.3315 - val_accuracy: 0.8192\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 713.0775 - accuracy: 0.7759 - val_loss: 546.7529 - val_accuracy: 0.8238\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.5670 - accuracy: 0.7736 - val_loss: 547.0325 - val_accuracy: 0.8195\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.8956 - accuracy: 0.7766 - val_loss: 546.5026 - val_accuracy: 0.8209\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.0842 - accuracy: 0.7775 - val_loss: 544.9640 - val_accuracy: 0.8186\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.8416 - accuracy: 0.7756 - val_loss: 549.8474 - val_accuracy: 0.8192\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.4678 - accuracy: 0.7754 - val_loss: 545.9960 - val_accuracy: 0.8207\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 712.0306 - accuracy: 0.7749 - val_loss: 544.8536 - val_accuracy: 0.8171\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.8556 - accuracy: 0.7779 - val_loss: 549.3169 - val_accuracy: 0.8165\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.5746 - accuracy: 0.7769 - val_loss: 546.1079 - val_accuracy: 0.8226\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 717.9764 - accuracy: 0.7759 - val_loss: 546.9197 - val_accuracy: 0.8242\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.2437 - accuracy: 0.7750 - val_loss: 561.8677 - val_accuracy: 0.8257\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 721.0876 - accuracy: 0.7760 - val_loss: 547.4796 - val_accuracy: 0.8150\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.0909 - accuracy: 0.7753 - val_loss: 552.9410 - val_accuracy: 0.8218\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 733.0011 - accuracy: 0.7735 - val_loss: 566.2643 - val_accuracy: 0.8216\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 744.3509 - accuracy: 0.7704 - val_loss: 561.2333 - val_accuracy: 0.8249\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.7243 - accuracy: 0.7737 - val_loss: 563.0444 - val_accuracy: 0.8216\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.1907 - accuracy: 0.7732 - val_loss: 551.9174 - val_accuracy: 0.8146\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.5734 - accuracy: 0.7738 - val_loss: 548.6722 - val_accuracy: 0.8168\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.1058 - accuracy: 0.7736 - val_loss: 549.5983 - val_accuracy: 0.8244\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.2304 - accuracy: 0.7762 - val_loss: 548.2595 - val_accuracy: 0.8171\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.5742 - accuracy: 0.7756 - val_loss: 552.3080 - val_accuracy: 0.8154\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.2301 - accuracy: 0.7752 - val_loss: 550.2353 - val_accuracy: 0.8204\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.1792 - accuracy: 0.7750 - val_loss: 546.7115 - val_accuracy: 0.8185\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.5020 - accuracy: 0.7756 - val_loss: 550.1871 - val_accuracy: 0.8163\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.8879 - accuracy: 0.7759 - val_loss: 546.6591 - val_accuracy: 0.8244\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.0848 - accuracy: 0.7783 - val_loss: 546.7741 - val_accuracy: 0.8188\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.0798 - accuracy: 0.7755 - val_loss: 545.0459 - val_accuracy: 0.8201\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.0933 - accuracy: 0.7755 - val_loss: 547.0051 - val_accuracy: 0.8205\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.1010 - accuracy: 0.7778 - val_loss: 544.8308 - val_accuracy: 0.8244\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.7965 - accuracy: 0.7755 - val_loss: 547.8510 - val_accuracy: 0.8203\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 710.3189 - accuracy: 0.7750 - val_loss: 545.8199 - val_accuracy: 0.8205\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 712.5844 - accuracy: 0.7775 - val_loss: 547.9151 - val_accuracy: 0.8232\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.1840 - accuracy: 0.7753 - val_loss: 547.1966 - val_accuracy: 0.8231\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 713.4344 - accuracy: 0.7752 - val_loss: 549.8730 - val_accuracy: 0.8269\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.8899 - accuracy: 0.7787 - val_loss: 545.7492 - val_accuracy: 0.8214\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.6868 - accuracy: 0.7757 - val_loss: 544.7549 - val_accuracy: 0.8152\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.1647 - accuracy: 0.7766 - val_loss: 546.3813 - val_accuracy: 0.8172\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 710.1313 - accuracy: 0.7762 - val_loss: 546.0929 - val_accuracy: 0.8211\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 711.1644 - accuracy: 0.7755 - val_loss: 547.8181 - val_accuracy: 0.8218\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.1080 - accuracy: 0.7751 - val_loss: 554.0238 - val_accuracy: 0.8258\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 713.2528 - accuracy: 0.7739 - val_loss: 546.5921 - val_accuracy: 0.8212\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.9891 - accuracy: 0.7764 - val_loss: 547.3505 - val_accuracy: 0.8263\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 713.9084 - accuracy: 0.7751 - val_loss: 556.5152 - val_accuracy: 0.8207\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.3636 - accuracy: 0.7752 - val_loss: 547.6539 - val_accuracy: 0.8236\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.1453 - accuracy: 0.7741 - val_loss: 545.7603 - val_accuracy: 0.8217\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 711.1627 - accuracy: 0.7761 - val_loss: 545.3749 - val_accuracy: 0.8170\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.0460 - accuracy: 0.7763 - val_loss: 545.3739 - val_accuracy: 0.8226\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.3759 - accuracy: 0.7749 - val_loss: 546.3259 - val_accuracy: 0.8241\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 710.5123 - accuracy: 0.7772 - val_loss: 546.4214 - val_accuracy: 0.8217\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 710.5981 - accuracy: 0.7752 - val_loss: 544.4646 - val_accuracy: 0.8190\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 710.6227 - accuracy: 0.7764 - val_loss: 546.2374 - val_accuracy: 0.8238\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.6567 - accuracy: 0.7750 - val_loss: 546.0504 - val_accuracy: 0.8192\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.5317 - accuracy: 0.7741 - val_loss: 550.2916 - val_accuracy: 0.8225\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.9803 - accuracy: 0.7754 - val_loss: 552.9648 - val_accuracy: 0.8245\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.5165 - accuracy: 0.7780 - val_loss: 545.1061 - val_accuracy: 0.8187\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.1752 - accuracy: 0.7748 - val_loss: 547.3429 - val_accuracy: 0.8232\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.2368 - accuracy: 0.7758 - val_loss: 545.8098 - val_accuracy: 0.8232\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.7260 - accuracy: 0.7762 - val_loss: 545.3458 - val_accuracy: 0.8189\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 710.4717 - accuracy: 0.7765 - val_loss: 547.6525 - val_accuracy: 0.8215\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.3876 - accuracy: 0.7762 - val_loss: 546.1166 - val_accuracy: 0.8199\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.2045 - accuracy: 0.7738 - val_loss: 548.1907 - val_accuracy: 0.8241\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 720.2838 - accuracy: 0.7744 - val_loss: 553.2056 - val_accuracy: 0.8142\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.0321 - accuracy: 0.7716 - val_loss: 545.9707 - val_accuracy: 0.8171\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.5787 - accuracy: 0.7769 - val_loss: 545.7231 - val_accuracy: 0.8240\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.8591 - accuracy: 0.7732 - val_loss: 547.5759 - val_accuracy: 0.8247\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 715.1042 - accuracy: 0.7753 - val_loss: 557.5623 - val_accuracy: 0.8210\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.4084 - accuracy: 0.7727 - val_loss: 546.8198 - val_accuracy: 0.8189\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 716.5457 - accuracy: 0.7742 - val_loss: 546.2122 - val_accuracy: 0.8251\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 711.7675 - accuracy: 0.7755 - val_loss: 545.3762 - val_accuracy: 0.8244\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 715.0950 - accuracy: 0.7741 - val_loss: 548.3795 - val_accuracy: 0.8230\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 725.6811 - accuracy: 0.7754 - val_loss: 557.5923 - val_accuracy: 0.8181\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 725.8545 - accuracy: 0.7731 - val_loss: 551.4555 - val_accuracy: 0.8235\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 720.5605 - accuracy: 0.7712 - val_loss: 552.9511 - val_accuracy: 0.8249\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 712.1727 - accuracy: 0.7750 - val_loss: 545.5572 - val_accuracy: 0.8229\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 709.5555 - accuracy: 0.7756 - val_loss: 546.3372 - val_accuracy: 0.8195\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 710.9155 - accuracy: 0.7764 - val_loss: 558.8656 - val_accuracy: 0.8225\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.8448 - accuracy: 0.7771 - val_loss: 561.9271 - val_accuracy: 0.8239\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 719.4846 - accuracy: 0.7753 - val_loss: 548.9951 - val_accuracy: 0.8205\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 714.0024 - accuracy: 0.7763 - val_loss: 565.3278 - val_accuracy: 0.8211\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 719.0591 - accuracy: 0.7782 - val_loss: 551.6990 - val_accuracy: 0.8187\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 722.7694 - accuracy: 0.7737 - val_loss: 545.8323 - val_accuracy: 0.8213\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 717.6023 - accuracy: 0.7776 - val_loss: 546.8573 - val_accuracy: 0.8267\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 712.8255 - accuracy: 0.7774 - val_loss: 547.7899 - val_accuracy: 0.8235\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 710.9610 - accuracy: 0.7764 - val_loss: 550.2585 - val_accuracy: 0.8238\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.3399 - accuracy: 0.7752 - val_loss: 544.4313 - val_accuracy: 0.8241\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 710.0552 - accuracy: 0.7776 - val_loss: 545.4705 - val_accuracy: 0.8219\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 709.0195 - accuracy: 0.7766 - val_loss: 542.9433 - val_accuracy: 0.8244\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 708.9239 - accuracy: 0.7771 - val_loss: 551.1905 - val_accuracy: 0.8201\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 716.0123 - accuracy: 0.7740 - val_loss: 544.9908 - val_accuracy: 0.8213\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 711.6053 - accuracy: 0.7761 - val_loss: 549.7049 - val_accuracy: 0.8245\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 718.1349 - accuracy: 0.7725 - val_loss: 551.1282 - val_accuracy: 0.8232\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.8452 - accuracy: 0.7758 - val_loss: 550.4624 - val_accuracy: 0.8223\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.4833 - accuracy: 0.7756 - val_loss: 548.4749 - val_accuracy: 0.8217\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.9490 - accuracy: 0.7729 - val_loss: 546.7686 - val_accuracy: 0.8225\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.2834 - accuracy: 0.7762 - val_loss: 547.8759 - val_accuracy: 0.8264\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 711.5488 - accuracy: 0.7757 - val_loss: 553.3286 - val_accuracy: 0.8252\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.3786 - accuracy: 0.7748 - val_loss: 547.1835 - val_accuracy: 0.8236\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.8301 - accuracy: 0.7730 - val_loss: 543.7537 - val_accuracy: 0.8251\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.1205 - accuracy: 0.7780 - val_loss: 542.7252 - val_accuracy: 0.8200\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 707.5392 - accuracy: 0.7773 - val_loss: 544.9284 - val_accuracy: 0.8188\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.3903 - accuracy: 0.7747 - val_loss: 552.4794 - val_accuracy: 0.8232\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.6823 - accuracy: 0.7738 - val_loss: 545.0732 - val_accuracy: 0.8197\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.4233 - accuracy: 0.7753 - val_loss: 551.3046 - val_accuracy: 0.8189\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.5510 - accuracy: 0.7754 - val_loss: 545.7287 - val_accuracy: 0.8224\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.9011 - accuracy: 0.7772 - val_loss: 543.2495 - val_accuracy: 0.8202\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.5693 - accuracy: 0.7766 - val_loss: 544.3903 - val_accuracy: 0.8275\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 708.4015 - accuracy: 0.7781 - val_loss: 544.0986 - val_accuracy: 0.8238\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 710.0992 - accuracy: 0.7789 - val_loss: 546.1302 - val_accuracy: 0.8237\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.9050 - accuracy: 0.7770 - val_loss: 544.9055 - val_accuracy: 0.8203\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.6505 - accuracy: 0.7767 - val_loss: 548.3627 - val_accuracy: 0.8206\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.8150 - accuracy: 0.7757 - val_loss: 546.4188 - val_accuracy: 0.8260\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.7543 - accuracy: 0.7775 - val_loss: 545.5522 - val_accuracy: 0.8239\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.1559 - accuracy: 0.7771 - val_loss: 543.9099 - val_accuracy: 0.8205\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 709.0770 - accuracy: 0.7764 - val_loss: 549.4982 - val_accuracy: 0.8240\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.0239 - accuracy: 0.7751 - val_loss: 562.0793 - val_accuracy: 0.8237\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.5796 - accuracy: 0.7749 - val_loss: 549.6394 - val_accuracy: 0.8254\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 712.6718 - accuracy: 0.7764 - val_loss: 546.9005 - val_accuracy: 0.8186\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 717.0439 - accuracy: 0.7771 - val_loss: 544.1520 - val_accuracy: 0.8249\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 717.1663 - accuracy: 0.7759 - val_loss: 547.0820 - val_accuracy: 0.8262\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.4092 - accuracy: 0.7788 - val_loss: 557.7402 - val_accuracy: 0.8219\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.7094 - accuracy: 0.7749 - val_loss: 549.3022 - val_accuracy: 0.8238\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 717.7693 - accuracy: 0.7730 - val_loss: 545.1133 - val_accuracy: 0.8262\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.2657 - accuracy: 0.7726 - val_loss: 545.2216 - val_accuracy: 0.8169\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 724.4983 - accuracy: 0.7750 - val_loss: 559.0448 - val_accuracy: 0.8212\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.0082 - accuracy: 0.7756 - val_loss: 552.6973 - val_accuracy: 0.8262\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.5550 - accuracy: 0.7718 - val_loss: 547.0828 - val_accuracy: 0.8264\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.2468 - accuracy: 0.7717 - val_loss: 549.7846 - val_accuracy: 0.8208\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.1523 - accuracy: 0.7776 - val_loss: 544.4026 - val_accuracy: 0.8272\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.1526 - accuracy: 0.7769 - val_loss: 550.5701 - val_accuracy: 0.8251\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 726.1799 - accuracy: 0.7765 - val_loss: 555.9385 - val_accuracy: 0.8192\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 725.9063 - accuracy: 0.7734 - val_loss: 561.2267 - val_accuracy: 0.8268\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.9011 - accuracy: 0.7765 - val_loss: 550.8857 - val_accuracy: 0.8187\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.7023 - accuracy: 0.7747 - val_loss: 549.7640 - val_accuracy: 0.8251\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.3418 - accuracy: 0.7786 - val_loss: 553.0912 - val_accuracy: 0.8219\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.6816 - accuracy: 0.7765 - val_loss: 544.6433 - val_accuracy: 0.8238\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 708.9924 - accuracy: 0.7780 - val_loss: 543.4236 - val_accuracy: 0.8197\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.2323 - accuracy: 0.7778 - val_loss: 545.0007 - val_accuracy: 0.8255\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 711.5090 - accuracy: 0.7777 - val_loss: 544.3863 - val_accuracy: 0.8246\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.4261 - accuracy: 0.7755 - val_loss: 542.7948 - val_accuracy: 0.8206\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.2255 - accuracy: 0.7768 - val_loss: 543.9726 - val_accuracy: 0.8264\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.0259 - accuracy: 0.7777 - val_loss: 543.5287 - val_accuracy: 0.8221\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.5506 - accuracy: 0.7762 - val_loss: 547.9240 - val_accuracy: 0.8249\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 711.9801 - accuracy: 0.7776 - val_loss: 544.5670 - val_accuracy: 0.8219\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 710.0164 - accuracy: 0.7765 - val_loss: 542.1749 - val_accuracy: 0.8240\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.6893 - accuracy: 0.7778 - val_loss: 542.6891 - val_accuracy: 0.8234\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 707.0884 - accuracy: 0.7783 - val_loss: 544.0090 - val_accuracy: 0.8244\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.0916 - accuracy: 0.7765 - val_loss: 546.3035 - val_accuracy: 0.8261\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 714.5190 - accuracy: 0.7750 - val_loss: 550.0125 - val_accuracy: 0.8268\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 713.6484 - accuracy: 0.7750 - val_loss: 545.8447 - val_accuracy: 0.8233\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.3694 - accuracy: 0.7767 - val_loss: 547.9895 - val_accuracy: 0.8209\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 709.6168 - accuracy: 0.7762 - val_loss: 543.6364 - val_accuracy: 0.8222\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.4767 - accuracy: 0.7764 - val_loss: 542.5839 - val_accuracy: 0.8262\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.9902 - accuracy: 0.7744 - val_loss: 545.9434 - val_accuracy: 0.8249\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.0462 - accuracy: 0.7781 - val_loss: 544.7374 - val_accuracy: 0.8258\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.1431 - accuracy: 0.7769 - val_loss: 545.6614 - val_accuracy: 0.8241\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.0419 - accuracy: 0.7764 - val_loss: 563.0485 - val_accuracy: 0.8223\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.5543 - accuracy: 0.7751 - val_loss: 547.9625 - val_accuracy: 0.8250\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.0306 - accuracy: 0.7775 - val_loss: 550.0616 - val_accuracy: 0.8235\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.4462 - accuracy: 0.7775 - val_loss: 562.7263 - val_accuracy: 0.8232\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.5245 - accuracy: 0.7747 - val_loss: 549.7007 - val_accuracy: 0.8251\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 713.8219 - accuracy: 0.7769 - val_loss: 545.7700 - val_accuracy: 0.8239\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.4185 - accuracy: 0.7763 - val_loss: 544.9718 - val_accuracy: 0.8255\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.7578 - accuracy: 0.7767 - val_loss: 549.4658 - val_accuracy: 0.8272\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.9948 - accuracy: 0.7764 - val_loss: 546.6732 - val_accuracy: 0.8254\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.4551 - accuracy: 0.7774 - val_loss: 546.6472 - val_accuracy: 0.8248\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.4349 - accuracy: 0.7769 - val_loss: 543.6664 - val_accuracy: 0.8229\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 717.0197 - accuracy: 0.7752 - val_loss: 552.8917 - val_accuracy: 0.8236\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.6129 - accuracy: 0.7762 - val_loss: 549.4179 - val_accuracy: 0.8269\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 710.6732 - accuracy: 0.7766 - val_loss: 543.6972 - val_accuracy: 0.8210\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.9260 - accuracy: 0.7767 - val_loss: 545.8793 - val_accuracy: 0.8210\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.3084 - accuracy: 0.7765 - val_loss: 542.4520 - val_accuracy: 0.8260\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.9280 - accuracy: 0.7784 - val_loss: 541.6320 - val_accuracy: 0.8232\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 706.7379 - accuracy: 0.7793 - val_loss: 541.6943 - val_accuracy: 0.8258\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.7973 - accuracy: 0.7760 - val_loss: 545.2112 - val_accuracy: 0.8228\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 708.3729 - accuracy: 0.7769 - val_loss: 545.8491 - val_accuracy: 0.8264\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.7211 - accuracy: 0.7753 - val_loss: 542.6628 - val_accuracy: 0.8254\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.8775 - accuracy: 0.7780 - val_loss: 551.7540 - val_accuracy: 0.8231\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.6122 - accuracy: 0.7746 - val_loss: 546.9356 - val_accuracy: 0.8256\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.3186 - accuracy: 0.7781 - val_loss: 544.7275 - val_accuracy: 0.8252\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.6406 - accuracy: 0.7772 - val_loss: 543.5728 - val_accuracy: 0.8257\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.5725 - accuracy: 0.7749 - val_loss: 541.5013 - val_accuracy: 0.8259\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.6725 - accuracy: 0.7789 - val_loss: 542.4469 - val_accuracy: 0.8236\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.2352 - accuracy: 0.7773 - val_loss: 543.0806 - val_accuracy: 0.8271\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.3064 - accuracy: 0.7786 - val_loss: 547.9003 - val_accuracy: 0.8242\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.4160 - accuracy: 0.7754 - val_loss: 542.5652 - val_accuracy: 0.8257\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.0734 - accuracy: 0.7763 - val_loss: 555.6097 - val_accuracy: 0.8249\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.2910 - accuracy: 0.7783 - val_loss: 543.5125 - val_accuracy: 0.8249\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.2062 - accuracy: 0.7772 - val_loss: 544.4772 - val_accuracy: 0.8251\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.3685 - accuracy: 0.7773 - val_loss: 545.0033 - val_accuracy: 0.8224\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.4341 - accuracy: 0.7764 - val_loss: 542.2159 - val_accuracy: 0.8260\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.9465 - accuracy: 0.7794 - val_loss: 544.0847 - val_accuracy: 0.8251\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.1993 - accuracy: 0.7776 - val_loss: 546.1676 - val_accuracy: 0.8211\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.9733 - accuracy: 0.7745 - val_loss: 543.8949 - val_accuracy: 0.8256\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.9441 - accuracy: 0.7759 - val_loss: 545.0117 - val_accuracy: 0.8259\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 709.8275 - accuracy: 0.7760 - val_loss: 547.3135 - val_accuracy: 0.8272\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.6061 - accuracy: 0.7771 - val_loss: 543.7094 - val_accuracy: 0.8233\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.9355 - accuracy: 0.7764 - val_loss: 544.4551 - val_accuracy: 0.8241\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.4542 - accuracy: 0.7783 - val_loss: 542.4737 - val_accuracy: 0.8250\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.1108 - accuracy: 0.7772 - val_loss: 541.2424 - val_accuracy: 0.8264\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.2923 - accuracy: 0.7777 - val_loss: 542.5797 - val_accuracy: 0.8228\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 706.8473 - accuracy: 0.7776 - val_loss: 543.8357 - val_accuracy: 0.8235\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 708.3168 - accuracy: 0.7766 - val_loss: 542.5307 - val_accuracy: 0.8214\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.4915 - accuracy: 0.7793 - val_loss: 541.4017 - val_accuracy: 0.8241\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.4008 - accuracy: 0.7783 - val_loss: 540.2122 - val_accuracy: 0.8236\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 705.1594 - accuracy: 0.7783 - val_loss: 542.0605 - val_accuracy: 0.8240\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.9562 - accuracy: 0.7776 - val_loss: 541.3068 - val_accuracy: 0.8279\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 705.9864 - accuracy: 0.7783 - val_loss: 541.7502 - val_accuracy: 0.8265\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 706.4333 - accuracy: 0.7779 - val_loss: 540.6542 - val_accuracy: 0.8249\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 711.5133 - accuracy: 0.7776 - val_loss: 551.7090 - val_accuracy: 0.8230\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 713.6156 - accuracy: 0.7775 - val_loss: 549.1440 - val_accuracy: 0.8219\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 713.5357 - accuracy: 0.7774 - val_loss: 543.9932 - val_accuracy: 0.8259\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.0602 - accuracy: 0.7768 - val_loss: 541.8906 - val_accuracy: 0.8258\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 717.2527 - accuracy: 0.7762 - val_loss: 552.2556 - val_accuracy: 0.8274\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 725.3846 - accuracy: 0.7756 - val_loss: 547.6466 - val_accuracy: 0.8208\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 719.7463 - accuracy: 0.7762 - val_loss: 544.4086 - val_accuracy: 0.8271\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.1932 - accuracy: 0.7775 - val_loss: 543.3895 - val_accuracy: 0.8226\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 715.9463 - accuracy: 0.7766 - val_loss: 544.9155 - val_accuracy: 0.8216\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.9212 - accuracy: 0.7733 - val_loss: 547.9136 - val_accuracy: 0.8262\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.8682 - accuracy: 0.7757 - val_loss: 541.9180 - val_accuracy: 0.8250\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 709.7346 - accuracy: 0.7780 - val_loss: 543.4481 - val_accuracy: 0.8225\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.9888 - accuracy: 0.7775 - val_loss: 545.2870 - val_accuracy: 0.8246\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.0285 - accuracy: 0.7776 - val_loss: 541.8674 - val_accuracy: 0.8183\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 707.8145 - accuracy: 0.7770 - val_loss: 542.6283 - val_accuracy: 0.8252\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.3239 - accuracy: 0.7776 - val_loss: 541.6126 - val_accuracy: 0.8250\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 705.0193 - accuracy: 0.7773 - val_loss: 545.8320 - val_accuracy: 0.8249\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.5870 - accuracy: 0.7775 - val_loss: 544.2584 - val_accuracy: 0.8270\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 711.2552 - accuracy: 0.7784 - val_loss: 542.2628 - val_accuracy: 0.8237\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 706.5765 - accuracy: 0.7766 - val_loss: 544.6577 - val_accuracy: 0.8212\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.1780 - accuracy: 0.7764 - val_loss: 544.2266 - val_accuracy: 0.8243\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.4678 - accuracy: 0.7765 - val_loss: 558.5569 - val_accuracy: 0.8243\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.9528 - accuracy: 0.7726 - val_loss: 546.0759 - val_accuracy: 0.8220\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.2809 - accuracy: 0.7793 - val_loss: 541.9609 - val_accuracy: 0.8233\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.8180 - accuracy: 0.7756 - val_loss: 549.3870 - val_accuracy: 0.8242\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 709.3091 - accuracy: 0.7753 - val_loss: 544.0831 - val_accuracy: 0.8241\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 710.2171 - accuracy: 0.7736 - val_loss: 549.5027 - val_accuracy: 0.8163\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.7719 - accuracy: 0.7708 - val_loss: 548.0810 - val_accuracy: 0.8258\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.4337 - accuracy: 0.7770 - val_loss: 546.8253 - val_accuracy: 0.8216\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.8903 - accuracy: 0.7774 - val_loss: 553.0705 - val_accuracy: 0.8209\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 723.4517 - accuracy: 0.7750 - val_loss: 549.5648 - val_accuracy: 0.8216\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 712.9766 - accuracy: 0.7767 - val_loss: 547.1475 - val_accuracy: 0.8224\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.0557 - accuracy: 0.7755 - val_loss: 545.7993 - val_accuracy: 0.8226\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.5248 - accuracy: 0.7766 - val_loss: 548.4768 - val_accuracy: 0.8195\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 713.9188 - accuracy: 0.7763 - val_loss: 549.4065 - val_accuracy: 0.8242\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.7349 - accuracy: 0.7773 - val_loss: 541.3599 - val_accuracy: 0.8221\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.6292 - accuracy: 0.7797 - val_loss: 541.5861 - val_accuracy: 0.8277\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.0782 - accuracy: 0.7789 - val_loss: 548.5641 - val_accuracy: 0.8228\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 722.1266 - accuracy: 0.7778 - val_loss: 541.4166 - val_accuracy: 0.8247\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 709.8196 - accuracy: 0.7776 - val_loss: 544.8621 - val_accuracy: 0.8270\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.7433 - accuracy: 0.7778 - val_loss: 542.7463 - val_accuracy: 0.8238\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 723.6548 - accuracy: 0.7762 - val_loss: 595.0062 - val_accuracy: 0.8249\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.9760 - accuracy: 0.7755 - val_loss: 546.0410 - val_accuracy: 0.8204\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.1937 - accuracy: 0.7732 - val_loss: 542.9532 - val_accuracy: 0.8189\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.7856 - accuracy: 0.7736 - val_loss: 542.1790 - val_accuracy: 0.8258\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 709.4016 - accuracy: 0.7760 - val_loss: 542.0375 - val_accuracy: 0.8254\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.3971 - accuracy: 0.7773 - val_loss: 549.9077 - val_accuracy: 0.8207\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.6920 - accuracy: 0.7762 - val_loss: 545.7728 - val_accuracy: 0.8224\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.7910 - accuracy: 0.7781 - val_loss: 546.5330 - val_accuracy: 0.8263\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.6028 - accuracy: 0.7774 - val_loss: 541.8884 - val_accuracy: 0.8236\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 705.2018 - accuracy: 0.7791 - val_loss: 548.9554 - val_accuracy: 0.8243\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.0698 - accuracy: 0.7774 - val_loss: 543.9127 - val_accuracy: 0.8258\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 707.4608 - accuracy: 0.7784 - val_loss: 543.7884 - val_accuracy: 0.8237\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.4808 - accuracy: 0.7777 - val_loss: 540.6404 - val_accuracy: 0.8229\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 705.2252 - accuracy: 0.7790 - val_loss: 541.9929 - val_accuracy: 0.8264\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 705.5811 - accuracy: 0.7795 - val_loss: 540.2090 - val_accuracy: 0.8265\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.4414 - accuracy: 0.7790 - val_loss: 540.9386 - val_accuracy: 0.8259\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.9805 - accuracy: 0.7783 - val_loss: 539.3976 - val_accuracy: 0.8256\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.7178 - accuracy: 0.7787 - val_loss: 541.8790 - val_accuracy: 0.8236\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.8647 - accuracy: 0.7782 - val_loss: 539.8245 - val_accuracy: 0.8224\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.2166 - accuracy: 0.7768 - val_loss: 543.4173 - val_accuracy: 0.8264\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 704.2274 - accuracy: 0.7793 - val_loss: 539.7947 - val_accuracy: 0.8264\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.4902 - accuracy: 0.7787 - val_loss: 541.7348 - val_accuracy: 0.8261\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.1804 - accuracy: 0.7800 - val_loss: 539.2596 - val_accuracy: 0.8256\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 703.7905 - accuracy: 0.7800 - val_loss: 540.4518 - val_accuracy: 0.8259\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.2098 - accuracy: 0.7790 - val_loss: 546.4045 - val_accuracy: 0.8245\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.0053 - accuracy: 0.7771 - val_loss: 546.4344 - val_accuracy: 0.8246\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 712.9788 - accuracy: 0.7789 - val_loss: 551.2466 - val_accuracy: 0.8218\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 723.3389 - accuracy: 0.7747 - val_loss: 548.6597 - val_accuracy: 0.8238\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.3181 - accuracy: 0.7752 - val_loss: 549.2382 - val_accuracy: 0.8220\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 715.5476 - accuracy: 0.7761 - val_loss: 544.3851 - val_accuracy: 0.8225\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 715.7436 - accuracy: 0.7762 - val_loss: 545.6903 - val_accuracy: 0.8236\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.6445 - accuracy: 0.7762 - val_loss: 544.0681 - val_accuracy: 0.8266\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.0824 - accuracy: 0.7772 - val_loss: 544.9063 - val_accuracy: 0.8231\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 705.4666 - accuracy: 0.7782 - val_loss: 540.1257 - val_accuracy: 0.8230\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.5649 - accuracy: 0.7778 - val_loss: 540.2784 - val_accuracy: 0.8246\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.9434 - accuracy: 0.7787 - val_loss: 542.4401 - val_accuracy: 0.8240\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 705.6421 - accuracy: 0.7786 - val_loss: 540.2140 - val_accuracy: 0.8252\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.8158 - accuracy: 0.7806 - val_loss: 539.9325 - val_accuracy: 0.8254\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 705.7877 - accuracy: 0.7795 - val_loss: 542.7475 - val_accuracy: 0.8265\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 707.6608 - accuracy: 0.7794 - val_loss: 542.1339 - val_accuracy: 0.8245\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 709.3115 - accuracy: 0.7783 - val_loss: 541.2221 - val_accuracy: 0.8265\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.3396 - accuracy: 0.7792 - val_loss: 543.7618 - val_accuracy: 0.8248\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.1192 - accuracy: 0.7784 - val_loss: 542.9942 - val_accuracy: 0.8263\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 710.9462 - accuracy: 0.7784 - val_loss: 545.1588 - val_accuracy: 0.8250\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.8908 - accuracy: 0.7785 - val_loss: 542.7166 - val_accuracy: 0.8262\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 710.6000 - accuracy: 0.7791 - val_loss: 539.3522 - val_accuracy: 0.8261\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 708.5161 - accuracy: 0.7793 - val_loss: 544.8979 - val_accuracy: 0.8259\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.6198 - accuracy: 0.7796 - val_loss: 553.0280 - val_accuracy: 0.8223\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 724.3368 - accuracy: 0.7759 - val_loss: 545.7565 - val_accuracy: 0.8263\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.0582 - accuracy: 0.7788 - val_loss: 547.7934 - val_accuracy: 0.8261\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.6134 - accuracy: 0.7789 - val_loss: 545.6205 - val_accuracy: 0.8264\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.8900 - accuracy: 0.7791 - val_loss: 545.1210 - val_accuracy: 0.8243\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.9640 - accuracy: 0.7775 - val_loss: 542.9110 - val_accuracy: 0.8269\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 708.7247 - accuracy: 0.7802 - val_loss: 539.6700 - val_accuracy: 0.8240\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.5325 - accuracy: 0.7774 - val_loss: 549.5881 - val_accuracy: 0.8230\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.9044 - accuracy: 0.7788 - val_loss: 543.0406 - val_accuracy: 0.8253\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 707.4385 - accuracy: 0.7785 - val_loss: 540.5141 - val_accuracy: 0.8262\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 705.8505 - accuracy: 0.7794 - val_loss: 540.1830 - val_accuracy: 0.8260\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.1530 - accuracy: 0.7796 - val_loss: 540.0108 - val_accuracy: 0.8255\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.4664 - accuracy: 0.7799 - val_loss: 539.2214 - val_accuracy: 0.8272\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 704.0667 - accuracy: 0.7808 - val_loss: 540.7134 - val_accuracy: 0.8255\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 705.4642 - accuracy: 0.7796 - val_loss: 550.1053 - val_accuracy: 0.8229\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.2320 - accuracy: 0.7777 - val_loss: 540.4704 - val_accuracy: 0.8268\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.9311 - accuracy: 0.7812 - val_loss: 540.1246 - val_accuracy: 0.8242\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 703.7514 - accuracy: 0.7798 - val_loss: 540.9174 - val_accuracy: 0.8272\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 703.4626 - accuracy: 0.7805 - val_loss: 538.9180 - val_accuracy: 0.8256\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 703.2522 - accuracy: 0.7795 - val_loss: 540.0339 - val_accuracy: 0.8275\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.4099 - accuracy: 0.7794 - val_loss: 543.0255 - val_accuracy: 0.8230\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.7804 - accuracy: 0.7787 - val_loss: 540.7889 - val_accuracy: 0.8263\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 705.5442 - accuracy: 0.7786 - val_loss: 545.6879 - val_accuracy: 0.8264\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.0100 - accuracy: 0.7787 - val_loss: 546.7916 - val_accuracy: 0.8235\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.5784 - accuracy: 0.7785 - val_loss: 540.3349 - val_accuracy: 0.8226\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.2057 - accuracy: 0.7782 - val_loss: 551.1805 - val_accuracy: 0.8245\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.7349 - accuracy: 0.7782 - val_loss: 538.7747 - val_accuracy: 0.8243\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.4455 - accuracy: 0.7784 - val_loss: 539.4772 - val_accuracy: 0.8266\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.5511 - accuracy: 0.7780 - val_loss: 539.2603 - val_accuracy: 0.8245\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 706.5239 - accuracy: 0.7782 - val_loss: 540.4053 - val_accuracy: 0.8240\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.6328 - accuracy: 0.7799 - val_loss: 547.5955 - val_accuracy: 0.8238\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 705.1353 - accuracy: 0.7776 - val_loss: 542.2980 - val_accuracy: 0.8234\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 704.0626 - accuracy: 0.7792 - val_loss: 540.9475 - val_accuracy: 0.8255\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.8030 - accuracy: 0.7795 - val_loss: 552.6746 - val_accuracy: 0.8263\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 705.2269 - accuracy: 0.7777 - val_loss: 539.4395 - val_accuracy: 0.8237\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 705.0204 - accuracy: 0.7798 - val_loss: 540.9319 - val_accuracy: 0.8275\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 706.2925 - accuracy: 0.7790 - val_loss: 540.2438 - val_accuracy: 0.8241\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 705.1277 - accuracy: 0.7804 - val_loss: 538.8708 - val_accuracy: 0.8276\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 705.6356 - accuracy: 0.7802 - val_loss: 538.7161 - val_accuracy: 0.8265\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 710.7542 - accuracy: 0.7794 - val_loss: 545.0681 - val_accuracy: 0.8285\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.5699 - accuracy: 0.7793 - val_loss: 541.0176 - val_accuracy: 0.8240\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.1835 - accuracy: 0.7807 - val_loss: 542.5219 - val_accuracy: 0.8250\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.2598 - accuracy: 0.7812 - val_loss: 538.0143 - val_accuracy: 0.8252\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.4042 - accuracy: 0.7793 - val_loss: 542.6856 - val_accuracy: 0.8256\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.3407 - accuracy: 0.7781 - val_loss: 544.3505 - val_accuracy: 0.8199\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.2807 - accuracy: 0.7785 - val_loss: 542.9581 - val_accuracy: 0.8244\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 703.6526 - accuracy: 0.7780 - val_loss: 538.8602 - val_accuracy: 0.8248\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 701.9092 - accuracy: 0.7801 - val_loss: 549.8433 - val_accuracy: 0.8250\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.3547 - accuracy: 0.7790 - val_loss: 543.9572 - val_accuracy: 0.8265\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.7961 - accuracy: 0.7808 - val_loss: 538.9813 - val_accuracy: 0.8248\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.5942 - accuracy: 0.7793 - val_loss: 539.6059 - val_accuracy: 0.8266\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.3129 - accuracy: 0.7789 - val_loss: 548.3390 - val_accuracy: 0.8263\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 709.8612 - accuracy: 0.7773 - val_loss: 539.3212 - val_accuracy: 0.8240\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 708.6998 - accuracy: 0.7789 - val_loss: 549.8015 - val_accuracy: 0.8274\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.2849 - accuracy: 0.7776 - val_loss: 586.2844 - val_accuracy: 0.8227\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 763.2454 - accuracy: 0.7769 - val_loss: 569.4223 - val_accuracy: 0.8219\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 745.3334 - accuracy: 0.7724 - val_loss: 556.1137 - val_accuracy: 0.8277\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.7597 - accuracy: 0.7762 - val_loss: 562.1084 - val_accuracy: 0.8288\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.7460 - accuracy: 0.7769 - val_loss: 551.3344 - val_accuracy: 0.8283\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.8815 - accuracy: 0.7778 - val_loss: 545.3448 - val_accuracy: 0.8266\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.6655 - accuracy: 0.7792 - val_loss: 543.4667 - val_accuracy: 0.8268\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.9979 - accuracy: 0.7790 - val_loss: 543.1442 - val_accuracy: 0.8289\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 705.4641 - accuracy: 0.7801 - val_loss: 543.7531 - val_accuracy: 0.8271\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 708.5017 - accuracy: 0.7801 - val_loss: 542.7968 - val_accuracy: 0.8263\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.7377 - accuracy: 0.7796 - val_loss: 543.3071 - val_accuracy: 0.8242\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 704.5343 - accuracy: 0.7794 - val_loss: 540.5172 - val_accuracy: 0.8268\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 703.0146 - accuracy: 0.7799 - val_loss: 538.5768 - val_accuracy: 0.8264\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.6328 - accuracy: 0.7816 - val_loss: 541.8243 - val_accuracy: 0.8248\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.6373 - accuracy: 0.7791 - val_loss: 539.1766 - val_accuracy: 0.8253\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 702.8154 - accuracy: 0.7811 - val_loss: 539.8595 - val_accuracy: 0.8271\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 702.4993 - accuracy: 0.7804 - val_loss: 541.0940 - val_accuracy: 0.8257\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 701.8130 - accuracy: 0.7796 - val_loss: 539.3151 - val_accuracy: 0.8270\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 703.2319 - accuracy: 0.7790 - val_loss: 543.2500 - val_accuracy: 0.8257\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.1466 - accuracy: 0.7798 - val_loss: 545.2123 - val_accuracy: 0.8245\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.3320 - accuracy: 0.7797 - val_loss: 540.4823 - val_accuracy: 0.8256\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.3285 - accuracy: 0.7798 - val_loss: 539.4360 - val_accuracy: 0.8257\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 702.7085 - accuracy: 0.7802 - val_loss: 540.4592 - val_accuracy: 0.8251\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.2170 - accuracy: 0.7798 - val_loss: 547.2802 - val_accuracy: 0.8253\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.5396 - accuracy: 0.7791 - val_loss: 562.4415 - val_accuracy: 0.8246\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.3209 - accuracy: 0.7801 - val_loss: 543.2292 - val_accuracy: 0.8258\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.5382 - accuracy: 0.7778 - val_loss: 539.6568 - val_accuracy: 0.8255\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.0884 - accuracy: 0.7802 - val_loss: 538.4099 - val_accuracy: 0.8271\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 701.7553 - accuracy: 0.7792 - val_loss: 538.2078 - val_accuracy: 0.8259\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 701.3931 - accuracy: 0.7801 - val_loss: 541.5480 - val_accuracy: 0.8257\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.7355 - accuracy: 0.7775 - val_loss: 542.2297 - val_accuracy: 0.8256\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 705.5210 - accuracy: 0.7797 - val_loss: 538.4197 - val_accuracy: 0.8255\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.4243 - accuracy: 0.7799 - val_loss: 547.3583 - val_accuracy: 0.8246\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.0116 - accuracy: 0.7785 - val_loss: 544.0971 - val_accuracy: 0.8263\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.1850 - accuracy: 0.7784 - val_loss: 551.6982 - val_accuracy: 0.8267\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 709.3398 - accuracy: 0.7772 - val_loss: 540.5300 - val_accuracy: 0.8266\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 703.7391 - accuracy: 0.7798 - val_loss: 538.4874 - val_accuracy: 0.8274\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 701.7125 - accuracy: 0.7802 - val_loss: 538.7732 - val_accuracy: 0.8230\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 702.9323 - accuracy: 0.7800 - val_loss: 540.6334 - val_accuracy: 0.8254\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 701.6672 - accuracy: 0.7811 - val_loss: 538.4664 - val_accuracy: 0.8281\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 705.7130 - accuracy: 0.7793 - val_loss: 545.1876 - val_accuracy: 0.8274\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 705.5292 - accuracy: 0.7798 - val_loss: 539.1597 - val_accuracy: 0.8271\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.3644 - accuracy: 0.7784 - val_loss: 541.0487 - val_accuracy: 0.8259\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 702.4768 - accuracy: 0.7814 - val_loss: 538.5280 - val_accuracy: 0.8248\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 701.8194 - accuracy: 0.7806 - val_loss: 539.8756 - val_accuracy: 0.8270\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 702.9149 - accuracy: 0.7795 - val_loss: 536.9714 - val_accuracy: 0.8248\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 702.8209 - accuracy: 0.7795 - val_loss: 537.8247 - val_accuracy: 0.8265\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 702.7002 - accuracy: 0.7806 - val_loss: 537.6284 - val_accuracy: 0.8292\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 701.9619 - accuracy: 0.7798 - val_loss: 537.3837 - val_accuracy: 0.8252\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 704.3278 - accuracy: 0.7793 - val_loss: 540.5838 - val_accuracy: 0.8281\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 703.5132 - accuracy: 0.7799 - val_loss: 537.2295 - val_accuracy: 0.8251\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 701.6604 - accuracy: 0.7806 - val_loss: 538.2910 - val_accuracy: 0.8256\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 701.1315 - accuracy: 0.7793 - val_loss: 537.8781 - val_accuracy: 0.8245\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 702.0027 - accuracy: 0.7829 - val_loss: 537.8818 - val_accuracy: 0.8263\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 705.5915 - accuracy: 0.7793 - val_loss: 537.8201 - val_accuracy: 0.8272\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 706.6995 - accuracy: 0.7809 - val_loss: 539.3647 - val_accuracy: 0.8272\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.9618 - accuracy: 0.7768 - val_loss: 540.0167 - val_accuracy: 0.8273\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.4036 - accuracy: 0.7773 - val_loss: 549.7833 - val_accuracy: 0.8263\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.5771 - accuracy: 0.7799 - val_loss: 542.8989 - val_accuracy: 0.8239\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.5620 - accuracy: 0.7802 - val_loss: 556.4159 - val_accuracy: 0.8297\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.4297 - accuracy: 0.7767 - val_loss: 541.0103 - val_accuracy: 0.8252\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.8716 - accuracy: 0.7796 - val_loss: 541.1065 - val_accuracy: 0.8265\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.6088 - accuracy: 0.7786 - val_loss: 540.1702 - val_accuracy: 0.8248\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.3064 - accuracy: 0.7807 - val_loss: 542.4404 - val_accuracy: 0.8282\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.9959 - accuracy: 0.7808 - val_loss: 537.3007 - val_accuracy: 0.8279\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 702.5189 - accuracy: 0.7795 - val_loss: 537.7043 - val_accuracy: 0.8279\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 700.8079 - accuracy: 0.7809 - val_loss: 544.2991 - val_accuracy: 0.8263\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.6951 - accuracy: 0.7785 - val_loss: 540.9847 - val_accuracy: 0.8248\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.8480 - accuracy: 0.7776 - val_loss: 539.4580 - val_accuracy: 0.8268\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 714.2130 - accuracy: 0.7787 - val_loss: 541.7838 - val_accuracy: 0.8277\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 713.1669 - accuracy: 0.7771 - val_loss: 543.8976 - val_accuracy: 0.8231\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.0142 - accuracy: 0.7795 - val_loss: 539.6353 - val_accuracy: 0.8277\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 712.5450 - accuracy: 0.7772 - val_loss: 543.8183 - val_accuracy: 0.8254\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.6672 - accuracy: 0.7768 - val_loss: 541.3769 - val_accuracy: 0.8259\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.0167 - accuracy: 0.7801 - val_loss: 539.3906 - val_accuracy: 0.8236\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 703.0508 - accuracy: 0.7800 - val_loss: 537.9899 - val_accuracy: 0.8283\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 701.6523 - accuracy: 0.7826 - val_loss: 538.8903 - val_accuracy: 0.8265\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 702.6703 - accuracy: 0.7805 - val_loss: 538.0569 - val_accuracy: 0.8254\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 702.0374 - accuracy: 0.7803 - val_loss: 539.2448 - val_accuracy: 0.8275\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 701.3256 - accuracy: 0.7814 - val_loss: 535.8892 - val_accuracy: 0.8274\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 701.1878 - accuracy: 0.7816 - val_loss: 544.6971 - val_accuracy: 0.8269\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 703.4336 - accuracy: 0.7817 - val_loss: 537.6789 - val_accuracy: 0.8278\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 701.0871 - accuracy: 0.7820 - val_loss: 538.0508 - val_accuracy: 0.8277\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.5883 - accuracy: 0.7816 - val_loss: 539.2299 - val_accuracy: 0.8266\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 704.0286 - accuracy: 0.7809 - val_loss: 539.2948 - val_accuracy: 0.8262\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.6305 - accuracy: 0.7820 - val_loss: 541.0882 - val_accuracy: 0.8285\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 703.6365 - accuracy: 0.7797 - val_loss: 540.8181 - val_accuracy: 0.8272\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 703.0103 - accuracy: 0.7811 - val_loss: 539.2398 - val_accuracy: 0.8290\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.3116 - accuracy: 0.7802 - val_loss: 542.8207 - val_accuracy: 0.8244\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 701.5675 - accuracy: 0.7811 - val_loss: 537.3445 - val_accuracy: 0.8260\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 701.4907 - accuracy: 0.7800 - val_loss: 536.5401 - val_accuracy: 0.8259\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 703.9104 - accuracy: 0.7803 - val_loss: 545.7693 - val_accuracy: 0.8243\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.7797 - accuracy: 0.7804 - val_loss: 545.2606 - val_accuracy: 0.8270\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.0762 - accuracy: 0.7796 - val_loss: 541.6193 - val_accuracy: 0.8266\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 707.3644 - accuracy: 0.7800 - val_loss: 543.8879 - val_accuracy: 0.8257\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 705.7650 - accuracy: 0.7801 - val_loss: 539.0245 - val_accuracy: 0.8278\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 702.5927 - accuracy: 0.7813 - val_loss: 537.9280 - val_accuracy: 0.8283\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 702.2578 - accuracy: 0.7814 - val_loss: 536.9950 - val_accuracy: 0.8286\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 700.6589 - accuracy: 0.7811 - val_loss: 536.9357 - val_accuracy: 0.8255\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 700.0039 - accuracy: 0.7821 - val_loss: 536.8878 - val_accuracy: 0.8261\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 699.5524 - accuracy: 0.7819 - val_loss: 535.4880 - val_accuracy: 0.8279\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 700.4687 - accuracy: 0.7828 - val_loss: 539.1606 - val_accuracy: 0.8250\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 708.0638 - accuracy: 0.7818 - val_loss: 539.8649 - val_accuracy: 0.8285\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 704.1629 - accuracy: 0.7811 - val_loss: 538.1899 - val_accuracy: 0.8268\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 707.5768 - accuracy: 0.7816 - val_loss: 544.7481 - val_accuracy: 0.8255\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.8836 - accuracy: 0.7800 - val_loss: 537.8096 - val_accuracy: 0.8249\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 705.2941 - accuracy: 0.7813 - val_loss: 541.4268 - val_accuracy: 0.8284\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 703.4514 - accuracy: 0.7804 - val_loss: 538.0801 - val_accuracy: 0.8243\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 704.1335 - accuracy: 0.7810 - val_loss: 538.7358 - val_accuracy: 0.8276\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 702.1919 - accuracy: 0.7816 - val_loss: 536.2549 - val_accuracy: 0.8291\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "# Upsample the second input image\n",
        "upsampled = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Combine the two input images using a convolutional layer\n",
        "combined = layers.Conv2D(31, kernel_size=1, activation='relu')(upsampled)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(combined)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "#conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "#pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer = layers.Conv2D(31, kernel_size=1, activation='relu')(pool2)\n",
        "# Define the model\n",
        "modelnew = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "# Compile the model\n",
        "modelnew.compile(optimizer='adam',\n",
        "loss='mean_absolute_error',\n",
        "metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = modelnew.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "_MRnn7fAifFM",
        "outputId": "5a351c89-eac6-4b28-d9ce-5bf06335c1ca"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUoAAAFNCAYAAABmLCa9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxcdb3/8dcne9qmadN9Sxe6QNlLZb0Csi8Cil4WAeFeFtErF9SLwFURUX+Xq14XBAVEAZFNCiJiBaSCIGApO7SlpbSlC93SNW3TbPP5/fE9aSZp2kwmmU4m5/18PPLIOWfOzHzPTPPu9/s95/s95u6IiMjO5WW7ACIi3Z2CUkSkHQpKEZF2KChFRNqhoBQRaYeCUkSkHQpKEZF2KCgla8zsOTNbb2bF2S6LyK4oKCUrzGwM8HHAgdN34/sW7K73kp5DQSnZ8nngn8DdwIVNG81slJk9amZrzGytmd2S9NilZjbXzKrNbI6ZTYm2u5mNT9rvbjP7XrR8tJktM7NrzGwlcJeZ9TezJ6L3WB8tj0x6foWZ3WVmH0WPPxZtf9fMTkvar9DMqszswIx9StItKCglWz4P3Bf9nGhmQ8wsH3gC+BAYA4wAHgQws38Fboie15dQC12b4nsNBSqA0cBlhH/3d0XrlUANcEvS/vcCvYC9gcHAT6LtvwXOT9rvFGCFu7+RYjkkR5nGesvuZmb/AjwLDHP3KjN7D7idUMN8PNre0Oo5TwHT3f1nbbyeAxPcfUG0fjewzN2/aWZHA08Dfd19207KcwDwrLv3N7NhwHJggLuvb7XfcGAeMMLdN5nZNOAVd/9B2h+G5ATVKCUbLgSedveqaP3+aNso4MPWIRkZBXyQ5vutSQ5JM+tlZreb2Ydmtgl4HugX1WhHAetahySAu38EvAh8xsz6AScTasTSw6ljW3YrMysFzgLyoz5DgGKgH7AKqDSzgjbCcimwx05ediuhqdxkKLAsab11s+lrwCTgEHdfGdUo3wAsep8KM+vn7hvaeK97gEsIfzsvu/vynR+t9BSqUcru9imgEZgMHBD97AW8ED22ArjJzHqbWYmZHRE9707gv8zsIAvGm9no6LE3gc+ZWb6ZnQQc1U4Zygj9khvMrAL4dtMD7r4C+Avwi+ikT6GZHZn03MeAKcCVhD5LiQEFpexuFwJ3ufsSd1/Z9EM4mXIucBowHlhCqBWeDeDuDwPfJzTTqwmBVRG95pXR8zYA50WP7cpPgVKgitAv+mSrxy8A6oH3gNXAVU0PuHsN8AgwFni0g8cuOUonc0Q6yMyuBya6+/nt7iw9gvooRTogaqpfTKh1Skyo6S2SIjO7lHCy5y/u/ny2yyO7j5reIiLtUI1SRKQdCkoRkXbk3MmcgQMH+pgxY7JdDBHpYV577bUqdx/U1mM5F5Rjxozh1VdfzXYxRKSHMbMPd/aYmt4iIu1QUIqItENBKSLSDgWliEg7FJQiIu1QUIqItENBKSLSDgWliEg7FJQiIu1QUIrI7lG3FWp2uGdb2zYshURjWF78ItRWt73f1nXQUNe87h7WF7/YubK2knNDGEUyxh2qV0Df4S23r1sEy2bByKmweQ1UHrLr16mvgTl/hH3Pgrw8WPQ8DN0PzODJ/4aDLoJBk2DDElj3ASyYAVvXwrHfhrx82LYR8gth5bvQZzCM+wS8Ow02LQcMyoZC2TBY/hoUl8Eex8DSV2DdQph0Erz9MBT3gff+DP3HwCk/DK9VUAx7fAI2rYC+w+BPV8Ga9+D0W2BrVSj3puXQawA01MK4o2HtAijsBR+9Ed5vyGTYvBoSDWH/hX+H1bNh/3Nh70+Hcv3xS7DynXD8R18Lz3wb5v6p+fMZ+TGo3wYHnAsTToDXfxu2vfUAzJsOfUfCpujecBNOhPefSu/7vPRZGDElvee2knPzUU6dOtU11lt2UF8TaiEbPoQJx+/4eGM9zPo1FPUKIXDwpWH7P34awmLqxTDnMXj5lrB9xEFRQD0C6xe1fK0RU2F59G/w8CvgzftD0AFYHpSUt11z6j8G1i/uiqPtvDEfh8UvZLsUmXXDxg7tbmavufvUNh9TUEq3teJt+PAlOPTy0MS6+5Mw+vBQG3v2+/CZO2H8cTD7MXj4wubnDd0PNi4LtZvVs+GUH4Ua4dsPNe/z9UXwg7G7/5h6kt6DYMua1Pcvr4Qz74DHvxxqivVbwn9gvSqguC+8cS9Ur4TJn4LaTeE/m30+C3+5OnzPBSXw3hPhtc74BexzZqi5P3ktHHElDJwEi/8B85+EE74He57SocNRUEr3VbcF8ovCH8gbvwt/CMMOgAPPh7tOCvt8bR7ccxpUzd/x+b0Hw5bVu7fMqSooDaF+6JfgD5el/rxBe8LZv4OXb4W9PxUCacjeocn89DfggPPCfxiFpWH/eU+G2uHxN8Jrd8OQfSC/AN58INSWm2qOUy+GV3/d8r1O+RFM/6+wfN3y0ORftwgG7AGv/gZ6DwxN+9L+YZ9NKwAPn3tefvj+CntB/VZorAuh1+SZG+CVO+G/l8GyV0N5h+y98+NOJMAToew73acxvG8GKCglO7ashVXvhv6zwXuFvrohk+GdabBtA0y5sPmPNNv2+WzoB2ztY5fCcTfA/4wITecT/wf+fhMc/d9Qtxn+9t3QnD7y6lAr2vPUsL2kPOzfpOp9WDMPxh8bAmPbJvjodXjplrBt2P7h+YMnh37NrrRkZuifHH5ACK9//CSEYl5+KMvy12Do/rsOqBjIWlBGN6P/GZAP3OnuN7V6vBK4B+gX7XOtu0/f1WsqKLOsoRZm3hZqJ8V9wraV74Tay9KZMOqQUGs581fw+wzeqHDcJ0JH/YiDYPYfwntvWALlo0ITrbYahu4TQq64L6yaDQ+eG577jVVQsw42r4J+o0OIFPUOj70zLdSO6raGvs4Be4TtC2aEmm7vAS3LUbUAZv4STrop1Ma6O/dwIiYXyrqbZSUozSwfmA8cT7iR/SzgXHefk7TPHcAb7v5LM5sMTHf3Mbt6XQVlF0s0hqbWwPFh/Z1pod/ogHNb7vfizaGfLy8/BBOEExkDJ8LjV3S+HKf9LNTqHr0UPv5foeZZXwM/nxKaorWb4eNfCX1bf/seHPX1ls08kU7aVVBmsq59MLDA3RdGhXgQOAOYk7SPA32j5XLgowyWp/vZsjb8sZtl4b2r4Cd7Q+VhsPBZuOL1cALkkYvD4xNPDM3m6V8PTcj5f9nxNV76eervN/640AFftxk2LoU+Q6DXQOgzKNRSC4rDfuc+0PycwlK4ZvGOr3XyTTtuE8mgTAblCMI9kJssA1pfgHYD8LSZXQH0Bo7LYHmy75VfwaiDQ3/U2g9CbWniSeH6uSGTwz71NfD0t+CQy0Oz78YB4I1wzgPNZ/HWfgAV45rP7OYXhFpgwzbIKwyhYwY1G8LlKmbhejuA9/8aapDv/Snsv/DZsP35H4br2JoknxFeM3fHY6k8HJa81PZxfnMN5BXAyrfgjqPhP14JJzUAGNLcnG3SFJIi3VS2e2/PBe529/8zs8OAe81sH3dPJO9kZpcBlwFUVlZmoZidMPdPoX8rLx9m3Rm2Xb0QlvwzLM9/Mvx85tcw9ii491OhJjfrV+Fsp0ejEx48F65fB+8+Co9e0vz6+3wWjr0efrZf87aPfy2clXzymuZtn74jdORX76TSnhyS7Tnn/nDSAmDNfHjpZjjhu+HMda8BUFAUHht+YIevZRPpjjLZR3kYcIO7nxitXwfg7v+TtM9s4CR3XxqtLwQOdfedXu+RM32U6z9sGV5dwfLC5ROpGH0EfNgFw7hK+sHlL4QhYSOnhlEhTbVTkR5kV32UmRzrPQuYYGZjzawIOAd4vNU+S4Bjo0LuBZQAHbiCtZtJNMLr98IL/9f1IQmphySEZndHXPF6y/XL/t70ptCvMpzcGThBISmxlLGgdPcG4MvAU8Bc4PfuPtvMbjSz06PdvgZcamZvAQ8AF3muXdhZvRJWReennv9RGHUw48a29z37d1AUXVLTbzScNw2O+RZc/NeW+x1xFVwyo3PlWj27efmUH+1634GTQr/hxJOTtk0Mv/c+s3PlEOkBMtpHGV0TOb3VtuuTlucAR2SyDBn386lQVx2GXc15bOf7XbM4jG4oHwkzvgtn3xuu3Wsal3zJDPjNiWEUxzHfCidoDvty89jjJv3HhusFm/oukx17fZiwYOZtYb2pTMV9obgcaqP+wtN+Bn+9Pky+sMex8NnfhO17ndZ8druoF3xtvi7BkaxZXb2NFRu2sf+ofi22r9q0jYQ7vYoKKC7Io6QwjNRZt6WO2R9t5F/GD2TFxm0M71faZWXJ9smc3FC7GarmhYubq1dB2ZCwfdWcEJLQdkgefV24LvHzf2weAjb8QLjg0R33HTkVrl/bclufIS3XP/FNOOrqsHzn8bDslZaPD58SZnzpMzjUBPtVwuzTwvLgveD1e8LIj/0/F0aOPHwRnPXb5gvHDzwvzPzSpKzV+8fYhq119OtV1OnXqalrpD6RoG9JYYtlgC21DfQuDn+S7o61cdmYuzNz0ToOHlNB1eZaigryqG1IUL2tnj0G9aG6toGq6lrGDuy9w/MTCeft5RvZf2Q5ZsZLH1QxvLyUMQN705hw3l9dzbJ1NYysKOX+mUs4fI8BHD95KCs3bePHT89n6pj+VPQuYvO2Bv42bzWjK3rxi+c+AOD2Cw7ikLEV3DdzCTMXreOD1ZspzDcqB/TmzSXr+e3FhzBhcB9u/tv7PDBzCZu2NXDcXkMoKjBemF/FxKFlfGxMBXe9uIjahgSlhfnU1IfKwJ5Dy3hvZfg7++4Ze/OtP86mtQMr+/HGkpbdTU9e9XH2HNp3h33ToSGMqbjndFj095YnSI68OoxImf9k28+5+K/hUqDOaGyAN+8LtdDfnRma6k010A1L4af7hOX8YmishfMfDcPhOuPDl0OINl2ulGXb6hv589sr2H9UOeMHl7GtvpHigrztIfDRhhpWV9dSXlrIoqrNVG9rYGT/Uhau2cKEIWU0JpyykgJmzF3N4XsMYMHqzWyta8DMKC8tZGh5CXc8v5B5K6vZsLWOzx40iq+dMJHXl6znsTc+4pHXl20vy6n7DuPIiQOZ/s5KFqzezIatdZyy7zDGDOzN5OF9GTOgN+8u38gVD7yx/TmfmDSIMw4YwS+f+4BRFb14Zu4qAI4YP4AXF4T/GK85aU9+/Y+FVG1OmlcRGD+4DwtWb26xvmJDDVvq2mhNtJKfZxw4qh+LqrawdksdA3oXsXZLeP1+vQrZsLV++77nHVLJfTOXtPk6ZSUFVG9raPf9suHgsRW8smgdEI73sHED+GhDDQurtvC5Qyq5/pOTt9c2U6Gx3p11Q3nH9j/uBviXr3RtGTavCRdnJ/vVsWG6r0MuD83tr87dcS7FbmL+qmoaE05+Xgi4iUPK2FrXQF1DgvLSQpas20plRS9eX7KBs25/mcaEt6hVJBvRr5RDxlXw6OvLd/dh5IzDxg1g1uJ1NCQ69vd93F5DWFS1mdqGBMvW1wAhLK86biLvrdjEqx+uZ1HVFgC+cNQ4BpeVsNfQMjbU1PPB6s089Gq4dPqmM/ejrKSAP7yxnP69ivjJM2FCk/MPreTqE/dkw9Y66hudNdW1/GxGeMww/uMT49lQU8eREwexeVsD3/vzHKa/s5KDx1awz/ByfvPiIiYNKWP6lR8nP89IJJy8pN+doaBMxzPfgX/8GC76M9x9atv7lFeGvsJN0R/sCd+HQ74QLrbeHaNtHjwvzLZz+T9g6L6Zf78km2sbuPOFhRw2bgDjBvVh5qK1/P7VZazbUstnpozkgkNHk59nzFq8nj+99RH3/vPDdl9zZ8G4Oxw6roJT9h3G9UnNuq+fNInBZSW8v6qaycP78v6qzTw4aykTBvehIN9IuLN+Sz1zVmxq8VrnH1pJVXUd4wf34ZZnF2zfvseg3vz83CkMLCvi3eUbmbuimh8+NW/74+MG9uZ3lxxCaWE+G2vqeWbuKj5cu5X+vQoZVdGLqWMqSLhT0auIHz49j7LiAk7aZyh7DevLbX//gE8fOILRA3pvf72l67byrT++y7iBfbj+tMlcM+3t7UE2ol8pT171cTZta+Ds21/m8qP24PxDR7c4jhcXVFG9rZ4TJg/dHkINjQk21zZ0uBviygff4I9vfsT8751MUUH3vLGCgjIdTbVIy9/xxElRWTg50zTbSiIRRrkUlu7e4Yg168Ms1gee3yUv15hw3lq2gSmV/fnnwrXc/eJiFlVtYd6q0D/Uuyif311yCH95dyV3PL+wS95zZ07bfzh/eitcHP+fx4znyImDeGPJBr4/PYwSKsrP45uf3IvDxg1g7MDeLFm3lT+++RFL123lu5/ah38sqOLgMRX0713EM3NWMbS8hG8/Ppufnn0A9Y2JNvvwABasrubGJ+Zyy+cO3N53uCvuzp/fWcHHxlTw0YYalqzbyhkHjNj++NrNtfQpKaAwL6/NGs/GmnqembOKg8dWMKqiV7ofV0oaE86KjTX88rkPuPrESV3S55qq2oZGNtbUM7isZLe9Z0cpKNtTXxOmAvvnL0KfY/JU9BCGGM74TvN6jow2eW/lJgrz8ygvLWT+ymqGlpfQp7iAXzz3AecdUklxQT4j+pdy38wPmfbaMt5eFo7rW5+czHefmNPOq6fn8qP24LcvL2af4eXsPaIvV584iTeXbGDy8L48+e5Knp23ml+cdxD5ecbGmnq21TcypG/LPy53x51ON7VEkikod+WmynCZzK78xyxoqIHbjwzrWQzKxVVbGFRWTO/iAuoaEqzatI3BfYvZ+/qnaEg4Ywf23t6H1NUmDO7D+0knF17/1vEc8v+e4ZR9h/F//7o/G2rqKSsJ5VqxcRt3vbiY/UeWc87Blbg7tQ2JDnWui+xO2Zo9KDe0F5IQbsSUn7mJG1pfClLfmGD+qmouvedV6hqdqs21QMvLJC46fAx/fmcFa6prW7xWuiF55MRBnLbfMK6e9jYAx+45mLeXb2TsgN489IVDeWtZuKxk7HXhstgXrz2Git5FvPfdkzFC7W5gn/AZFRfkU1ZSyP+c2dxvamYKSclZCspUZGDYXvW2evoUF/Do68v52sNvceaUEZy+/3CenrOK+3dyqUZTSALc/dLinb729z+9D0+8tYIpo/tx67PhOrerjpvAs/PW8NbSlteaFeYbB43uz2//PVzKNH9VNZUVvbjgsDEkojOmZsYB0UW/3zx1LzZsrWdEdDFvvpq/EgNqere+9KfXQPjXu8I9WiCcKDnj1rD86xPDmOeDLurw29Q3JthYU8/LH6xlSN8Szr7jZQ4YteNFsqk4c8oIHn19Ofl5xtdPnMT8VZvZWFPPF44ax8A+xYwd2Hzmc8XGGp6Zu5rzDq4kL894+YO19C0toLKiF6uraxm3k5MaInGjpndbtm0MN7Vqrah3uOAawmU+pyVNTntxavcXdnfuenExNz4xh/svOYTP3Tmzzf12FpIPXnYoT89exaNvLGtxYfCeQ8v4xXlTGDeoDz8+6wBqGxopLth1c3ZYeSkXJF32cdgezbcyKEvhrK6IxDkob6qEwW3cES4vv7k/sris3Rs9NSacRVWbGT84NM/fXLqBs257mbrGMNPPzkIyWXFBHq9+8zgWVW2hV1E+4weXcei4AVx/WvPomHeWbaSyohflvQqTnqc+P5HdoXte+bm7rN5xzCjHfad54tkUfOdPsznux88z+6ON3DzjfT5164vbQzLZj8/av83nn7zPUObeeBJlJYXsN7Lf9sBtbd+R5S1CUkR2n/jWKFvrNxqueC3cnW5jakPjVm7cxm9fDiNOTr35Hzs8PnlYX+as2MTEIX04c8pIGhLO/iP7MWfFRr7y0FtAaArrekCR7k1B2SS/qPkWnk33cNnJia75q6r50VPzeHrOqh0eu+nMfRk/uA8j+pcyrLyUhWs2M7AsvN5ZU0cBMGloGQN6FzNr8boW/Yci0j3FMyjXLdpxW15+G8vNQdnQmODulxZzz8uLWbquZqcvfeTEQS3mwRs3qM9O9zty4qA2HxOR7iWefZTT/m3HbZYUlE2zkB993fZNX7rvdb7357k7hOQFh45m1jeabx5ZVhLP/3tEerJ4/lU3RKNZJp0SpkP79fEtz27nF24fpphIODX1jW02swH++5S9KC1qDtneRfH8SEV6snj+VSei2YDyC5ub2Xk7fhRb6xqYfP1T24fmJTt0XAWfP2xMi5AETdQg0hPFNCijGZvzCqBiXFg+4soWu9Q2NDL5+nCBedNY6yZ/v/roFvP+ATzyxcN3mJdQRHqGeAZl8vySpf1bzAb09rINnH5L2/fD/uape/HJ/YYztHzHOfUOGt2fg0b37/Kiikj2xTMoE9EF4YkdZ9NuHZLjB/fhtvOnMKy8dPuNn0QkXuL5l99Uo2w1c/lP/jq/xfq4Qb155qtH7a5SiUg3Fc+gjPooq6q3cc/T8ygvLWRrXSM/m/H+9l2O22sIt50/JVslFJFuJJ5BWTEONq/ilqVjuXvBgh0efuvbJ1BeqnHVIhLEMyj7jyGxajZ3b2zZrP74hIHsPbxcISkiLcQzKBtqqS8ZABtbXvP4y/MPoo9O2IhIK/Ecwrh5FfXFA3bYrJAUkbbEMyjXLWJzH83aIyKpiWcVqn4rtXlhhp/7LzmExWu3cmBlvywXSkS6q3gGpSeoT4T+yWH9Sjl8/MAsF0hEurN4Nr0TjdR7OPSSwnh+BCKSunimhDfS4KFGWZQfz49ARFIXz5RINNIY1SgLC+L5EYhI6uKZEt5IQ3ToqlGKSHvilxLu4Akao6Z3gSbaFZF2xDAowxRrDZ6HGeQrKEWkHfELymjmoBcXrscdzBSUIrJr8QvKhy4AIBHDQxeR9MQvLd4P98FpjOGhi0h6YpsWqlGKSKpimxaqUYpIqmKbFgl0EkdEUhPboCyigbOnjsp2MUQkB8Rz9iCghDr6D+iV7WKISA6IbY2yxOoozFfzW0TaF+saZV5ebP+fEJEOiFdQJhq3L5ZQR0I1ShFJQbyqVPU12xdLrJ45H23KYmFEJFfEq0aZFJSvJCZRXVOfxcKISK6IV42yIQTlfX0u4veNR+Oe5fKISE7IaFCa2UlmNs/MFpjZtTvZ5ywzm2Nms83s/kyWp6lGOXjUJMD4xql7ZfTtRKRnyFjT28zygVuB44FlwCwze9zd5yTtMwG4DjjC3deb2eBMlQeAOY8D0JBfAsDAPsUZfTsR6RkyWaM8GFjg7gvdvQ54EDij1T6XAre6+3oAd1+dwfLAs98DoM6KANDVQSKSikxGxQhgadL6smhbsonARDN70cz+aWYnZbA829VZqEnma9JeEUlBts96FwATgKOBkcDzZravu29I3snMLgMuA6isrOz0m9ZaaHrrNhAikopM1iiXA8mzToyMtiVbBjzu7vXuvgiYTwjOFtz9Dnef6u5TBw0a1OmC1VsReabbQIhIajIZlLOACWY21syKgHOAx1vt8xihNomZDSQ0xRdmsEwAbKNQtUkRSVnGgtLdG4AvA08Bc4Hfu/tsM7vRzE6PdnsKWGtmc4BngavdfW2mytQk4ZCn2qSIpCijfZTuPh2Y3mrb9UnLDnw1+sm8wt5Qv4X1BUPIz1va/v4iImT/ZM7u1X8MVIylEZ3xFpHUxetKwkQ95BWQSDh56qMUkRTFJygTjVA1HxINNLrrZI6IpCw+QfnOtPD7vSdoTCgoRSR18QnKLWu2LzYmXH2UIpKy+ARlY23zYkKjckQkdfE56+2J7YuPvL4siwURkVwTnxqlxedQRaRrxSc9mm4s9oUXslsOEck58QvKofsCcNDo/lksjIjkkhgFZQNYPphRVlzAfiPLs10iEckR8QrKvHwAHE2KISKpi09QeiPkhZP8CXd0dZCIpCo+QZloHZRKShFJTTyuo2xsgH/+AvIKgTAfJcpJEUlRPGqUy18LvxP14bcm7hWRDohHULaiPkoR6YiYBKW3WEu4Y2p7i0iK4hGU3jIow+VB2SmKiOSeeARlUo3S3XHXrWpFJHXxCMqkmYOaKpfKSRFJVUyCMqlGGf3WWW8RSVU8gjKp6Z2IQlN9lCKSqngEZVLTuyko1UcpIqmKSVBGNcr9zlYfpYh0WDyCsqnpPfXftwel+ihFJFXxCMrtTW9TH6WIdFhMgjL6bc1BqZE5IpKqeARlc1ImZ6aISEraDUozO80sx29h2NT0trzti+qjFJFUpRKAZwPvm9kPzGzPTBcoI7af6tZ1lCLSce0GpbufDxwIfADcbWYvm9llZlaW8dJ1meamt66jFJGOSqlJ7e6bgGnAg8Aw4NPA62Z2RQbL1nW21yjzkoYwZq00IpJjUumjPN3M/gA8BxQCB7v7ycD+wNcyW7wusr2PUjVKEem4VO6Z8xngJ+7+fPJGd99qZhdnplhdLemst0bmiEgHpRKUNwArmlbMrBQY4u6L3X1GpgrWpZKb3hqZIyIdlEof5cNAImm9MdqWO9poequPUkRSlUpQFrh7XdNKtFyUuSJlgs56i0j6UgnKNWZ2etOKmZ0BVGWuSBnQRtNbMSkiqUqlj/Jy4D4zu4WQL0uBz2e0VF0tqemtPkoR6ah2g9LdPwAONbM+0frmjJcqY5L6KHN7UKaI7Eap1Cgxs1OBvYGSpr49d78xg+XqWknXBGn2IBHpqHaD0sxuA3oBnwDuBD4LvJLhcnWxEI41DQm+8shbgK6jFJHUpdIAPdzdPw+sd/fvAIcBEzNbrC4W9VE+NXs1by3dAKiPUkRSl0pQbot+bzWz4UA9Ybx37oia25vrGrZvUk6KSKpS6aP8k5n1A34IvE5ox/4qo6XqciEoE978/8J+I/plqzAikmN2GZTRhL0z3H0D8IiZPQGUuPvG3VK6rhI1vesbQ2BOGlJG5YBe2SyRiOSQXTa93T0B3Jq0XptzIQnbm97bGkNgTvviYdksjYjkmFT6KGeY2Wcsp8f8RUFZ7/TrVUhZSWGWyyMiuSSVoPwCYRKMWjPbZGbVZrYpw+XqWlHTe1tDgpKC/CwXRkRyTSojc3Lolg874c01ytIiBaWIdEwqM5wf2dZPKi9uZieZ2TwzW2Bm1+5iv+EpJW8AAA9XSURBVM+YmZvZ1I4UPnUhKJ97v4qifI1dFJGOSeXyoKuTlkuAg4HXgGN29SQzyyecCDoeWAbMMrPH3X1Oq/3KgCuBmR0od8c0Nb3rnaWrqjP2NiLSM6XS9D4ted3MRgE/TeG1DwYWuPvC6HkPAmcAc1rt913gf2kZyF0ranq7xneLSBrSaYcuA/ZKYb8RhCnZkp83InkHM5sCjHL3P6dRjg7z9ncREdlBKpNi/JzmjMkDDiCM0OmU6GL2HwMXpbDvZcBlAJWVlR1/s6hGmVCNUkTSkEof5atJyw3AA+7+YgrPWw6MSlofGW1rUgbsAzwXXaI5FHjczE539+T3xN3vAO4AmDp1ascrhlEfpZreIpKOVIJyGrDN3RshnKQxs17uvrWd580CJpjZWEJAngN8runBaITPwKZ1M3sO+K/WIdk11EcpIulLaWQOUJq0Xgo8096T3L0B+DLwFDAX+L27zzazG5PvwbNbJJ3MOXW/3Jr4SESyL5UaZUny7R/cfbOZpTSjhLtPB6a32nb9TvY9OpXXTEvU9O7fu5ibzzkwY28jIj1TKjXKLdHZaQDM7CCgJnNFyoRQo+zXq4h83dBbRDoolRrlVcDDZvYR4S6MQ4GzM1qqrhY1vYuLUrpFkIhIC6lccD7LzPYEJkWb5rl7fWaL1cWipnd5aVGWCyIiuSiVsd7/AfR293fd/V2gj5l9KfNF60qhRtm/d3GWyyEiuSiVPspLoxnOAXD39cClmStSBnhzH6WISEelEpT5yZP2RpNd5FTiNN3Lu3dJThVbRLqJVM5uPAk8ZGa3R+tfAP6SuSJ1vcbGRvKAUp3MEZE0pJIc1xDGWV8erb9NOPOdM+obGykESgo1aa+IdFy7Te/oBmMzgcWEqdOOIYy0yRn1DY0AlBbpXjki0nE7rVGa2UTg3OinCngIwN0/sXuK1nUaGkNQlqjpLSJp2FVyvAe8AHzS3RcAmNlXdkupulhDQ7iOsqRQQSkiHberpveZwArgWTP7lZkdC7k5/U5jIgpK3VhMRNKw06B098fc/RxgT+BZwlDGwWb2SzM7YXcVsCs0JhpJuFGoG4uJSBpSOZmzxd3vj+6dMxJ4g3AmPGckEo6DglJE0tKh5HD39e5+h7sfm6kCZUIikSBBnm5VKyJpiUVyJBKNOFCQn5NdrCKSZTEJSsdRH6WIpCcWyZFIJABT01tE0hKL5Ei4k8AoLFDTW0Q6Lh5BmWhU01tE0haL5NDlQSLSGbFIjqbLgwp11ltE0hCLoMQTOOgOjCKSlpgEpQNGnikoRaTjYhGUTjjrraAUkXTEIihD09tQy1tE0hGToAxnvU01ShFJQ4yCUiEpIumJR1CSUFCKSNriEZSqUYpIJygoRUTaEY+gREEpIumLR1C6+ihFJH0xCUrVKEUkffEISlBQikja4hGUnsB1sbmIpCkmQenZLoGI5LB4BCVOIi6HKiJdLhbpYYSbi4mIpCMWQdk0KYaISDpiE5SqUYpIuuIRlNHEvSIi6YhHULqDLg8SkTTFIyg11ltEOiEeQakhjCLSCbEISl0eJCKdEYugVI1SRDojHkGJ4xaTQxWRLheL9DBdcC4inRCLoARdcC4i6YtHUGpkjoh0QkaD0sxOMrN5ZrbAzK5t4/GvmtkcM3vbzGaY2ejMlCRBQheci0iaMhaUZpYP3AqcDEwGzjWzya12ewOY6u77AdOAH2SkLKpRikgnZLJGeTCwwN0Xunsd8CBwRvIO7v6su2+NVv8JjMxccRSUIpKeTAblCGBp0vqyaNvOXAz8pa0HzOwyM3vVzF5ds2ZNx0uiW0GISCd0i5M5ZnY+MBX4YVuPu/sd7j7V3acOGjSo46+vsd4i0gkFGXzt5cCopPWR0bYWzOw44BvAUe5em5GSqI9SRDohkzXKWcAEMxtrZkXAOcDjyTuY2YHA7cDp7r46c0VxvHtUnkUkB2UsPdy9Afgy8BQwF/i9u882sxvN7PRotx8CfYCHzexNM3t8Jy/XKYbjqlCKSJoy2fTG3acD01ttuz5p+bhMvn/Sm6Kmt4ikKxbtUdOkGCLSCfFID9d8lCKSvlgEpWlSDBHphFgEJaCcFJG0xSQodXmQiKQvFulhGsIoIp0Qj6BUH6WIdEIsghLQWG8RSVssgtI8AWp6i0ia4hGUanqLSCfEIigBjcwRkbTFIj1MI3NEpBPiEZRqeotIJ8QiKMF1MkdE0haLoAyzBykoRSQ9sQlKNb1FJF2xCEpN3CsinRGLoDQAXR4kImmKRXoYGpkjIumLRVCiPkoR6YRYBKWBznqLSNriEZQamSMinRCPoNQF5yLSCbEISkBnvUUkbbFIjzzU9BaR9MUiKAE1vUUkbbEISg1hFJHOiEVQ5pFQH6WIpC0+6aEKpYikKRZBae7E5FBFJANikR6aj1JEOiM2QWkKShFJU2yCUp2UIpKumASlblcrIumLRXqYRuaISCfEJCidPPVRikiaenxQJhIe6pJ5Pf5QRSRDenx6NCRcZ71FpFN6fFAm3KP5KHv8oYpIhvT49GiMapTqoxSRdPX4oGxo6qNUjVJE0tTj0yORcPJIqI9SRNLW44OyqUapoBSRdPX4oHxv5SbAsbz8bBdFRHJUjw/KC379Cnm6PEhEOqHHB6WRoNAa8fzibBdFRHJUjw/KIhoA8IKiLJdERHJVjw/KYuoAqEdBKSLp6dFB2dCYoJh6AOpMQSki6enRQVmQn8fnpgwGoI7CLJdGRHJVRoPSzE4ys3lmtsDMrm3j8WIzeyh6fKaZjenqMvTKD32U21xBKSLpyVhQmlk+cCtwMjAZONfMJrfa7WJgvbuPB34C/G9Xl6PUQlDWKihFJE2ZrFEeDCxw94XuXgc8CJzRap8zgHui5WnAsdbFFzxOXjcDUI1SRNKXyaAcASxNWl8WbWtzH3dvADYCA7qsBNWrmLLyQV5PjGe/w47rspcVkXgpyHYBUmFmlwGXAVRWVqb+xLIh5F34BFOG7A1FvTJUOhHp6TJZo1wOjEpaHxlta3MfMysAyoG1rV/I3e9w96nuPnXQoEEdK8WojykkRaRTMhmUs4AJZjbWzIqAc4DHW+3zOHBhtPxZ4G/u7hksk4hIh2Ws6e3uDWb2ZeApIB/4jbvPNrMbgVfd/XHg18C9ZrYAWEcIUxGRbiWjfZTuPh2Y3mrb9UnL24B/zWQZREQ6q0ePzBER6QoKShGRdigoRUTaoaAUEWmHglJEpB0KShGRdigoRUTaYbk2EMbM1gAfdvBpA4GqDBQnG3rKsfSU4wAdS3fV0WMZ7e5tjpHOuaBMh5m96u5Ts12OrtBTjqWnHAfoWLqrrjwWNb1FRNqhoBQRaUdcgvKObBegC/WUY+kpxwE6lu6qy44lFn2UIiKdEZcapYhI2np0ULZ3u9zuxsxGmdmzZjbHzGab2ZXR9goz+6uZvR/97h9tNzO7OTq+t81sSnaPoCUzyzezN8zsiWh9bHRb4gXRbYqLou0Zv21xZ5hZPzObZmbvmdlcMzssh7+Tr0T/tt41swfMrCRXvhcz+42ZrTazd5O2dfh7MLMLo/3fN7ML23qvHbh7j/whTBb8ATAOKALeAiZnu1ztlHkYMCVaLgPmE271+wPg2mj7tcD/RsunAH8BDDgUmJntY2h1PF8F7geeiNZ/D5wTLd8GfDFa/hJwW7R8DvBQtsve6jjuAS6JlouAfrn4nRBu5rcIKE36Pi7Kle8FOBKYArybtK1D3wNQASyMfvePlvu3+97Z/vIy+KEeBjyVtH4dcF22y9XBY/gjcDwwDxgWbRsGzIuWbwfOTdp/+37Z/iHcI2kGcAzwRPQPtgooaP39EGbBPyxaLoj2s2wfQ1Se8ihcrNX2XPxOmu56WhF9zk8AJ+bS9wKMaRWUHfoegHOB25O2t9hvZz89uemdyu1yu62omXMgMBMY4u4roodWAkOi5e58jD8Fvg4kovUBwAYPtyWGlmXN7G2LO2cssAa4K+pGuNPMepOD34m7Lwd+BCwBVhA+59fIze+lSUe/h7S+n54clDnLzPoAjwBXufum5Mc8/DfYrS9VMLNPAqvd/bVsl6ULFBCae7909wOBLYQm3na58J0ARP13ZxDCfzjQGzgpq4XqQpn8HnpyUKZyu9xux8wKCSF5n7s/Gm1eZWbDoseHAauj7d31GI8ATjezxcCDhOb3z4B+0W2JoWVZU7ptcZYsA5a5+8xofRohOHPtOwE4Dljk7mvcvR54lPBd5eL30qSj30Na309PDspUbpfbrZiZEe5MOdfdf5z0UPJtfS8k9F02bf98dIbvUGBjUjMka9z9Oncf6e5jCJ/739z9POBZwm2JYcfj6Ja3LXb3lcBSM5sUbToWmEOOfSeRJcChZtYr+rfWdCw5970k6ej38BRwgpn1j2rYJ0Tbdi3bHcwZ7vg9hXDm+APgG9kuTwrl/RdC0+Ft4M3o5xRCv9AM4H3gGaAi2t+AW6PjeweYmu1jaOOYjqb5rPc44BVgAfAwUBxtL4nWF0SPj8t2uVsdwwHAq9H38hjhbGlOfifAd4D3gHeBe4HiXPlegAcIfav1hJr+xel8D8C/R8e0APi3VN5bI3NERNrRk5veIiJdQkEpItIOBaWISDsUlCIi7VBQioi0Q0Ep3ZaZNZrZm0k/XTYDlJmNSZ6FRmRXCtrfRSRratz9gGwXQkQ1Ssk5ZrbYzH5gZu+Y2StmNj7aPsbM/hbNPzjDzCqj7UPM7A9m9lb0c3j0Uvlm9qtofsanzaw02v8/LcwJ+raZPZilw5RuREEp3Vlpq6b32UmPbXT3fYFbCDMVAfwcuMfd9wPuA26Ott8M/N3d9yeM054dbZ8A3OruewMbgM9E268FDoxe5/JMHZzkDo3MkW7LzDa7e582ti8GjnH3hdEkIivdfYCZVRHmJqyPtq9w94FmtgYY6e61Sa8xBviru0+I1q8BCt39e2b2JLCZMFzxMXffnOFDlW5ONUrJVb6T5Y6oTVpupLnP/lTCOOEpwKykmXUkphSUkqvOTvr9crT8EmG2IoDzgBei5RnAF2H7fXzKd/aiZpYHjHL3Z4FrCFOL7VCrlXjR/5TSnZWa2ZtJ60+6e9MlQv3N7G1CrfDcaNsVhJnIrybMSv5v0fYrgTvM7GJCzfGLhFlo2pIP/C4KUwNudvcNXXZEkpPURyk5J+qjnOruVdkui8SDmt4iIu1QjVJEpB2qUYqItENBKSLSDgWliEg7FJQiIu1QUIqItENBKSLSjv8P+eaQRQ3xG0UAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extract the accuracy and loss values from the history object\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the first graph in the first subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(acc, label='Training accuracy')\n",
        "plt.plot(val_acc, label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Plot the second graph in the second subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRFS4ZGMioYT",
        "outputId": "b101708c-1b4b-4cb0-f070-8e76d4b402d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 8999.3369 - accuracy: 0.1269 - val_loss: 6384.4287 - val_accuracy: 0.0052\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 7598.2627 - accuracy: 0.1273 - val_loss: 5270.9937 - val_accuracy: 0.0043\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 6529.5312 - accuracy: 0.0912 - val_loss: 4892.1494 - val_accuracy: 0.0067\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 5769.7363 - accuracy: 0.0425 - val_loss: 4218.0933 - val_accuracy: 0.0136\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 5101.8047 - accuracy: 0.0430 - val_loss: 3737.3274 - val_accuracy: 0.1145\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4513.3267 - accuracy: 0.1104 - val_loss: 3373.8928 - val_accuracy: 0.2379\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3954.6655 - accuracy: 0.3950 - val_loss: 2940.8396 - val_accuracy: 0.3315\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3432.8994 - accuracy: 0.4056 - val_loss: 2518.2637 - val_accuracy: 0.2918\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3100.7112 - accuracy: 0.3485 - val_loss: 2377.0549 - val_accuracy: 0.2513\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 2852.3784 - accuracy: 0.3840 - val_loss: 2199.6743 - val_accuracy: 0.2187\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 2660.3472 - accuracy: 0.2717 - val_loss: 2011.2109 - val_accuracy: 0.2136\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 2504.3979 - accuracy: 0.3200 - val_loss: 1861.6267 - val_accuracy: 0.2135\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2390.9924 - accuracy: 0.3360 - val_loss: 1775.9833 - val_accuracy: 0.2628\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 2331.3057 - accuracy: 0.4050 - val_loss: 1735.6125 - val_accuracy: 0.5271\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 2299.5925 - accuracy: 0.3936 - val_loss: 1705.7991 - val_accuracy: 0.5983\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 2270.2231 - accuracy: 0.4122 - val_loss: 1693.1517 - val_accuracy: 0.6138\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 2252.2708 - accuracy: 0.4255 - val_loss: 1677.1173 - val_accuracy: 0.6111\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 2236.8999 - accuracy: 0.4405 - val_loss: 1656.5293 - val_accuracy: 0.6196\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 2221.0525 - accuracy: 0.4541 - val_loss: 1641.8850 - val_accuracy: 0.6277\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 2202.0469 - accuracy: 0.4530 - val_loss: 1622.6069 - val_accuracy: 0.6526\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 2187.7095 - accuracy: 0.4746 - val_loss: 1607.2968 - val_accuracy: 0.6632\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 2174.5000 - accuracy: 0.4933 - val_loss: 1604.9590 - val_accuracy: 0.6878\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 2167.2761 - accuracy: 0.4793 - val_loss: 1592.1243 - val_accuracy: 0.6838\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 2167.1418 - accuracy: 0.5128 - val_loss: 1595.3093 - val_accuracy: 0.6871\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 2162.6697 - accuracy: 0.5239 - val_loss: 1573.3619 - val_accuracy: 0.6862\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 2141.4932 - accuracy: 0.5145 - val_loss: 1577.2240 - val_accuracy: 0.6940\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 2138.7737 - accuracy: 0.5222 - val_loss: 1551.6406 - val_accuracy: 0.6887\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 2123.4124 - accuracy: 0.5240 - val_loss: 1548.8545 - val_accuracy: 0.6894\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2116.6169 - accuracy: 0.5318 - val_loss: 1540.2556 - val_accuracy: 0.6993\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 2078.0181 - accuracy: 0.6268 - val_loss: 1462.1646 - val_accuracy: 0.7339\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1976.4412 - accuracy: 0.6473 - val_loss: 1304.7141 - val_accuracy: 0.7400\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1927.0077 - accuracy: 0.6463 - val_loss: 1251.8384 - val_accuracy: 0.7551\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1861.5797 - accuracy: 0.6795 - val_loss: 1215.6870 - val_accuracy: 0.7526\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1665.8458 - accuracy: 0.6674 - val_loss: 1091.3439 - val_accuracy: 0.7534\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1570.3149 - accuracy: 0.5753 - val_loss: 1081.9773 - val_accuracy: 0.7558\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1541.8475 - accuracy: 0.6842 - val_loss: 1057.6606 - val_accuracy: 0.7544\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1517.0066 - accuracy: 0.6775 - val_loss: 1038.1923 - val_accuracy: 0.7564\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1501.8250 - accuracy: 0.6757 - val_loss: 1028.3905 - val_accuracy: 0.7589\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1494.9191 - accuracy: 0.6893 - val_loss: 1023.6771 - val_accuracy: 0.7566\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1483.1299 - accuracy: 0.6981 - val_loss: 1004.7835 - val_accuracy: 0.7568\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1477.4341 - accuracy: 0.6930 - val_loss: 1001.5205 - val_accuracy: 0.7573\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1472.2573 - accuracy: 0.6961 - val_loss: 998.6873 - val_accuracy: 0.7579\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1440.8217 - accuracy: 0.6938 - val_loss: 943.3411 - val_accuracy: 0.7550\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1255.7887 - accuracy: 0.6640 - val_loss: 864.6240 - val_accuracy: 0.7463\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1209.8580 - accuracy: 0.6075 - val_loss: 842.4281 - val_accuracy: 0.7577\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1180.1138 - accuracy: 0.6898 - val_loss: 831.5773 - val_accuracy: 0.7480\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1164.5332 - accuracy: 0.6967 - val_loss: 816.2288 - val_accuracy: 0.7501\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1150.6705 - accuracy: 0.6945 - val_loss: 809.6901 - val_accuracy: 0.7563\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1148.7955 - accuracy: 0.6965 - val_loss: 806.2614 - val_accuracy: 0.7546\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1142.7306 - accuracy: 0.6966 - val_loss: 794.3189 - val_accuracy: 0.7532\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1134.8346 - accuracy: 0.7014 - val_loss: 787.3793 - val_accuracy: 0.7600\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1132.0704 - accuracy: 0.7015 - val_loss: 787.3683 - val_accuracy: 0.7548\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1128.4362 - accuracy: 0.7009 - val_loss: 785.2870 - val_accuracy: 0.7593\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1126.1249 - accuracy: 0.7056 - val_loss: 788.7872 - val_accuracy: 0.7630\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1127.6506 - accuracy: 0.7036 - val_loss: 783.5148 - val_accuracy: 0.7593\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1123.5486 - accuracy: 0.7079 - val_loss: 782.2650 - val_accuracy: 0.7570\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1124.0347 - accuracy: 0.7058 - val_loss: 784.2042 - val_accuracy: 0.7584\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1122.0858 - accuracy: 0.7012 - val_loss: 780.5304 - val_accuracy: 0.7599\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1118.4564 - accuracy: 0.7111 - val_loss: 775.0953 - val_accuracy: 0.7594\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1114.4524 - accuracy: 0.7100 - val_loss: 776.3611 - val_accuracy: 0.7620\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1113.8887 - accuracy: 0.7115 - val_loss: 779.0113 - val_accuracy: 0.7584\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1117.4673 - accuracy: 0.7146 - val_loss: 784.7511 - val_accuracy: 0.7621\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1114.8163 - accuracy: 0.7131 - val_loss: 774.5370 - val_accuracy: 0.7590\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1113.2529 - accuracy: 0.7148 - val_loss: 771.9756 - val_accuracy: 0.7594\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1108.3379 - accuracy: 0.7162 - val_loss: 785.4905 - val_accuracy: 0.7627\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1112.8356 - accuracy: 0.7162 - val_loss: 771.7632 - val_accuracy: 0.7638\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1106.3147 - accuracy: 0.7190 - val_loss: 791.5029 - val_accuracy: 0.7623\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1118.2836 - accuracy: 0.7189 - val_loss: 775.9425 - val_accuracy: 0.7704\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1116.9816 - accuracy: 0.7260 - val_loss: 775.5737 - val_accuracy: 0.7652\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1104.1438 - accuracy: 0.7245 - val_loss: 767.5028 - val_accuracy: 0.7652\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1098.8960 - accuracy: 0.7207 - val_loss: 768.3516 - val_accuracy: 0.7709\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1100.3260 - accuracy: 0.7276 - val_loss: 769.4710 - val_accuracy: 0.7671\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1098.8845 - accuracy: 0.7232 - val_loss: 767.0199 - val_accuracy: 0.7715\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1101.0957 - accuracy: 0.7240 - val_loss: 767.3740 - val_accuracy: 0.7708\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1098.4645 - accuracy: 0.7262 - val_loss: 772.7469 - val_accuracy: 0.7725\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1095.7823 - accuracy: 0.7248 - val_loss: 763.9860 - val_accuracy: 0.7735\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1091.4139 - accuracy: 0.7261 - val_loss: 764.1908 - val_accuracy: 0.7713\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1090.4323 - accuracy: 0.7281 - val_loss: 767.3096 - val_accuracy: 0.7760\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1094.0638 - accuracy: 0.7235 - val_loss: 759.9365 - val_accuracy: 0.7709\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1091.1428 - accuracy: 0.7266 - val_loss: 766.8949 - val_accuracy: 0.7739\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1093.2732 - accuracy: 0.7217 - val_loss: 760.0302 - val_accuracy: 0.7770\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1093.9656 - accuracy: 0.7257 - val_loss: 763.9202 - val_accuracy: 0.7669\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1089.8823 - accuracy: 0.7276 - val_loss: 761.2784 - val_accuracy: 0.7782\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1086.9542 - accuracy: 0.7329 - val_loss: 759.4376 - val_accuracy: 0.7782\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1084.9061 - accuracy: 0.7277 - val_loss: 759.3215 - val_accuracy: 0.7798\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1084.3794 - accuracy: 0.7305 - val_loss: 758.2243 - val_accuracy: 0.7717\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1082.3905 - accuracy: 0.7313 - val_loss: 760.9709 - val_accuracy: 0.7750\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1085.3815 - accuracy: 0.7294 - val_loss: 757.4330 - val_accuracy: 0.7773\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1082.1876 - accuracy: 0.7265 - val_loss: 758.7288 - val_accuracy: 0.7725\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1083.3505 - accuracy: 0.7321 - val_loss: 756.7343 - val_accuracy: 0.7684\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1089.1549 - accuracy: 0.7330 - val_loss: 756.2221 - val_accuracy: 0.7825\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1086.6223 - accuracy: 0.7300 - val_loss: 766.6575 - val_accuracy: 0.7694\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1084.9606 - accuracy: 0.7313 - val_loss: 756.6467 - val_accuracy: 0.7775\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1079.5106 - accuracy: 0.7335 - val_loss: 753.3883 - val_accuracy: 0.7782\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1077.0106 - accuracy: 0.7310 - val_loss: 752.2047 - val_accuracy: 0.7774\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1076.7604 - accuracy: 0.7341 - val_loss: 755.4332 - val_accuracy: 0.7822\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1075.7188 - accuracy: 0.7328 - val_loss: 754.0986 - val_accuracy: 0.7772\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1075.9554 - accuracy: 0.7362 - val_loss: 753.1130 - val_accuracy: 0.7742\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1073.9175 - accuracy: 0.7324 - val_loss: 753.0346 - val_accuracy: 0.7808\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1076.0217 - accuracy: 0.7301 - val_loss: 755.0497 - val_accuracy: 0.7711\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1073.8629 - accuracy: 0.7303 - val_loss: 753.7188 - val_accuracy: 0.7809\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1074.0881 - accuracy: 0.7318 - val_loss: 751.2048 - val_accuracy: 0.7806\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1071.0378 - accuracy: 0.7340 - val_loss: 753.5296 - val_accuracy: 0.7811\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1072.4076 - accuracy: 0.7323 - val_loss: 750.4169 - val_accuracy: 0.7703\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1070.9425 - accuracy: 0.7313 - val_loss: 752.0409 - val_accuracy: 0.7798\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1070.7517 - accuracy: 0.7339 - val_loss: 748.6412 - val_accuracy: 0.7715\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1069.0625 - accuracy: 0.7373 - val_loss: 750.0363 - val_accuracy: 0.7766\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1070.6666 - accuracy: 0.7327 - val_loss: 750.7720 - val_accuracy: 0.7840\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1070.7172 - accuracy: 0.7384 - val_loss: 748.4170 - val_accuracy: 0.7735\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1068.5491 - accuracy: 0.7321 - val_loss: 750.2237 - val_accuracy: 0.7814\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1067.3599 - accuracy: 0.7350 - val_loss: 751.3839 - val_accuracy: 0.7800\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1067.9871 - accuracy: 0.7352 - val_loss: 758.2498 - val_accuracy: 0.7778\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1071.7156 - accuracy: 0.7347 - val_loss: 750.0831 - val_accuracy: 0.7796\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1067.2936 - accuracy: 0.7363 - val_loss: 748.3222 - val_accuracy: 0.7736\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1066.6138 - accuracy: 0.7360 - val_loss: 748.9478 - val_accuracy: 0.7797\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1069.3724 - accuracy: 0.7354 - val_loss: 750.4490 - val_accuracy: 0.7814\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1068.2284 - accuracy: 0.7354 - val_loss: 749.4870 - val_accuracy: 0.7847\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1076.6422 - accuracy: 0.7379 - val_loss: 760.9136 - val_accuracy: 0.7732\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1070.9238 - accuracy: 0.7347 - val_loss: 746.3643 - val_accuracy: 0.7814\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1063.7126 - accuracy: 0.7351 - val_loss: 749.1719 - val_accuracy: 0.7830\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1065.3475 - accuracy: 0.7404 - val_loss: 748.6874 - val_accuracy: 0.7785\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1069.3845 - accuracy: 0.7357 - val_loss: 745.4742 - val_accuracy: 0.7771\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1066.7933 - accuracy: 0.7404 - val_loss: 758.7108 - val_accuracy: 0.7784\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1075.9115 - accuracy: 0.7379 - val_loss: 746.3605 - val_accuracy: 0.7734\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1064.9525 - accuracy: 0.7377 - val_loss: 750.8040 - val_accuracy: 0.7932\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1064.5337 - accuracy: 0.7361 - val_loss: 746.7769 - val_accuracy: 0.7784\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1060.5813 - accuracy: 0.7349 - val_loss: 743.4340 - val_accuracy: 0.7788\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1060.1194 - accuracy: 0.7400 - val_loss: 743.1293 - val_accuracy: 0.7789\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1059.9001 - accuracy: 0.7401 - val_loss: 746.7828 - val_accuracy: 0.7865\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1060.6406 - accuracy: 0.7408 - val_loss: 744.8140 - val_accuracy: 0.7821\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1060.1736 - accuracy: 0.7399 - val_loss: 742.5436 - val_accuracy: 0.7805\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1060.4055 - accuracy: 0.7416 - val_loss: 746.3207 - val_accuracy: 0.7862\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1065.6393 - accuracy: 0.7362 - val_loss: 753.2535 - val_accuracy: 0.7909\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1065.3376 - accuracy: 0.7357 - val_loss: 744.2193 - val_accuracy: 0.7830\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1061.0554 - accuracy: 0.7351 - val_loss: 746.8291 - val_accuracy: 0.7807\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1063.8344 - accuracy: 0.7390 - val_loss: 745.2827 - val_accuracy: 0.7801\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1059.0287 - accuracy: 0.7435 - val_loss: 744.0281 - val_accuracy: 0.7830\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1057.7988 - accuracy: 0.7408 - val_loss: 742.7373 - val_accuracy: 0.7847\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1058.8009 - accuracy: 0.7422 - val_loss: 741.1000 - val_accuracy: 0.7797\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1057.7526 - accuracy: 0.7422 - val_loss: 741.4503 - val_accuracy: 0.7837\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1059.0958 - accuracy: 0.7411 - val_loss: 740.7920 - val_accuracy: 0.7800\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1057.5753 - accuracy: 0.7423 - val_loss: 744.0823 - val_accuracy: 0.7848\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1058.0380 - accuracy: 0.7415 - val_loss: 740.5066 - val_accuracy: 0.7851\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1055.7762 - accuracy: 0.7440 - val_loss: 741.6025 - val_accuracy: 0.7840\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1055.8425 - accuracy: 0.7439 - val_loss: 740.6304 - val_accuracy: 0.7854\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1055.2693 - accuracy: 0.7431 - val_loss: 740.2794 - val_accuracy: 0.7913\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1053.6184 - accuracy: 0.7443 - val_loss: 746.1378 - val_accuracy: 0.7880\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1058.0149 - accuracy: 0.7418 - val_loss: 739.8637 - val_accuracy: 0.7891\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1054.3943 - accuracy: 0.7455 - val_loss: 738.4792 - val_accuracy: 0.7846\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1052.6600 - accuracy: 0.7443 - val_loss: 737.8019 - val_accuracy: 0.7897\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1051.9950 - accuracy: 0.7434 - val_loss: 738.6441 - val_accuracy: 0.7841\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1051.5094 - accuracy: 0.7432 - val_loss: 737.5378 - val_accuracy: 0.7862\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1052.6580 - accuracy: 0.7442 - val_loss: 746.9749 - val_accuracy: 0.7852\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1057.5082 - accuracy: 0.7402 - val_loss: 739.2000 - val_accuracy: 0.7896\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1054.9261 - accuracy: 0.7409 - val_loss: 737.6635 - val_accuracy: 0.7902\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1049.9553 - accuracy: 0.7422 - val_loss: 736.5392 - val_accuracy: 0.7838\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1049.8840 - accuracy: 0.7468 - val_loss: 737.7015 - val_accuracy: 0.7841\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1050.1106 - accuracy: 0.7442 - val_loss: 736.5679 - val_accuracy: 0.7880\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1050.6942 - accuracy: 0.7465 - val_loss: 736.7151 - val_accuracy: 0.7846\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1051.5441 - accuracy: 0.7435 - val_loss: 737.1413 - val_accuracy: 0.7897\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1049.6997 - accuracy: 0.7449 - val_loss: 735.4227 - val_accuracy: 0.7846\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1047.9659 - accuracy: 0.7468 - val_loss: 736.0172 - val_accuracy: 0.7960\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1048.0818 - accuracy: 0.7442 - val_loss: 736.3572 - val_accuracy: 0.7952\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1047.8423 - accuracy: 0.7472 - val_loss: 738.1386 - val_accuracy: 0.7964\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1046.8989 - accuracy: 0.7456 - val_loss: 736.6355 - val_accuracy: 0.7888\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1047.6326 - accuracy: 0.7446 - val_loss: 736.1575 - val_accuracy: 0.7979\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1047.3496 - accuracy: 0.7421 - val_loss: 742.6121 - val_accuracy: 0.7874\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1048.1249 - accuracy: 0.7466 - val_loss: 734.7023 - val_accuracy: 0.7902\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1048.2887 - accuracy: 0.7461 - val_loss: 737.4863 - val_accuracy: 0.7917\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1057.4226 - accuracy: 0.7435 - val_loss: 738.6540 - val_accuracy: 0.7888\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1050.1118 - accuracy: 0.7469 - val_loss: 735.3592 - val_accuracy: 0.7908\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1047.2882 - accuracy: 0.7444 - val_loss: 737.4810 - val_accuracy: 0.7917\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1047.5364 - accuracy: 0.7446 - val_loss: 734.1254 - val_accuracy: 0.8020\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1047.2559 - accuracy: 0.7444 - val_loss: 733.8074 - val_accuracy: 0.7885\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1045.3502 - accuracy: 0.7464 - val_loss: 735.1304 - val_accuracy: 0.7935\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1045.2362 - accuracy: 0.7470 - val_loss: 735.4064 - val_accuracy: 0.7901\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1045.0819 - accuracy: 0.7442 - val_loss: 733.8596 - val_accuracy: 0.7907\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1045.6290 - accuracy: 0.7457 - val_loss: 736.0463 - val_accuracy: 0.7903\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1047.9818 - accuracy: 0.7433 - val_loss: 734.2609 - val_accuracy: 0.7912\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1045.5305 - accuracy: 0.7467 - val_loss: 734.6741 - val_accuracy: 0.7917\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1044.3719 - accuracy: 0.7461 - val_loss: 735.8235 - val_accuracy: 0.7964\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1050.1486 - accuracy: 0.7460 - val_loss: 751.7107 - val_accuracy: 0.7972\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1058.1293 - accuracy: 0.7448 - val_loss: 739.4258 - val_accuracy: 0.7961\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1046.0494 - accuracy: 0.7479 - val_loss: 734.8325 - val_accuracy: 0.7914\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1045.4430 - accuracy: 0.7428 - val_loss: 733.7979 - val_accuracy: 0.7959\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1051.8689 - accuracy: 0.7487 - val_loss: 735.2876 - val_accuracy: 0.7954\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1013.9443 - accuracy: 0.7446 - val_loss: 657.7856 - val_accuracy: 0.7876\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 964.4992 - accuracy: 0.7494 - val_loss: 672.3285 - val_accuracy: 0.7921\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 918.4844 - accuracy: 0.7476 - val_loss: 634.0756 - val_accuracy: 0.7897\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 855.4637 - accuracy: 0.7474 - val_loss: 617.3125 - val_accuracy: 0.7875\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 813.2217 - accuracy: 0.7439 - val_loss: 599.3763 - val_accuracy: 0.7892\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 795.5668 - accuracy: 0.7318 - val_loss: 601.8938 - val_accuracy: 0.7972\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 787.3145 - accuracy: 0.7403 - val_loss: 605.4634 - val_accuracy: 0.7905\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 782.9673 - accuracy: 0.7453 - val_loss: 606.3869 - val_accuracy: 0.7865\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 779.7402 - accuracy: 0.7409 - val_loss: 611.0953 - val_accuracy: 0.7939\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 784.3685 - accuracy: 0.7469 - val_loss: 612.2301 - val_accuracy: 0.7949\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 788.9482 - accuracy: 0.7422 - val_loss: 608.9906 - val_accuracy: 0.7877\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 779.3860 - accuracy: 0.7431 - val_loss: 603.6816 - val_accuracy: 0.7977\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 772.7765 - accuracy: 0.7455 - val_loss: 603.4922 - val_accuracy: 0.7946\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 771.1191 - accuracy: 0.7468 - val_loss: 600.8120 - val_accuracy: 0.7917\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 771.9818 - accuracy: 0.7453 - val_loss: 597.7132 - val_accuracy: 0.7922\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 771.6453 - accuracy: 0.7377 - val_loss: 596.5314 - val_accuracy: 0.7895\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 769.7991 - accuracy: 0.7440 - val_loss: 596.2240 - val_accuracy: 0.7981\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 774.0004 - accuracy: 0.7445 - val_loss: 612.9020 - val_accuracy: 0.7924\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 784.7478 - accuracy: 0.7428 - val_loss: 592.8520 - val_accuracy: 0.7909\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 773.9940 - accuracy: 0.7464 - val_loss: 595.5734 - val_accuracy: 0.7956\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 774.6957 - accuracy: 0.7429 - val_loss: 592.2869 - val_accuracy: 0.7954\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 770.9703 - accuracy: 0.7438 - val_loss: 596.1083 - val_accuracy: 0.7998\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 770.7985 - accuracy: 0.7492 - val_loss: 602.3246 - val_accuracy: 0.8019\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 778.2693 - accuracy: 0.7441 - val_loss: 589.4862 - val_accuracy: 0.7945\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 771.8073 - accuracy: 0.7466 - val_loss: 593.0947 - val_accuracy: 0.7942\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 766.8300 - accuracy: 0.7467 - val_loss: 589.1276 - val_accuracy: 0.7968\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 772.6088 - accuracy: 0.7447 - val_loss: 587.7490 - val_accuracy: 0.7977\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 769.7642 - accuracy: 0.7480 - val_loss: 588.6415 - val_accuracy: 0.8014\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 771.0424 - accuracy: 0.7452 - val_loss: 588.1009 - val_accuracy: 0.7940\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 770.7148 - accuracy: 0.7478 - val_loss: 591.4332 - val_accuracy: 0.8025\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 766.1863 - accuracy: 0.7476 - val_loss: 585.8488 - val_accuracy: 0.7989\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 768.2833 - accuracy: 0.7480 - val_loss: 600.2209 - val_accuracy: 0.8027\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 798.2884 - accuracy: 0.7460 - val_loss: 603.8512 - val_accuracy: 0.7939\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 782.2411 - accuracy: 0.7429 - val_loss: 593.4631 - val_accuracy: 0.7932\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 771.3330 - accuracy: 0.7466 - val_loss: 588.9928 - val_accuracy: 0.7955\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 765.0812 - accuracy: 0.7492 - val_loss: 585.0569 - val_accuracy: 0.8017\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 762.7109 - accuracy: 0.7488 - val_loss: 585.2625 - val_accuracy: 0.8035\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 765.8645 - accuracy: 0.7509 - val_loss: 583.7853 - val_accuracy: 0.7964\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 760.7277 - accuracy: 0.7488 - val_loss: 584.9810 - val_accuracy: 0.7961\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 761.8519 - accuracy: 0.7447 - val_loss: 585.3178 - val_accuracy: 0.8009\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 762.6986 - accuracy: 0.7488 - val_loss: 584.0191 - val_accuracy: 0.8029\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 760.5061 - accuracy: 0.7504 - val_loss: 582.3566 - val_accuracy: 0.7940\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 760.5614 - accuracy: 0.7496 - val_loss: 584.7426 - val_accuracy: 0.7990\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 761.0625 - accuracy: 0.7532 - val_loss: 582.2701 - val_accuracy: 0.7938\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 758.0349 - accuracy: 0.7515 - val_loss: 581.9088 - val_accuracy: 0.7992\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 758.5921 - accuracy: 0.7486 - val_loss: 582.6766 - val_accuracy: 0.7994\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 761.4869 - accuracy: 0.7510 - val_loss: 584.1385 - val_accuracy: 0.7979\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 762.8398 - accuracy: 0.7531 - val_loss: 588.2952 - val_accuracy: 0.8029\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 762.7574 - accuracy: 0.7543 - val_loss: 582.9016 - val_accuracy: 0.7943\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 764.7362 - accuracy: 0.7522 - val_loss: 597.9729 - val_accuracy: 0.7971\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 773.5367 - accuracy: 0.7517 - val_loss: 583.7380 - val_accuracy: 0.8013\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 763.9797 - accuracy: 0.7517 - val_loss: 583.5564 - val_accuracy: 0.8001\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 762.4760 - accuracy: 0.7511 - val_loss: 606.8470 - val_accuracy: 0.7975\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 764.9614 - accuracy: 0.7513 - val_loss: 583.6807 - val_accuracy: 0.8011\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 761.5460 - accuracy: 0.7553 - val_loss: 585.8513 - val_accuracy: 0.7983\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 758.7152 - accuracy: 0.7498 - val_loss: 585.1972 - val_accuracy: 0.7961\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 760.3880 - accuracy: 0.7511 - val_loss: 581.0082 - val_accuracy: 0.7966\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 760.1351 - accuracy: 0.7509 - val_loss: 580.8288 - val_accuracy: 0.7992\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 757.6674 - accuracy: 0.7548 - val_loss: 580.5296 - val_accuracy: 0.7948\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 757.5443 - accuracy: 0.7537 - val_loss: 580.0732 - val_accuracy: 0.7990\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 756.5057 - accuracy: 0.7533 - val_loss: 581.6497 - val_accuracy: 0.7945\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 756.0511 - accuracy: 0.7532 - val_loss: 581.2193 - val_accuracy: 0.7975\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 760.1413 - accuracy: 0.7560 - val_loss: 580.3616 - val_accuracy: 0.7960\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.4272 - accuracy: 0.7525 - val_loss: 581.7216 - val_accuracy: 0.7966\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 757.1859 - accuracy: 0.7557 - val_loss: 580.5242 - val_accuracy: 0.7992\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 757.1182 - accuracy: 0.7534 - val_loss: 580.2815 - val_accuracy: 0.7992\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 755.9874 - accuracy: 0.7539 - val_loss: 580.7486 - val_accuracy: 0.8027\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 754.6622 - accuracy: 0.7557 - val_loss: 580.7261 - val_accuracy: 0.7988\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 755.1108 - accuracy: 0.7552 - val_loss: 581.1688 - val_accuracy: 0.7958\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 760.9661 - accuracy: 0.7517 - val_loss: 584.3961 - val_accuracy: 0.7915\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 759.2299 - accuracy: 0.7553 - val_loss: 581.3530 - val_accuracy: 0.8022\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 757.6001 - accuracy: 0.7537 - val_loss: 587.2584 - val_accuracy: 0.8019\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 763.1133 - accuracy: 0.7519 - val_loss: 582.2101 - val_accuracy: 0.8014\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 761.9391 - accuracy: 0.7539 - val_loss: 583.1554 - val_accuracy: 0.8044\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 757.2455 - accuracy: 0.7519 - val_loss: 580.5751 - val_accuracy: 0.7955\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 757.1783 - accuracy: 0.7539 - val_loss: 580.5992 - val_accuracy: 0.7977\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.5652 - accuracy: 0.7535 - val_loss: 581.9453 - val_accuracy: 0.8007\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 755.3788 - accuracy: 0.7541 - val_loss: 587.2234 - val_accuracy: 0.8024\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 758.5024 - accuracy: 0.7562 - val_loss: 587.4494 - val_accuracy: 0.8033\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 758.0678 - accuracy: 0.7532 - val_loss: 580.3558 - val_accuracy: 0.7994\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 754.9028 - accuracy: 0.7555 - val_loss: 578.8774 - val_accuracy: 0.8006\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.1572 - accuracy: 0.7544 - val_loss: 579.0630 - val_accuracy: 0.8009\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 753.5421 - accuracy: 0.7560 - val_loss: 583.8729 - val_accuracy: 0.8012\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 754.8472 - accuracy: 0.7571 - val_loss: 579.5025 - val_accuracy: 0.7991\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 753.5161 - accuracy: 0.7534 - val_loss: 580.3077 - val_accuracy: 0.7997\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 754.0627 - accuracy: 0.7555 - val_loss: 579.6492 - val_accuracy: 0.8007\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.7650 - accuracy: 0.7547 - val_loss: 578.7862 - val_accuracy: 0.7998\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.8771 - accuracy: 0.7548 - val_loss: 579.1666 - val_accuracy: 0.8008\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 752.9852 - accuracy: 0.7560 - val_loss: 580.5886 - val_accuracy: 0.7978\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 755.2870 - accuracy: 0.7550 - val_loss: 580.6270 - val_accuracy: 0.7983\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 758.9597 - accuracy: 0.7575 - val_loss: 587.1133 - val_accuracy: 0.7996\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 755.6135 - accuracy: 0.7559 - val_loss: 582.6264 - val_accuracy: 0.7979\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 752.7794 - accuracy: 0.7558 - val_loss: 579.6071 - val_accuracy: 0.8020\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 753.1586 - accuracy: 0.7592 - val_loss: 579.2054 - val_accuracy: 0.8036\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 755.6992 - accuracy: 0.7539 - val_loss: 586.4003 - val_accuracy: 0.8038\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 758.5084 - accuracy: 0.7553 - val_loss: 582.6387 - val_accuracy: 0.8005\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 754.4642 - accuracy: 0.7512 - val_loss: 579.9156 - val_accuracy: 0.8006\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 754.5825 - accuracy: 0.7564 - val_loss: 590.3906 - val_accuracy: 0.8039\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 762.4312 - accuracy: 0.7546 - val_loss: 584.9092 - val_accuracy: 0.7979\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 760.6539 - accuracy: 0.7562 - val_loss: 582.0561 - val_accuracy: 0.8000\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 755.9478 - accuracy: 0.7526 - val_loss: 587.9109 - val_accuracy: 0.8037\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.2472 - accuracy: 0.7538 - val_loss: 583.7023 - val_accuracy: 0.8037\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 754.5525 - accuracy: 0.7588 - val_loss: 581.0538 - val_accuracy: 0.7977\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 751.0863 - accuracy: 0.7555 - val_loss: 580.4406 - val_accuracy: 0.8034\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.5477 - accuracy: 0.7581 - val_loss: 577.2316 - val_accuracy: 0.8008\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 749.0594 - accuracy: 0.7573 - val_loss: 578.2729 - val_accuracy: 0.7966\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 749.9183 - accuracy: 0.7568 - val_loss: 579.6793 - val_accuracy: 0.8011\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 750.7103 - accuracy: 0.7561 - val_loss: 579.4860 - val_accuracy: 0.8059\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.5434 - accuracy: 0.7572 - val_loss: 584.2059 - val_accuracy: 0.8064\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 752.9821 - accuracy: 0.7576 - val_loss: 586.2052 - val_accuracy: 0.8023\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 759.5744 - accuracy: 0.7571 - val_loss: 584.0983 - val_accuracy: 0.8034\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 756.6360 - accuracy: 0.7555 - val_loss: 585.3484 - val_accuracy: 0.7964\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 754.8193 - accuracy: 0.7553 - val_loss: 578.5784 - val_accuracy: 0.7996\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 754.0109 - accuracy: 0.7575 - val_loss: 579.8956 - val_accuracy: 0.8011\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 752.7618 - accuracy: 0.7559 - val_loss: 584.1232 - val_accuracy: 0.8034\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 756.4274 - accuracy: 0.7542 - val_loss: 584.7462 - val_accuracy: 0.8029\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 752.4142 - accuracy: 0.7575 - val_loss: 578.4659 - val_accuracy: 0.7979\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 748.8417 - accuracy: 0.7572 - val_loss: 577.2241 - val_accuracy: 0.8059\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 748.6022 - accuracy: 0.7586 - val_loss: 577.3701 - val_accuracy: 0.8031\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 750.2243 - accuracy: 0.7553 - val_loss: 578.0635 - val_accuracy: 0.8008\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 751.2264 - accuracy: 0.7577 - val_loss: 580.9619 - val_accuracy: 0.7984\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 750.3223 - accuracy: 0.7548 - val_loss: 576.7979 - val_accuracy: 0.8024\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 750.7767 - accuracy: 0.7574 - val_loss: 576.5196 - val_accuracy: 0.8000\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 746.9113 - accuracy: 0.7576 - val_loss: 576.3983 - val_accuracy: 0.8011\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 746.6228 - accuracy: 0.7561 - val_loss: 576.5035 - val_accuracy: 0.8028\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.7899 - accuracy: 0.7560 - val_loss: 575.8821 - val_accuracy: 0.7998\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.2295 - accuracy: 0.7595 - val_loss: 576.8417 - val_accuracy: 0.7960\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.9783 - accuracy: 0.7552 - val_loss: 580.2693 - val_accuracy: 0.8035\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 748.6572 - accuracy: 0.7570 - val_loss: 580.8604 - val_accuracy: 0.7962\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 748.5858 - accuracy: 0.7535 - val_loss: 576.6561 - val_accuracy: 0.8003\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.2841 - accuracy: 0.7568 - val_loss: 576.0439 - val_accuracy: 0.7975\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 747.6580 - accuracy: 0.7571 - val_loss: 584.2744 - val_accuracy: 0.8014\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 759.8423 - accuracy: 0.7571 - val_loss: 582.2372 - val_accuracy: 0.8027\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 754.2377 - accuracy: 0.7561 - val_loss: 579.5101 - val_accuracy: 0.7923\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.4069 - accuracy: 0.7571 - val_loss: 581.3684 - val_accuracy: 0.8001\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 750.9204 - accuracy: 0.7566 - val_loss: 576.8409 - val_accuracy: 0.7935\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.6282 - accuracy: 0.7583 - val_loss: 577.1708 - val_accuracy: 0.8003\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 746.7352 - accuracy: 0.7541 - val_loss: 576.0786 - val_accuracy: 0.7993\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 744.9512 - accuracy: 0.7584 - val_loss: 578.1443 - val_accuracy: 0.7991\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.5021 - accuracy: 0.7566 - val_loss: 580.2191 - val_accuracy: 0.7983\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.4455 - accuracy: 0.7569 - val_loss: 575.8919 - val_accuracy: 0.8027\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.5507 - accuracy: 0.7581 - val_loss: 575.2961 - val_accuracy: 0.7997\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 746.2596 - accuracy: 0.7551 - val_loss: 575.1868 - val_accuracy: 0.7968\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 747.3388 - accuracy: 0.7584 - val_loss: 577.7523 - val_accuracy: 0.8027\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.4216 - accuracy: 0.7582 - val_loss: 574.8834 - val_accuracy: 0.8037\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 745.4313 - accuracy: 0.7570 - val_loss: 579.4683 - val_accuracy: 0.7988\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 752.8606 - accuracy: 0.7562 - val_loss: 578.3568 - val_accuracy: 0.8014\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 748.7896 - accuracy: 0.7558 - val_loss: 579.0112 - val_accuracy: 0.7999\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 748.7991 - accuracy: 0.7604 - val_loss: 579.8335 - val_accuracy: 0.8013\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.6727 - accuracy: 0.7591 - val_loss: 575.4927 - val_accuracy: 0.7969\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 744.9673 - accuracy: 0.7580 - val_loss: 578.9382 - val_accuracy: 0.7979\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 745.2247 - accuracy: 0.7590 - val_loss: 575.5407 - val_accuracy: 0.7985\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.7982 - accuracy: 0.7554 - val_loss: 577.2541 - val_accuracy: 0.8015\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 746.3076 - accuracy: 0.7589 - val_loss: 576.2205 - val_accuracy: 0.7998\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 749.1989 - accuracy: 0.7582 - val_loss: 590.1044 - val_accuracy: 0.7984\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 756.8784 - accuracy: 0.7562 - val_loss: 579.3606 - val_accuracy: 0.8001\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.1799 - accuracy: 0.7568 - val_loss: 575.3322 - val_accuracy: 0.8044\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.0261 - accuracy: 0.7573 - val_loss: 574.7526 - val_accuracy: 0.7988\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 742.4939 - accuracy: 0.7584 - val_loss: 574.4799 - val_accuracy: 0.8016\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.7394 - accuracy: 0.7553 - val_loss: 580.3263 - val_accuracy: 0.7995\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 747.9248 - accuracy: 0.7565 - val_loss: 578.4233 - val_accuracy: 0.7947\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 746.6120 - accuracy: 0.7572 - val_loss: 576.6134 - val_accuracy: 0.8037\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 756.5966 - accuracy: 0.7577 - val_loss: 581.1577 - val_accuracy: 0.7997\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 756.7787 - accuracy: 0.7568 - val_loss: 580.2594 - val_accuracy: 0.7957\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.9756 - accuracy: 0.7580 - val_loss: 591.4910 - val_accuracy: 0.7944\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.2373 - accuracy: 0.7599 - val_loss: 580.4196 - val_accuracy: 0.7998\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 746.4858 - accuracy: 0.7571 - val_loss: 575.2253 - val_accuracy: 0.8000\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 742.8276 - accuracy: 0.7577 - val_loss: 576.1246 - val_accuracy: 0.8003\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 743.7934 - accuracy: 0.7603 - val_loss: 577.5732 - val_accuracy: 0.7977\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 748.5720 - accuracy: 0.7594 - val_loss: 576.0806 - val_accuracy: 0.8042\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 753.8904 - accuracy: 0.7586 - val_loss: 575.6311 - val_accuracy: 0.7992\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 751.2185 - accuracy: 0.7567 - val_loss: 585.1774 - val_accuracy: 0.7976\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.7233 - accuracy: 0.7581 - val_loss: 586.5760 - val_accuracy: 0.7958\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.0765 - accuracy: 0.7589 - val_loss: 575.8094 - val_accuracy: 0.8032\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 743.1990 - accuracy: 0.7606 - val_loss: 577.6484 - val_accuracy: 0.8029\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 742.7222 - accuracy: 0.7594 - val_loss: 573.8174 - val_accuracy: 0.8026\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.9835 - accuracy: 0.7600 - val_loss: 574.0988 - val_accuracy: 0.7971\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 740.3796 - accuracy: 0.7599 - val_loss: 574.8454 - val_accuracy: 0.8008\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 741.2527 - accuracy: 0.7622 - val_loss: 574.1190 - val_accuracy: 0.8011\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.0089 - accuracy: 0.7596 - val_loss: 573.5510 - val_accuracy: 0.7967\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 740.6517 - accuracy: 0.7597 - val_loss: 574.4411 - val_accuracy: 0.8009\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 741.9664 - accuracy: 0.7602 - val_loss: 575.5436 - val_accuracy: 0.8023\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 742.0166 - accuracy: 0.7606 - val_loss: 574.0372 - val_accuracy: 0.8018\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 743.4993 - accuracy: 0.7591 - val_loss: 573.9125 - val_accuracy: 0.8000\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.3166 - accuracy: 0.7601 - val_loss: 574.5538 - val_accuracy: 0.8014\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 740.1805 - accuracy: 0.7570 - val_loss: 573.5846 - val_accuracy: 0.8004\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 739.7164 - accuracy: 0.7590 - val_loss: 573.2867 - val_accuracy: 0.8018\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 739.4036 - accuracy: 0.7616 - val_loss: 572.7321 - val_accuracy: 0.8016\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 739.1011 - accuracy: 0.7606 - val_loss: 572.7859 - val_accuracy: 0.8019\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 741.4011 - accuracy: 0.7622 - val_loss: 574.3546 - val_accuracy: 0.8001\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 740.3406 - accuracy: 0.7587 - val_loss: 573.4141 - val_accuracy: 0.8017\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.0217 - accuracy: 0.7604 - val_loss: 573.9443 - val_accuracy: 0.8005\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.8425 - accuracy: 0.7608 - val_loss: 576.0135 - val_accuracy: 0.8014\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 746.2584 - accuracy: 0.7597 - val_loss: 581.0991 - val_accuracy: 0.7974\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 751.7418 - accuracy: 0.7604 - val_loss: 584.9643 - val_accuracy: 0.8014\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.6520 - accuracy: 0.7618 - val_loss: 573.7117 - val_accuracy: 0.7998\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.4895 - accuracy: 0.7584 - val_loss: 576.2802 - val_accuracy: 0.7985\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 741.7642 - accuracy: 0.7587 - val_loss: 579.0123 - val_accuracy: 0.7926\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 742.8588 - accuracy: 0.7603 - val_loss: 574.0956 - val_accuracy: 0.7969\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 738.9955 - accuracy: 0.7596 - val_loss: 574.2267 - val_accuracy: 0.7984\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 740.6743 - accuracy: 0.7610 - val_loss: 573.9134 - val_accuracy: 0.8036\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.5182 - accuracy: 0.7608 - val_loss: 572.6472 - val_accuracy: 0.8000\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.0343 - accuracy: 0.7603 - val_loss: 578.9116 - val_accuracy: 0.7991\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 746.5035 - accuracy: 0.7608 - val_loss: 574.6630 - val_accuracy: 0.8027\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 740.6429 - accuracy: 0.7610 - val_loss: 572.0167 - val_accuracy: 0.8020\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.7677 - accuracy: 0.7621 - val_loss: 576.4523 - val_accuracy: 0.8027\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 740.6928 - accuracy: 0.7579 - val_loss: 574.0078 - val_accuracy: 0.7969\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 739.0580 - accuracy: 0.7600 - val_loss: 573.7987 - val_accuracy: 0.7998\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 739.4172 - accuracy: 0.7630 - val_loss: 578.5047 - val_accuracy: 0.8021\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.4490 - accuracy: 0.7607 - val_loss: 573.8821 - val_accuracy: 0.7951\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.6447 - accuracy: 0.7597 - val_loss: 572.8162 - val_accuracy: 0.8009\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 743.6871 - accuracy: 0.7600 - val_loss: 571.1934 - val_accuracy: 0.8032\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 745.6507 - accuracy: 0.7632 - val_loss: 593.2086 - val_accuracy: 0.7951\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 766.3339 - accuracy: 0.7623 - val_loss: 573.3864 - val_accuracy: 0.8000\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 752.1462 - accuracy: 0.7600 - val_loss: 582.7120 - val_accuracy: 0.8035\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.6262 - accuracy: 0.7599 - val_loss: 577.7743 - val_accuracy: 0.7964\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.2391 - accuracy: 0.7573 - val_loss: 577.9346 - val_accuracy: 0.8004\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.3571 - accuracy: 0.7597 - val_loss: 587.4531 - val_accuracy: 0.8015\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 743.6801 - accuracy: 0.7606 - val_loss: 575.0807 - val_accuracy: 0.8017\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 739.9071 - accuracy: 0.7633 - val_loss: 572.0590 - val_accuracy: 0.8000\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.0146 - accuracy: 0.7625 - val_loss: 578.4529 - val_accuracy: 0.8005\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 740.2686 - accuracy: 0.7623 - val_loss: 572.0358 - val_accuracy: 0.8007\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.7870 - accuracy: 0.7609 - val_loss: 571.5489 - val_accuracy: 0.8031\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 736.5408 - accuracy: 0.7617 - val_loss: 571.3605 - val_accuracy: 0.8051\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.0869 - accuracy: 0.7622 - val_loss: 573.0904 - val_accuracy: 0.8013\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.7459 - accuracy: 0.7639 - val_loss: 571.2412 - val_accuracy: 0.7966\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 736.9233 - accuracy: 0.7621 - val_loss: 571.4899 - val_accuracy: 0.7986\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.2171 - accuracy: 0.7623 - val_loss: 572.0333 - val_accuracy: 0.7936\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.9091 - accuracy: 0.7618 - val_loss: 571.7841 - val_accuracy: 0.8027\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 736.0687 - accuracy: 0.7634 - val_loss: 571.7021 - val_accuracy: 0.7984\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 737.7854 - accuracy: 0.7613 - val_loss: 573.3466 - val_accuracy: 0.8020\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.5300 - accuracy: 0.7632 - val_loss: 572.4778 - val_accuracy: 0.8010\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 736.4029 - accuracy: 0.7625 - val_loss: 577.4619 - val_accuracy: 0.7979\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 743.3250 - accuracy: 0.7636 - val_loss: 583.3181 - val_accuracy: 0.8065\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.2229 - accuracy: 0.7624 - val_loss: 599.7835 - val_accuracy: 0.7988\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 756.3199 - accuracy: 0.7649 - val_loss: 576.7131 - val_accuracy: 0.8049\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 743.4469 - accuracy: 0.7602 - val_loss: 573.9182 - val_accuracy: 0.8052\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 739.8608 - accuracy: 0.7638 - val_loss: 585.3578 - val_accuracy: 0.8016\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 743.5199 - accuracy: 0.7634 - val_loss: 572.8185 - val_accuracy: 0.7994\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.3611 - accuracy: 0.7625 - val_loss: 571.6172 - val_accuracy: 0.8020\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.2313 - accuracy: 0.7648 - val_loss: 571.3510 - val_accuracy: 0.8028\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.3326 - accuracy: 0.7624 - val_loss: 569.8644 - val_accuracy: 0.8003\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.2266 - accuracy: 0.7630 - val_loss: 578.5330 - val_accuracy: 0.8019\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 738.8187 - accuracy: 0.7632 - val_loss: 573.7126 - val_accuracy: 0.8018\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 736.1326 - accuracy: 0.7622 - val_loss: 571.3380 - val_accuracy: 0.7927\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 735.0485 - accuracy: 0.7602 - val_loss: 570.8847 - val_accuracy: 0.7945\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.1194 - accuracy: 0.7629 - val_loss: 570.0660 - val_accuracy: 0.7999\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 737.7152 - accuracy: 0.7639 - val_loss: 572.9404 - val_accuracy: 0.8021\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.9420 - accuracy: 0.7623 - val_loss: 571.8522 - val_accuracy: 0.7940\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.4005 - accuracy: 0.7627 - val_loss: 572.1682 - val_accuracy: 0.8028\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 739.5298 - accuracy: 0.7633 - val_loss: 571.5720 - val_accuracy: 0.8069\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 741.4838 - accuracy: 0.7634 - val_loss: 578.7335 - val_accuracy: 0.7953\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 739.3349 - accuracy: 0.7629 - val_loss: 570.5103 - val_accuracy: 0.7998\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.7639 - accuracy: 0.7612 - val_loss: 579.2812 - val_accuracy: 0.7969\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.8668 - accuracy: 0.7630 - val_loss: 579.4147 - val_accuracy: 0.7985\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.5931 - accuracy: 0.7620 - val_loss: 571.5057 - val_accuracy: 0.7944\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.1963 - accuracy: 0.7633 - val_loss: 570.3407 - val_accuracy: 0.8048\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.9605 - accuracy: 0.7615 - val_loss: 570.0692 - val_accuracy: 0.7970\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 734.3723 - accuracy: 0.7632 - val_loss: 569.6251 - val_accuracy: 0.8002\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.4612 - accuracy: 0.7642 - val_loss: 570.7612 - val_accuracy: 0.7992\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 734.8560 - accuracy: 0.7629 - val_loss: 571.9572 - val_accuracy: 0.7996\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.7846 - accuracy: 0.7627 - val_loss: 570.1642 - val_accuracy: 0.7989\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 737.9299 - accuracy: 0.7622 - val_loss: 570.5791 - val_accuracy: 0.7997\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.7753 - accuracy: 0.7636 - val_loss: 571.0344 - val_accuracy: 0.7979\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.4364 - accuracy: 0.7601 - val_loss: 570.3936 - val_accuracy: 0.7960\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 734.3581 - accuracy: 0.7619 - val_loss: 571.3132 - val_accuracy: 0.8018\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.8943 - accuracy: 0.7626 - val_loss: 568.9359 - val_accuracy: 0.7959\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 735.4907 - accuracy: 0.7633 - val_loss: 571.4083 - val_accuracy: 0.7972\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.8958 - accuracy: 0.7619 - val_loss: 572.4235 - val_accuracy: 0.8000\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 738.4726 - accuracy: 0.7645 - val_loss: 571.5062 - val_accuracy: 0.7990\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 736.5815 - accuracy: 0.7628 - val_loss: 571.6352 - val_accuracy: 0.7972\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 733.7728 - accuracy: 0.7633 - val_loss: 569.6493 - val_accuracy: 0.8037\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 733.3185 - accuracy: 0.7639 - val_loss: 570.1451 - val_accuracy: 0.8002\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.2917 - accuracy: 0.7627 - val_loss: 569.7567 - val_accuracy: 0.8027\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.1240 - accuracy: 0.7624 - val_loss: 569.7617 - val_accuracy: 0.7911\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.9739 - accuracy: 0.7625 - val_loss: 570.5444 - val_accuracy: 0.7941\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.8123 - accuracy: 0.7646 - val_loss: 573.0551 - val_accuracy: 0.7967\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 734.1225 - accuracy: 0.7618 - val_loss: 569.7985 - val_accuracy: 0.7936\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 732.9031 - accuracy: 0.7608 - val_loss: 569.8658 - val_accuracy: 0.7999\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.6628 - accuracy: 0.7622 - val_loss: 574.4391 - val_accuracy: 0.7930\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.7601 - accuracy: 0.7619 - val_loss: 569.9854 - val_accuracy: 0.7973\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 738.9601 - accuracy: 0.7618 - val_loss: 577.3242 - val_accuracy: 0.7962\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 736.9894 - accuracy: 0.7611 - val_loss: 573.5897 - val_accuracy: 0.7963\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.5803 - accuracy: 0.7613 - val_loss: 569.2846 - val_accuracy: 0.7995\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.6511 - accuracy: 0.7625 - val_loss: 570.7525 - val_accuracy: 0.8031\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.4801 - accuracy: 0.7633 - val_loss: 569.1036 - val_accuracy: 0.7953\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 733.3993 - accuracy: 0.7612 - val_loss: 570.3419 - val_accuracy: 0.7955\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.9320 - accuracy: 0.7604 - val_loss: 571.4966 - val_accuracy: 0.7966\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 733.4551 - accuracy: 0.7605 - val_loss: 570.8027 - val_accuracy: 0.7975\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 734.9903 - accuracy: 0.7630 - val_loss: 570.4099 - val_accuracy: 0.7980\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 740.6671 - accuracy: 0.7629 - val_loss: 599.1099 - val_accuracy: 0.7981\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 754.0475 - accuracy: 0.7615 - val_loss: 571.2928 - val_accuracy: 0.8005\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 738.7805 - accuracy: 0.7607 - val_loss: 572.0797 - val_accuracy: 0.7938\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 734.4508 - accuracy: 0.7597 - val_loss: 568.5973 - val_accuracy: 0.7968\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 734.0950 - accuracy: 0.7638 - val_loss: 568.4417 - val_accuracy: 0.7967\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 732.4994 - accuracy: 0.7614 - val_loss: 570.7278 - val_accuracy: 0.8036\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 733.2344 - accuracy: 0.7638 - val_loss: 569.2886 - val_accuracy: 0.7961\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 732.7767 - accuracy: 0.7607 - val_loss: 570.6069 - val_accuracy: 0.7951\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 732.0893 - accuracy: 0.7615 - val_loss: 568.6470 - val_accuracy: 0.7984\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 731.6663 - accuracy: 0.7638 - val_loss: 569.6345 - val_accuracy: 0.8055\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 731.7603 - accuracy: 0.7638 - val_loss: 569.8094 - val_accuracy: 0.7980\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 731.2048 - accuracy: 0.7624 - val_loss: 569.3129 - val_accuracy: 0.7987\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 732.0055 - accuracy: 0.7602 - val_loss: 568.0505 - val_accuracy: 0.8007\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 732.2214 - accuracy: 0.7648 - val_loss: 575.1598 - val_accuracy: 0.8001\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 739.5524 - accuracy: 0.7644 - val_loss: 569.8248 - val_accuracy: 0.8004\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 731.9780 - accuracy: 0.7613 - val_loss: 568.7532 - val_accuracy: 0.7974\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 732.4424 - accuracy: 0.7649 - val_loss: 574.0726 - val_accuracy: 0.7955\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.7480 - accuracy: 0.7618 - val_loss: 569.1224 - val_accuracy: 0.7950\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.0456 - accuracy: 0.7647 - val_loss: 571.4179 - val_accuracy: 0.7964\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.5952 - accuracy: 0.7628 - val_loss: 578.6406 - val_accuracy: 0.7880\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 737.9366 - accuracy: 0.7588 - val_loss: 568.5178 - val_accuracy: 0.7954\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.5374 - accuracy: 0.7639 - val_loss: 571.9493 - val_accuracy: 0.7997\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.0504 - accuracy: 0.7622 - val_loss: 569.7126 - val_accuracy: 0.7965\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.5781 - accuracy: 0.7622 - val_loss: 567.9163 - val_accuracy: 0.7975\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.3809 - accuracy: 0.7633 - val_loss: 575.2774 - val_accuracy: 0.7996\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 740.1620 - accuracy: 0.7628 - val_loss: 571.6600 - val_accuracy: 0.8008\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.1571 - accuracy: 0.7624 - val_loss: 569.0995 - val_accuracy: 0.7980\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.2228 - accuracy: 0.7619 - val_loss: 567.3170 - val_accuracy: 0.8008\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.7428 - accuracy: 0.7631 - val_loss: 567.9443 - val_accuracy: 0.7976\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.1503 - accuracy: 0.7624 - val_loss: 571.1345 - val_accuracy: 0.7975\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.8501 - accuracy: 0.7602 - val_loss: 568.7900 - val_accuracy: 0.7945\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.0522 - accuracy: 0.7622 - val_loss: 568.0543 - val_accuracy: 0.7951\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.2483 - accuracy: 0.7628 - val_loss: 568.3641 - val_accuracy: 0.7973\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 732.5358 - accuracy: 0.7604 - val_loss: 568.6219 - val_accuracy: 0.7945\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 732.5312 - accuracy: 0.7651 - val_loss: 568.3109 - val_accuracy: 0.7953\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.5026 - accuracy: 0.7640 - val_loss: 568.8704 - val_accuracy: 0.7984\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 731.9669 - accuracy: 0.7627 - val_loss: 569.7950 - val_accuracy: 0.7988\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.6527 - accuracy: 0.7627 - val_loss: 567.4434 - val_accuracy: 0.8014\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.8446 - accuracy: 0.7651 - val_loss: 567.5582 - val_accuracy: 0.7976\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 736.2565 - accuracy: 0.7648 - val_loss: 571.0007 - val_accuracy: 0.7935\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.5987 - accuracy: 0.7661 - val_loss: 573.8684 - val_accuracy: 0.7946\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.9050 - accuracy: 0.7629 - val_loss: 610.1795 - val_accuracy: 0.7979\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.1374 - accuracy: 0.7612 - val_loss: 570.2188 - val_accuracy: 0.7958\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 742.2771 - accuracy: 0.7609 - val_loss: 570.6387 - val_accuracy: 0.7919\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.3922 - accuracy: 0.7601 - val_loss: 570.2924 - val_accuracy: 0.7926\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 731.5005 - accuracy: 0.7636 - val_loss: 567.7819 - val_accuracy: 0.7929\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.5228 - accuracy: 0.7623 - val_loss: 569.1549 - val_accuracy: 0.8000\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.1910 - accuracy: 0.7614 - val_loss: 568.2615 - val_accuracy: 0.7967\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.6025 - accuracy: 0.7635 - val_loss: 568.3914 - val_accuracy: 0.7982\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.2821 - accuracy: 0.7636 - val_loss: 566.5925 - val_accuracy: 0.7945\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.8438 - accuracy: 0.7637 - val_loss: 566.6346 - val_accuracy: 0.7989\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.6978 - accuracy: 0.7638 - val_loss: 570.9772 - val_accuracy: 0.8018\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.2609 - accuracy: 0.7646 - val_loss: 568.0338 - val_accuracy: 0.7990\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.9352 - accuracy: 0.7649 - val_loss: 567.4905 - val_accuracy: 0.8016\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.8020 - accuracy: 0.7633 - val_loss: 569.5255 - val_accuracy: 0.7974\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 732.5291 - accuracy: 0.7637 - val_loss: 567.9618 - val_accuracy: 0.7959\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.1278 - accuracy: 0.7641 - val_loss: 568.4505 - val_accuracy: 0.7922\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.4178 - accuracy: 0.7594 - val_loss: 568.2246 - val_accuracy: 0.7884\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.7045 - accuracy: 0.7632 - val_loss: 566.5280 - val_accuracy: 0.7953\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.7422 - accuracy: 0.7647 - val_loss: 566.3683 - val_accuracy: 0.7989\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.3150 - accuracy: 0.7640 - val_loss: 566.5823 - val_accuracy: 0.7944\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.5839 - accuracy: 0.7645 - val_loss: 565.5860 - val_accuracy: 0.8009\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.4916 - accuracy: 0.7647 - val_loss: 566.2310 - val_accuracy: 0.7981\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.6432 - accuracy: 0.7631 - val_loss: 566.3180 - val_accuracy: 0.8013\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.9735 - accuracy: 0.7635 - val_loss: 566.8887 - val_accuracy: 0.8018\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.5427 - accuracy: 0.7653 - val_loss: 566.4180 - val_accuracy: 0.8013\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.7701 - accuracy: 0.7666 - val_loss: 577.0939 - val_accuracy: 0.7968\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.6624 - accuracy: 0.7640 - val_loss: 566.1359 - val_accuracy: 0.8006\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.4432 - accuracy: 0.7625 - val_loss: 567.6470 - val_accuracy: 0.7997\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.4985 - accuracy: 0.7628 - val_loss: 580.4988 - val_accuracy: 0.8009\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 740.8213 - accuracy: 0.7638 - val_loss: 569.8644 - val_accuracy: 0.7931\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.1407 - accuracy: 0.7605 - val_loss: 590.7994 - val_accuracy: 0.7977\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 763.1072 - accuracy: 0.7593 - val_loss: 589.1152 - val_accuracy: 0.8004\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.9430 - accuracy: 0.7619 - val_loss: 575.2541 - val_accuracy: 0.7883\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.6281 - accuracy: 0.7606 - val_loss: 584.1716 - val_accuracy: 0.7942\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.3331 - accuracy: 0.7644 - val_loss: 568.3719 - val_accuracy: 0.7994\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.6933 - accuracy: 0.7612 - val_loss: 568.5995 - val_accuracy: 0.7993\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 729.2181 - accuracy: 0.7650 - val_loss: 565.7401 - val_accuracy: 0.7975\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.2677 - accuracy: 0.7635 - val_loss: 569.1988 - val_accuracy: 0.7996\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 736.1450 - accuracy: 0.7642 - val_loss: 566.5367 - val_accuracy: 0.7957\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.4083 - accuracy: 0.7649 - val_loss: 571.9313 - val_accuracy: 0.7964\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.9798 - accuracy: 0.7621 - val_loss: 565.5693 - val_accuracy: 0.7964\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.6794 - accuracy: 0.7660 - val_loss: 571.0513 - val_accuracy: 0.7994\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.6974 - accuracy: 0.7632 - val_loss: 565.8749 - val_accuracy: 0.7950\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.4899 - accuracy: 0.7630 - val_loss: 568.9105 - val_accuracy: 0.7986\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 733.0541 - accuracy: 0.7656 - val_loss: 567.3076 - val_accuracy: 0.7965\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.2745 - accuracy: 0.7643 - val_loss: 567.6563 - val_accuracy: 0.7980\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.3491 - accuracy: 0.7629 - val_loss: 566.9602 - val_accuracy: 0.7984\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.6634 - accuracy: 0.7641 - val_loss: 568.1392 - val_accuracy: 0.7962\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.1238 - accuracy: 0.7633 - val_loss: 565.8684 - val_accuracy: 0.7989\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.9286 - accuracy: 0.7615 - val_loss: 570.5015 - val_accuracy: 0.7952\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.6803 - accuracy: 0.7635 - val_loss: 565.4542 - val_accuracy: 0.7998\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 728.2167 - accuracy: 0.7633 - val_loss: 566.8956 - val_accuracy: 0.7943\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.0399 - accuracy: 0.7621 - val_loss: 566.3219 - val_accuracy: 0.7938\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.7463 - accuracy: 0.7636 - val_loss: 565.5901 - val_accuracy: 0.8001\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.8474 - accuracy: 0.7659 - val_loss: 565.4492 - val_accuracy: 0.7925\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.8923 - accuracy: 0.7641 - val_loss: 565.5558 - val_accuracy: 0.7931\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.9429 - accuracy: 0.7647 - val_loss: 567.5157 - val_accuracy: 0.7984\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 736.2253 - accuracy: 0.7648 - val_loss: 573.7274 - val_accuracy: 0.7884\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.6478 - accuracy: 0.7624 - val_loss: 565.8248 - val_accuracy: 0.7998\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 729.6406 - accuracy: 0.7647 - val_loss: 567.7877 - val_accuracy: 0.7961\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.7074 - accuracy: 0.7617 - val_loss: 566.3085 - val_accuracy: 0.7998\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 727.6758 - accuracy: 0.7645 - val_loss: 565.0255 - val_accuracy: 0.7947\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.8209 - accuracy: 0.7641 - val_loss: 569.9882 - val_accuracy: 0.7887\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.7636 - accuracy: 0.7650 - val_loss: 565.3219 - val_accuracy: 0.7960\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.6304 - accuracy: 0.7627 - val_loss: 565.1318 - val_accuracy: 0.7938\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.3395 - accuracy: 0.7636 - val_loss: 564.4737 - val_accuracy: 0.7913\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.0545 - accuracy: 0.7648 - val_loss: 573.7501 - val_accuracy: 0.7913\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.0908 - accuracy: 0.7626 - val_loss: 573.6439 - val_accuracy: 0.7935\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.3871 - accuracy: 0.7639 - val_loss: 567.2370 - val_accuracy: 0.7988\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.3600 - accuracy: 0.7622 - val_loss: 568.2913 - val_accuracy: 0.7955\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.9383 - accuracy: 0.7641 - val_loss: 567.0585 - val_accuracy: 0.7925\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 727.3270 - accuracy: 0.7641 - val_loss: 565.5709 - val_accuracy: 0.7959\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.0294 - accuracy: 0.7632 - val_loss: 564.2094 - val_accuracy: 0.7949\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.4951 - accuracy: 0.7631 - val_loss: 564.4210 - val_accuracy: 0.7941\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.6309 - accuracy: 0.7643 - val_loss: 565.1515 - val_accuracy: 0.7911\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 727.0688 - accuracy: 0.7631 - val_loss: 564.6812 - val_accuracy: 0.7940\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.4352 - accuracy: 0.7658 - val_loss: 565.4412 - val_accuracy: 0.7958\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.6096 - accuracy: 0.7632 - val_loss: 571.3503 - val_accuracy: 0.7947\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.8395 - accuracy: 0.7619 - val_loss: 582.3267 - val_accuracy: 0.7965\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.0070 - accuracy: 0.7599 - val_loss: 571.0771 - val_accuracy: 0.7940\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.2980 - accuracy: 0.7619 - val_loss: 564.4288 - val_accuracy: 0.7950\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.3541 - accuracy: 0.7636 - val_loss: 564.7346 - val_accuracy: 0.7933\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 726.8788 - accuracy: 0.7630 - val_loss: 569.0391 - val_accuracy: 0.7970\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.5210 - accuracy: 0.7643 - val_loss: 572.0662 - val_accuracy: 0.7878\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 739.3699 - accuracy: 0.7628 - val_loss: 569.6193 - val_accuracy: 0.7930\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.2332 - accuracy: 0.7617 - val_loss: 567.0980 - val_accuracy: 0.7904\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.6491 - accuracy: 0.7615 - val_loss: 574.8072 - val_accuracy: 0.7971\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 732.5414 - accuracy: 0.7633 - val_loss: 565.1215 - val_accuracy: 0.7937\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.4902 - accuracy: 0.7625 - val_loss: 565.1036 - val_accuracy: 0.7898\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.4272 - accuracy: 0.7636 - val_loss: 566.5422 - val_accuracy: 0.7916\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 726.9399 - accuracy: 0.7601 - val_loss: 565.4115 - val_accuracy: 0.7997\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.5828 - accuracy: 0.7643 - val_loss: 564.7775 - val_accuracy: 0.7960\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 726.6520 - accuracy: 0.7636 - val_loss: 565.2781 - val_accuracy: 0.7968\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.9596 - accuracy: 0.7643 - val_loss: 567.7540 - val_accuracy: 0.7920\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.9247 - accuracy: 0.7620 - val_loss: 569.3906 - val_accuracy: 0.7919\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.5288 - accuracy: 0.7633 - val_loss: 573.8486 - val_accuracy: 0.7926\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.4828 - accuracy: 0.7643 - val_loss: 564.2828 - val_accuracy: 0.7899\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.9998 - accuracy: 0.7626 - val_loss: 564.1169 - val_accuracy: 0.7897\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 726.1943 - accuracy: 0.7644 - val_loss: 564.3303 - val_accuracy: 0.7923\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.5875 - accuracy: 0.7633 - val_loss: 566.4025 - val_accuracy: 0.7909\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.3752 - accuracy: 0.7638 - val_loss: 563.5238 - val_accuracy: 0.7940\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.6825 - accuracy: 0.7615 - val_loss: 564.4651 - val_accuracy: 0.7915\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.6591 - accuracy: 0.7654 - val_loss: 565.1490 - val_accuracy: 0.7913\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.7047 - accuracy: 0.7636 - val_loss: 567.6177 - val_accuracy: 0.7938\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.9094 - accuracy: 0.7641 - val_loss: 564.6713 - val_accuracy: 0.7954\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.2949 - accuracy: 0.7645 - val_loss: 564.3633 - val_accuracy: 0.7951\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.0023 - accuracy: 0.7646 - val_loss: 566.0741 - val_accuracy: 0.7939\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.1688 - accuracy: 0.7645 - val_loss: 564.8682 - val_accuracy: 0.7962\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 727.0040 - accuracy: 0.7656 - val_loss: 566.3094 - val_accuracy: 0.7937\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.9288 - accuracy: 0.7653 - val_loss: 569.2526 - val_accuracy: 0.7944\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.2079 - accuracy: 0.7617 - val_loss: 564.0225 - val_accuracy: 0.7920\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.4901 - accuracy: 0.7632 - val_loss: 564.7416 - val_accuracy: 0.7950\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.5899 - accuracy: 0.7639 - val_loss: 565.8745 - val_accuracy: 0.7930\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.3838 - accuracy: 0.7616 - val_loss: 563.7496 - val_accuracy: 0.7926\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.1489 - accuracy: 0.7659 - val_loss: 567.2606 - val_accuracy: 0.7893\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 726.8121 - accuracy: 0.7629 - val_loss: 569.3906 - val_accuracy: 0.7908\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.8228 - accuracy: 0.7648 - val_loss: 563.0475 - val_accuracy: 0.7942\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.8392 - accuracy: 0.7628 - val_loss: 566.7311 - val_accuracy: 0.7932\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.7496 - accuracy: 0.7620 - val_loss: 565.2432 - val_accuracy: 0.7930\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.8099 - accuracy: 0.7646 - val_loss: 592.2578 - val_accuracy: 0.7898\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.2897 - accuracy: 0.7629 - val_loss: 565.6913 - val_accuracy: 0.7923\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.7896 - accuracy: 0.7633 - val_loss: 568.7075 - val_accuracy: 0.7964\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.7264 - accuracy: 0.7649 - val_loss: 563.6322 - val_accuracy: 0.7975\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.2059 - accuracy: 0.7630 - val_loss: 572.2914 - val_accuracy: 0.7932\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 734.7214 - accuracy: 0.7619 - val_loss: 565.6303 - val_accuracy: 0.7940\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.9796 - accuracy: 0.7639 - val_loss: 563.9251 - val_accuracy: 0.7972\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 727.0784 - accuracy: 0.7619 - val_loss: 563.9317 - val_accuracy: 0.7918\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.1195 - accuracy: 0.7631 - val_loss: 563.3964 - val_accuracy: 0.7911\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.8527 - accuracy: 0.7658 - val_loss: 562.8560 - val_accuracy: 0.7892\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 724.1823 - accuracy: 0.7642 - val_loss: 563.3347 - val_accuracy: 0.7912\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.7705 - accuracy: 0.7655 - val_loss: 562.7483 - val_accuracy: 0.7923\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.1378 - accuracy: 0.7651 - val_loss: 561.7668 - val_accuracy: 0.7927\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.9417 - accuracy: 0.7636 - val_loss: 563.5089 - val_accuracy: 0.7904\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 724.7968 - accuracy: 0.7641 - val_loss: 565.4482 - val_accuracy: 0.7904\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.4840 - accuracy: 0.7629 - val_loss: 566.9653 - val_accuracy: 0.7895\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.2833 - accuracy: 0.7653 - val_loss: 565.3629 - val_accuracy: 0.7944\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 728.4585 - accuracy: 0.7656 - val_loss: 574.6563 - val_accuracy: 0.7946\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.6215 - accuracy: 0.7650 - val_loss: 571.6565 - val_accuracy: 0.7873\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 734.5377 - accuracy: 0.7619 - val_loss: 565.4465 - val_accuracy: 0.7914\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.7478 - accuracy: 0.7581 - val_loss: 564.0969 - val_accuracy: 0.7886\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.0187 - accuracy: 0.7634 - val_loss: 563.5714 - val_accuracy: 0.7936\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 725.3885 - accuracy: 0.7625 - val_loss: 564.4622 - val_accuracy: 0.7892\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 728.7372 - accuracy: 0.7673 - val_loss: 562.0710 - val_accuracy: 0.7921\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.0739 - accuracy: 0.7648 - val_loss: 566.8743 - val_accuracy: 0.7943\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.6542 - accuracy: 0.7651 - val_loss: 565.4703 - val_accuracy: 0.7901\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.5669 - accuracy: 0.7652 - val_loss: 562.5859 - val_accuracy: 0.7939\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.2179 - accuracy: 0.7650 - val_loss: 564.3661 - val_accuracy: 0.7919\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.4030 - accuracy: 0.7630 - val_loss: 568.9914 - val_accuracy: 0.7944\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.8790 - accuracy: 0.7645 - val_loss: 563.3422 - val_accuracy: 0.7910\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.8012 - accuracy: 0.7641 - val_loss: 562.3573 - val_accuracy: 0.7920\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.7507 - accuracy: 0.7645 - val_loss: 562.7962 - val_accuracy: 0.7911\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.3423 - accuracy: 0.7644 - val_loss: 562.1607 - val_accuracy: 0.7899\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 723.7087 - accuracy: 0.7642 - val_loss: 563.9545 - val_accuracy: 0.7923\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 724.5475 - accuracy: 0.7634 - val_loss: 562.5344 - val_accuracy: 0.7880\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.6516 - accuracy: 0.7642 - val_loss: 563.4270 - val_accuracy: 0.7901\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.4989 - accuracy: 0.7651 - val_loss: 562.2641 - val_accuracy: 0.7905\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.8223 - accuracy: 0.7640 - val_loss: 564.0131 - val_accuracy: 0.7948\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.0067 - accuracy: 0.7635 - val_loss: 561.8217 - val_accuracy: 0.7994\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.6589 - accuracy: 0.7646 - val_loss: 566.7031 - val_accuracy: 0.7878\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.2742 - accuracy: 0.7614 - val_loss: 569.1602 - val_accuracy: 0.7907\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.9420 - accuracy: 0.7650 - val_loss: 562.9119 - val_accuracy: 0.7935\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.5014 - accuracy: 0.7638 - val_loss: 564.8649 - val_accuracy: 0.7906\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.7932 - accuracy: 0.7650 - val_loss: 562.5430 - val_accuracy: 0.7854\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.4150 - accuracy: 0.7643 - val_loss: 565.1963 - val_accuracy: 0.7920\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.0860 - accuracy: 0.7643 - val_loss: 564.0970 - val_accuracy: 0.7957\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.3312 - accuracy: 0.7631 - val_loss: 566.1215 - val_accuracy: 0.7865\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.6938 - accuracy: 0.7640 - val_loss: 574.8975 - val_accuracy: 0.7907\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.4416 - accuracy: 0.7639 - val_loss: 567.5291 - val_accuracy: 0.7979\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.1299 - accuracy: 0.7619 - val_loss: 565.8457 - val_accuracy: 0.7898\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 743.0748 - accuracy: 0.7654 - val_loss: 589.4107 - val_accuracy: 0.7978\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 736.4227 - accuracy: 0.7629 - val_loss: 570.7511 - val_accuracy: 0.7917\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.7128 - accuracy: 0.7620 - val_loss: 564.4202 - val_accuracy: 0.7882\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.8351 - accuracy: 0.7629 - val_loss: 566.1501 - val_accuracy: 0.7927\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.7308 - accuracy: 0.7640 - val_loss: 561.4570 - val_accuracy: 0.7889\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.3636 - accuracy: 0.7658 - val_loss: 567.3352 - val_accuracy: 0.7884\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.0649 - accuracy: 0.7659 - val_loss: 561.1348 - val_accuracy: 0.7906\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.4423 - accuracy: 0.7638 - val_loss: 574.5571 - val_accuracy: 0.7964\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.0179 - accuracy: 0.7607 - val_loss: 571.3768 - val_accuracy: 0.7922\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.5450 - accuracy: 0.7635 - val_loss: 566.0536 - val_accuracy: 0.7909\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.4981 - accuracy: 0.7612 - val_loss: 562.9127 - val_accuracy: 0.7921\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.3438 - accuracy: 0.7626 - val_loss: 562.0629 - val_accuracy: 0.7976\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.8393 - accuracy: 0.7668 - val_loss: 563.6733 - val_accuracy: 0.7938\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.3606 - accuracy: 0.7633 - val_loss: 562.4992 - val_accuracy: 0.7916\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.9950 - accuracy: 0.7650 - val_loss: 563.0588 - val_accuracy: 0.7924\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.8826 - accuracy: 0.7663 - val_loss: 561.5222 - val_accuracy: 0.7942\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.4169 - accuracy: 0.7662 - val_loss: 564.7555 - val_accuracy: 0.7944\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.6957 - accuracy: 0.7634 - val_loss: 561.8715 - val_accuracy: 0.7922\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.7081 - accuracy: 0.7648 - val_loss: 562.1446 - val_accuracy: 0.7948\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.1066 - accuracy: 0.7649 - val_loss: 560.6814 - val_accuracy: 0.7900\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 722.1821 - accuracy: 0.7654 - val_loss: 561.8059 - val_accuracy: 0.7899\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 722.5235 - accuracy: 0.7646 - val_loss: 561.2769 - val_accuracy: 0.7902\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.6163 - accuracy: 0.7642 - val_loss: 560.4230 - val_accuracy: 0.7929\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.2612 - accuracy: 0.7666 - val_loss: 560.0027 - val_accuracy: 0.7930\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.2875 - accuracy: 0.7653 - val_loss: 561.5768 - val_accuracy: 0.7940\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.1669 - accuracy: 0.7647 - val_loss: 563.1335 - val_accuracy: 0.7898\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.7329 - accuracy: 0.7650 - val_loss: 563.2113 - val_accuracy: 0.7903\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.0450 - accuracy: 0.7644 - val_loss: 561.7043 - val_accuracy: 0.7910\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.6584 - accuracy: 0.7641 - val_loss: 562.5666 - val_accuracy: 0.7886\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.0356 - accuracy: 0.7640 - val_loss: 560.3908 - val_accuracy: 0.7882\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.4794 - accuracy: 0.7633 - val_loss: 562.6271 - val_accuracy: 0.7909\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.7830 - accuracy: 0.7654 - val_loss: 560.9197 - val_accuracy: 0.7915\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.7371 - accuracy: 0.7643 - val_loss: 566.6456 - val_accuracy: 0.7948\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.0941 - accuracy: 0.7664 - val_loss: 560.7266 - val_accuracy: 0.7915\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.2148 - accuracy: 0.7649 - val_loss: 583.5966 - val_accuracy: 0.7913\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.0435 - accuracy: 0.7667 - val_loss: 564.0323 - val_accuracy: 0.7958\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.6904 - accuracy: 0.7632 - val_loss: 562.0020 - val_accuracy: 0.7925\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.0856 - accuracy: 0.7653 - val_loss: 563.1290 - val_accuracy: 0.7975\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.4944 - accuracy: 0.7659 - val_loss: 560.1986 - val_accuracy: 0.7933\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.5421 - accuracy: 0.7641 - val_loss: 559.4655 - val_accuracy: 0.7964\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.0902 - accuracy: 0.7662 - val_loss: 562.1656 - val_accuracy: 0.7956\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.6591 - accuracy: 0.7637 - val_loss: 559.7037 - val_accuracy: 0.7923\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.1309 - accuracy: 0.7657 - val_loss: 559.7650 - val_accuracy: 0.7878\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.0129 - accuracy: 0.7649 - val_loss: 560.4597 - val_accuracy: 0.7879\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.1945 - accuracy: 0.7661 - val_loss: 561.6912 - val_accuracy: 0.7916\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.1591 - accuracy: 0.7639 - val_loss: 559.7690 - val_accuracy: 0.7915\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.8259 - accuracy: 0.7658 - val_loss: 561.4008 - val_accuracy: 0.7940\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.4858 - accuracy: 0.7638 - val_loss: 560.4375 - val_accuracy: 0.7923\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.0824 - accuracy: 0.7641 - val_loss: 559.6812 - val_accuracy: 0.7924\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 723.3286 - accuracy: 0.7662 - val_loss: 559.5565 - val_accuracy: 0.7921\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.0236 - accuracy: 0.7646 - val_loss: 560.5497 - val_accuracy: 0.7977\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.8853 - accuracy: 0.7652 - val_loss: 561.3654 - val_accuracy: 0.7945\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.9849 - accuracy: 0.7656 - val_loss: 560.9600 - val_accuracy: 0.7917\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.7938 - accuracy: 0.7650 - val_loss: 559.4669 - val_accuracy: 0.7916\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.1018 - accuracy: 0.7655 - val_loss: 560.4385 - val_accuracy: 0.7980\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 724.8095 - accuracy: 0.7662 - val_loss: 560.0602 - val_accuracy: 0.7934\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.4161 - accuracy: 0.7656 - val_loss: 560.3363 - val_accuracy: 0.7911\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.5590 - accuracy: 0.7658 - val_loss: 560.2609 - val_accuracy: 0.7929\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 725.6219 - accuracy: 0.7657 - val_loss: 563.7300 - val_accuracy: 0.7966\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.3461 - accuracy: 0.7637 - val_loss: 564.0821 - val_accuracy: 0.7940\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.2233 - accuracy: 0.7653 - val_loss: 563.3203 - val_accuracy: 0.7944\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.0634 - accuracy: 0.7644 - val_loss: 560.0031 - val_accuracy: 0.7923\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 720.8883 - accuracy: 0.7659 - val_loss: 560.2585 - val_accuracy: 0.7945\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.6222 - accuracy: 0.7647 - val_loss: 562.2358 - val_accuracy: 0.7893\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.6835 - accuracy: 0.7647 - val_loss: 560.7584 - val_accuracy: 0.7940\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.1906 - accuracy: 0.7640 - val_loss: 559.1404 - val_accuracy: 0.7932\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.2946 - accuracy: 0.7656 - val_loss: 559.2280 - val_accuracy: 0.7959\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.0254 - accuracy: 0.7664 - val_loss: 558.9533 - val_accuracy: 0.8000\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.0267 - accuracy: 0.7664 - val_loss: 560.8239 - val_accuracy: 0.7995\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.1383 - accuracy: 0.7655 - val_loss: 558.9385 - val_accuracy: 0.7989\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.9392 - accuracy: 0.7659 - val_loss: 559.1485 - val_accuracy: 0.7960\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.5621 - accuracy: 0.7641 - val_loss: 559.4013 - val_accuracy: 0.7936\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.6904 - accuracy: 0.7671 - val_loss: 558.6762 - val_accuracy: 0.7951\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.3220 - accuracy: 0.7663 - val_loss: 558.4908 - val_accuracy: 0.7912\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.5338 - accuracy: 0.7655 - val_loss: 563.2896 - val_accuracy: 0.7952\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.6059 - accuracy: 0.7650 - val_loss: 565.5649 - val_accuracy: 0.7992\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 724.0771 - accuracy: 0.7639 - val_loss: 563.5755 - val_accuracy: 0.7930\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.5847 - accuracy: 0.7649 - val_loss: 561.0162 - val_accuracy: 0.7936\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.8466 - accuracy: 0.7644 - val_loss: 560.6646 - val_accuracy: 0.7972\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 723.2192 - accuracy: 0.7641 - val_loss: 559.8515 - val_accuracy: 0.7982\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.7313 - accuracy: 0.7642 - val_loss: 560.3301 - val_accuracy: 0.7951\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.2454 - accuracy: 0.7637 - val_loss: 559.4670 - val_accuracy: 0.7960\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.4507 - accuracy: 0.7671 - val_loss: 559.4384 - val_accuracy: 0.7959\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.6260 - accuracy: 0.7646 - val_loss: 564.4032 - val_accuracy: 0.7915\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.7701 - accuracy: 0.7651 - val_loss: 560.0990 - val_accuracy: 0.7968\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.2653 - accuracy: 0.7672 - val_loss: 565.0853 - val_accuracy: 0.7884\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.7076 - accuracy: 0.7638 - val_loss: 560.1909 - val_accuracy: 0.7900\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.4512 - accuracy: 0.7630 - val_loss: 577.8558 - val_accuracy: 0.7898\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 732.9736 - accuracy: 0.7651 - val_loss: 592.0071 - val_accuracy: 0.7868\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 761.9278 - accuracy: 0.7666 - val_loss: 598.2877 - val_accuracy: 0.7998\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.4988 - accuracy: 0.7615 - val_loss: 567.3011 - val_accuracy: 0.7988\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.2816 - accuracy: 0.7621 - val_loss: 565.4984 - val_accuracy: 0.8008\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 727.2307 - accuracy: 0.7658 - val_loss: 562.5950 - val_accuracy: 0.7947\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 723.5392 - accuracy: 0.7647 - val_loss: 559.2436 - val_accuracy: 0.7981\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.9662 - accuracy: 0.7655 - val_loss: 559.3145 - val_accuracy: 0.7961\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.8118 - accuracy: 0.7669 - val_loss: 561.8397 - val_accuracy: 0.7991\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.0783 - accuracy: 0.7655 - val_loss: 560.9236 - val_accuracy: 0.7919\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.9213 - accuracy: 0.7658 - val_loss: 557.4854 - val_accuracy: 0.7964\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.0095 - accuracy: 0.7658 - val_loss: 560.3476 - val_accuracy: 0.7957\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.4910 - accuracy: 0.7639 - val_loss: 558.7582 - val_accuracy: 0.7903\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.6423 - accuracy: 0.7661 - val_loss: 558.7745 - val_accuracy: 0.7968\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.4518 - accuracy: 0.7664 - val_loss: 558.3598 - val_accuracy: 0.7973\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.9750 - accuracy: 0.7635 - val_loss: 558.7179 - val_accuracy: 0.7992\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 720.5114 - accuracy: 0.7666 - val_loss: 558.1296 - val_accuracy: 0.7943\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.0477 - accuracy: 0.7669 - val_loss: 557.7846 - val_accuracy: 0.7954\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.5279 - accuracy: 0.7668 - val_loss: 561.5136 - val_accuracy: 0.8001\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.7511 - accuracy: 0.7654 - val_loss: 557.7401 - val_accuracy: 0.7930\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.4678 - accuracy: 0.7654 - val_loss: 558.1411 - val_accuracy: 0.7957\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.3154 - accuracy: 0.7671 - val_loss: 560.3456 - val_accuracy: 0.7958\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.7468 - accuracy: 0.7656 - val_loss: 558.2870 - val_accuracy: 0.7926\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 722.8660 - accuracy: 0.7662 - val_loss: 559.8674 - val_accuracy: 0.7891\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.7383 - accuracy: 0.7655 - val_loss: 558.7247 - val_accuracy: 0.7914\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.5596 - accuracy: 0.7675 - val_loss: 557.3762 - val_accuracy: 0.7981\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.3941 - accuracy: 0.7654 - val_loss: 559.6035 - val_accuracy: 0.7926\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.2095 - accuracy: 0.7669 - val_loss: 571.2962 - val_accuracy: 0.7943\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.7275 - accuracy: 0.7659 - val_loss: 558.3867 - val_accuracy: 0.7940\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.1510 - accuracy: 0.7661 - val_loss: 559.1971 - val_accuracy: 0.7920\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.8727 - accuracy: 0.7655 - val_loss: 559.9102 - val_accuracy: 0.7904\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 735.3964 - accuracy: 0.7649 - val_loss: 584.6934 - val_accuracy: 0.7973\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 732.9386 - accuracy: 0.7669 - val_loss: 558.6711 - val_accuracy: 0.7924\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.7696 - accuracy: 0.7645 - val_loss: 559.5067 - val_accuracy: 0.7969\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.6378 - accuracy: 0.7656 - val_loss: 557.0291 - val_accuracy: 0.7931\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 720.4464 - accuracy: 0.7664 - val_loss: 556.8840 - val_accuracy: 0.7945\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.7004 - accuracy: 0.7677 - val_loss: 556.5820 - val_accuracy: 0.7932\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.0586 - accuracy: 0.7668 - val_loss: 557.3822 - val_accuracy: 0.8009\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.0859 - accuracy: 0.7685 - val_loss: 558.6831 - val_accuracy: 0.7922\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.4212 - accuracy: 0.7680 - val_loss: 562.1415 - val_accuracy: 0.7965\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.9005 - accuracy: 0.7667 - val_loss: 563.4526 - val_accuracy: 0.8009\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.3034 - accuracy: 0.7662 - val_loss: 558.8857 - val_accuracy: 0.7982\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.2787 - accuracy: 0.7673 - val_loss: 556.5550 - val_accuracy: 0.7949\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.7537 - accuracy: 0.7659 - val_loss: 566.9271 - val_accuracy: 0.7999\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.3947 - accuracy: 0.7677 - val_loss: 563.0084 - val_accuracy: 0.7976\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.8198 - accuracy: 0.7662 - val_loss: 556.3135 - val_accuracy: 0.7982\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.5905 - accuracy: 0.7653 - val_loss: 566.2717 - val_accuracy: 0.7950\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.5853 - accuracy: 0.7662 - val_loss: 562.1011 - val_accuracy: 0.7917\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.3372 - accuracy: 0.7657 - val_loss: 559.1556 - val_accuracy: 0.7897\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.0186 - accuracy: 0.7641 - val_loss: 559.4420 - val_accuracy: 0.7929\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.0889 - accuracy: 0.7648 - val_loss: 557.3632 - val_accuracy: 0.7969\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.9433 - accuracy: 0.7654 - val_loss: 567.6928 - val_accuracy: 0.7941\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.2336 - accuracy: 0.7680 - val_loss: 557.8562 - val_accuracy: 0.7949\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.5880 - accuracy: 0.7652 - val_loss: 557.6655 - val_accuracy: 0.7980\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.7556 - accuracy: 0.7673 - val_loss: 558.4111 - val_accuracy: 0.7990\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.9539 - accuracy: 0.7671 - val_loss: 557.8140 - val_accuracy: 0.7954\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.9720 - accuracy: 0.7675 - val_loss: 560.6417 - val_accuracy: 0.7942\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.6546 - accuracy: 0.7651 - val_loss: 557.3253 - val_accuracy: 0.7923\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.8405 - accuracy: 0.7665 - val_loss: 557.6761 - val_accuracy: 0.7965\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.9186 - accuracy: 0.7670 - val_loss: 561.6210 - val_accuracy: 0.7978\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.9290 - accuracy: 0.7671 - val_loss: 556.8150 - val_accuracy: 0.7963\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.1172 - accuracy: 0.7667 - val_loss: 557.7755 - val_accuracy: 0.7919\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.0668 - accuracy: 0.7693 - val_loss: 574.9924 - val_accuracy: 0.7935\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.3141 - accuracy: 0.7649 - val_loss: 582.6117 - val_accuracy: 0.7929\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.2660 - accuracy: 0.7680 - val_loss: 566.0845 - val_accuracy: 0.7992\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.3092 - accuracy: 0.7630 - val_loss: 559.0261 - val_accuracy: 0.8000\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.3105 - accuracy: 0.7659 - val_loss: 558.6467 - val_accuracy: 0.7961\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.0346 - accuracy: 0.7649 - val_loss: 557.4015 - val_accuracy: 0.7951\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.6380 - accuracy: 0.7675 - val_loss: 558.9045 - val_accuracy: 0.7986\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 719.1625 - accuracy: 0.7676 - val_loss: 556.5014 - val_accuracy: 0.7971\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.9247 - accuracy: 0.7644 - val_loss: 556.5533 - val_accuracy: 0.7989\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 723.3495 - accuracy: 0.7679 - val_loss: 564.9365 - val_accuracy: 0.7944\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.0591 - accuracy: 0.7652 - val_loss: 557.0305 - val_accuracy: 0.7998\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.5420 - accuracy: 0.7641 - val_loss: 566.1932 - val_accuracy: 0.7979\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.7969 - accuracy: 0.7649 - val_loss: 558.0901 - val_accuracy: 0.7959\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.4222 - accuracy: 0.7674 - val_loss: 556.3011 - val_accuracy: 0.7931\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.7373 - accuracy: 0.7673 - val_loss: 559.3826 - val_accuracy: 0.7963\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.9823 - accuracy: 0.7660 - val_loss: 556.2316 - val_accuracy: 0.7958\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.1392 - accuracy: 0.7682 - val_loss: 556.6652 - val_accuracy: 0.8005\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.2952 - accuracy: 0.7673 - val_loss: 558.1392 - val_accuracy: 0.7955\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.1364 - accuracy: 0.7674 - val_loss: 560.9707 - val_accuracy: 0.7992\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 739.5140 - accuracy: 0.7642 - val_loss: 565.5886 - val_accuracy: 0.7976\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.5325 - accuracy: 0.7647 - val_loss: 589.6010 - val_accuracy: 0.7933\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 748.8333 - accuracy: 0.7654 - val_loss: 573.9713 - val_accuracy: 0.7927\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.6367 - accuracy: 0.7665 - val_loss: 558.4988 - val_accuracy: 0.8008\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.7678 - accuracy: 0.7680 - val_loss: 560.0766 - val_accuracy: 0.7999\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 720.4831 - accuracy: 0.7681 - val_loss: 555.5315 - val_accuracy: 0.8022\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.9349 - accuracy: 0.7684 - val_loss: 557.4952 - val_accuracy: 0.7998\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.0477 - accuracy: 0.7676 - val_loss: 558.9159 - val_accuracy: 0.7936\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.6538 - accuracy: 0.7667 - val_loss: 556.3860 - val_accuracy: 0.7948\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.4041 - accuracy: 0.7661 - val_loss: 556.6085 - val_accuracy: 0.7945\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.8840 - accuracy: 0.7674 - val_loss: 556.3309 - val_accuracy: 0.7993\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.4852 - accuracy: 0.7671 - val_loss: 557.2737 - val_accuracy: 0.7985\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.7280 - accuracy: 0.7672 - val_loss: 555.6550 - val_accuracy: 0.7971\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.5730 - accuracy: 0.7657 - val_loss: 555.7845 - val_accuracy: 0.7968\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.8464 - accuracy: 0.7678 - val_loss: 564.4318 - val_accuracy: 0.7978\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.1024 - accuracy: 0.7686 - val_loss: 556.4172 - val_accuracy: 0.7924\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.0562 - accuracy: 0.7667 - val_loss: 556.4406 - val_accuracy: 0.7953\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.3973 - accuracy: 0.7679 - val_loss: 555.6755 - val_accuracy: 0.7997\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.7188 - accuracy: 0.7672 - val_loss: 559.2366 - val_accuracy: 0.7919\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.9830 - accuracy: 0.7664 - val_loss: 557.4858 - val_accuracy: 0.7895\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.1036 - accuracy: 0.7654 - val_loss: 555.3697 - val_accuracy: 0.7954\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.9186 - accuracy: 0.7663 - val_loss: 557.0031 - val_accuracy: 0.7968\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.9250 - accuracy: 0.7669 - val_loss: 556.2469 - val_accuracy: 0.8008\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 720.3415 - accuracy: 0.7670 - val_loss: 558.0021 - val_accuracy: 0.7970\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.8357 - accuracy: 0.7657 - val_loss: 556.9370 - val_accuracy: 0.8019\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.0899 - accuracy: 0.7663 - val_loss: 555.3607 - val_accuracy: 0.8004\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.6912 - accuracy: 0.7677 - val_loss: 557.5660 - val_accuracy: 0.7928\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.5011 - accuracy: 0.7644 - val_loss: 556.5609 - val_accuracy: 0.7948\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.9927 - accuracy: 0.7642 - val_loss: 557.3446 - val_accuracy: 0.7974\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.9255 - accuracy: 0.7689 - val_loss: 555.5958 - val_accuracy: 0.7958\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.6859 - accuracy: 0.7660 - val_loss: 556.4937 - val_accuracy: 0.7914\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.0795 - accuracy: 0.7675 - val_loss: 561.0315 - val_accuracy: 0.7962\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.3478 - accuracy: 0.7669 - val_loss: 555.9610 - val_accuracy: 0.7926\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.2031 - accuracy: 0.7672 - val_loss: 555.9309 - val_accuracy: 0.7957\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.6624 - accuracy: 0.7635 - val_loss: 556.7850 - val_accuracy: 0.7961\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.1266 - accuracy: 0.7672 - val_loss: 556.4103 - val_accuracy: 0.7986\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.8403 - accuracy: 0.7662 - val_loss: 558.3399 - val_accuracy: 0.7976\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.6708 - accuracy: 0.7680 - val_loss: 555.6891 - val_accuracy: 0.7948\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.4427 - accuracy: 0.7660 - val_loss: 554.7590 - val_accuracy: 0.7996\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.9778 - accuracy: 0.7673 - val_loss: 555.3353 - val_accuracy: 0.7968\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.2476 - accuracy: 0.7667 - val_loss: 554.6314 - val_accuracy: 0.7991\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.5229 - accuracy: 0.7667 - val_loss: 557.2360 - val_accuracy: 0.7973\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.0792 - accuracy: 0.7674 - val_loss: 555.7880 - val_accuracy: 0.7970\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.7155 - accuracy: 0.7662 - val_loss: 561.7436 - val_accuracy: 0.7978\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.3182 - accuracy: 0.7664 - val_loss: 556.1326 - val_accuracy: 0.7963\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.2745 - accuracy: 0.7678 - val_loss: 556.2581 - val_accuracy: 0.7945\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 719.5575 - accuracy: 0.7676 - val_loss: 555.5773 - val_accuracy: 0.7999\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.6171 - accuracy: 0.7663 - val_loss: 554.7388 - val_accuracy: 0.7987\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.2460 - accuracy: 0.7667 - val_loss: 554.4592 - val_accuracy: 0.7977\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.9541 - accuracy: 0.7674 - val_loss: 555.2034 - val_accuracy: 0.8000\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.0687 - accuracy: 0.7666 - val_loss: 557.8069 - val_accuracy: 0.7988\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.8019 - accuracy: 0.7658 - val_loss: 555.5619 - val_accuracy: 0.7922\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.5708 - accuracy: 0.7654 - val_loss: 558.1036 - val_accuracy: 0.7899\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.5179 - accuracy: 0.7647 - val_loss: 556.2719 - val_accuracy: 0.7963\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.8820 - accuracy: 0.7669 - val_loss: 559.9684 - val_accuracy: 0.7941\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.5389 - accuracy: 0.7641 - val_loss: 559.3287 - val_accuracy: 0.8024\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.5912 - accuracy: 0.7664 - val_loss: 556.9677 - val_accuracy: 0.7945\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.7869 - accuracy: 0.7675 - val_loss: 566.8248 - val_accuracy: 0.7971\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.6329 - accuracy: 0.7674 - val_loss: 555.2620 - val_accuracy: 0.7971\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 717.9977 - accuracy: 0.7675 - val_loss: 555.0564 - val_accuracy: 0.7976\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.2549 - accuracy: 0.7673 - val_loss: 554.1462 - val_accuracy: 0.7960\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.1599 - accuracy: 0.7673 - val_loss: 553.9844 - val_accuracy: 0.7986\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.0994 - accuracy: 0.7655 - val_loss: 555.5362 - val_accuracy: 0.7981\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.5159 - accuracy: 0.7671 - val_loss: 555.0468 - val_accuracy: 0.7968\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.3220 - accuracy: 0.7672 - val_loss: 558.4861 - val_accuracy: 0.7972\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.2911 - accuracy: 0.7670 - val_loss: 554.3975 - val_accuracy: 0.7888\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.9267 - accuracy: 0.7663 - val_loss: 554.9501 - val_accuracy: 0.7985\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.4831 - accuracy: 0.7659 - val_loss: 554.9670 - val_accuracy: 0.7965\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.3113 - accuracy: 0.7664 - val_loss: 558.1575 - val_accuracy: 0.8018\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.9542 - accuracy: 0.7659 - val_loss: 554.7463 - val_accuracy: 0.8018\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.8110 - accuracy: 0.7677 - val_loss: 555.6254 - val_accuracy: 0.8031\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.0410 - accuracy: 0.7668 - val_loss: 554.3389 - val_accuracy: 0.7993\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.8077 - accuracy: 0.7662 - val_loss: 556.2982 - val_accuracy: 0.7972\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.2955 - accuracy: 0.7662 - val_loss: 556.1539 - val_accuracy: 0.7890\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.2331 - accuracy: 0.7663 - val_loss: 554.3887 - val_accuracy: 0.7951\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.1836 - accuracy: 0.7676 - val_loss: 554.4353 - val_accuracy: 0.7968\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.5912 - accuracy: 0.7643 - val_loss: 555.3321 - val_accuracy: 0.7971\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 720.2369 - accuracy: 0.7663 - val_loss: 556.4168 - val_accuracy: 0.7975\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.7579 - accuracy: 0.7652 - val_loss: 555.3231 - val_accuracy: 0.7956\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.5364 - accuracy: 0.7656 - val_loss: 555.1901 - val_accuracy: 0.7966\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.5391 - accuracy: 0.7676 - val_loss: 555.8958 - val_accuracy: 0.8009\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.6525 - accuracy: 0.7683 - val_loss: 554.4785 - val_accuracy: 0.7934\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.6661 - accuracy: 0.7663 - val_loss: 553.5276 - val_accuracy: 0.8000\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 716.2327 - accuracy: 0.7677 - val_loss: 555.5195 - val_accuracy: 0.7975\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.1851 - accuracy: 0.7665 - val_loss: 557.3602 - val_accuracy: 0.7989\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.3591 - accuracy: 0.7681 - val_loss: 556.3140 - val_accuracy: 0.7984\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.9567 - accuracy: 0.7654 - val_loss: 556.5457 - val_accuracy: 0.8038\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.9278 - accuracy: 0.7650 - val_loss: 555.3608 - val_accuracy: 0.7977\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.7201 - accuracy: 0.7671 - val_loss: 554.3784 - val_accuracy: 0.7970\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.4068 - accuracy: 0.7661 - val_loss: 557.2057 - val_accuracy: 0.7915\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.5449 - accuracy: 0.7667 - val_loss: 554.4052 - val_accuracy: 0.8007\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.0937 - accuracy: 0.7661 - val_loss: 556.1823 - val_accuracy: 0.7986\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.5804 - accuracy: 0.7691 - val_loss: 554.7534 - val_accuracy: 0.7980\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.1998 - accuracy: 0.7670 - val_loss: 553.6746 - val_accuracy: 0.7970\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 715.7545 - accuracy: 0.7666 - val_loss: 555.3096 - val_accuracy: 0.7970\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.8261 - accuracy: 0.7670 - val_loss: 553.9315 - val_accuracy: 0.8005\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.4212 - accuracy: 0.7669 - val_loss: 553.2081 - val_accuracy: 0.8009\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.3617 - accuracy: 0.7675 - val_loss: 553.9301 - val_accuracy: 0.8022\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.0976 - accuracy: 0.7670 - val_loss: 556.3951 - val_accuracy: 0.8001\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.4082 - accuracy: 0.7656 - val_loss: 563.1240 - val_accuracy: 0.8032\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.8489 - accuracy: 0.7671 - val_loss: 577.4175 - val_accuracy: 0.7985\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.9922 - accuracy: 0.7660 - val_loss: 557.7260 - val_accuracy: 0.8004\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.4182 - accuracy: 0.7653 - val_loss: 559.2455 - val_accuracy: 0.7918\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.6512 - accuracy: 0.7661 - val_loss: 555.1700 - val_accuracy: 0.7970\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.6633 - accuracy: 0.7666 - val_loss: 556.7711 - val_accuracy: 0.7959\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.8181 - accuracy: 0.7660 - val_loss: 557.8307 - val_accuracy: 0.7974\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.2734 - accuracy: 0.7662 - val_loss: 553.9526 - val_accuracy: 0.7979\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 716.5815 - accuracy: 0.7680 - val_loss: 554.4112 - val_accuracy: 0.8012\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.8563 - accuracy: 0.7667 - val_loss: 553.5625 - val_accuracy: 0.8023\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 716.6315 - accuracy: 0.7662 - val_loss: 556.1542 - val_accuracy: 0.8005\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.1495 - accuracy: 0.7678 - val_loss: 555.4973 - val_accuracy: 0.7969\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.5173 - accuracy: 0.7663 - val_loss: 553.8013 - val_accuracy: 0.7967\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.6735 - accuracy: 0.7669 - val_loss: 553.7305 - val_accuracy: 0.7984\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.1360 - accuracy: 0.7669 - val_loss: 552.9930 - val_accuracy: 0.7975\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.6248 - accuracy: 0.7664 - val_loss: 554.2430 - val_accuracy: 0.7966\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 715.7590 - accuracy: 0.7661 - val_loss: 553.0680 - val_accuracy: 0.8023\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.4277 - accuracy: 0.7671 - val_loss: 554.1166 - val_accuracy: 0.7974\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.5031 - accuracy: 0.7647 - val_loss: 554.2604 - val_accuracy: 0.7998\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.9877 - accuracy: 0.7661 - val_loss: 552.9443 - val_accuracy: 0.7985\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.9550 - accuracy: 0.7671 - val_loss: 553.1407 - val_accuracy: 0.7916\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.5668 - accuracy: 0.7660 - val_loss: 563.1699 - val_accuracy: 0.7965\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.4534 - accuracy: 0.7676 - val_loss: 557.0538 - val_accuracy: 0.7984\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.8870 - accuracy: 0.7660 - val_loss: 554.8680 - val_accuracy: 0.7983\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.2149 - accuracy: 0.7652 - val_loss: 557.6838 - val_accuracy: 0.7975\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.1133 - accuracy: 0.7643 - val_loss: 556.9444 - val_accuracy: 0.7959\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.5092 - accuracy: 0.7660 - val_loss: 556.4052 - val_accuracy: 0.8000\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.6389 - accuracy: 0.7664 - val_loss: 553.6982 - val_accuracy: 0.7971\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 716.7863 - accuracy: 0.7653 - val_loss: 554.7468 - val_accuracy: 0.7990\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.1000 - accuracy: 0.7670 - val_loss: 552.4297 - val_accuracy: 0.8002\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 716.2480 - accuracy: 0.7669 - val_loss: 559.2780 - val_accuracy: 0.7965\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.4673 - accuracy: 0.7656 - val_loss: 556.5428 - val_accuracy: 0.7965\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.5068 - accuracy: 0.7662 - val_loss: 553.1931 - val_accuracy: 0.7984\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.7407 - accuracy: 0.7665 - val_loss: 553.5526 - val_accuracy: 0.8007\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.3206 - accuracy: 0.7665 - val_loss: 554.8838 - val_accuracy: 0.7972\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.1039 - accuracy: 0.7650 - val_loss: 552.4619 - val_accuracy: 0.7985\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.3007 - accuracy: 0.7666 - val_loss: 553.6733 - val_accuracy: 0.7992\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.1718 - accuracy: 0.7664 - val_loss: 553.6324 - val_accuracy: 0.7920\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.7975 - accuracy: 0.7673 - val_loss: 552.9565 - val_accuracy: 0.8031\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.9577 - accuracy: 0.7667 - val_loss: 554.1606 - val_accuracy: 0.7974\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.8281 - accuracy: 0.7650 - val_loss: 553.2037 - val_accuracy: 0.8005\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.1168 - accuracy: 0.7673 - val_loss: 553.6930 - val_accuracy: 0.8006\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.8502 - accuracy: 0.7672 - val_loss: 554.6143 - val_accuracy: 0.8008\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.2936 - accuracy: 0.7688 - val_loss: 558.3781 - val_accuracy: 0.8013\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.8265 - accuracy: 0.7677 - val_loss: 553.5654 - val_accuracy: 0.8052\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.5614 - accuracy: 0.7660 - val_loss: 558.6807 - val_accuracy: 0.7999\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 725.6719 - accuracy: 0.7658 - val_loss: 557.5690 - val_accuracy: 0.8015\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "# Upsample the second input image\n",
        "upsampled = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Combine the two input images using a convolutional layer\n",
        "combined = layers.Conv2D(31, kernel_size=1, activation='relu')(upsampled)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(combined)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "#conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "#pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer = layers.Conv2D(31, kernel_size=1, activation='relu')(pool2)\n",
        "# Define the model\n",
        "modelnew = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "# Compile the model\n",
        "modelnew.compile(optimizer='adam',\n",
        "loss='mean_absolute_error',\n",
        "metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = modelnew.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "kkKCzkDmit_b",
        "outputId": "0dad1e06-2f3e-4fca-ee05-1383a7ecac74"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extract the accuracy and loss values from the history object\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the first graph in the first subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(acc, label='Training accuracy')\n",
        "plt.plot(val_acc, label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Plot the second graph in the second subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqnohuFakLck",
        "outputId": "980bb7b3-ee60-4efd-80ec-14fe784e005d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 8947.4902 - accuracy: 0.0432 - val_loss: 6212.2568 - val_accuracy: 2.3058e-04\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 7208.3828 - accuracy: 0.0079 - val_loss: 5868.0312 - val_accuracy: 5.3711e-04\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 6080.8027 - accuracy: 0.0029 - val_loss: 5012.7109 - val_accuracy: 0.0043\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 5026.2490 - accuracy: 0.0033 - val_loss: 4318.7075 - val_accuracy: 0.0052\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 4178.8877 - accuracy: 0.0050 - val_loss: 3542.8728 - val_accuracy: 0.1587\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3545.1611 - accuracy: 0.1980 - val_loss: 2958.1323 - val_accuracy: 0.1850\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 2990.0674 - accuracy: 0.1974 - val_loss: 2540.0166 - val_accuracy: 0.1440\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 2665.2056 - accuracy: 0.1727 - val_loss: 2179.8149 - val_accuracy: 0.1845\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2442.1199 - accuracy: 0.1965 - val_loss: 1928.6722 - val_accuracy: 0.1869\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2260.1104 - accuracy: 0.2203 - val_loss: 1765.4951 - val_accuracy: 0.1910\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2098.0913 - accuracy: 0.2328 - val_loss: 1660.2246 - val_accuracy: 0.5331\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1987.7406 - accuracy: 0.2844 - val_loss: 1535.0410 - val_accuracy: 0.5316\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1869.7401 - accuracy: 0.3046 - val_loss: 1425.9738 - val_accuracy: 0.5383\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1782.1672 - accuracy: 0.3139 - val_loss: 1364.4319 - val_accuracy: 0.5794\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1721.8323 - accuracy: 0.3274 - val_loss: 1304.8938 - val_accuracy: 0.6278\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1673.1599 - accuracy: 0.3441 - val_loss: 1289.1643 - val_accuracy: 0.6325\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1639.6979 - accuracy: 0.3488 - val_loss: 1273.8717 - val_accuracy: 0.6343\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1605.7332 - accuracy: 0.3571 - val_loss: 1250.9840 - val_accuracy: 0.6407\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1583.0939 - accuracy: 0.3551 - val_loss: 1247.4731 - val_accuracy: 0.6275\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1566.4514 - accuracy: 0.3565 - val_loss: 1247.0470 - val_accuracy: 0.6027\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1555.2020 - accuracy: 0.3619 - val_loss: 1248.6722 - val_accuracy: 0.6129\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1543.9453 - accuracy: 0.3574 - val_loss: 1239.6954 - val_accuracy: 0.6161\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1544.2816 - accuracy: 0.3644 - val_loss: 1235.4799 - val_accuracy: 0.6211\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1524.4194 - accuracy: 0.4079 - val_loss: 1203.7002 - val_accuracy: 0.6117\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1511.5616 - accuracy: 0.4206 - val_loss: 1200.1797 - val_accuracy: 0.6044\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1518.4457 - accuracy: 0.4251 - val_loss: 1179.9308 - val_accuracy: 0.6426\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1492.3895 - accuracy: 0.4267 - val_loss: 1157.5037 - val_accuracy: 0.6053\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1477.6792 - accuracy: 0.4432 - val_loss: 1116.5367 - val_accuracy: 0.6686\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1331.6003 - accuracy: 0.4566 - val_loss: 1017.2148 - val_accuracy: 0.6298\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1216.8893 - accuracy: 0.4245 - val_loss: 1012.9503 - val_accuracy: 0.6498\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1191.8706 - accuracy: 0.4345 - val_loss: 989.6653 - val_accuracy: 0.6671\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1182.7336 - accuracy: 0.4671 - val_loss: 953.8028 - val_accuracy: 0.6756\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1158.0953 - accuracy: 0.4601 - val_loss: 976.7537 - val_accuracy: 0.6803\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1142.4554 - accuracy: 0.5181 - val_loss: 935.8074 - val_accuracy: 0.6833\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1131.7150 - accuracy: 0.5687 - val_loss: 921.0816 - val_accuracy: 0.6822\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1123.1720 - accuracy: 0.5659 - val_loss: 930.6394 - val_accuracy: 0.6670\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1124.9923 - accuracy: 0.5697 - val_loss: 919.1733 - val_accuracy: 0.6763\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1121.8658 - accuracy: 0.5630 - val_loss: 915.5351 - val_accuracy: 0.6735\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1115.1189 - accuracy: 0.5430 - val_loss: 920.2545 - val_accuracy: 0.6501\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1113.8862 - accuracy: 0.5509 - val_loss: 916.5740 - val_accuracy: 0.6583\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1113.9303 - accuracy: 0.5640 - val_loss: 912.0587 - val_accuracy: 0.6641\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1109.1218 - accuracy: 0.5516 - val_loss: 912.2169 - val_accuracy: 0.6650\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1108.1268 - accuracy: 0.5501 - val_loss: 904.6646 - val_accuracy: 0.6648\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1106.0591 - accuracy: 0.5404 - val_loss: 908.2867 - val_accuracy: 0.6599\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1108.8112 - accuracy: 0.5498 - val_loss: 914.9655 - val_accuracy: 0.6422\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1099.3656 - accuracy: 0.5683 - val_loss: 903.5779 - val_accuracy: 0.6632\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1101.9126 - accuracy: 0.5650 - val_loss: 924.9953 - val_accuracy: 0.6608\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1110.3459 - accuracy: 0.5728 - val_loss: 948.8510 - val_accuracy: 0.6687\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1119.7358 - accuracy: 0.5581 - val_loss: 930.6995 - val_accuracy: 0.6554\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1108.9124 - accuracy: 0.5613 - val_loss: 906.7543 - val_accuracy: 0.6262\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1096.6976 - accuracy: 0.5698 - val_loss: 898.3721 - val_accuracy: 0.6751\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1102.2853 - accuracy: 0.5746 - val_loss: 894.8413 - val_accuracy: 0.6600\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1095.3811 - accuracy: 0.5639 - val_loss: 897.3203 - val_accuracy: 0.6704\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1085.8889 - accuracy: 0.5571 - val_loss: 893.7462 - val_accuracy: 0.6009\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1081.6447 - accuracy: 0.5703 - val_loss: 887.5816 - val_accuracy: 0.6478\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1077.8713 - accuracy: 0.5710 - val_loss: 889.8793 - val_accuracy: 0.6098\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1079.1580 - accuracy: 0.5682 - val_loss: 906.3937 - val_accuracy: 0.6668\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1081.3350 - accuracy: 0.5605 - val_loss: 892.1446 - val_accuracy: 0.6251\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1078.2231 - accuracy: 0.5630 - val_loss: 899.8781 - val_accuracy: 0.5762\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1085.0428 - accuracy: 0.5498 - val_loss: 884.2122 - val_accuracy: 0.6762\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1074.1071 - accuracy: 0.5591 - val_loss: 887.5513 - val_accuracy: 0.6270\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1072.9979 - accuracy: 0.5665 - val_loss: 891.8898 - val_accuracy: 0.6431\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1073.5659 - accuracy: 0.5547 - val_loss: 888.8992 - val_accuracy: 0.6499\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1073.9535 - accuracy: 0.5621 - val_loss: 888.5564 - val_accuracy: 0.6524\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1081.6937 - accuracy: 0.5478 - val_loss: 884.6179 - val_accuracy: 0.6118\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1075.5581 - accuracy: 0.5589 - val_loss: 880.0430 - val_accuracy: 0.6200\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1068.3701 - accuracy: 0.5628 - val_loss: 881.7407 - val_accuracy: 0.5998\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1067.3440 - accuracy: 0.5613 - val_loss: 878.6826 - val_accuracy: 0.6139\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1070.2545 - accuracy: 0.5681 - val_loss: 880.4377 - val_accuracy: 0.6675\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1073.9196 - accuracy: 0.5596 - val_loss: 885.4575 - val_accuracy: 0.6357\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1065.7150 - accuracy: 0.5773 - val_loss: 875.8975 - val_accuracy: 0.6797\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1063.0044 - accuracy: 0.5595 - val_loss: 875.8088 - val_accuracy: 0.6457\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1061.5870 - accuracy: 0.5700 - val_loss: 874.2585 - val_accuracy: 0.6603\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1071.9733 - accuracy: 0.5654 - val_loss: 910.4900 - val_accuracy: 0.6268\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1075.6053 - accuracy: 0.5737 - val_loss: 887.7750 - val_accuracy: 0.6660\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1075.4852 - accuracy: 0.5660 - val_loss: 888.0458 - val_accuracy: 0.6409\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1081.6732 - accuracy: 0.5645 - val_loss: 877.5662 - val_accuracy: 0.6886\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1074.5988 - accuracy: 0.5760 - val_loss: 875.2050 - val_accuracy: 0.6620\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1060.7371 - accuracy: 0.5760 - val_loss: 870.2153 - val_accuracy: 0.6189\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1058.6547 - accuracy: 0.5664 - val_loss: 879.1910 - val_accuracy: 0.6214\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1056.5164 - accuracy: 0.5822 - val_loss: 870.5579 - val_accuracy: 0.6484\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1055.3083 - accuracy: 0.5737 - val_loss: 878.4091 - val_accuracy: 0.6790\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1055.2513 - accuracy: 0.5728 - val_loss: 867.9442 - val_accuracy: 0.6678\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1057.3027 - accuracy: 0.5756 - val_loss: 868.7093 - val_accuracy: 0.6647\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1052.3391 - accuracy: 0.5752 - val_loss: 865.6972 - val_accuracy: 0.6784\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1051.1296 - accuracy: 0.5775 - val_loss: 866.9375 - val_accuracy: 0.6755\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1052.4347 - accuracy: 0.5796 - val_loss: 886.6117 - val_accuracy: 0.6757\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1061.4578 - accuracy: 0.5619 - val_loss: 871.7733 - val_accuracy: 0.6620\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1053.8511 - accuracy: 0.5675 - val_loss: 864.1367 - val_accuracy: 0.6655\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1051.0259 - accuracy: 0.5774 - val_loss: 863.9197 - val_accuracy: 0.6688\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1049.9025 - accuracy: 0.5670 - val_loss: 868.2807 - val_accuracy: 0.6819\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1057.3644 - accuracy: 0.5655 - val_loss: 862.8064 - val_accuracy: 0.6585\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1047.2571 - accuracy: 0.5804 - val_loss: 861.3694 - val_accuracy: 0.6799\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1046.5085 - accuracy: 0.5840 - val_loss: 861.6287 - val_accuracy: 0.6673\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1046.5624 - accuracy: 0.5771 - val_loss: 863.2084 - val_accuracy: 0.6694\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1044.2820 - accuracy: 0.5728 - val_loss: 862.5250 - val_accuracy: 0.6870\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1052.0920 - accuracy: 0.5722 - val_loss: 863.1982 - val_accuracy: 0.6613\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1051.5518 - accuracy: 0.5820 - val_loss: 870.0991 - val_accuracy: 0.6552\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1057.5459 - accuracy: 0.5729 - val_loss: 867.9047 - val_accuracy: 0.6885\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1047.5509 - accuracy: 0.5866 - val_loss: 856.8413 - val_accuracy: 0.6673\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1041.2635 - accuracy: 0.5806 - val_loss: 856.9245 - val_accuracy: 0.6801\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1041.0496 - accuracy: 0.5818 - val_loss: 857.2500 - val_accuracy: 0.6766\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1042.2664 - accuracy: 0.5712 - val_loss: 857.0891 - val_accuracy: 0.6721\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1041.3478 - accuracy: 0.5641 - val_loss: 858.7566 - val_accuracy: 0.6805\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1045.5154 - accuracy: 0.5786 - val_loss: 855.6198 - val_accuracy: 0.6658\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1046.4647 - accuracy: 0.5721 - val_loss: 866.3101 - val_accuracy: 0.6742\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1045.4080 - accuracy: 0.5809 - val_loss: 858.6353 - val_accuracy: 0.6606\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1040.3412 - accuracy: 0.5783 - val_loss: 854.9172 - val_accuracy: 0.6655\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1038.3704 - accuracy: 0.5788 - val_loss: 854.9630 - val_accuracy: 0.6799\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1040.9482 - accuracy: 0.5794 - val_loss: 859.3186 - val_accuracy: 0.6830\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1038.2570 - accuracy: 0.5766 - val_loss: 866.6106 - val_accuracy: 0.6661\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1045.7063 - accuracy: 0.5785 - val_loss: 854.7648 - val_accuracy: 0.6616\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1041.6995 - accuracy: 0.5817 - val_loss: 865.0067 - val_accuracy: 0.6810\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1039.6171 - accuracy: 0.5757 - val_loss: 859.2695 - val_accuracy: 0.6750\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1044.7645 - accuracy: 0.5770 - val_loss: 860.1746 - val_accuracy: 0.6863\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1041.0455 - accuracy: 0.5841 - val_loss: 857.5928 - val_accuracy: 0.6755\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1038.6273 - accuracy: 0.5777 - val_loss: 852.4823 - val_accuracy: 0.6739\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1034.1129 - accuracy: 0.5825 - val_loss: 851.9385 - val_accuracy: 0.6830\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1034.3445 - accuracy: 0.5820 - val_loss: 854.6122 - val_accuracy: 0.6767\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1036.3348 - accuracy: 0.5780 - val_loss: 852.9219 - val_accuracy: 0.6861\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1036.4233 - accuracy: 0.5762 - val_loss: 851.1752 - val_accuracy: 0.6615\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1033.6132 - accuracy: 0.5850 - val_loss: 852.4293 - val_accuracy: 0.6868\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1033.5110 - accuracy: 0.5850 - val_loss: 852.3612 - val_accuracy: 0.6841\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1034.4817 - accuracy: 0.5827 - val_loss: 851.1371 - val_accuracy: 0.6814\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1033.2881 - accuracy: 0.5795 - val_loss: 871.7874 - val_accuracy: 0.6865\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1040.4902 - accuracy: 0.5750 - val_loss: 854.4547 - val_accuracy: 0.6884\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1035.8882 - accuracy: 0.5765 - val_loss: 850.8051 - val_accuracy: 0.6769\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1032.4523 - accuracy: 0.5827 - val_loss: 853.4149 - val_accuracy: 0.6863\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1033.2697 - accuracy: 0.5824 - val_loss: 853.2620 - val_accuracy: 0.6812\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1032.0602 - accuracy: 0.5841 - val_loss: 848.4681 - val_accuracy: 0.6856\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1031.3488 - accuracy: 0.5802 - val_loss: 849.1370 - val_accuracy: 0.6811\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1030.1255 - accuracy: 0.5860 - val_loss: 849.9750 - val_accuracy: 0.6834\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1030.1395 - accuracy: 0.5839 - val_loss: 849.6375 - val_accuracy: 0.6836\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1030.4241 - accuracy: 0.5830 - val_loss: 850.1527 - val_accuracy: 0.6836\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1031.3234 - accuracy: 0.5868 - val_loss: 856.7987 - val_accuracy: 0.6763\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1036.4275 - accuracy: 0.5751 - val_loss: 855.7884 - val_accuracy: 0.6876\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1036.7628 - accuracy: 0.5861 - val_loss: 848.5752 - val_accuracy: 0.6852\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1032.4205 - accuracy: 0.5837 - val_loss: 849.7986 - val_accuracy: 0.6900\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1028.8309 - accuracy: 0.5817 - val_loss: 850.9404 - val_accuracy: 0.6865\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1030.6957 - accuracy: 0.5840 - val_loss: 848.0792 - val_accuracy: 0.6906\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1034.0004 - accuracy: 0.5822 - val_loss: 851.6934 - val_accuracy: 0.6883\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1033.9473 - accuracy: 0.5888 - val_loss: 848.4958 - val_accuracy: 0.6834\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1028.5984 - accuracy: 0.5821 - val_loss: 853.5187 - val_accuracy: 0.6836\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1028.6443 - accuracy: 0.5836 - val_loss: 847.0177 - val_accuracy: 0.6894\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1028.7532 - accuracy: 0.5862 - val_loss: 847.6912 - val_accuracy: 0.6842\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1029.9438 - accuracy: 0.5846 - val_loss: 848.5093 - val_accuracy: 0.6754\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1037.6094 - accuracy: 0.5856 - val_loss: 856.2788 - val_accuracy: 0.6900\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1054.4412 - accuracy: 0.5804 - val_loss: 858.6607 - val_accuracy: 0.6753\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1032.1290 - accuracy: 0.5899 - val_loss: 854.7271 - val_accuracy: 0.6905\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1028.3153 - accuracy: 0.5796 - val_loss: 845.1240 - val_accuracy: 0.6754\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1026.2896 - accuracy: 0.5882 - val_loss: 845.6227 - val_accuracy: 0.6895\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1025.7606 - accuracy: 0.5840 - val_loss: 844.1373 - val_accuracy: 0.6897\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1025.1936 - accuracy: 0.5867 - val_loss: 846.1665 - val_accuracy: 0.6894\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1028.8827 - accuracy: 0.5836 - val_loss: 850.6497 - val_accuracy: 0.6795\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1029.7314 - accuracy: 0.5861 - val_loss: 848.5709 - val_accuracy: 0.6880\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1025.7876 - accuracy: 0.5890 - val_loss: 844.0779 - val_accuracy: 0.6859\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1026.7159 - accuracy: 0.5848 - val_loss: 847.4431 - val_accuracy: 0.6746\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1030.5514 - accuracy: 0.5800 - val_loss: 846.1597 - val_accuracy: 0.6832\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1029.9059 - accuracy: 0.5869 - val_loss: 846.8425 - val_accuracy: 0.6859\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1026.0623 - accuracy: 0.5879 - val_loss: 844.5463 - val_accuracy: 0.6897\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1025.3922 - accuracy: 0.5882 - val_loss: 844.2161 - val_accuracy: 0.6808\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1023.8100 - accuracy: 0.5853 - val_loss: 843.0156 - val_accuracy: 0.6756\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1025.8905 - accuracy: 0.5870 - val_loss: 846.0486 - val_accuracy: 0.6865\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1025.0242 - accuracy: 0.5874 - val_loss: 841.6846 - val_accuracy: 0.6852\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1023.6674 - accuracy: 0.5880 - val_loss: 856.4907 - val_accuracy: 0.6910\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1028.5197 - accuracy: 0.5873 - val_loss: 846.1350 - val_accuracy: 0.6921\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1025.4991 - accuracy: 0.5874 - val_loss: 842.8284 - val_accuracy: 0.6863\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1021.9656 - accuracy: 0.5908 - val_loss: 842.3318 - val_accuracy: 0.6923\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1026.8289 - accuracy: 0.5859 - val_loss: 842.6539 - val_accuracy: 0.6922\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1024.2616 - accuracy: 0.5902 - val_loss: 843.9953 - val_accuracy: 0.6869\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1026.0233 - accuracy: 0.5880 - val_loss: 843.8920 - val_accuracy: 0.6885\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1025.8568 - accuracy: 0.5866 - val_loss: 847.1334 - val_accuracy: 0.6828\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1024.1353 - accuracy: 0.5802 - val_loss: 841.9985 - val_accuracy: 0.6837\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1024.6227 - accuracy: 0.5898 - val_loss: 848.3615 - val_accuracy: 0.6902\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1025.3861 - accuracy: 0.5878 - val_loss: 842.3918 - val_accuracy: 0.6891\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1023.7504 - accuracy: 0.5894 - val_loss: 844.0814 - val_accuracy: 0.6908\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1025.6428 - accuracy: 0.5913 - val_loss: 842.2672 - val_accuracy: 0.6783\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1026.3406 - accuracy: 0.5902 - val_loss: 842.8598 - val_accuracy: 0.6804\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1024.3860 - accuracy: 0.5919 - val_loss: 844.2738 - val_accuracy: 0.6840\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1022.9742 - accuracy: 0.5922 - val_loss: 844.6873 - val_accuracy: 0.6902\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1021.8647 - accuracy: 0.5843 - val_loss: 842.8444 - val_accuracy: 0.6754\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1021.4805 - accuracy: 0.5880 - val_loss: 842.7379 - val_accuracy: 0.6908\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1025.1519 - accuracy: 0.5924 - val_loss: 843.2025 - val_accuracy: 0.6844\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1031.6267 - accuracy: 0.5853 - val_loss: 842.9873 - val_accuracy: 0.6894\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1025.6313 - accuracy: 0.5915 - val_loss: 850.0752 - val_accuracy: 0.6791\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1024.0200 - accuracy: 0.5924 - val_loss: 841.0282 - val_accuracy: 0.6851\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1022.2983 - accuracy: 0.5919 - val_loss: 859.1373 - val_accuracy: 0.6902\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1024.7715 - accuracy: 0.5915 - val_loss: 840.1278 - val_accuracy: 0.6869\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1020.9741 - accuracy: 0.5932 - val_loss: 843.6735 - val_accuracy: 0.6924\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1023.1744 - accuracy: 0.5932 - val_loss: 840.8890 - val_accuracy: 0.6922\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1019.1931 - accuracy: 0.5930 - val_loss: 839.1791 - val_accuracy: 0.6855\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1018.2930 - accuracy: 0.5916 - val_loss: 840.3055 - val_accuracy: 0.6804\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1017.5423 - accuracy: 0.5932 - val_loss: 839.1265 - val_accuracy: 0.6819\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1020.5615 - accuracy: 0.5912 - val_loss: 840.0179 - val_accuracy: 0.6891\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 978.9158 - accuracy: 0.5941 - val_loss: 673.4811 - val_accuracy: 0.6925\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 862.9640 - accuracy: 0.5907 - val_loss: 643.1758 - val_accuracy: 0.6856\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 834.8615 - accuracy: 0.5928 - val_loss: 619.8518 - val_accuracy: 0.6904\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 802.6771 - accuracy: 0.5870 - val_loss: 612.0186 - val_accuracy: 0.6657\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 793.8649 - accuracy: 0.5932 - val_loss: 596.9656 - val_accuracy: 0.6718\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 787.2198 - accuracy: 0.5880 - val_loss: 595.8062 - val_accuracy: 0.6821\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 784.4529 - accuracy: 0.5845 - val_loss: 593.7759 - val_accuracy: 0.6789\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 786.7779 - accuracy: 0.5946 - val_loss: 610.5360 - val_accuracy: 0.6824\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 792.6498 - accuracy: 0.5894 - val_loss: 609.1061 - val_accuracy: 0.6882\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 800.5659 - accuracy: 0.5945 - val_loss: 599.8136 - val_accuracy: 0.6754\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 796.6291 - accuracy: 0.5891 - val_loss: 593.5621 - val_accuracy: 0.6906\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 779.8640 - accuracy: 0.5977 - val_loss: 588.7943 - val_accuracy: 0.6893\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 773.1456 - accuracy: 0.5978 - val_loss: 588.4388 - val_accuracy: 0.6939\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 770.6131 - accuracy: 0.6443 - val_loss: 585.5656 - val_accuracy: 0.7188\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 769.0191 - accuracy: 0.6935 - val_loss: 585.0540 - val_accuracy: 0.7387\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 767.3408 - accuracy: 0.7295 - val_loss: 583.5429 - val_accuracy: 0.7402\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 767.0892 - accuracy: 0.7310 - val_loss: 583.2568 - val_accuracy: 0.7522\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 763.9023 - accuracy: 0.7337 - val_loss: 583.7783 - val_accuracy: 0.7483\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 765.0989 - accuracy: 0.7347 - val_loss: 581.7429 - val_accuracy: 0.7517\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 763.2208 - accuracy: 0.7345 - val_loss: 584.2972 - val_accuracy: 0.7480\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 770.5166 - accuracy: 0.7311 - val_loss: 585.8231 - val_accuracy: 0.7578\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 764.0481 - accuracy: 0.7335 - val_loss: 581.8114 - val_accuracy: 0.7586\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 763.9526 - accuracy: 0.7384 - val_loss: 579.4937 - val_accuracy: 0.7550\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 761.0399 - accuracy: 0.7307 - val_loss: 581.8187 - val_accuracy: 0.7554\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 765.3141 - accuracy: 0.7353 - val_loss: 596.1266 - val_accuracy: 0.7525\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 778.1365 - accuracy: 0.7330 - val_loss: 590.9868 - val_accuracy: 0.7510\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 781.1329 - accuracy: 0.7375 - val_loss: 601.2241 - val_accuracy: 0.7495\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 769.6472 - accuracy: 0.7309 - val_loss: 582.5361 - val_accuracy: 0.7555\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 764.0546 - accuracy: 0.7360 - val_loss: 581.3862 - val_accuracy: 0.7574\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 761.7453 - accuracy: 0.7368 - val_loss: 583.4222 - val_accuracy: 0.7522\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 761.5724 - accuracy: 0.7396 - val_loss: 580.0026 - val_accuracy: 0.7600\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 759.0401 - accuracy: 0.7363 - val_loss: 577.9539 - val_accuracy: 0.7569\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 757.7784 - accuracy: 0.7392 - val_loss: 575.7300 - val_accuracy: 0.7597\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 759.5903 - accuracy: 0.7352 - val_loss: 576.1107 - val_accuracy: 0.7666\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 760.4932 - accuracy: 0.7364 - val_loss: 576.1533 - val_accuracy: 0.7585\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 758.0525 - accuracy: 0.7405 - val_loss: 576.5217 - val_accuracy: 0.7600\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 756.1264 - accuracy: 0.7388 - val_loss: 574.6865 - val_accuracy: 0.7648\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 756.6512 - accuracy: 0.7380 - val_loss: 575.8387 - val_accuracy: 0.7646\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 758.2080 - accuracy: 0.7393 - val_loss: 578.1199 - val_accuracy: 0.7615\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 763.8154 - accuracy: 0.7399 - val_loss: 595.5936 - val_accuracy: 0.7626\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 769.7627 - accuracy: 0.7378 - val_loss: 580.5642 - val_accuracy: 0.7705\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 764.8754 - accuracy: 0.7382 - val_loss: 585.4430 - val_accuracy: 0.7678\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 767.4589 - accuracy: 0.7374 - val_loss: 580.4357 - val_accuracy: 0.7674\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 763.9939 - accuracy: 0.7406 - val_loss: 577.9236 - val_accuracy: 0.7679\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 764.3297 - accuracy: 0.7389 - val_loss: 579.4227 - val_accuracy: 0.7626\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 759.1271 - accuracy: 0.7376 - val_loss: 576.4578 - val_accuracy: 0.7617\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 755.6483 - accuracy: 0.7404 - val_loss: 573.8685 - val_accuracy: 0.7675\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 756.4320 - accuracy: 0.7432 - val_loss: 578.1740 - val_accuracy: 0.7591\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 756.7033 - accuracy: 0.7414 - val_loss: 579.3557 - val_accuracy: 0.7670\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 760.1989 - accuracy: 0.7429 - val_loss: 577.6075 - val_accuracy: 0.7578\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 756.4797 - accuracy: 0.7425 - val_loss: 575.6918 - val_accuracy: 0.7661\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 766.4476 - accuracy: 0.7418 - val_loss: 574.7606 - val_accuracy: 0.7636\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 762.8261 - accuracy: 0.7403 - val_loss: 575.0928 - val_accuracy: 0.7693\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 759.5880 - accuracy: 0.7380 - val_loss: 575.8801 - val_accuracy: 0.7691\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 755.7788 - accuracy: 0.7414 - val_loss: 579.0574 - val_accuracy: 0.7672\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 762.6848 - accuracy: 0.7381 - val_loss: 576.9310 - val_accuracy: 0.7633\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 763.6254 - accuracy: 0.7422 - val_loss: 587.8711 - val_accuracy: 0.7528\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 767.8144 - accuracy: 0.7378 - val_loss: 583.5095 - val_accuracy: 0.7687\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 764.0146 - accuracy: 0.7410 - val_loss: 595.6953 - val_accuracy: 0.7693\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 760.8372 - accuracy: 0.7434 - val_loss: 577.8912 - val_accuracy: 0.7612\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 753.8036 - accuracy: 0.7435 - val_loss: 572.5936 - val_accuracy: 0.7697\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 751.7598 - accuracy: 0.7419 - val_loss: 573.6382 - val_accuracy: 0.7650\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 755.8889 - accuracy: 0.7403 - val_loss: 574.9554 - val_accuracy: 0.7760\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 752.2136 - accuracy: 0.7391 - val_loss: 575.3775 - val_accuracy: 0.7647\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 757.4080 - accuracy: 0.7440 - val_loss: 576.2499 - val_accuracy: 0.7741\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 756.1472 - accuracy: 0.7436 - val_loss: 577.6735 - val_accuracy: 0.7776\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 756.5923 - accuracy: 0.7442 - val_loss: 578.9941 - val_accuracy: 0.7692\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 755.8945 - accuracy: 0.7437 - val_loss: 574.0615 - val_accuracy: 0.7718\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 755.0333 - accuracy: 0.7443 - val_loss: 575.1996 - val_accuracy: 0.7765\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 757.2796 - accuracy: 0.7418 - val_loss: 584.1688 - val_accuracy: 0.7760\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 754.7275 - accuracy: 0.7419 - val_loss: 572.0874 - val_accuracy: 0.7700\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.3849 - accuracy: 0.7447 - val_loss: 570.6959 - val_accuracy: 0.7693\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.1918 - accuracy: 0.7442 - val_loss: 574.8837 - val_accuracy: 0.7735\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 754.9126 - accuracy: 0.7445 - val_loss: 570.4910 - val_accuracy: 0.7705\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 750.2311 - accuracy: 0.7464 - val_loss: 576.1362 - val_accuracy: 0.7723\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 752.2438 - accuracy: 0.7429 - val_loss: 573.5681 - val_accuracy: 0.7828\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 751.0196 - accuracy: 0.7457 - val_loss: 574.3402 - val_accuracy: 0.7745\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.6865 - accuracy: 0.7475 - val_loss: 569.5182 - val_accuracy: 0.7765\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.1492 - accuracy: 0.7472 - val_loss: 572.0320 - val_accuracy: 0.7728\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.9615 - accuracy: 0.7450 - val_loss: 568.8969 - val_accuracy: 0.7752\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.3264 - accuracy: 0.7474 - val_loss: 568.8787 - val_accuracy: 0.7754\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.3398 - accuracy: 0.7468 - val_loss: 570.0200 - val_accuracy: 0.7714\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 747.9041 - accuracy: 0.7456 - val_loss: 571.4873 - val_accuracy: 0.7784\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.3608 - accuracy: 0.7469 - val_loss: 571.4431 - val_accuracy: 0.7734\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 746.7893 - accuracy: 0.7436 - val_loss: 581.1727 - val_accuracy: 0.7761\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 752.7784 - accuracy: 0.7489 - val_loss: 573.0145 - val_accuracy: 0.7781\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 749.7673 - accuracy: 0.7469 - val_loss: 569.3773 - val_accuracy: 0.7709\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 748.0976 - accuracy: 0.7476 - val_loss: 570.3363 - val_accuracy: 0.7858\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.1141 - accuracy: 0.7468 - val_loss: 570.5137 - val_accuracy: 0.7746\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 746.3220 - accuracy: 0.7479 - val_loss: 569.1140 - val_accuracy: 0.7774\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 745.8536 - accuracy: 0.7453 - val_loss: 568.0844 - val_accuracy: 0.7769\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.2324 - accuracy: 0.7485 - val_loss: 571.0764 - val_accuracy: 0.7799\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.2734 - accuracy: 0.7475 - val_loss: 569.7598 - val_accuracy: 0.7841\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 749.1526 - accuracy: 0.7473 - val_loss: 568.9012 - val_accuracy: 0.7809\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 746.3969 - accuracy: 0.7505 - val_loss: 569.9556 - val_accuracy: 0.7825\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 755.2327 - accuracy: 0.7481 - val_loss: 574.7782 - val_accuracy: 0.7758\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 770.9510 - accuracy: 0.7441 - val_loss: 599.4493 - val_accuracy: 0.7866\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 759.4011 - accuracy: 0.7470 - val_loss: 570.7091 - val_accuracy: 0.7813\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 752.0216 - accuracy: 0.7478 - val_loss: 578.7295 - val_accuracy: 0.7699\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 753.9574 - accuracy: 0.7464 - val_loss: 569.3989 - val_accuracy: 0.7824\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.1829 - accuracy: 0.7499 - val_loss: 572.4215 - val_accuracy: 0.7758\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 747.6215 - accuracy: 0.7488 - val_loss: 571.0616 - val_accuracy: 0.7791\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 747.8743 - accuracy: 0.7500 - val_loss: 569.1492 - val_accuracy: 0.7821\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.2792 - accuracy: 0.7510 - val_loss: 568.3995 - val_accuracy: 0.7819\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.1475 - accuracy: 0.7496 - val_loss: 571.5184 - val_accuracy: 0.7908\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 746.4977 - accuracy: 0.7493 - val_loss: 573.8839 - val_accuracy: 0.7770\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 747.7347 - accuracy: 0.7498 - val_loss: 568.7598 - val_accuracy: 0.7852\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 745.2885 - accuracy: 0.7505 - val_loss: 566.9453 - val_accuracy: 0.7886\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.8325 - accuracy: 0.7518 - val_loss: 570.6461 - val_accuracy: 0.7908\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 749.1522 - accuracy: 0.7520 - val_loss: 581.9900 - val_accuracy: 0.7837\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 750.8976 - accuracy: 0.7521 - val_loss: 574.0630 - val_accuracy: 0.7852\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 765.8972 - accuracy: 0.7482 - val_loss: 615.4162 - val_accuracy: 0.7838\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 755.6802 - accuracy: 0.7501 - val_loss: 570.1008 - val_accuracy: 0.7851\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.7110 - accuracy: 0.7529 - val_loss: 570.3886 - val_accuracy: 0.7906\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.0201 - accuracy: 0.7501 - val_loss: 573.8589 - val_accuracy: 0.7884\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 746.9957 - accuracy: 0.7513 - val_loss: 569.8600 - val_accuracy: 0.7877\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 744.5237 - accuracy: 0.7525 - val_loss: 568.7082 - val_accuracy: 0.7879\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.7547 - accuracy: 0.7526 - val_loss: 566.8373 - val_accuracy: 0.7819\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 740.9325 - accuracy: 0.7514 - val_loss: 566.2177 - val_accuracy: 0.7835\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 740.8142 - accuracy: 0.7521 - val_loss: 566.5578 - val_accuracy: 0.7858\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 740.8281 - accuracy: 0.7522 - val_loss: 565.2916 - val_accuracy: 0.7869\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.5823 - accuracy: 0.7528 - val_loss: 568.4906 - val_accuracy: 0.7881\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 741.9764 - accuracy: 0.7535 - val_loss: 576.6898 - val_accuracy: 0.7897\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 747.2860 - accuracy: 0.7546 - val_loss: 568.2866 - val_accuracy: 0.7936\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 754.3002 - accuracy: 0.7522 - val_loss: 569.3904 - val_accuracy: 0.7920\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 755.2071 - accuracy: 0.7513 - val_loss: 578.8063 - val_accuracy: 0.7915\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 748.2985 - accuracy: 0.7555 - val_loss: 569.8415 - val_accuracy: 0.7809\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.1425 - accuracy: 0.7524 - val_loss: 566.6061 - val_accuracy: 0.7873\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 742.1389 - accuracy: 0.7538 - val_loss: 566.1775 - val_accuracy: 0.7871\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.4241 - accuracy: 0.7524 - val_loss: 566.1404 - val_accuracy: 0.7877\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.7705 - accuracy: 0.7548 - val_loss: 566.6158 - val_accuracy: 0.7967\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 743.6240 - accuracy: 0.7536 - val_loss: 567.8599 - val_accuracy: 0.7903\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 740.8336 - accuracy: 0.7526 - val_loss: 566.5824 - val_accuracy: 0.7897\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.1168 - accuracy: 0.7556 - val_loss: 566.1290 - val_accuracy: 0.7930\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 739.3508 - accuracy: 0.7541 - val_loss: 567.5363 - val_accuracy: 0.7936\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 741.7819 - accuracy: 0.7525 - val_loss: 567.0605 - val_accuracy: 0.7913\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 741.2170 - accuracy: 0.7569 - val_loss: 572.4038 - val_accuracy: 0.7867\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 742.3408 - accuracy: 0.7545 - val_loss: 564.6302 - val_accuracy: 0.7856\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 738.2700 - accuracy: 0.7543 - val_loss: 564.8228 - val_accuracy: 0.7949\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 741.0720 - accuracy: 0.7551 - val_loss: 573.3440 - val_accuracy: 0.7934\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 761.5979 - accuracy: 0.7536 - val_loss: 608.4881 - val_accuracy: 0.7850\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.9537 - accuracy: 0.7554 - val_loss: 568.4474 - val_accuracy: 0.7942\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.8608 - accuracy: 0.7496 - val_loss: 569.7845 - val_accuracy: 0.7928\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 741.3446 - accuracy: 0.7530 - val_loss: 569.3630 - val_accuracy: 0.7931\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 740.8464 - accuracy: 0.7528 - val_loss: 564.4564 - val_accuracy: 0.7908\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.6127 - accuracy: 0.7550 - val_loss: 568.5082 - val_accuracy: 0.7921\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 740.4400 - accuracy: 0.7488 - val_loss: 567.1688 - val_accuracy: 0.7906\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.7839 - accuracy: 0.7562 - val_loss: 567.8425 - val_accuracy: 0.7941\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.3422 - accuracy: 0.7541 - val_loss: 565.8005 - val_accuracy: 0.7882\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.9490 - accuracy: 0.7551 - val_loss: 567.1127 - val_accuracy: 0.7937\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.9493 - accuracy: 0.7547 - val_loss: 563.0092 - val_accuracy: 0.7944\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 738.2490 - accuracy: 0.7553 - val_loss: 567.1533 - val_accuracy: 0.7933\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.8655 - accuracy: 0.7523 - val_loss: 599.0670 - val_accuracy: 0.7924\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.9855 - accuracy: 0.7547 - val_loss: 567.3175 - val_accuracy: 0.7940\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 740.3927 - accuracy: 0.7557 - val_loss: 565.5262 - val_accuracy: 0.7947\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 741.9708 - accuracy: 0.7513 - val_loss: 567.2442 - val_accuracy: 0.7993\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 756.7640 - accuracy: 0.7565 - val_loss: 611.8344 - val_accuracy: 0.7913\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 778.9657 - accuracy: 0.7571 - val_loss: 590.8961 - val_accuracy: 0.7965\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 759.1195 - accuracy: 0.7573 - val_loss: 577.4308 - val_accuracy: 0.7964\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 753.6764 - accuracy: 0.7541 - val_loss: 573.6847 - val_accuracy: 0.7980\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 750.2761 - accuracy: 0.7563 - val_loss: 575.0959 - val_accuracy: 0.7899\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 744.3630 - accuracy: 0.7545 - val_loss: 564.6389 - val_accuracy: 0.7988\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.1768 - accuracy: 0.7591 - val_loss: 563.7166 - val_accuracy: 0.7940\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 742.4799 - accuracy: 0.7554 - val_loss: 585.2126 - val_accuracy: 0.7975\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 742.4198 - accuracy: 0.7563 - val_loss: 575.2526 - val_accuracy: 0.7896\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 741.0062 - accuracy: 0.7559 - val_loss: 565.8855 - val_accuracy: 0.7999\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.2430 - accuracy: 0.7555 - val_loss: 562.9258 - val_accuracy: 0.7950\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 741.7758 - accuracy: 0.7582 - val_loss: 562.4819 - val_accuracy: 0.7990\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 734.2050 - accuracy: 0.7599 - val_loss: 562.5374 - val_accuracy: 0.7973\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.9028 - accuracy: 0.7597 - val_loss: 562.9628 - val_accuracy: 0.7976\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 734.9499 - accuracy: 0.7573 - val_loss: 562.7516 - val_accuracy: 0.8025\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 735.1452 - accuracy: 0.7610 - val_loss: 562.9902 - val_accuracy: 0.7974\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 733.6483 - accuracy: 0.7554 - val_loss: 565.5647 - val_accuracy: 0.7966\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 740.6915 - accuracy: 0.7587 - val_loss: 568.1151 - val_accuracy: 0.8013\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 742.0709 - accuracy: 0.7568 - val_loss: 563.0377 - val_accuracy: 0.7998\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.1390 - accuracy: 0.7592 - val_loss: 561.3455 - val_accuracy: 0.8010\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.9103 - accuracy: 0.7603 - val_loss: 561.2100 - val_accuracy: 0.8017\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.0576 - accuracy: 0.7604 - val_loss: 564.5705 - val_accuracy: 0.8004\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.3401 - accuracy: 0.7590 - val_loss: 564.8096 - val_accuracy: 0.7944\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 739.5384 - accuracy: 0.7624 - val_loss: 578.2272 - val_accuracy: 0.7922\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 750.3520 - accuracy: 0.7597 - val_loss: 564.3128 - val_accuracy: 0.7984\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 741.5228 - accuracy: 0.7578 - val_loss: 574.2374 - val_accuracy: 0.7970\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.1386 - accuracy: 0.7603 - val_loss: 565.2064 - val_accuracy: 0.8033\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.0016 - accuracy: 0.7623 - val_loss: 570.4520 - val_accuracy: 0.7997\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.3420 - accuracy: 0.7602 - val_loss: 563.7308 - val_accuracy: 0.7944\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.5037 - accuracy: 0.7591 - val_loss: 566.8489 - val_accuracy: 0.8037\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.8716 - accuracy: 0.7601 - val_loss: 560.7015 - val_accuracy: 0.8002\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.6832 - accuracy: 0.7617 - val_loss: 563.5629 - val_accuracy: 0.8045\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.4804 - accuracy: 0.7622 - val_loss: 562.6956 - val_accuracy: 0.8062\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.8057 - accuracy: 0.7607 - val_loss: 560.7899 - val_accuracy: 0.8052\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.8372 - accuracy: 0.7615 - val_loss: 559.5060 - val_accuracy: 0.8004\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.9762 - accuracy: 0.7637 - val_loss: 565.1640 - val_accuracy: 0.8013\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.3419 - accuracy: 0.7604 - val_loss: 563.8566 - val_accuracy: 0.7981\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.6490 - accuracy: 0.7592 - val_loss: 560.8550 - val_accuracy: 0.8022\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 732.8724 - accuracy: 0.7628 - val_loss: 565.5022 - val_accuracy: 0.7982\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 738.0857 - accuracy: 0.7600 - val_loss: 564.6077 - val_accuracy: 0.7928\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.9500 - accuracy: 0.7612 - val_loss: 567.2656 - val_accuracy: 0.7928\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 736.7835 - accuracy: 0.7600 - val_loss: 564.2264 - val_accuracy: 0.8004\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.2523 - accuracy: 0.7605 - val_loss: 562.5009 - val_accuracy: 0.8024\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.8130 - accuracy: 0.7611 - val_loss: 564.6431 - val_accuracy: 0.7989\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.2535 - accuracy: 0.7632 - val_loss: 559.7819 - val_accuracy: 0.8023\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.2734 - accuracy: 0.7623 - val_loss: 562.3832 - val_accuracy: 0.8030\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 737.7375 - accuracy: 0.7588 - val_loss: 560.6736 - val_accuracy: 0.8011\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.0277 - accuracy: 0.7633 - val_loss: 561.6953 - val_accuracy: 0.8022\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.7693 - accuracy: 0.7619 - val_loss: 560.3516 - val_accuracy: 0.7984\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.5725 - accuracy: 0.7621 - val_loss: 558.5898 - val_accuracy: 0.8024\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.6591 - accuracy: 0.7638 - val_loss: 558.9128 - val_accuracy: 0.7969\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.9648 - accuracy: 0.7619 - val_loss: 559.2138 - val_accuracy: 0.8063\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.0615 - accuracy: 0.7609 - val_loss: 564.0019 - val_accuracy: 0.7999\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.9050 - accuracy: 0.7608 - val_loss: 583.3443 - val_accuracy: 0.7943\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 741.1490 - accuracy: 0.7615 - val_loss: 567.8398 - val_accuracy: 0.7945\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.5215 - accuracy: 0.7615 - val_loss: 559.1771 - val_accuracy: 0.8014\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.2112 - accuracy: 0.7620 - val_loss: 559.1906 - val_accuracy: 0.8001\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.9581 - accuracy: 0.7644 - val_loss: 560.8498 - val_accuracy: 0.8046\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.9225 - accuracy: 0.7641 - val_loss: 561.1503 - val_accuracy: 0.7988\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 732.9984 - accuracy: 0.7638 - val_loss: 566.9554 - val_accuracy: 0.7958\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 732.8038 - accuracy: 0.7606 - val_loss: 560.3270 - val_accuracy: 0.8015\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.9377 - accuracy: 0.7629 - val_loss: 559.7546 - val_accuracy: 0.7976\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.8417 - accuracy: 0.7621 - val_loss: 558.9278 - val_accuracy: 0.8050\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.5130 - accuracy: 0.7637 - val_loss: 560.4882 - val_accuracy: 0.8051\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.2280 - accuracy: 0.7651 - val_loss: 557.7880 - val_accuracy: 0.8021\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.3412 - accuracy: 0.7639 - val_loss: 559.5854 - val_accuracy: 0.8002\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.1122 - accuracy: 0.7637 - val_loss: 560.4314 - val_accuracy: 0.8062\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.0976 - accuracy: 0.7645 - val_loss: 563.3649 - val_accuracy: 0.8004\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 732.2870 - accuracy: 0.7618 - val_loss: 561.0199 - val_accuracy: 0.8022\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.3733 - accuracy: 0.7647 - val_loss: 560.8828 - val_accuracy: 0.8004\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.9644 - accuracy: 0.7614 - val_loss: 575.6353 - val_accuracy: 0.8063\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.2443 - accuracy: 0.7629 - val_loss: 604.5697 - val_accuracy: 0.8068\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 773.9024 - accuracy: 0.7583 - val_loss: 636.5487 - val_accuracy: 0.7974\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 792.1036 - accuracy: 0.7590 - val_loss: 589.6713 - val_accuracy: 0.7951\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 779.3682 - accuracy: 0.7551 - val_loss: 565.6205 - val_accuracy: 0.8066\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.7212 - accuracy: 0.7582 - val_loss: 562.0954 - val_accuracy: 0.8011\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.1937 - accuracy: 0.7591 - val_loss: 560.4974 - val_accuracy: 0.7997\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.3043 - accuracy: 0.7635 - val_loss: 559.4873 - val_accuracy: 0.8059\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.6169 - accuracy: 0.7618 - val_loss: 558.4462 - val_accuracy: 0.8048\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 730.4736 - accuracy: 0.7649 - val_loss: 562.1853 - val_accuracy: 0.8044\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.7753 - accuracy: 0.7652 - val_loss: 558.5977 - val_accuracy: 0.8034\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.1949 - accuracy: 0.7616 - val_loss: 557.4073 - val_accuracy: 0.8065\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.2453 - accuracy: 0.7635 - val_loss: 558.0273 - val_accuracy: 0.8067\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.0911 - accuracy: 0.7648 - val_loss: 558.2835 - val_accuracy: 0.8030\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.6816 - accuracy: 0.7647 - val_loss: 559.8336 - val_accuracy: 0.8010\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 726.8004 - accuracy: 0.7646 - val_loss: 557.8394 - val_accuracy: 0.8042\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.4222 - accuracy: 0.7669 - val_loss: 558.0833 - val_accuracy: 0.8040\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.7263 - accuracy: 0.7610 - val_loss: 568.7603 - val_accuracy: 0.8054\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 735.9599 - accuracy: 0.7665 - val_loss: 557.6760 - val_accuracy: 0.8074\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 727.7391 - accuracy: 0.7634 - val_loss: 559.3672 - val_accuracy: 0.8061\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.8614 - accuracy: 0.7648 - val_loss: 560.8894 - val_accuracy: 0.8015\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.2996 - accuracy: 0.7660 - val_loss: 557.5145 - val_accuracy: 0.8066\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.9421 - accuracy: 0.7644 - val_loss: 556.4852 - val_accuracy: 0.8078\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.8998 - accuracy: 0.7667 - val_loss: 557.3452 - val_accuracy: 0.8064\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.0307 - accuracy: 0.7645 - val_loss: 557.9182 - val_accuracy: 0.8104\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.8514 - accuracy: 0.7646 - val_loss: 557.0848 - val_accuracy: 0.8055\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.1376 - accuracy: 0.7641 - val_loss: 560.7322 - val_accuracy: 0.8086\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.5115 - accuracy: 0.7638 - val_loss: 560.4108 - val_accuracy: 0.7989\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 732.1704 - accuracy: 0.7638 - val_loss: 560.9724 - val_accuracy: 0.8063\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 733.7222 - accuracy: 0.7627 - val_loss: 560.3319 - val_accuracy: 0.8057\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.4291 - accuracy: 0.7654 - val_loss: 559.5071 - val_accuracy: 0.8070\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.6177 - accuracy: 0.7644 - val_loss: 560.0856 - val_accuracy: 0.8051\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.4905 - accuracy: 0.7646 - val_loss: 557.2636 - val_accuracy: 0.8026\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.0745 - accuracy: 0.7669 - val_loss: 556.7006 - val_accuracy: 0.8090\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.9679 - accuracy: 0.7649 - val_loss: 559.2266 - val_accuracy: 0.8075\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.2390 - accuracy: 0.7670 - val_loss: 556.2611 - val_accuracy: 0.8069\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 724.9616 - accuracy: 0.7653 - val_loss: 556.3531 - val_accuracy: 0.8078\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.0418 - accuracy: 0.7648 - val_loss: 558.4824 - val_accuracy: 0.8040\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 730.2238 - accuracy: 0.7648 - val_loss: 560.8485 - val_accuracy: 0.8124\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.6404 - accuracy: 0.7634 - val_loss: 557.5276 - val_accuracy: 0.8021\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.3646 - accuracy: 0.7659 - val_loss: 564.9254 - val_accuracy: 0.8016\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 740.6362 - accuracy: 0.7650 - val_loss: 563.6299 - val_accuracy: 0.8013\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.4164 - accuracy: 0.7655 - val_loss: 556.9879 - val_accuracy: 0.8080\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.7213 - accuracy: 0.7662 - val_loss: 557.5354 - val_accuracy: 0.8070\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 726.4219 - accuracy: 0.7637 - val_loss: 559.8043 - val_accuracy: 0.8067\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 726.5673 - accuracy: 0.7648 - val_loss: 556.6161 - val_accuracy: 0.8110\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 724.4460 - accuracy: 0.7629 - val_loss: 555.6268 - val_accuracy: 0.8126\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 723.8730 - accuracy: 0.7659 - val_loss: 563.8926 - val_accuracy: 0.8098\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 732.3278 - accuracy: 0.7658 - val_loss: 562.6799 - val_accuracy: 0.8117\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 728.9449 - accuracy: 0.7653 - val_loss: 557.1732 - val_accuracy: 0.8052\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 726.0085 - accuracy: 0.7650 - val_loss: 559.4818 - val_accuracy: 0.8124\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 726.8139 - accuracy: 0.7653 - val_loss: 557.1038 - val_accuracy: 0.8089\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 724.4735 - accuracy: 0.7628 - val_loss: 556.9524 - val_accuracy: 0.8089\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 725.2635 - accuracy: 0.7649 - val_loss: 555.6779 - val_accuracy: 0.8077\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 727.8228 - accuracy: 0.7663 - val_loss: 564.7347 - val_accuracy: 0.8022\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 731.4295 - accuracy: 0.7631 - val_loss: 556.7471 - val_accuracy: 0.8074\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 728.2837 - accuracy: 0.7647 - val_loss: 584.3626 - val_accuracy: 0.8101\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 731.0312 - accuracy: 0.7634 - val_loss: 557.8049 - val_accuracy: 0.8089\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 730.7819 - accuracy: 0.7657 - val_loss: 564.9261 - val_accuracy: 0.8037\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 729.6042 - accuracy: 0.7671 - val_loss: 568.6630 - val_accuracy: 0.8100\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 735.7899 - accuracy: 0.7666 - val_loss: 563.7587 - val_accuracy: 0.8075\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 731.7182 - accuracy: 0.7644 - val_loss: 562.1351 - val_accuracy: 0.8056\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.8069 - accuracy: 0.7631 - val_loss: 556.1700 - val_accuracy: 0.8086\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.9165 - accuracy: 0.7659 - val_loss: 558.0182 - val_accuracy: 0.8069\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.0203 - accuracy: 0.7643 - val_loss: 557.9354 - val_accuracy: 0.8094\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 724.4997 - accuracy: 0.7665 - val_loss: 556.4545 - val_accuracy: 0.8077\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 724.9983 - accuracy: 0.7655 - val_loss: 556.7243 - val_accuracy: 0.8014\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.6456 - accuracy: 0.7643 - val_loss: 555.1006 - val_accuracy: 0.8069\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.2376 - accuracy: 0.7659 - val_loss: 556.1844 - val_accuracy: 0.8052\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 728.8839 - accuracy: 0.7647 - val_loss: 556.6821 - val_accuracy: 0.8035\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 727.9426 - accuracy: 0.7635 - val_loss: 562.8170 - val_accuracy: 0.8094\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.0705 - accuracy: 0.7666 - val_loss: 557.1542 - val_accuracy: 0.8021\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.0992 - accuracy: 0.7636 - val_loss: 559.7568 - val_accuracy: 0.8068\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.7834 - accuracy: 0.7635 - val_loss: 559.4543 - val_accuracy: 0.8075\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 742.5886 - accuracy: 0.7628 - val_loss: 572.1041 - val_accuracy: 0.8036\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.3776 - accuracy: 0.7645 - val_loss: 559.0956 - val_accuracy: 0.8043\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.0704 - accuracy: 0.7641 - val_loss: 557.5441 - val_accuracy: 0.8004\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.1808 - accuracy: 0.7674 - val_loss: 555.8388 - val_accuracy: 0.8052\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.0654 - accuracy: 0.7688 - val_loss: 555.0797 - val_accuracy: 0.8071\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.9976 - accuracy: 0.7657 - val_loss: 555.9636 - val_accuracy: 0.8065\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.7233 - accuracy: 0.7670 - val_loss: 555.3134 - val_accuracy: 0.8104\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.3780 - accuracy: 0.7674 - val_loss: 555.9662 - val_accuracy: 0.8073\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.0151 - accuracy: 0.7663 - val_loss: 555.7254 - val_accuracy: 0.8075\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.3622 - accuracy: 0.7659 - val_loss: 553.5043 - val_accuracy: 0.8105\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.2943 - accuracy: 0.7702 - val_loss: 554.3193 - val_accuracy: 0.8088\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.0492 - accuracy: 0.7650 - val_loss: 554.6368 - val_accuracy: 0.8063\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.4431 - accuracy: 0.7673 - val_loss: 554.3741 - val_accuracy: 0.8079\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.3532 - accuracy: 0.7678 - val_loss: 559.9934 - val_accuracy: 0.8053\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.8476 - accuracy: 0.7657 - val_loss: 558.1906 - val_accuracy: 0.8100\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.6345 - accuracy: 0.7659 - val_loss: 574.1392 - val_accuracy: 0.8074\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.5214 - accuracy: 0.7665 - val_loss: 556.3124 - val_accuracy: 0.8072\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.8936 - accuracy: 0.7664 - val_loss: 555.6942 - val_accuracy: 0.8110\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.4163 - accuracy: 0.7662 - val_loss: 554.4653 - val_accuracy: 0.8095\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.9655 - accuracy: 0.7651 - val_loss: 556.3925 - val_accuracy: 0.8062\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.9304 - accuracy: 0.7681 - val_loss: 554.9101 - val_accuracy: 0.8085\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.3134 - accuracy: 0.7674 - val_loss: 554.2466 - val_accuracy: 0.8073\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.5382 - accuracy: 0.7676 - val_loss: 554.7103 - val_accuracy: 0.8064\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 721.8956 - accuracy: 0.7670 - val_loss: 557.2305 - val_accuracy: 0.8025\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.4219 - accuracy: 0.7653 - val_loss: 557.7160 - val_accuracy: 0.8103\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.9742 - accuracy: 0.7661 - val_loss: 571.1022 - val_accuracy: 0.8104\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 772.7809 - accuracy: 0.7585 - val_loss: 613.6887 - val_accuracy: 0.8027\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 759.6182 - accuracy: 0.7583 - val_loss: 583.1028 - val_accuracy: 0.8094\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.7662 - accuracy: 0.7644 - val_loss: 560.2487 - val_accuracy: 0.8088\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.7573 - accuracy: 0.7668 - val_loss: 602.3015 - val_accuracy: 0.8081\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.7352 - accuracy: 0.7645 - val_loss: 562.5804 - val_accuracy: 0.8114\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 731.4757 - accuracy: 0.7667 - val_loss: 559.5078 - val_accuracy: 0.8081\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.8209 - accuracy: 0.7690 - val_loss: 555.2701 - val_accuracy: 0.8085\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.6005 - accuracy: 0.7665 - val_loss: 555.8690 - val_accuracy: 0.8046\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.4774 - accuracy: 0.7652 - val_loss: 557.6902 - val_accuracy: 0.8066\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.0217 - accuracy: 0.7662 - val_loss: 560.3713 - val_accuracy: 0.8069\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.1268 - accuracy: 0.7653 - val_loss: 556.4260 - val_accuracy: 0.8041\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.9846 - accuracy: 0.7658 - val_loss: 556.9819 - val_accuracy: 0.8107\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.0058 - accuracy: 0.7688 - val_loss: 554.2106 - val_accuracy: 0.8079\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 722.2939 - accuracy: 0.7684 - val_loss: 553.7787 - val_accuracy: 0.8052\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.0985 - accuracy: 0.7671 - val_loss: 560.3687 - val_accuracy: 0.8093\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 723.3545 - accuracy: 0.7685 - val_loss: 553.0034 - val_accuracy: 0.8108\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.9208 - accuracy: 0.7676 - val_loss: 559.0128 - val_accuracy: 0.8119\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.1269 - accuracy: 0.7667 - val_loss: 571.6996 - val_accuracy: 0.8006\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.4755 - accuracy: 0.7680 - val_loss: 559.1871 - val_accuracy: 0.8150\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.8422 - accuracy: 0.7636 - val_loss: 556.2364 - val_accuracy: 0.8101\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.6846 - accuracy: 0.7655 - val_loss: 555.7449 - val_accuracy: 0.8120\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.7551 - accuracy: 0.7651 - val_loss: 554.3807 - val_accuracy: 0.8079\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.2603 - accuracy: 0.7685 - val_loss: 556.5628 - val_accuracy: 0.8074\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.6866 - accuracy: 0.7660 - val_loss: 554.5443 - val_accuracy: 0.8085\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.0839 - accuracy: 0.7655 - val_loss: 553.8635 - val_accuracy: 0.8106\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.4750 - accuracy: 0.7675 - val_loss: 567.6143 - val_accuracy: 0.8099\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.8386 - accuracy: 0.7674 - val_loss: 562.2158 - val_accuracy: 0.8076\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.7418 - accuracy: 0.7675 - val_loss: 560.5059 - val_accuracy: 0.8099\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.8674 - accuracy: 0.7703 - val_loss: 552.7952 - val_accuracy: 0.8097\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.7767 - accuracy: 0.7695 - val_loss: 553.1775 - val_accuracy: 0.8092\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.1551 - accuracy: 0.7677 - val_loss: 553.0905 - val_accuracy: 0.8060\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.2313 - accuracy: 0.7671 - val_loss: 555.9337 - val_accuracy: 0.8066\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.0814 - accuracy: 0.7693 - val_loss: 552.7885 - val_accuracy: 0.8032\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.1751 - accuracy: 0.7632 - val_loss: 572.9314 - val_accuracy: 0.8076\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.1719 - accuracy: 0.7701 - val_loss: 556.9128 - val_accuracy: 0.8117\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.7781 - accuracy: 0.7671 - val_loss: 557.4254 - val_accuracy: 0.8054\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.3110 - accuracy: 0.7684 - val_loss: 553.1766 - val_accuracy: 0.8082\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.3327 - accuracy: 0.7695 - val_loss: 553.2285 - val_accuracy: 0.8095\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.2885 - accuracy: 0.7674 - val_loss: 557.2074 - val_accuracy: 0.8085\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.6253 - accuracy: 0.7699 - val_loss: 553.5316 - val_accuracy: 0.8055\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.1302 - accuracy: 0.7679 - val_loss: 553.4135 - val_accuracy: 0.8090\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.8858 - accuracy: 0.7692 - val_loss: 553.1813 - val_accuracy: 0.8089\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.7210 - accuracy: 0.7683 - val_loss: 556.2767 - val_accuracy: 0.8089\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.7388 - accuracy: 0.7711 - val_loss: 552.8524 - val_accuracy: 0.8092\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.1030 - accuracy: 0.7682 - val_loss: 559.7809 - val_accuracy: 0.8088\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.1629 - accuracy: 0.7689 - val_loss: 554.8192 - val_accuracy: 0.8070\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.2369 - accuracy: 0.7696 - val_loss: 552.8985 - val_accuracy: 0.8086\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.1340 - accuracy: 0.7675 - val_loss: 565.4595 - val_accuracy: 0.8089\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.2818 - accuracy: 0.7684 - val_loss: 557.0651 - val_accuracy: 0.8074\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.4178 - accuracy: 0.7633 - val_loss: 558.6546 - val_accuracy: 0.8098\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.1040 - accuracy: 0.7664 - val_loss: 554.6663 - val_accuracy: 0.8074\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.7028 - accuracy: 0.7667 - val_loss: 555.4731 - val_accuracy: 0.8058\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.0244 - accuracy: 0.7703 - val_loss: 552.6360 - val_accuracy: 0.8037\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.8404 - accuracy: 0.7692 - val_loss: 560.8934 - val_accuracy: 0.8040\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.3063 - accuracy: 0.7696 - val_loss: 553.2216 - val_accuracy: 0.8009\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.6243 - accuracy: 0.7677 - val_loss: 557.5143 - val_accuracy: 0.8107\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.8373 - accuracy: 0.7709 - val_loss: 554.8475 - val_accuracy: 0.8096\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 720.9081 - accuracy: 0.7678 - val_loss: 553.2525 - val_accuracy: 0.8094\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.9145 - accuracy: 0.7674 - val_loss: 553.8883 - val_accuracy: 0.8060\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.0749 - accuracy: 0.7688 - val_loss: 552.3286 - val_accuracy: 0.8058\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.2116 - accuracy: 0.7693 - val_loss: 550.9793 - val_accuracy: 0.8088\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.3342 - accuracy: 0.7704 - val_loss: 561.8495 - val_accuracy: 0.8079\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.4935 - accuracy: 0.7680 - val_loss: 554.7776 - val_accuracy: 0.8098\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.6258 - accuracy: 0.7688 - val_loss: 554.3098 - val_accuracy: 0.8116\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.6984 - accuracy: 0.7674 - val_loss: 555.1475 - val_accuracy: 0.8083\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.1588 - accuracy: 0.7667 - val_loss: 565.1676 - val_accuracy: 0.8074\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.2496 - accuracy: 0.7705 - val_loss: 553.8005 - val_accuracy: 0.8068\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.3730 - accuracy: 0.7714 - val_loss: 563.1146 - val_accuracy: 0.8043\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.9034 - accuracy: 0.7644 - val_loss: 553.8477 - val_accuracy: 0.8090\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.8605 - accuracy: 0.7690 - val_loss: 552.5704 - val_accuracy: 0.8055\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.2584 - accuracy: 0.7678 - val_loss: 554.4459 - val_accuracy: 0.8072\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.3578 - accuracy: 0.7691 - val_loss: 552.3910 - val_accuracy: 0.8067\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.4753 - accuracy: 0.7688 - val_loss: 552.3162 - val_accuracy: 0.8012\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.4300 - accuracy: 0.7715 - val_loss: 555.6376 - val_accuracy: 0.8057\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.1092 - accuracy: 0.7682 - val_loss: 555.0585 - val_accuracy: 0.8062\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.3074 - accuracy: 0.7698 - val_loss: 558.6814 - val_accuracy: 0.8057\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.6279 - accuracy: 0.7677 - val_loss: 553.0491 - val_accuracy: 0.8065\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.1816 - accuracy: 0.7721 - val_loss: 551.4183 - val_accuracy: 0.8075\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.2396 - accuracy: 0.7702 - val_loss: 552.1306 - val_accuracy: 0.8101\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.0482 - accuracy: 0.7705 - val_loss: 551.9236 - val_accuracy: 0.8097\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.8487 - accuracy: 0.7692 - val_loss: 552.6849 - val_accuracy: 0.8081\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.6479 - accuracy: 0.7698 - val_loss: 565.4523 - val_accuracy: 0.8112\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.3689 - accuracy: 0.7681 - val_loss: 570.8936 - val_accuracy: 0.8107\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.1670 - accuracy: 0.7672 - val_loss: 563.1466 - val_accuracy: 0.8074\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.3186 - accuracy: 0.7692 - val_loss: 570.2896 - val_accuracy: 0.8030\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.2686 - accuracy: 0.7674 - val_loss: 562.1437 - val_accuracy: 0.8104\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.8769 - accuracy: 0.7671 - val_loss: 560.4214 - val_accuracy: 0.8026\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 726.6729 - accuracy: 0.7670 - val_loss: 553.1946 - val_accuracy: 0.8047\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.9915 - accuracy: 0.7675 - val_loss: 554.0085 - val_accuracy: 0.8133\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.9067 - accuracy: 0.7688 - val_loss: 562.4776 - val_accuracy: 0.8015\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.4219 - accuracy: 0.7674 - val_loss: 560.6918 - val_accuracy: 0.8107\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.6595 - accuracy: 0.7703 - val_loss: 563.1129 - val_accuracy: 0.8050\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 729.3333 - accuracy: 0.7665 - val_loss: 572.9359 - val_accuracy: 0.8076\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.8392 - accuracy: 0.7690 - val_loss: 560.4882 - val_accuracy: 0.8121\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 732.9037 - accuracy: 0.7701 - val_loss: 577.3668 - val_accuracy: 0.8093\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.6992 - accuracy: 0.7649 - val_loss: 559.1907 - val_accuracy: 0.8143\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 726.8203 - accuracy: 0.7708 - val_loss: 570.1713 - val_accuracy: 0.8136\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 730.7625 - accuracy: 0.7693 - val_loss: 564.9822 - val_accuracy: 0.8050\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.4974 - accuracy: 0.7690 - val_loss: 556.0855 - val_accuracy: 0.8056\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.2097 - accuracy: 0.7731 - val_loss: 554.3110 - val_accuracy: 0.8005\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.5068 - accuracy: 0.7674 - val_loss: 558.9995 - val_accuracy: 0.8014\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 723.9449 - accuracy: 0.7699 - val_loss: 552.4104 - val_accuracy: 0.8073\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.1000 - accuracy: 0.7713 - val_loss: 553.1937 - val_accuracy: 0.8116\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.3884 - accuracy: 0.7721 - val_loss: 553.0157 - val_accuracy: 0.8125\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.5937 - accuracy: 0.7718 - val_loss: 551.2173 - val_accuracy: 0.8098\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.4258 - accuracy: 0.7719 - val_loss: 551.2297 - val_accuracy: 0.8056\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.3975 - accuracy: 0.7702 - val_loss: 555.1340 - val_accuracy: 0.8060\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.2520 - accuracy: 0.7695 - val_loss: 566.4949 - val_accuracy: 0.8079\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.4898 - accuracy: 0.7686 - val_loss: 556.7391 - val_accuracy: 0.8078\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 721.9423 - accuracy: 0.7715 - val_loss: 552.5436 - val_accuracy: 0.8090\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.6721 - accuracy: 0.7676 - val_loss: 554.4735 - val_accuracy: 0.8116\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.0110 - accuracy: 0.7685 - val_loss: 551.5781 - val_accuracy: 0.8113\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.5233 - accuracy: 0.7704 - val_loss: 553.3057 - val_accuracy: 0.8069\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.1033 - accuracy: 0.7695 - val_loss: 555.1638 - val_accuracy: 0.8116\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.4636 - accuracy: 0.7701 - val_loss: 554.8483 - val_accuracy: 0.8089\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.2250 - accuracy: 0.7707 - val_loss: 574.4774 - val_accuracy: 0.8103\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.3008 - accuracy: 0.7697 - val_loss: 551.5742 - val_accuracy: 0.8100\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.5419 - accuracy: 0.7709 - val_loss: 584.8072 - val_accuracy: 0.8093\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 734.4521 - accuracy: 0.7700 - val_loss: 591.1022 - val_accuracy: 0.8054\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 733.0255 - accuracy: 0.7697 - val_loss: 561.5377 - val_accuracy: 0.8077\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.4135 - accuracy: 0.7670 - val_loss: 556.7869 - val_accuracy: 0.8090\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.9589 - accuracy: 0.7699 - val_loss: 554.7237 - val_accuracy: 0.8073\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.1832 - accuracy: 0.7690 - val_loss: 550.8091 - val_accuracy: 0.8070\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.1957 - accuracy: 0.7698 - val_loss: 551.4413 - val_accuracy: 0.8101\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.4648 - accuracy: 0.7705 - val_loss: 549.3821 - val_accuracy: 0.8123\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.1315 - accuracy: 0.7697 - val_loss: 550.4182 - val_accuracy: 0.8113\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.1734 - accuracy: 0.7715 - val_loss: 550.5112 - val_accuracy: 0.8044\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.0260 - accuracy: 0.7693 - val_loss: 552.0312 - val_accuracy: 0.8093\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.3759 - accuracy: 0.7714 - val_loss: 551.0842 - val_accuracy: 0.8085\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.8519 - accuracy: 0.7706 - val_loss: 552.3150 - val_accuracy: 0.8100\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.4361 - accuracy: 0.7718 - val_loss: 551.0239 - val_accuracy: 0.8096\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.7310 - accuracy: 0.7725 - val_loss: 553.2638 - val_accuracy: 0.8034\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.2905 - accuracy: 0.7701 - val_loss: 551.1188 - val_accuracy: 0.8103\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.5590 - accuracy: 0.7699 - val_loss: 552.1006 - val_accuracy: 0.8121\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.9926 - accuracy: 0.7713 - val_loss: 551.0566 - val_accuracy: 0.8041\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.8698 - accuracy: 0.7710 - val_loss: 570.7010 - val_accuracy: 0.8112\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 736.1602 - accuracy: 0.7710 - val_loss: 570.5537 - val_accuracy: 0.8086\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 740.6826 - accuracy: 0.7698 - val_loss: 556.0613 - val_accuracy: 0.8044\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.4842 - accuracy: 0.7712 - val_loss: 552.3162 - val_accuracy: 0.8108\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.2816 - accuracy: 0.7684 - val_loss: 551.4598 - val_accuracy: 0.8044\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 716.7071 - accuracy: 0.7699 - val_loss: 554.1385 - val_accuracy: 0.8097\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.7742 - accuracy: 0.7729 - val_loss: 549.9698 - val_accuracy: 0.8117\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.9503 - accuracy: 0.7707 - val_loss: 552.6075 - val_accuracy: 0.8039\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.5204 - accuracy: 0.7727 - val_loss: 549.7117 - val_accuracy: 0.8088\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.4219 - accuracy: 0.7726 - val_loss: 549.7361 - val_accuracy: 0.8103\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.2351 - accuracy: 0.7730 - val_loss: 552.8647 - val_accuracy: 0.8023\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.6036 - accuracy: 0.7700 - val_loss: 552.6706 - val_accuracy: 0.8097\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.1343 - accuracy: 0.7709 - val_loss: 549.5938 - val_accuracy: 0.8132\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.7070 - accuracy: 0.7704 - val_loss: 549.5514 - val_accuracy: 0.8109\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.9299 - accuracy: 0.7719 - val_loss: 554.6083 - val_accuracy: 0.8092\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.4913 - accuracy: 0.7707 - val_loss: 554.4371 - val_accuracy: 0.8109\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.7001 - accuracy: 0.7694 - val_loss: 549.6942 - val_accuracy: 0.8122\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.1215 - accuracy: 0.7733 - val_loss: 549.5058 - val_accuracy: 0.8131\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.3843 - accuracy: 0.7718 - val_loss: 548.9337 - val_accuracy: 0.8080\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.4601 - accuracy: 0.7712 - val_loss: 549.1702 - val_accuracy: 0.8105\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.0970 - accuracy: 0.7692 - val_loss: 550.7570 - val_accuracy: 0.8068\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.7811 - accuracy: 0.7722 - val_loss: 550.0267 - val_accuracy: 0.8074\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.4722 - accuracy: 0.7718 - val_loss: 549.9332 - val_accuracy: 0.8075\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.5102 - accuracy: 0.7725 - val_loss: 555.5923 - val_accuracy: 0.8113\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.2972 - accuracy: 0.7707 - val_loss: 551.5891 - val_accuracy: 0.8052\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.7011 - accuracy: 0.7704 - val_loss: 557.5282 - val_accuracy: 0.8103\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.7974 - accuracy: 0.7686 - val_loss: 550.8621 - val_accuracy: 0.8069\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.4007 - accuracy: 0.7701 - val_loss: 562.2065 - val_accuracy: 0.8119\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 736.9420 - accuracy: 0.7674 - val_loss: 594.7293 - val_accuracy: 0.8072\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.9590 - accuracy: 0.7692 - val_loss: 560.9453 - val_accuracy: 0.8048\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 723.2075 - accuracy: 0.7690 - val_loss: 561.2399 - val_accuracy: 0.8064\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.8514 - accuracy: 0.7702 - val_loss: 578.0612 - val_accuracy: 0.8094\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 727.7830 - accuracy: 0.7714 - val_loss: 551.4893 - val_accuracy: 0.8098\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.5735 - accuracy: 0.7675 - val_loss: 550.8293 - val_accuracy: 0.8120\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.0917 - accuracy: 0.7686 - val_loss: 549.9284 - val_accuracy: 0.8037\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.2942 - accuracy: 0.7700 - val_loss: 558.1045 - val_accuracy: 0.8104\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.5157 - accuracy: 0.7720 - val_loss: 549.9300 - val_accuracy: 0.8046\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.2532 - accuracy: 0.7690 - val_loss: 551.2484 - val_accuracy: 0.8031\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.1333 - accuracy: 0.7705 - val_loss: 551.7794 - val_accuracy: 0.8081\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.6868 - accuracy: 0.7720 - val_loss: 555.2031 - val_accuracy: 0.8089\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.4373 - accuracy: 0.7709 - val_loss: 555.9864 - val_accuracy: 0.8100\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.2704 - accuracy: 0.7705 - val_loss: 550.9238 - val_accuracy: 0.8071\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.3206 - accuracy: 0.7705 - val_loss: 549.1892 - val_accuracy: 0.8084\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.9997 - accuracy: 0.7704 - val_loss: 549.1154 - val_accuracy: 0.8071\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.4104 - accuracy: 0.7713 - val_loss: 552.0110 - val_accuracy: 0.8086\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.2495 - accuracy: 0.7721 - val_loss: 548.9788 - val_accuracy: 0.8101\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.4940 - accuracy: 0.7679 - val_loss: 559.8919 - val_accuracy: 0.8032\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.8977 - accuracy: 0.7716 - val_loss: 551.4915 - val_accuracy: 0.8053\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.2379 - accuracy: 0.7712 - val_loss: 548.7481 - val_accuracy: 0.8077\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 713.7248 - accuracy: 0.7708 - val_loss: 549.0843 - val_accuracy: 0.8100\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.3252 - accuracy: 0.7711 - val_loss: 549.2305 - val_accuracy: 0.8075\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.8633 - accuracy: 0.7695 - val_loss: 559.1580 - val_accuracy: 0.8098\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.9285 - accuracy: 0.7693 - val_loss: 550.5533 - val_accuracy: 0.8125\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.6309 - accuracy: 0.7710 - val_loss: 558.4681 - val_accuracy: 0.8096\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.6808 - accuracy: 0.7694 - val_loss: 557.4153 - val_accuracy: 0.8100\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.3396 - accuracy: 0.7688 - val_loss: 554.0184 - val_accuracy: 0.8071\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.3057 - accuracy: 0.7694 - val_loss: 556.9932 - val_accuracy: 0.8097\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.8892 - accuracy: 0.7717 - val_loss: 553.1143 - val_accuracy: 0.8055\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.9137 - accuracy: 0.7718 - val_loss: 549.1293 - val_accuracy: 0.8033\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.2213 - accuracy: 0.7725 - val_loss: 551.8828 - val_accuracy: 0.8076\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 715.4668 - accuracy: 0.7702 - val_loss: 549.4113 - val_accuracy: 0.8108\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.9666 - accuracy: 0.7704 - val_loss: 550.8390 - val_accuracy: 0.8058\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.1765 - accuracy: 0.7716 - val_loss: 547.6169 - val_accuracy: 0.8083\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.8904 - accuracy: 0.7702 - val_loss: 548.8264 - val_accuracy: 0.8072\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.7326 - accuracy: 0.7726 - val_loss: 551.4589 - val_accuracy: 0.8036\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.8775 - accuracy: 0.7723 - val_loss: 551.8356 - val_accuracy: 0.8061\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.0837 - accuracy: 0.7716 - val_loss: 553.0850 - val_accuracy: 0.8125\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.2949 - accuracy: 0.7711 - val_loss: 549.5546 - val_accuracy: 0.8074\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.5627 - accuracy: 0.7707 - val_loss: 548.3972 - val_accuracy: 0.8067\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.5636 - accuracy: 0.7699 - val_loss: 557.9872 - val_accuracy: 0.8119\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.6247 - accuracy: 0.7706 - val_loss: 559.7379 - val_accuracy: 0.8081\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.3051 - accuracy: 0.7684 - val_loss: 555.6157 - val_accuracy: 0.8060\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.2364 - accuracy: 0.7667 - val_loss: 551.5175 - val_accuracy: 0.8042\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.5471 - accuracy: 0.7695 - val_loss: 549.5552 - val_accuracy: 0.8084\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 716.5000 - accuracy: 0.7714 - val_loss: 552.3569 - val_accuracy: 0.8055\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.2113 - accuracy: 0.7710 - val_loss: 550.0325 - val_accuracy: 0.8043\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.3957 - accuracy: 0.7703 - val_loss: 547.5880 - val_accuracy: 0.8082\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.4675 - accuracy: 0.7694 - val_loss: 553.9570 - val_accuracy: 0.8088\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.4313 - accuracy: 0.7711 - val_loss: 551.9613 - val_accuracy: 0.8104\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.0716 - accuracy: 0.7722 - val_loss: 570.9888 - val_accuracy: 0.8112\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.4652 - accuracy: 0.7716 - val_loss: 555.7148 - val_accuracy: 0.8104\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.4042 - accuracy: 0.7724 - val_loss: 549.0475 - val_accuracy: 0.8084\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.3281 - accuracy: 0.7708 - val_loss: 553.1002 - val_accuracy: 0.8107\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 717.9296 - accuracy: 0.7730 - val_loss: 554.5516 - val_accuracy: 0.8136\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.9733 - accuracy: 0.7707 - val_loss: 550.1564 - val_accuracy: 0.8070\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.9620 - accuracy: 0.7710 - val_loss: 552.8140 - val_accuracy: 0.8137\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.3497 - accuracy: 0.7708 - val_loss: 551.3211 - val_accuracy: 0.8118\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.3656 - accuracy: 0.7718 - val_loss: 548.9774 - val_accuracy: 0.8075\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.6882 - accuracy: 0.7700 - val_loss: 549.4423 - val_accuracy: 0.8126\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.2042 - accuracy: 0.7728 - val_loss: 547.0198 - val_accuracy: 0.8128\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.0979 - accuracy: 0.7739 - val_loss: 548.5227 - val_accuracy: 0.8134\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.3370 - accuracy: 0.7728 - val_loss: 551.6575 - val_accuracy: 0.8077\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.1838 - accuracy: 0.7727 - val_loss: 549.0571 - val_accuracy: 0.8068\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 712.5627 - accuracy: 0.7731 - val_loss: 548.5023 - val_accuracy: 0.8114\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.2556 - accuracy: 0.7739 - val_loss: 549.4534 - val_accuracy: 0.8112\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.6791 - accuracy: 0.7732 - val_loss: 549.7998 - val_accuracy: 0.8071\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.1111 - accuracy: 0.7696 - val_loss: 554.9663 - val_accuracy: 0.8037\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.7682 - accuracy: 0.7725 - val_loss: 549.0134 - val_accuracy: 0.8119\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.0613 - accuracy: 0.7718 - val_loss: 547.9200 - val_accuracy: 0.8093\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 711.9741 - accuracy: 0.7737 - val_loss: 548.7134 - val_accuracy: 0.8068\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 711.3981 - accuracy: 0.7724 - val_loss: 548.0917 - val_accuracy: 0.8117\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 711.3096 - accuracy: 0.7728 - val_loss: 547.5626 - val_accuracy: 0.8116\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.1186 - accuracy: 0.7720 - val_loss: 547.7294 - val_accuracy: 0.8078\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.4983 - accuracy: 0.7720 - val_loss: 551.2257 - val_accuracy: 0.8100\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.3585 - accuracy: 0.7709 - val_loss: 548.1569 - val_accuracy: 0.8104\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 712.7139 - accuracy: 0.7708 - val_loss: 547.6141 - val_accuracy: 0.8091\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.8650 - accuracy: 0.7703 - val_loss: 547.5775 - val_accuracy: 0.8113\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.8969 - accuracy: 0.7723 - val_loss: 547.8085 - val_accuracy: 0.8094\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.5522 - accuracy: 0.7721 - val_loss: 550.7933 - val_accuracy: 0.8096\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.1348 - accuracy: 0.7711 - val_loss: 554.3373 - val_accuracy: 0.8096\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.0621 - accuracy: 0.7724 - val_loss: 550.7145 - val_accuracy: 0.8109\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.3370 - accuracy: 0.7705 - val_loss: 551.1989 - val_accuracy: 0.8078\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.7941 - accuracy: 0.7709 - val_loss: 553.4641 - val_accuracy: 0.8050\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.5992 - accuracy: 0.7722 - val_loss: 556.0229 - val_accuracy: 0.8045\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.1625 - accuracy: 0.7703 - val_loss: 547.8392 - val_accuracy: 0.8129\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.2498 - accuracy: 0.7713 - val_loss: 547.3665 - val_accuracy: 0.8097\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.8572 - accuracy: 0.7723 - val_loss: 547.1187 - val_accuracy: 0.8095\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.0765 - accuracy: 0.7724 - val_loss: 553.0647 - val_accuracy: 0.8090\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.7902 - accuracy: 0.7716 - val_loss: 573.3364 - val_accuracy: 0.8126\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.0302 - accuracy: 0.7717 - val_loss: 553.5894 - val_accuracy: 0.8105\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.2940 - accuracy: 0.7716 - val_loss: 547.8347 - val_accuracy: 0.8100\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 716.3334 - accuracy: 0.7723 - val_loss: 548.4036 - val_accuracy: 0.8077\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 714.1755 - accuracy: 0.7715 - val_loss: 548.4667 - val_accuracy: 0.8062\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.4083 - accuracy: 0.7730 - val_loss: 548.6985 - val_accuracy: 0.8050\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.5439 - accuracy: 0.7716 - val_loss: 549.4184 - val_accuracy: 0.8110\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.3528 - accuracy: 0.7719 - val_loss: 547.2562 - val_accuracy: 0.8067\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.6744 - accuracy: 0.7719 - val_loss: 558.9355 - val_accuracy: 0.8086\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.1492 - accuracy: 0.7716 - val_loss: 555.9803 - val_accuracy: 0.8115\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.0367 - accuracy: 0.7739 - val_loss: 558.1527 - val_accuracy: 0.8092\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.0688 - accuracy: 0.7700 - val_loss: 549.9014 - val_accuracy: 0.8068\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.9368 - accuracy: 0.7718 - val_loss: 551.3225 - val_accuracy: 0.8051\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.6923 - accuracy: 0.7705 - val_loss: 547.8428 - val_accuracy: 0.8128\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.8069 - accuracy: 0.7724 - val_loss: 548.1233 - val_accuracy: 0.8125\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.6230 - accuracy: 0.7726 - val_loss: 546.3274 - val_accuracy: 0.8068\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.3793 - accuracy: 0.7733 - val_loss: 559.4026 - val_accuracy: 0.8047\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.8873 - accuracy: 0.7727 - val_loss: 572.4646 - val_accuracy: 0.8094\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 749.9889 - accuracy: 0.7715 - val_loss: 548.7286 - val_accuracy: 0.8137\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.8832 - accuracy: 0.7736 - val_loss: 594.7432 - val_accuracy: 0.8063\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 737.3956 - accuracy: 0.7670 - val_loss: 562.6331 - val_accuracy: 0.8117\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 737.5851 - accuracy: 0.7692 - val_loss: 557.3441 - val_accuracy: 0.8021\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.4660 - accuracy: 0.7668 - val_loss: 558.6375 - val_accuracy: 0.8100\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.7885 - accuracy: 0.7708 - val_loss: 548.9848 - val_accuracy: 0.8078\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.3064 - accuracy: 0.7700 - val_loss: 550.5043 - val_accuracy: 0.8091\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.9798 - accuracy: 0.7718 - val_loss: 551.5335 - val_accuracy: 0.8117\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.9685 - accuracy: 0.7722 - val_loss: 546.8098 - val_accuracy: 0.8098\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.4169 - accuracy: 0.7737 - val_loss: 546.8224 - val_accuracy: 0.8083\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.0287 - accuracy: 0.7727 - val_loss: 564.9250 - val_accuracy: 0.8098\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.8280 - accuracy: 0.7716 - val_loss: 554.4817 - val_accuracy: 0.8074\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 730.3952 - accuracy: 0.7725 - val_loss: 555.9285 - val_accuracy: 0.8087\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.0086 - accuracy: 0.7730 - val_loss: 563.4800 - val_accuracy: 0.8133\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.2639 - accuracy: 0.7730 - val_loss: 548.0037 - val_accuracy: 0.8132\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.4274 - accuracy: 0.7736 - val_loss: 546.4865 - val_accuracy: 0.8111\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.8184 - accuracy: 0.7735 - val_loss: 550.8265 - val_accuracy: 0.8059\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.7886 - accuracy: 0.7736 - val_loss: 550.0128 - val_accuracy: 0.8109\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 711.9868 - accuracy: 0.7738 - val_loss: 555.3003 - val_accuracy: 0.8077\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.4417 - accuracy: 0.7745 - val_loss: 546.6482 - val_accuracy: 0.8117\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 709.8633 - accuracy: 0.7731 - val_loss: 545.8183 - val_accuracy: 0.8064\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 711.8817 - accuracy: 0.7735 - val_loss: 548.3477 - val_accuracy: 0.8154\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.7632 - accuracy: 0.7731 - val_loss: 548.7770 - val_accuracy: 0.8123\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.6315 - accuracy: 0.7730 - val_loss: 551.4136 - val_accuracy: 0.8081\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.7876 - accuracy: 0.7725 - val_loss: 564.9083 - val_accuracy: 0.8061\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 742.1027 - accuracy: 0.7679 - val_loss: 557.3599 - val_accuracy: 0.8131\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.4603 - accuracy: 0.7706 - val_loss: 554.8635 - val_accuracy: 0.8025\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.4327 - accuracy: 0.7718 - val_loss: 548.6346 - val_accuracy: 0.8103\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 711.8754 - accuracy: 0.7701 - val_loss: 546.8917 - val_accuracy: 0.8086\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.4606 - accuracy: 0.7725 - val_loss: 547.9957 - val_accuracy: 0.8113\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 711.8906 - accuracy: 0.7731 - val_loss: 546.2723 - val_accuracy: 0.8082\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 710.4296 - accuracy: 0.7730 - val_loss: 546.2499 - val_accuracy: 0.8071\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 710.7048 - accuracy: 0.7735 - val_loss: 549.3002 - val_accuracy: 0.8062\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 710.8640 - accuracy: 0.7729 - val_loss: 546.8955 - val_accuracy: 0.8095\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.5995 - accuracy: 0.7716 - val_loss: 546.4847 - val_accuracy: 0.8103\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 709.4542 - accuracy: 0.7727 - val_loss: 547.7509 - val_accuracy: 0.8084\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.2917 - accuracy: 0.7725 - val_loss: 546.2108 - val_accuracy: 0.8080\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.9846 - accuracy: 0.7738 - val_loss: 546.0975 - val_accuracy: 0.8092\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.3562 - accuracy: 0.7733 - val_loss: 552.6382 - val_accuracy: 0.8125\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.9320 - accuracy: 0.7738 - val_loss: 546.2736 - val_accuracy: 0.8089\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.5477 - accuracy: 0.7724 - val_loss: 546.7939 - val_accuracy: 0.8079\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.3301 - accuracy: 0.7725 - val_loss: 561.7807 - val_accuracy: 0.8079\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.8199 - accuracy: 0.7695 - val_loss: 557.9146 - val_accuracy: 0.8080\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 738.6970 - accuracy: 0.7717 - val_loss: 557.7455 - val_accuracy: 0.8118\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.9777 - accuracy: 0.7696 - val_loss: 562.8842 - val_accuracy: 0.8085\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.0198 - accuracy: 0.7699 - val_loss: 549.0393 - val_accuracy: 0.8044\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.0656 - accuracy: 0.7729 - val_loss: 549.9716 - val_accuracy: 0.8129\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.2805 - accuracy: 0.7732 - val_loss: 547.9617 - val_accuracy: 0.8117\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.5201 - accuracy: 0.7704 - val_loss: 549.3575 - val_accuracy: 0.8112\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.8184 - accuracy: 0.7742 - val_loss: 546.6678 - val_accuracy: 0.8103\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.9242 - accuracy: 0.7717 - val_loss: 546.6522 - val_accuracy: 0.8136\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.3512 - accuracy: 0.7751 - val_loss: 553.7601 - val_accuracy: 0.8040\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.9443 - accuracy: 0.7718 - val_loss: 548.8502 - val_accuracy: 0.8084\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.4884 - accuracy: 0.7704 - val_loss: 549.5521 - val_accuracy: 0.8111\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.4014 - accuracy: 0.7730 - val_loss: 549.2017 - val_accuracy: 0.8055\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.3158 - accuracy: 0.7715 - val_loss: 549.3766 - val_accuracy: 0.8113\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.8234 - accuracy: 0.7699 - val_loss: 551.4005 - val_accuracy: 0.8115\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.2424 - accuracy: 0.7731 - val_loss: 546.7002 - val_accuracy: 0.8098\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.9568 - accuracy: 0.7735 - val_loss: 549.3754 - val_accuracy: 0.8074\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.1072 - accuracy: 0.7740 - val_loss: 548.2339 - val_accuracy: 0.8093\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.4532 - accuracy: 0.7705 - val_loss: 545.4301 - val_accuracy: 0.8073\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 708.7107 - accuracy: 0.7734 - val_loss: 545.5079 - val_accuracy: 0.8086\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 709.6241 - accuracy: 0.7728 - val_loss: 545.9457 - val_accuracy: 0.8110\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.7281 - accuracy: 0.7729 - val_loss: 549.3324 - val_accuracy: 0.8121\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.4725 - accuracy: 0.7738 - val_loss: 547.2363 - val_accuracy: 0.8127\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 708.5792 - accuracy: 0.7744 - val_loss: 545.7005 - val_accuracy: 0.8094\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 709.0523 - accuracy: 0.7731 - val_loss: 545.7181 - val_accuracy: 0.8078\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.5059 - accuracy: 0.7720 - val_loss: 545.4811 - val_accuracy: 0.8097\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 709.2269 - accuracy: 0.7721 - val_loss: 548.2897 - val_accuracy: 0.8123\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.6736 - accuracy: 0.7721 - val_loss: 544.4275 - val_accuracy: 0.8089\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.3572 - accuracy: 0.7730 - val_loss: 547.8856 - val_accuracy: 0.8083\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.3093 - accuracy: 0.7722 - val_loss: 549.3461 - val_accuracy: 0.8064\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 716.4916 - accuracy: 0.7722 - val_loss: 550.9065 - val_accuracy: 0.8062\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.7693 - accuracy: 0.7706 - val_loss: 547.7418 - val_accuracy: 0.8098\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 709.0992 - accuracy: 0.7739 - val_loss: 546.4634 - val_accuracy: 0.8080\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.5519 - accuracy: 0.7720 - val_loss: 547.0176 - val_accuracy: 0.8116\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.1876 - accuracy: 0.7736 - val_loss: 545.1689 - val_accuracy: 0.8080\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.0939 - accuracy: 0.7714 - val_loss: 546.0615 - val_accuracy: 0.8049\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.0005 - accuracy: 0.7716 - val_loss: 553.2153 - val_accuracy: 0.8087\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.7469 - accuracy: 0.7709 - val_loss: 548.6685 - val_accuracy: 0.8047\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.9850 - accuracy: 0.7692 - val_loss: 552.5262 - val_accuracy: 0.8114\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.8580 - accuracy: 0.7715 - val_loss: 548.7316 - val_accuracy: 0.8051\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.8589 - accuracy: 0.7732 - val_loss: 548.5981 - val_accuracy: 0.8128\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.9662 - accuracy: 0.7715 - val_loss: 546.0627 - val_accuracy: 0.8095\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.1341 - accuracy: 0.7739 - val_loss: 549.2498 - val_accuracy: 0.8084\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.1172 - accuracy: 0.7694 - val_loss: 558.6437 - val_accuracy: 0.8056\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.1594 - accuracy: 0.7694 - val_loss: 552.7568 - val_accuracy: 0.8112\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.7094 - accuracy: 0.7717 - val_loss: 551.8638 - val_accuracy: 0.8116\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.7454 - accuracy: 0.7720 - val_loss: 550.5675 - val_accuracy: 0.8076\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.3928 - accuracy: 0.7732 - val_loss: 555.9658 - val_accuracy: 0.8125\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.7655 - accuracy: 0.7728 - val_loss: 553.7169 - val_accuracy: 0.8117\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.5461 - accuracy: 0.7723 - val_loss: 545.9689 - val_accuracy: 0.8081\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.2849 - accuracy: 0.7733 - val_loss: 545.0115 - val_accuracy: 0.8055\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.9805 - accuracy: 0.7726 - val_loss: 544.1934 - val_accuracy: 0.8095\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.3082 - accuracy: 0.7729 - val_loss: 543.2560 - val_accuracy: 0.8075\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.4315 - accuracy: 0.7743 - val_loss: 546.1947 - val_accuracy: 0.8125\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.3743 - accuracy: 0.7727 - val_loss: 544.5695 - val_accuracy: 0.8095\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.6913 - accuracy: 0.7732 - val_loss: 542.6539 - val_accuracy: 0.8099\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 707.4376 - accuracy: 0.7732 - val_loss: 543.9626 - val_accuracy: 0.8121\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.1870 - accuracy: 0.7725 - val_loss: 543.8433 - val_accuracy: 0.8127\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.5169 - accuracy: 0.7751 - val_loss: 567.6641 - val_accuracy: 0.8072\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.5403 - accuracy: 0.7715 - val_loss: 546.7232 - val_accuracy: 0.8051\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.3172 - accuracy: 0.7718 - val_loss: 555.9583 - val_accuracy: 0.8104\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 710.8290 - accuracy: 0.7722 - val_loss: 545.7100 - val_accuracy: 0.8050\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 710.0830 - accuracy: 0.7729 - val_loss: 546.9122 - val_accuracy: 0.8083\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 709.4625 - accuracy: 0.7720 - val_loss: 545.1326 - val_accuracy: 0.8087\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 708.2134 - accuracy: 0.7688 - val_loss: 546.3888 - val_accuracy: 0.8092\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 706.8680 - accuracy: 0.7733 - val_loss: 543.2695 - val_accuracy: 0.8126\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 706.7407 - accuracy: 0.7724 - val_loss: 543.0890 - val_accuracy: 0.8101\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 707.8762 - accuracy: 0.7734 - val_loss: 551.3518 - val_accuracy: 0.8099\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.9409 - accuracy: 0.7726 - val_loss: 548.3789 - val_accuracy: 0.8084\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.1577 - accuracy: 0.7722 - val_loss: 551.1624 - val_accuracy: 0.8082\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.9955 - accuracy: 0.7735 - val_loss: 544.4009 - val_accuracy: 0.8068\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 709.0468 - accuracy: 0.7738 - val_loss: 552.5351 - val_accuracy: 0.8123\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.9332 - accuracy: 0.7748 - val_loss: 559.4888 - val_accuracy: 0.8095\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.5319 - accuracy: 0.7724 - val_loss: 554.0639 - val_accuracy: 0.8127\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.7582 - accuracy: 0.7744 - val_loss: 567.4310 - val_accuracy: 0.8098\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.3629 - accuracy: 0.7713 - val_loss: 551.3311 - val_accuracy: 0.8108\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.5973 - accuracy: 0.7703 - val_loss: 550.9890 - val_accuracy: 0.8124\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.7001 - accuracy: 0.7717 - val_loss: 547.8132 - val_accuracy: 0.8086\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.1393 - accuracy: 0.7700 - val_loss: 554.4597 - val_accuracy: 0.8098\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.5156 - accuracy: 0.7728 - val_loss: 564.4457 - val_accuracy: 0.8103\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.3312 - accuracy: 0.7716 - val_loss: 576.8887 - val_accuracy: 0.8089\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 731.8232 - accuracy: 0.7703 - val_loss: 549.0193 - val_accuracy: 0.8111\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.5925 - accuracy: 0.7716 - val_loss: 547.2597 - val_accuracy: 0.8105\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.5900 - accuracy: 0.7717 - val_loss: 546.2773 - val_accuracy: 0.8109\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 711.4230 - accuracy: 0.7706 - val_loss: 546.2738 - val_accuracy: 0.8091\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.3947 - accuracy: 0.7728 - val_loss: 543.6347 - val_accuracy: 0.8115\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.4768 - accuracy: 0.7731 - val_loss: 544.2740 - val_accuracy: 0.8090\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 705.8019 - accuracy: 0.7749 - val_loss: 542.4467 - val_accuracy: 0.8074\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.7236 - accuracy: 0.7735 - val_loss: 542.2823 - val_accuracy: 0.8113\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 705.9694 - accuracy: 0.7744 - val_loss: 542.0082 - val_accuracy: 0.8095\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 706.8058 - accuracy: 0.7742 - val_loss: 542.0966 - val_accuracy: 0.8132\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 705.8568 - accuracy: 0.7740 - val_loss: 544.7006 - val_accuracy: 0.8073\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 707.4632 - accuracy: 0.7729 - val_loss: 543.7083 - val_accuracy: 0.8106\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 707.1447 - accuracy: 0.7750 - val_loss: 542.5084 - val_accuracy: 0.8090\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 707.7209 - accuracy: 0.7753 - val_loss: 547.3881 - val_accuracy: 0.8085\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 711.0966 - accuracy: 0.7735 - val_loss: 545.1258 - val_accuracy: 0.8106\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.0986 - accuracy: 0.7718 - val_loss: 553.6610 - val_accuracy: 0.8097\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.7520 - accuracy: 0.7735 - val_loss: 547.4937 - val_accuracy: 0.8079\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.4105 - accuracy: 0.7715 - val_loss: 543.6093 - val_accuracy: 0.8092\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.9594 - accuracy: 0.7735 - val_loss: 543.3625 - val_accuracy: 0.8114\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.5120 - accuracy: 0.7736 - val_loss: 545.0517 - val_accuracy: 0.8100\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 708.0484 - accuracy: 0.7725 - val_loss: 546.0498 - val_accuracy: 0.8091\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.7183 - accuracy: 0.7748 - val_loss: 550.9824 - val_accuracy: 0.8122\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 709.5916 - accuracy: 0.7712 - val_loss: 552.0596 - val_accuracy: 0.8117\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.0142 - accuracy: 0.7730 - val_loss: 547.1843 - val_accuracy: 0.8071\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.4024 - accuracy: 0.7747 - val_loss: 542.6933 - val_accuracy: 0.8086\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 706.1628 - accuracy: 0.7722 - val_loss: 541.9067 - val_accuracy: 0.8100\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.2409 - accuracy: 0.7744 - val_loss: 547.8811 - val_accuracy: 0.8115\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.7827 - accuracy: 0.7747 - val_loss: 544.3031 - val_accuracy: 0.8096\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.5282 - accuracy: 0.7734 - val_loss: 545.6790 - val_accuracy: 0.8084\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 707.2614 - accuracy: 0.7734 - val_loss: 542.7963 - val_accuracy: 0.8119\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.7947 - accuracy: 0.7740 - val_loss: 550.6685 - val_accuracy: 0.8128\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.3734 - accuracy: 0.7751 - val_loss: 541.5621 - val_accuracy: 0.8104\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 706.0897 - accuracy: 0.7737 - val_loss: 542.7490 - val_accuracy: 0.8084\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 705.4999 - accuracy: 0.7728 - val_loss: 543.1106 - val_accuracy: 0.8124\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 705.3080 - accuracy: 0.7734 - val_loss: 541.8624 - val_accuracy: 0.8125\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 706.7006 - accuracy: 0.7743 - val_loss: 543.0502 - val_accuracy: 0.8105\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.3682 - accuracy: 0.7747 - val_loss: 547.5176 - val_accuracy: 0.8067\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 707.2299 - accuracy: 0.7741 - val_loss: 542.5191 - val_accuracy: 0.8084\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.8814 - accuracy: 0.7753 - val_loss: 544.3658 - val_accuracy: 0.8107\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 709.1373 - accuracy: 0.7730 - val_loss: 552.0849 - val_accuracy: 0.8103\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.2571 - accuracy: 0.7736 - val_loss: 547.4056 - val_accuracy: 0.8095\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 710.5449 - accuracy: 0.7728 - val_loss: 544.0575 - val_accuracy: 0.8103\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.7830 - accuracy: 0.7724 - val_loss: 549.1337 - val_accuracy: 0.8103\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.7206 - accuracy: 0.7734 - val_loss: 545.3959 - val_accuracy: 0.8101\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.5535 - accuracy: 0.7731 - val_loss: 567.2927 - val_accuracy: 0.8090\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.7819 - accuracy: 0.7745 - val_loss: 544.4769 - val_accuracy: 0.8043\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.2491 - accuracy: 0.7722 - val_loss: 547.8381 - val_accuracy: 0.8111\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.4337 - accuracy: 0.7711 - val_loss: 542.6123 - val_accuracy: 0.8120\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.0487 - accuracy: 0.7741 - val_loss: 541.2307 - val_accuracy: 0.8102\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 707.0743 - accuracy: 0.7761 - val_loss: 541.9286 - val_accuracy: 0.8114\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 707.2592 - accuracy: 0.7742 - val_loss: 541.8281 - val_accuracy: 0.8121\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.4203 - accuracy: 0.7751 - val_loss: 545.2197 - val_accuracy: 0.8076\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 710.6895 - accuracy: 0.7731 - val_loss: 543.8175 - val_accuracy: 0.8110\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 709.6807 - accuracy: 0.7741 - val_loss: 572.9394 - val_accuracy: 0.8123\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.9974 - accuracy: 0.7753 - val_loss: 554.1495 - val_accuracy: 0.8098\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.3439 - accuracy: 0.7755 - val_loss: 555.7176 - val_accuracy: 0.8063\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.6188 - accuracy: 0.7701 - val_loss: 546.2595 - val_accuracy: 0.8095\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.0139 - accuracy: 0.7688 - val_loss: 550.1183 - val_accuracy: 0.8047\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.2514 - accuracy: 0.7716 - val_loss: 557.8420 - val_accuracy: 0.8108\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.8197 - accuracy: 0.7711 - val_loss: 558.0893 - val_accuracy: 0.8070\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 723.3864 - accuracy: 0.7753 - val_loss: 551.9899 - val_accuracy: 0.8094\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.8602 - accuracy: 0.7741 - val_loss: 548.1902 - val_accuracy: 0.8100\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.7709 - accuracy: 0.7675 - val_loss: 544.9330 - val_accuracy: 0.8121\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 709.8184 - accuracy: 0.7730 - val_loss: 542.6196 - val_accuracy: 0.8111\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 707.7808 - accuracy: 0.7718 - val_loss: 541.1376 - val_accuracy: 0.8119\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 706.0857 - accuracy: 0.7736 - val_loss: 541.6849 - val_accuracy: 0.8072\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 705.0764 - accuracy: 0.7736 - val_loss: 541.9375 - val_accuracy: 0.8115\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 705.5723 - accuracy: 0.7733 - val_loss: 544.3601 - val_accuracy: 0.8127\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 706.7136 - accuracy: 0.7760 - val_loss: 544.5014 - val_accuracy: 0.8111\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.8808 - accuracy: 0.7752 - val_loss: 540.8028 - val_accuracy: 0.8079\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.2518 - accuracy: 0.7741 - val_loss: 541.2110 - val_accuracy: 0.8119\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 705.8975 - accuracy: 0.7750 - val_loss: 541.1676 - val_accuracy: 0.8125\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 704.3314 - accuracy: 0.7763 - val_loss: 540.6508 - val_accuracy: 0.8070\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.7068 - accuracy: 0.7751 - val_loss: 548.8925 - val_accuracy: 0.8076\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.9182 - accuracy: 0.7742 - val_loss: 542.5486 - val_accuracy: 0.8091\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.3746 - accuracy: 0.7754 - val_loss: 544.4924 - val_accuracy: 0.8090\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.5183 - accuracy: 0.7724 - val_loss: 545.7177 - val_accuracy: 0.8108\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 706.1921 - accuracy: 0.7738 - val_loss: 542.0208 - val_accuracy: 0.8109\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 705.1595 - accuracy: 0.7745 - val_loss: 541.1544 - val_accuracy: 0.8100\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 706.4308 - accuracy: 0.7741 - val_loss: 543.0865 - val_accuracy: 0.8103\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 705.7903 - accuracy: 0.7756 - val_loss: 542.1234 - val_accuracy: 0.8059\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 705.5822 - accuracy: 0.7745 - val_loss: 542.1785 - val_accuracy: 0.8113\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.3249 - accuracy: 0.7732 - val_loss: 542.8514 - val_accuracy: 0.8102\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 725.8703 - accuracy: 0.7747 - val_loss: 543.7484 - val_accuracy: 0.8139\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.9716 - accuracy: 0.7724 - val_loss: 550.2906 - val_accuracy: 0.8116\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.2186 - accuracy: 0.7724 - val_loss: 541.6044 - val_accuracy: 0.8112\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "# Upsample the second input image\n",
        "upsampled = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Combine the two input images using a convolutional layer\n",
        "combined = layers.Conv2D(31, kernel_size=1, activation='relu')(upsampled)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(128, kernel_size=1, activation='relu')(combined)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "#conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "#pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer = layers.Conv2D(31, kernel_size=1, activation='relu')(pool2)\n",
        "# Define the model\n",
        "modelnew = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "# Compile the model\n",
        "modelnew.compile(optimizer='adam',\n",
        "loss='mean_absolute_error',\n",
        "metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = modelnew.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyvjGjb8peTU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AE06V75peV1",
        "outputId": "b9f3037d-505b-4cc2-f3f7-8b785294f1f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 8396.3613 - accuracy: 0.0938 - val_loss: 5614.2480 - val_accuracy: 0.1698\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 6329.8174 - accuracy: 0.1908 - val_loss: 4332.3721 - val_accuracy: 0.1774\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 4855.6240 - accuracy: 0.1373 - val_loss: 3166.6174 - val_accuracy: 0.2920\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 3917.7681 - accuracy: 0.1955 - val_loss: 2653.8518 - val_accuracy: 0.3579\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3334.2678 - accuracy: 0.1663 - val_loss: 2592.3169 - val_accuracy: 0.3772\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3078.0518 - accuracy: 0.1297 - val_loss: 2297.9985 - val_accuracy: 0.4274\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2790.8369 - accuracy: 0.3552 - val_loss: 2172.5000 - val_accuracy: 0.5281\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 2582.3767 - accuracy: 0.3735 - val_loss: 2000.9160 - val_accuracy: 0.5757\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2417.1824 - accuracy: 0.4248 - val_loss: 1816.7701 - val_accuracy: 0.5965\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 2272.1936 - accuracy: 0.4251 - val_loss: 1603.0477 - val_accuracy: 0.6085\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 2059.3164 - accuracy: 0.4112 - val_loss: 1560.1625 - val_accuracy: 0.5385\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1998.6786 - accuracy: 0.4152 - val_loss: 1517.8104 - val_accuracy: 0.5955\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1945.7216 - accuracy: 0.4119 - val_loss: 1481.6920 - val_accuracy: 0.5411\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1907.7040 - accuracy: 0.4166 - val_loss: 1450.5712 - val_accuracy: 0.5551\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1833.7700 - accuracy: 0.4414 - val_loss: 1243.5535 - val_accuracy: 0.6124\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1647.5839 - accuracy: 0.4349 - val_loss: 1078.6901 - val_accuracy: 0.4371\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1439.1642 - accuracy: 0.5092 - val_loss: 1015.1978 - val_accuracy: 0.6540\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1356.0178 - accuracy: 0.4068 - val_loss: 942.6676 - val_accuracy: 0.5444\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1316.2369 - accuracy: 0.5287 - val_loss: 909.2753 - val_accuracy: 0.7023\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1295.5455 - accuracy: 0.5448 - val_loss: 913.3631 - val_accuracy: 0.6876\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1286.5865 - accuracy: 0.5792 - val_loss: 885.8204 - val_accuracy: 0.7306\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1268.1591 - accuracy: 0.5972 - val_loss: 894.1108 - val_accuracy: 0.7240\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1260.4229 - accuracy: 0.5928 - val_loss: 874.3715 - val_accuracy: 0.7403\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1250.1957 - accuracy: 0.6087 - val_loss: 871.5456 - val_accuracy: 0.7578\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1241.6261 - accuracy: 0.6151 - val_loss: 859.8746 - val_accuracy: 0.7524\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1236.7202 - accuracy: 0.6167 - val_loss: 861.5851 - val_accuracy: 0.7314\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1227.0413 - accuracy: 0.6236 - val_loss: 853.2319 - val_accuracy: 0.7620\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1220.3263 - accuracy: 0.6201 - val_loss: 847.3995 - val_accuracy: 0.7657\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1222.9161 - accuracy: 0.6323 - val_loss: 846.9665 - val_accuracy: 0.7617\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1217.8060 - accuracy: 0.6359 - val_loss: 857.2076 - val_accuracy: 0.7568\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1221.6096 - accuracy: 0.6269 - val_loss: 841.2995 - val_accuracy: 0.7539\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1210.6493 - accuracy: 0.6379 - val_loss: 841.6993 - val_accuracy: 0.7510\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1203.6376 - accuracy: 0.6345 - val_loss: 845.1823 - val_accuracy: 0.7769\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1197.2919 - accuracy: 0.6374 - val_loss: 834.9350 - val_accuracy: 0.7710\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1194.0303 - accuracy: 0.6369 - val_loss: 827.5989 - val_accuracy: 0.7602\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1191.4928 - accuracy: 0.6395 - val_loss: 823.3483 - val_accuracy: 0.7683\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1192.7856 - accuracy: 0.6417 - val_loss: 816.5898 - val_accuracy: 0.7706\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1185.3339 - accuracy: 0.6377 - val_loss: 818.2130 - val_accuracy: 0.7731\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1185.6323 - accuracy: 0.6437 - val_loss: 829.1591 - val_accuracy: 0.7764\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1182.9839 - accuracy: 0.6462 - val_loss: 817.5732 - val_accuracy: 0.7658\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1175.5275 - accuracy: 0.6438 - val_loss: 820.8580 - val_accuracy: 0.7697\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1174.7988 - accuracy: 0.6486 - val_loss: 823.4014 - val_accuracy: 0.7722\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1179.3647 - accuracy: 0.6518 - val_loss: 809.8757 - val_accuracy: 0.7688\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1173.1798 - accuracy: 0.6458 - val_loss: 808.0673 - val_accuracy: 0.7658\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1176.6919 - accuracy: 0.6469 - val_loss: 812.5598 - val_accuracy: 0.7631\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1173.7084 - accuracy: 0.6379 - val_loss: 809.0323 - val_accuracy: 0.7647\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1165.7772 - accuracy: 0.6528 - val_loss: 803.0558 - val_accuracy: 0.7682\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1170.6665 - accuracy: 0.6502 - val_loss: 814.3788 - val_accuracy: 0.7603\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1161.5780 - accuracy: 0.6464 - val_loss: 802.9349 - val_accuracy: 0.7683\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1161.1027 - accuracy: 0.6499 - val_loss: 804.4408 - val_accuracy: 0.7728\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1161.8025 - accuracy: 0.6504 - val_loss: 805.6314 - val_accuracy: 0.7673\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1161.0094 - accuracy: 0.6519 - val_loss: 802.2764 - val_accuracy: 0.7727\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1156.0626 - accuracy: 0.6493 - val_loss: 799.5208 - val_accuracy: 0.7655\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1163.1498 - accuracy: 0.6493 - val_loss: 793.6302 - val_accuracy: 0.7680\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1151.5197 - accuracy: 0.6545 - val_loss: 791.8045 - val_accuracy: 0.7722\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1154.9960 - accuracy: 0.6570 - val_loss: 799.2858 - val_accuracy: 0.7650\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1150.9995 - accuracy: 0.6575 - val_loss: 794.8205 - val_accuracy: 0.7656\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1148.3663 - accuracy: 0.6546 - val_loss: 790.9500 - val_accuracy: 0.7672\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1146.6410 - accuracy: 0.6616 - val_loss: 791.2370 - val_accuracy: 0.7643\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1148.7653 - accuracy: 0.6574 - val_loss: 794.4570 - val_accuracy: 0.7693\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1146.1713 - accuracy: 0.6597 - val_loss: 793.1992 - val_accuracy: 0.7690\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1146.7522 - accuracy: 0.6593 - val_loss: 791.4774 - val_accuracy: 0.7683\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1144.9266 - accuracy: 0.6609 - val_loss: 785.9028 - val_accuracy: 0.7675\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1142.1907 - accuracy: 0.6562 - val_loss: 790.0759 - val_accuracy: 0.7729\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1140.5059 - accuracy: 0.6626 - val_loss: 784.1305 - val_accuracy: 0.7703\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1138.0437 - accuracy: 0.6634 - val_loss: 790.2198 - val_accuracy: 0.7709\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1141.6093 - accuracy: 0.6642 - val_loss: 784.0807 - val_accuracy: 0.7704\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1141.7563 - accuracy: 0.6593 - val_loss: 783.5250 - val_accuracy: 0.7678\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1138.7898 - accuracy: 0.6650 - val_loss: 784.7645 - val_accuracy: 0.7746\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1134.8181 - accuracy: 0.6639 - val_loss: 781.1102 - val_accuracy: 0.7677\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1132.9060 - accuracy: 0.6637 - val_loss: 782.1169 - val_accuracy: 0.7663\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1134.8660 - accuracy: 0.6631 - val_loss: 784.0427 - val_accuracy: 0.7729\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1134.4779 - accuracy: 0.6661 - val_loss: 781.0317 - val_accuracy: 0.7665\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1132.4628 - accuracy: 0.6654 - val_loss: 780.2725 - val_accuracy: 0.7720\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1129.1434 - accuracy: 0.6670 - val_loss: 784.0526 - val_accuracy: 0.7691\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1130.8778 - accuracy: 0.6639 - val_loss: 779.9550 - val_accuracy: 0.7714\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1131.0828 - accuracy: 0.6670 - val_loss: 780.5494 - val_accuracy: 0.7686\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1129.3851 - accuracy: 0.6678 - val_loss: 777.8414 - val_accuracy: 0.7630\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1132.3599 - accuracy: 0.6637 - val_loss: 786.1017 - val_accuracy: 0.7779\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1139.2703 - accuracy: 0.6670 - val_loss: 805.9248 - val_accuracy: 0.7748\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1143.2002 - accuracy: 0.6705 - val_loss: 777.9804 - val_accuracy: 0.7677\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1135.2574 - accuracy: 0.6662 - val_loss: 787.6406 - val_accuracy: 0.7657\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1135.9702 - accuracy: 0.6701 - val_loss: 785.8440 - val_accuracy: 0.7699\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1134.4417 - accuracy: 0.6675 - val_loss: 798.3835 - val_accuracy: 0.7714\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1134.9130 - accuracy: 0.6684 - val_loss: 775.4472 - val_accuracy: 0.7676\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1124.7891 - accuracy: 0.6678 - val_loss: 776.7675 - val_accuracy: 0.7723\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1121.2057 - accuracy: 0.6694 - val_loss: 773.6450 - val_accuracy: 0.7773\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1119.4497 - accuracy: 0.6681 - val_loss: 772.8486 - val_accuracy: 0.7683\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1122.3075 - accuracy: 0.6705 - val_loss: 774.4682 - val_accuracy: 0.7730\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1121.3264 - accuracy: 0.6669 - val_loss: 772.7640 - val_accuracy: 0.7752\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1118.6522 - accuracy: 0.6734 - val_loss: 776.2457 - val_accuracy: 0.7734\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1120.4329 - accuracy: 0.6676 - val_loss: 774.7222 - val_accuracy: 0.7813\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1122.2036 - accuracy: 0.6727 - val_loss: 776.0859 - val_accuracy: 0.7712\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1119.0555 - accuracy: 0.6691 - val_loss: 773.3344 - val_accuracy: 0.7746\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1117.0897 - accuracy: 0.6709 - val_loss: 771.3800 - val_accuracy: 0.7770\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1114.8451 - accuracy: 0.6714 - val_loss: 770.3898 - val_accuracy: 0.7708\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1116.7083 - accuracy: 0.6712 - val_loss: 770.1783 - val_accuracy: 0.7790\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1115.4857 - accuracy: 0.6735 - val_loss: 770.6389 - val_accuracy: 0.7801\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1115.7567 - accuracy: 0.6713 - val_loss: 770.5095 - val_accuracy: 0.7708\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1113.3087 - accuracy: 0.6707 - val_loss: 769.0946 - val_accuracy: 0.7782\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1113.8564 - accuracy: 0.6712 - val_loss: 773.1700 - val_accuracy: 0.7752\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1117.3972 - accuracy: 0.6734 - val_loss: 771.1511 - val_accuracy: 0.7730\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1118.8463 - accuracy: 0.6712 - val_loss: 771.2074 - val_accuracy: 0.7748\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1113.8888 - accuracy: 0.6766 - val_loss: 771.1877 - val_accuracy: 0.7807\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1114.4910 - accuracy: 0.6742 - val_loss: 790.2761 - val_accuracy: 0.7766\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1131.5846 - accuracy: 0.6744 - val_loss: 776.3942 - val_accuracy: 0.7791\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1119.0575 - accuracy: 0.6763 - val_loss: 772.9498 - val_accuracy: 0.7792\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1111.7245 - accuracy: 0.6778 - val_loss: 767.9737 - val_accuracy: 0.7785\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1111.2474 - accuracy: 0.6796 - val_loss: 766.6342 - val_accuracy: 0.7791\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1109.5015 - accuracy: 0.6808 - val_loss: 769.3181 - val_accuracy: 0.7820\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1110.8339 - accuracy: 0.6805 - val_loss: 766.1020 - val_accuracy: 0.7752\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1110.9476 - accuracy: 0.6793 - val_loss: 765.4590 - val_accuracy: 0.7791\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1109.9359 - accuracy: 0.6838 - val_loss: 766.1819 - val_accuracy: 0.7844\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1112.2402 - accuracy: 0.6793 - val_loss: 782.2140 - val_accuracy: 0.7854\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1114.9633 - accuracy: 0.6790 - val_loss: 777.9984 - val_accuracy: 0.7782\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1109.8409 - accuracy: 0.6805 - val_loss: 768.5574 - val_accuracy: 0.7838\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1107.0762 - accuracy: 0.6803 - val_loss: 763.6453 - val_accuracy: 0.7831\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1106.5669 - accuracy: 0.6834 - val_loss: 768.6602 - val_accuracy: 0.7806\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1107.8823 - accuracy: 0.6824 - val_loss: 767.5092 - val_accuracy: 0.7843\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1106.1890 - accuracy: 0.6857 - val_loss: 765.7238 - val_accuracy: 0.7846\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1104.6764 - accuracy: 0.6849 - val_loss: 762.9194 - val_accuracy: 0.7858\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1103.3615 - accuracy: 0.6836 - val_loss: 763.2537 - val_accuracy: 0.7867\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1102.5371 - accuracy: 0.6884 - val_loss: 763.9877 - val_accuracy: 0.7836\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1102.8342 - accuracy: 0.6854 - val_loss: 762.9210 - val_accuracy: 0.7842\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1102.6685 - accuracy: 0.6857 - val_loss: 761.9435 - val_accuracy: 0.7869\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1102.1013 - accuracy: 0.6849 - val_loss: 764.0035 - val_accuracy: 0.7853\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1102.3839 - accuracy: 0.6882 - val_loss: 762.7427 - val_accuracy: 0.7893\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1100.9298 - accuracy: 0.6888 - val_loss: 762.0729 - val_accuracy: 0.7827\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1099.9647 - accuracy: 0.6866 - val_loss: 762.3361 - val_accuracy: 0.7902\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1103.3356 - accuracy: 0.6881 - val_loss: 763.0922 - val_accuracy: 0.7858\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1103.3231 - accuracy: 0.6889 - val_loss: 760.2469 - val_accuracy: 0.7902\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1101.7666 - accuracy: 0.6912 - val_loss: 759.5068 - val_accuracy: 0.7852\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1099.1946 - accuracy: 0.6899 - val_loss: 760.8207 - val_accuracy: 0.7929\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1104.0155 - accuracy: 0.6928 - val_loss: 762.7982 - val_accuracy: 0.7853\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1101.3977 - accuracy: 0.6858 - val_loss: 760.5021 - val_accuracy: 0.7930\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1099.7655 - accuracy: 0.6915 - val_loss: 759.1764 - val_accuracy: 0.7905\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1100.2679 - accuracy: 0.6919 - val_loss: 763.9604 - val_accuracy: 0.7889\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1099.3328 - accuracy: 0.6880 - val_loss: 760.1910 - val_accuracy: 0.7914\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1097.6901 - accuracy: 0.6896 - val_loss: 760.4294 - val_accuracy: 0.7950\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1097.2714 - accuracy: 0.6911 - val_loss: 758.2118 - val_accuracy: 0.7949\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1096.6257 - accuracy: 0.6944 - val_loss: 760.3755 - val_accuracy: 0.7904\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1096.9065 - accuracy: 0.6902 - val_loss: 761.5088 - val_accuracy: 0.7994\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1096.8036 - accuracy: 0.6954 - val_loss: 759.5806 - val_accuracy: 0.7947\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1095.5432 - accuracy: 0.6910 - val_loss: 757.8179 - val_accuracy: 0.8000\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1096.9318 - accuracy: 0.6923 - val_loss: 759.8749 - val_accuracy: 0.7951\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1096.2185 - accuracy: 0.6912 - val_loss: 759.6365 - val_accuracy: 0.7955\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1096.8245 - accuracy: 0.6948 - val_loss: 759.3666 - val_accuracy: 0.7988\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1096.4563 - accuracy: 0.6929 - val_loss: 757.0563 - val_accuracy: 0.7954\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1096.8521 - accuracy: 0.6912 - val_loss: 757.2415 - val_accuracy: 0.8013\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1095.8726 - accuracy: 0.6917 - val_loss: 757.3394 - val_accuracy: 0.7904\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1094.1650 - accuracy: 0.6938 - val_loss: 755.6787 - val_accuracy: 0.8001\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1094.0245 - accuracy: 0.6938 - val_loss: 757.4830 - val_accuracy: 0.7993\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1098.0005 - accuracy: 0.6931 - val_loss: 757.9508 - val_accuracy: 0.7976\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1097.2351 - accuracy: 0.6929 - val_loss: 756.3734 - val_accuracy: 0.8007\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1094.0137 - accuracy: 0.6965 - val_loss: 757.5769 - val_accuracy: 0.7958\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1093.4485 - accuracy: 0.6908 - val_loss: 759.0615 - val_accuracy: 0.7988\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1095.3300 - accuracy: 0.6935 - val_loss: 756.8918 - val_accuracy: 0.7919\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1094.2949 - accuracy: 0.6916 - val_loss: 767.8693 - val_accuracy: 0.7981\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1108.4764 - accuracy: 0.6933 - val_loss: 764.5740 - val_accuracy: 0.7973\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1099.1179 - accuracy: 0.6932 - val_loss: 759.3902 - val_accuracy: 0.8019\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1097.3324 - accuracy: 0.6942 - val_loss: 754.9924 - val_accuracy: 0.7996\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1094.0546 - accuracy: 0.6949 - val_loss: 755.9928 - val_accuracy: 0.8006\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1095.6589 - accuracy: 0.6939 - val_loss: 763.7352 - val_accuracy: 0.7948\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1093.2643 - accuracy: 0.6954 - val_loss: 768.1078 - val_accuracy: 0.8005\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1115.0670 - accuracy: 0.6950 - val_loss: 788.2838 - val_accuracy: 0.7971\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1106.8236 - accuracy: 0.6930 - val_loss: 764.3580 - val_accuracy: 0.8004\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1095.9894 - accuracy: 0.6957 - val_loss: 756.0153 - val_accuracy: 0.8026\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1090.5540 - accuracy: 0.6952 - val_loss: 757.1235 - val_accuracy: 0.7976\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1090.4971 - accuracy: 0.6949 - val_loss: 755.3358 - val_accuracy: 0.8033\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1091.0842 - accuracy: 0.6955 - val_loss: 755.1937 - val_accuracy: 0.7951\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1089.7906 - accuracy: 0.6932 - val_loss: 752.9922 - val_accuracy: 0.8071\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1088.6946 - accuracy: 0.6966 - val_loss: 752.3636 - val_accuracy: 0.7976\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1087.4041 - accuracy: 0.6975 - val_loss: 751.7451 - val_accuracy: 0.8050\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1089.4725 - accuracy: 0.6951 - val_loss: 752.4255 - val_accuracy: 0.7963\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1087.6940 - accuracy: 0.6900 - val_loss: 753.2006 - val_accuracy: 0.8014\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1088.1508 - accuracy: 0.6970 - val_loss: 751.8820 - val_accuracy: 0.8046\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1087.3427 - accuracy: 0.6919 - val_loss: 750.8811 - val_accuracy: 0.8024\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1085.4794 - accuracy: 0.6956 - val_loss: 752.0121 - val_accuracy: 0.8051\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1086.0585 - accuracy: 0.6971 - val_loss: 759.8841 - val_accuracy: 0.8025\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1089.2260 - accuracy: 0.6961 - val_loss: 754.0158 - val_accuracy: 0.7958\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1087.4299 - accuracy: 0.6956 - val_loss: 752.6050 - val_accuracy: 0.8073\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1087.4857 - accuracy: 0.6966 - val_loss: 754.6160 - val_accuracy: 0.7998\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1088.3125 - accuracy: 0.6944 - val_loss: 753.9329 - val_accuracy: 0.8019\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1086.9205 - accuracy: 0.6943 - val_loss: 752.5640 - val_accuracy: 0.8006\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1087.5720 - accuracy: 0.6949 - val_loss: 754.9955 - val_accuracy: 0.8005\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1086.3099 - accuracy: 0.6977 - val_loss: 753.7831 - val_accuracy: 0.7937\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1087.3867 - accuracy: 0.6930 - val_loss: 751.8511 - val_accuracy: 0.8017\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1086.1671 - accuracy: 0.6960 - val_loss: 751.7335 - val_accuracy: 0.8010\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1085.1776 - accuracy: 0.6960 - val_loss: 752.5931 - val_accuracy: 0.8038\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1084.0184 - accuracy: 0.6957 - val_loss: 751.0715 - val_accuracy: 0.7980\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1085.3241 - accuracy: 0.6943 - val_loss: 750.5547 - val_accuracy: 0.7999\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1085.5732 - accuracy: 0.6975 - val_loss: 750.3243 - val_accuracy: 0.8016\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1082.8560 - accuracy: 0.6968 - val_loss: 751.8290 - val_accuracy: 0.8007\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1082.5442 - accuracy: 0.6963 - val_loss: 749.6589 - val_accuracy: 0.7969\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1081.9771 - accuracy: 0.6977 - val_loss: 751.0325 - val_accuracy: 0.7988\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1083.1382 - accuracy: 0.6975 - val_loss: 751.2545 - val_accuracy: 0.8008\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1082.6901 - accuracy: 0.6952 - val_loss: 749.1304 - val_accuracy: 0.8045\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1080.8610 - accuracy: 0.6981 - val_loss: 748.9342 - val_accuracy: 0.8013\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1082.6570 - accuracy: 0.6949 - val_loss: 757.4822 - val_accuracy: 0.8053\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1086.3999 - accuracy: 0.6968 - val_loss: 752.3769 - val_accuracy: 0.8013\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1082.2013 - accuracy: 0.6989 - val_loss: 749.2436 - val_accuracy: 0.8005\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1081.2511 - accuracy: 0.6961 - val_loss: 750.8985 - val_accuracy: 0.8023\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1082.8743 - accuracy: 0.6978 - val_loss: 748.7255 - val_accuracy: 0.8035\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1079.8141 - accuracy: 0.6972 - val_loss: 715.2639 - val_accuracy: 0.8004\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 923.7155 - accuracy: 0.6484 - val_loss: 693.7424 - val_accuracy: 0.7747\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 819.0614 - accuracy: 0.6661 - val_loss: 598.1775 - val_accuracy: 0.7936\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 786.5068 - accuracy: 0.6848 - val_loss: 591.0322 - val_accuracy: 0.8057\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 773.2911 - accuracy: 0.7279 - val_loss: 586.4719 - val_accuracy: 0.7967\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 766.2777 - accuracy: 0.7316 - val_loss: 583.7708 - val_accuracy: 0.7984\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 764.1742 - accuracy: 0.7240 - val_loss: 582.0140 - val_accuracy: 0.7996\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 763.9247 - accuracy: 0.7319 - val_loss: 586.6994 - val_accuracy: 0.7934\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 769.4948 - accuracy: 0.7260 - val_loss: 581.9391 - val_accuracy: 0.8029\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 770.6937 - accuracy: 0.7307 - val_loss: 591.6669 - val_accuracy: 0.7980\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 773.3763 - accuracy: 0.7345 - val_loss: 607.8821 - val_accuracy: 0.7935\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 777.0502 - accuracy: 0.7327 - val_loss: 582.7394 - val_accuracy: 0.8035\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 772.0955 - accuracy: 0.7391 - val_loss: 592.9017 - val_accuracy: 0.7981\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 775.4198 - accuracy: 0.7297 - val_loss: 580.2668 - val_accuracy: 0.7954\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 761.0354 - accuracy: 0.7355 - val_loss: 583.7480 - val_accuracy: 0.8031\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 763.3961 - accuracy: 0.7382 - val_loss: 580.7812 - val_accuracy: 0.7947\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 764.6550 - accuracy: 0.7316 - val_loss: 581.1161 - val_accuracy: 0.8016\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 760.6300 - accuracy: 0.7334 - val_loss: 578.9406 - val_accuracy: 0.7971\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 760.2457 - accuracy: 0.7340 - val_loss: 578.2439 - val_accuracy: 0.7998\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 763.8600 - accuracy: 0.7367 - val_loss: 585.2792 - val_accuracy: 0.7969\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 766.0588 - accuracy: 0.7308 - val_loss: 585.0435 - val_accuracy: 0.8001\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 763.1859 - accuracy: 0.7356 - val_loss: 577.7018 - val_accuracy: 0.8019\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 759.7093 - accuracy: 0.7385 - val_loss: 577.6492 - val_accuracy: 0.8029\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.3892 - accuracy: 0.7357 - val_loss: 584.5531 - val_accuracy: 0.7988\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 761.6226 - accuracy: 0.7373 - val_loss: 579.3844 - val_accuracy: 0.8020\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.8511 - accuracy: 0.7399 - val_loss: 580.7006 - val_accuracy: 0.8056\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 757.5800 - accuracy: 0.7369 - val_loss: 581.0605 - val_accuracy: 0.7986\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 765.1147 - accuracy: 0.7364 - val_loss: 582.0755 - val_accuracy: 0.8011\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 761.9698 - accuracy: 0.7412 - val_loss: 576.4603 - val_accuracy: 0.8017\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 757.2483 - accuracy: 0.7412 - val_loss: 576.6182 - val_accuracy: 0.7966\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 757.4708 - accuracy: 0.7397 - val_loss: 576.2661 - val_accuracy: 0.7995\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 759.9714 - accuracy: 0.7389 - val_loss: 579.7550 - val_accuracy: 0.8004\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 758.9784 - accuracy: 0.7415 - val_loss: 577.8925 - val_accuracy: 0.8014\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 759.3669 - accuracy: 0.7386 - val_loss: 577.2310 - val_accuracy: 0.8027\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 759.3398 - accuracy: 0.7405 - val_loss: 578.2819 - val_accuracy: 0.8020\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 759.5378 - accuracy: 0.7398 - val_loss: 575.9754 - val_accuracy: 0.8011\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 756.8220 - accuracy: 0.7421 - val_loss: 579.5480 - val_accuracy: 0.7994\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.6491 - accuracy: 0.7410 - val_loss: 576.1939 - val_accuracy: 0.7972\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 756.8145 - accuracy: 0.7374 - val_loss: 577.1175 - val_accuracy: 0.8007\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 756.4197 - accuracy: 0.7415 - val_loss: 577.6158 - val_accuracy: 0.7999\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 755.6863 - accuracy: 0.7440 - val_loss: 579.2050 - val_accuracy: 0.8034\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 760.6223 - accuracy: 0.7448 - val_loss: 576.4781 - val_accuracy: 0.7994\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 762.1354 - accuracy: 0.7401 - val_loss: 581.1281 - val_accuracy: 0.7932\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 779.4988 - accuracy: 0.7431 - val_loss: 598.5283 - val_accuracy: 0.8016\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 770.5837 - accuracy: 0.7436 - val_loss: 580.3187 - val_accuracy: 0.8002\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 772.1571 - accuracy: 0.7429 - val_loss: 581.7689 - val_accuracy: 0.7942\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 761.9586 - accuracy: 0.7432 - val_loss: 576.1530 - val_accuracy: 0.8003\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 757.1538 - accuracy: 0.7449 - val_loss: 575.0734 - val_accuracy: 0.8011\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 754.1854 - accuracy: 0.7421 - val_loss: 577.6946 - val_accuracy: 0.8020\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.4335 - accuracy: 0.7466 - val_loss: 577.3641 - val_accuracy: 0.8035\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 754.8718 - accuracy: 0.7481 - val_loss: 575.4876 - val_accuracy: 0.7978\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.6322 - accuracy: 0.7469 - val_loss: 577.8375 - val_accuracy: 0.7994\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.7321 - accuracy: 0.7461 - val_loss: 575.0403 - val_accuracy: 0.8015\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.3799 - accuracy: 0.7404 - val_loss: 575.0543 - val_accuracy: 0.8005\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 760.8349 - accuracy: 0.7446 - val_loss: 589.8262 - val_accuracy: 0.7984\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 769.5226 - accuracy: 0.7459 - val_loss: 581.4245 - val_accuracy: 0.8008\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 764.8428 - accuracy: 0.7494 - val_loss: 581.6218 - val_accuracy: 0.7990\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.3421 - accuracy: 0.7500 - val_loss: 580.2469 - val_accuracy: 0.8054\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 757.5136 - accuracy: 0.7481 - val_loss: 578.5743 - val_accuracy: 0.7988\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 768.9398 - accuracy: 0.7505 - val_loss: 576.8193 - val_accuracy: 0.7996\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 756.7446 - accuracy: 0.7487 - val_loss: 576.7181 - val_accuracy: 0.8010\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 755.0730 - accuracy: 0.7496 - val_loss: 578.4287 - val_accuracy: 0.7989\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 753.5469 - accuracy: 0.7482 - val_loss: 579.0132 - val_accuracy: 0.8025\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 753.5947 - accuracy: 0.7517 - val_loss: 575.3448 - val_accuracy: 0.8017\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.8932 - accuracy: 0.7509 - val_loss: 573.8798 - val_accuracy: 0.8016\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.3044 - accuracy: 0.7503 - val_loss: 573.1297 - val_accuracy: 0.8028\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.8327 - accuracy: 0.7531 - val_loss: 574.2478 - val_accuracy: 0.7993\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.7591 - accuracy: 0.7512 - val_loss: 576.4910 - val_accuracy: 0.7996\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 752.7719 - accuracy: 0.7491 - val_loss: 575.0901 - val_accuracy: 0.8001\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.5477 - accuracy: 0.7516 - val_loss: 572.3007 - val_accuracy: 0.7952\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 752.3281 - accuracy: 0.7488 - val_loss: 573.9139 - val_accuracy: 0.8029\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.2256 - accuracy: 0.7544 - val_loss: 574.0181 - val_accuracy: 0.8002\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.1637 - accuracy: 0.7507 - val_loss: 572.1224 - val_accuracy: 0.8030\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.0402 - accuracy: 0.7515 - val_loss: 571.7664 - val_accuracy: 0.7991\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 749.2971 - accuracy: 0.7517 - val_loss: 574.1812 - val_accuracy: 0.8045\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 750.5618 - accuracy: 0.7529 - val_loss: 578.7841 - val_accuracy: 0.8021\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 753.8941 - accuracy: 0.7551 - val_loss: 575.3660 - val_accuracy: 0.7972\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.9786 - accuracy: 0.7538 - val_loss: 572.9409 - val_accuracy: 0.8061\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.2545 - accuracy: 0.7507 - val_loss: 571.6541 - val_accuracy: 0.8020\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.2317 - accuracy: 0.7537 - val_loss: 571.9375 - val_accuracy: 0.7989\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 749.5117 - accuracy: 0.7544 - val_loss: 572.7286 - val_accuracy: 0.8023\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 751.7471 - accuracy: 0.7540 - val_loss: 572.7233 - val_accuracy: 0.8040\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.7099 - accuracy: 0.7551 - val_loss: 574.0861 - val_accuracy: 0.8053\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.4009 - accuracy: 0.7554 - val_loss: 571.0430 - val_accuracy: 0.7998\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.8043 - accuracy: 0.7547 - val_loss: 571.5078 - val_accuracy: 0.7984\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.5115 - accuracy: 0.7537 - val_loss: 572.3820 - val_accuracy: 0.8011\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.2772 - accuracy: 0.7502 - val_loss: 571.5827 - val_accuracy: 0.7974\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 749.9616 - accuracy: 0.7552 - val_loss: 571.1085 - val_accuracy: 0.8047\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.4079 - accuracy: 0.7543 - val_loss: 575.6982 - val_accuracy: 0.8034\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 750.7193 - accuracy: 0.7562 - val_loss: 576.2728 - val_accuracy: 0.8060\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 753.6448 - accuracy: 0.7559 - val_loss: 571.1687 - val_accuracy: 0.8021\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.3350 - accuracy: 0.7568 - val_loss: 571.6461 - val_accuracy: 0.8038\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.9285 - accuracy: 0.7533 - val_loss: 574.6057 - val_accuracy: 0.8023\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 749.4842 - accuracy: 0.7575 - val_loss: 571.9620 - val_accuracy: 0.8021\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.8708 - accuracy: 0.7556 - val_loss: 582.2394 - val_accuracy: 0.8034\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.9760 - accuracy: 0.7580 - val_loss: 570.7514 - val_accuracy: 0.8025\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 748.2426 - accuracy: 0.7565 - val_loss: 570.7339 - val_accuracy: 0.8015\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 748.3405 - accuracy: 0.7536 - val_loss: 571.7576 - val_accuracy: 0.7998\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 747.0183 - accuracy: 0.7565 - val_loss: 571.2681 - val_accuracy: 0.8054\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 746.9811 - accuracy: 0.7591 - val_loss: 570.1200 - val_accuracy: 0.8013\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 745.7264 - accuracy: 0.7560 - val_loss: 571.2091 - val_accuracy: 0.8031\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 747.5798 - accuracy: 0.7557 - val_loss: 570.6923 - val_accuracy: 0.7994\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 747.6637 - accuracy: 0.7564 - val_loss: 573.7307 - val_accuracy: 0.8007\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.0618 - accuracy: 0.7581 - val_loss: 574.7959 - val_accuracy: 0.8066\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 772.4753 - accuracy: 0.7550 - val_loss: 592.7659 - val_accuracy: 0.7982\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.0904 - accuracy: 0.7542 - val_loss: 573.3688 - val_accuracy: 0.8055\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 752.1230 - accuracy: 0.7549 - val_loss: 577.6595 - val_accuracy: 0.7981\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 763.2070 - accuracy: 0.7555 - val_loss: 587.0865 - val_accuracy: 0.8012\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 757.4767 - accuracy: 0.7543 - val_loss: 585.6135 - val_accuracy: 0.8009\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.4675 - accuracy: 0.7587 - val_loss: 575.6169 - val_accuracy: 0.7987\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.5499 - accuracy: 0.7528 - val_loss: 577.3718 - val_accuracy: 0.8049\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 748.3613 - accuracy: 0.7566 - val_loss: 573.9481 - val_accuracy: 0.8025\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 746.4656 - accuracy: 0.7552 - val_loss: 571.2357 - val_accuracy: 0.8008\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 745.6094 - accuracy: 0.7546 - val_loss: 570.8377 - val_accuracy: 0.7985\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.9833 - accuracy: 0.7563 - val_loss: 573.2327 - val_accuracy: 0.8056\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 749.8132 - accuracy: 0.7617 - val_loss: 578.0230 - val_accuracy: 0.8020\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 759.8412 - accuracy: 0.7552 - val_loss: 570.5573 - val_accuracy: 0.8040\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 756.0856 - accuracy: 0.7599 - val_loss: 579.7220 - val_accuracy: 0.7997\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 753.7266 - accuracy: 0.7581 - val_loss: 570.9058 - val_accuracy: 0.7978\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.2433 - accuracy: 0.7572 - val_loss: 569.5313 - val_accuracy: 0.8042\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.0214 - accuracy: 0.7594 - val_loss: 569.1121 - val_accuracy: 0.8045\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.6971 - accuracy: 0.7608 - val_loss: 569.7027 - val_accuracy: 0.8006\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.8207 - accuracy: 0.7594 - val_loss: 570.7309 - val_accuracy: 0.8066\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 744.1298 - accuracy: 0.7582 - val_loss: 570.0411 - val_accuracy: 0.8010\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 744.5826 - accuracy: 0.7577 - val_loss: 570.8184 - val_accuracy: 0.8064\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.5532 - accuracy: 0.7604 - val_loss: 571.2806 - val_accuracy: 0.8032\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.3141 - accuracy: 0.7574 - val_loss: 574.6699 - val_accuracy: 0.8032\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 747.1658 - accuracy: 0.7556 - val_loss: 576.8074 - val_accuracy: 0.8041\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.4103 - accuracy: 0.7606 - val_loss: 570.3835 - val_accuracy: 0.8026\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 746.6616 - accuracy: 0.7577 - val_loss: 571.9992 - val_accuracy: 0.8050\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.4675 - accuracy: 0.7555 - val_loss: 571.0644 - val_accuracy: 0.8007\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.1735 - accuracy: 0.7584 - val_loss: 569.4895 - val_accuracy: 0.7999\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.2615 - accuracy: 0.7604 - val_loss: 572.1493 - val_accuracy: 0.8041\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.5028 - accuracy: 0.7604 - val_loss: 571.5111 - val_accuracy: 0.8031\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 744.8347 - accuracy: 0.7620 - val_loss: 570.5321 - val_accuracy: 0.8062\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.7485 - accuracy: 0.7567 - val_loss: 568.7012 - val_accuracy: 0.8076\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 742.3703 - accuracy: 0.7574 - val_loss: 568.6288 - val_accuracy: 0.8024\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 742.6943 - accuracy: 0.7618 - val_loss: 569.0799 - val_accuracy: 0.8058\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 742.6624 - accuracy: 0.7594 - val_loss: 572.7376 - val_accuracy: 0.8033\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.2131 - accuracy: 0.7596 - val_loss: 568.5477 - val_accuracy: 0.8039\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 743.3901 - accuracy: 0.7619 - val_loss: 568.9738 - val_accuracy: 0.8020\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 742.7673 - accuracy: 0.7583 - val_loss: 569.8428 - val_accuracy: 0.8052\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 745.4877 - accuracy: 0.7604 - val_loss: 576.8189 - val_accuracy: 0.8007\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 745.7725 - accuracy: 0.7604 - val_loss: 587.7946 - val_accuracy: 0.8046\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 753.8223 - accuracy: 0.7581 - val_loss: 570.3728 - val_accuracy: 0.8039\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 749.4161 - accuracy: 0.7600 - val_loss: 569.5756 - val_accuracy: 0.8052\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.6836 - accuracy: 0.7614 - val_loss: 581.1180 - val_accuracy: 0.8037\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.2869 - accuracy: 0.7573 - val_loss: 571.8554 - val_accuracy: 0.8073\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 747.4333 - accuracy: 0.7604 - val_loss: 569.9973 - val_accuracy: 0.7989\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 745.8835 - accuracy: 0.7611 - val_loss: 568.4263 - val_accuracy: 0.8051\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.0914 - accuracy: 0.7582 - val_loss: 573.2094 - val_accuracy: 0.8068\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.9020 - accuracy: 0.7628 - val_loss: 571.5380 - val_accuracy: 0.8012\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.1809 - accuracy: 0.7602 - val_loss: 572.5634 - val_accuracy: 0.8083\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 747.1451 - accuracy: 0.7595 - val_loss: 571.3281 - val_accuracy: 0.8059\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 742.6436 - accuracy: 0.7606 - val_loss: 567.4265 - val_accuracy: 0.8041\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.0666 - accuracy: 0.7617 - val_loss: 568.5567 - val_accuracy: 0.8099\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 741.9067 - accuracy: 0.7602 - val_loss: 570.2897 - val_accuracy: 0.8046\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.3810 - accuracy: 0.7637 - val_loss: 570.9343 - val_accuracy: 0.8078\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 740.4948 - accuracy: 0.7631 - val_loss: 568.7551 - val_accuracy: 0.8035\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 740.7560 - accuracy: 0.7607 - val_loss: 568.5041 - val_accuracy: 0.7992\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 741.7541 - accuracy: 0.7615 - val_loss: 568.8966 - val_accuracy: 0.8078\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.5895 - accuracy: 0.7603 - val_loss: 567.8533 - val_accuracy: 0.8004\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 741.2607 - accuracy: 0.7642 - val_loss: 569.9710 - val_accuracy: 0.8042\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.3915 - accuracy: 0.7639 - val_loss: 569.4844 - val_accuracy: 0.8030\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.6428 - accuracy: 0.7619 - val_loss: 566.4461 - val_accuracy: 0.8048\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.9733 - accuracy: 0.7627 - val_loss: 567.2372 - val_accuracy: 0.8053\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.7409 - accuracy: 0.7620 - val_loss: 566.7338 - val_accuracy: 0.8078\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.1573 - accuracy: 0.7629 - val_loss: 567.4587 - val_accuracy: 0.8007\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.5023 - accuracy: 0.7639 - val_loss: 566.2624 - val_accuracy: 0.8064\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.0505 - accuracy: 0.7626 - val_loss: 567.8774 - val_accuracy: 0.8008\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.3912 - accuracy: 0.7622 - val_loss: 566.3564 - val_accuracy: 0.8076\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 738.8893 - accuracy: 0.7632 - val_loss: 567.4370 - val_accuracy: 0.8059\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 739.6666 - accuracy: 0.7603 - val_loss: 567.7063 - val_accuracy: 0.8043\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.6309 - accuracy: 0.7638 - val_loss: 567.5811 - val_accuracy: 0.8057\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 738.6749 - accuracy: 0.7635 - val_loss: 566.6088 - val_accuracy: 0.8033\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.2356 - accuracy: 0.7621 - val_loss: 569.1102 - val_accuracy: 0.8030\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.0272 - accuracy: 0.7647 - val_loss: 566.3129 - val_accuracy: 0.8088\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.3235 - accuracy: 0.7641 - val_loss: 567.3661 - val_accuracy: 0.8020\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.5016 - accuracy: 0.7638 - val_loss: 566.0530 - val_accuracy: 0.8075\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.4085 - accuracy: 0.7648 - val_loss: 565.9470 - val_accuracy: 0.8049\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.7361 - accuracy: 0.7581 - val_loss: 567.0781 - val_accuracy: 0.8041\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.5947 - accuracy: 0.7660 - val_loss: 573.0424 - val_accuracy: 0.8096\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.6849 - accuracy: 0.7643 - val_loss: 567.2257 - val_accuracy: 0.8044\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.8563 - accuracy: 0.7630 - val_loss: 566.8922 - val_accuracy: 0.8095\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.8404 - accuracy: 0.7635 - val_loss: 566.1624 - val_accuracy: 0.8024\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.3502 - accuracy: 0.7666 - val_loss: 568.3515 - val_accuracy: 0.8030\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 743.2737 - accuracy: 0.7633 - val_loss: 568.9576 - val_accuracy: 0.8046\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.1857 - accuracy: 0.7640 - val_loss: 575.3361 - val_accuracy: 0.8039\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.5961 - accuracy: 0.7616 - val_loss: 568.4120 - val_accuracy: 0.8027\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.0202 - accuracy: 0.7660 - val_loss: 569.5966 - val_accuracy: 0.8054\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 738.9250 - accuracy: 0.7663 - val_loss: 567.0830 - val_accuracy: 0.8019\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 741.2311 - accuracy: 0.7653 - val_loss: 568.0875 - val_accuracy: 0.8060\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.6749 - accuracy: 0.7650 - val_loss: 567.3790 - val_accuracy: 0.8003\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 741.5941 - accuracy: 0.7641 - val_loss: 566.9083 - val_accuracy: 0.8119\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 738.1126 - accuracy: 0.7630 - val_loss: 570.6104 - val_accuracy: 0.8053\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.3307 - accuracy: 0.7646 - val_loss: 565.1508 - val_accuracy: 0.8046\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.5886 - accuracy: 0.7663 - val_loss: 564.9821 - val_accuracy: 0.8040\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.9510 - accuracy: 0.7670 - val_loss: 570.1213 - val_accuracy: 0.8053\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 739.5396 - accuracy: 0.7661 - val_loss: 566.2256 - val_accuracy: 0.8083\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.3912 - accuracy: 0.7653 - val_loss: 571.4545 - val_accuracy: 0.8082\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 741.3437 - accuracy: 0.7669 - val_loss: 566.9449 - val_accuracy: 0.8083\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 739.4825 - accuracy: 0.7660 - val_loss: 567.6347 - val_accuracy: 0.8045\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.0463 - accuracy: 0.7647 - val_loss: 565.5304 - val_accuracy: 0.8070\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.6267 - accuracy: 0.7675 - val_loss: 569.9052 - val_accuracy: 0.8060\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 738.8016 - accuracy: 0.7670 - val_loss: 567.1771 - val_accuracy: 0.8050\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.5584 - accuracy: 0.7639 - val_loss: 565.7587 - val_accuracy: 0.8056\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 739.9231 - accuracy: 0.7627 - val_loss: 565.5744 - val_accuracy: 0.8055\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.4211 - accuracy: 0.7679 - val_loss: 565.1501 - val_accuracy: 0.8064\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 739.7654 - accuracy: 0.7668 - val_loss: 587.0667 - val_accuracy: 0.8031\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 751.6075 - accuracy: 0.7639 - val_loss: 578.0107 - val_accuracy: 0.8035\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 749.4532 - accuracy: 0.7648 - val_loss: 575.0501 - val_accuracy: 0.8056\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 759.0513 - accuracy: 0.7613 - val_loss: 568.3096 - val_accuracy: 0.8067\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 743.8010 - accuracy: 0.7649 - val_loss: 565.7094 - val_accuracy: 0.8030\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 741.1339 - accuracy: 0.7626 - val_loss: 565.7403 - val_accuracy: 0.8092\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.0430 - accuracy: 0.7667 - val_loss: 579.6456 - val_accuracy: 0.8106\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.6021 - accuracy: 0.7630 - val_loss: 583.6186 - val_accuracy: 0.8037\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.0735 - accuracy: 0.7680 - val_loss: 568.7849 - val_accuracy: 0.8072\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.7358 - accuracy: 0.7674 - val_loss: 572.5792 - val_accuracy: 0.8077\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 739.5883 - accuracy: 0.7673 - val_loss: 570.6101 - val_accuracy: 0.8093\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 741.2235 - accuracy: 0.7670 - val_loss: 566.7226 - val_accuracy: 0.8047\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.8495 - accuracy: 0.7683 - val_loss: 563.7309 - val_accuracy: 0.8089\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.8055 - accuracy: 0.7671 - val_loss: 567.1145 - val_accuracy: 0.8066\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.2843 - accuracy: 0.7686 - val_loss: 565.0824 - val_accuracy: 0.8097\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 735.5471 - accuracy: 0.7656 - val_loss: 564.7868 - val_accuracy: 0.8009\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.7726 - accuracy: 0.7672 - val_loss: 564.8755 - val_accuracy: 0.8130\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.6411 - accuracy: 0.7671 - val_loss: 564.7717 - val_accuracy: 0.8041\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.8076 - accuracy: 0.7660 - val_loss: 565.8502 - val_accuracy: 0.8062\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.6925 - accuracy: 0.7695 - val_loss: 564.6757 - val_accuracy: 0.8116\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.3090 - accuracy: 0.7684 - val_loss: 564.5208 - val_accuracy: 0.8083\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 736.9128 - accuracy: 0.7687 - val_loss: 568.8204 - val_accuracy: 0.8045\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.3577 - accuracy: 0.7710 - val_loss: 563.5887 - val_accuracy: 0.8044\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.1826 - accuracy: 0.7678 - val_loss: 567.4916 - val_accuracy: 0.8069\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.7969 - accuracy: 0.7670 - val_loss: 566.1022 - val_accuracy: 0.8097\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.3524 - accuracy: 0.7695 - val_loss: 567.0128 - val_accuracy: 0.8051\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.1581 - accuracy: 0.7668 - val_loss: 574.1084 - val_accuracy: 0.8077\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 735.6277 - accuracy: 0.7689 - val_loss: 563.4287 - val_accuracy: 0.8041\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.9242 - accuracy: 0.7666 - val_loss: 564.0280 - val_accuracy: 0.8132\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.4496 - accuracy: 0.7664 - val_loss: 566.3064 - val_accuracy: 0.8027\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.5624 - accuracy: 0.7671 - val_loss: 565.2162 - val_accuracy: 0.8060\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.7424 - accuracy: 0.7690 - val_loss: 565.0459 - val_accuracy: 0.8040\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.9015 - accuracy: 0.7688 - val_loss: 563.2111 - val_accuracy: 0.8093\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.7309 - accuracy: 0.7671 - val_loss: 563.7083 - val_accuracy: 0.8060\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 732.9905 - accuracy: 0.7700 - val_loss: 565.2690 - val_accuracy: 0.8057\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.8491 - accuracy: 0.7672 - val_loss: 563.4313 - val_accuracy: 0.8005\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.0784 - accuracy: 0.7674 - val_loss: 562.6863 - val_accuracy: 0.8097\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.2600 - accuracy: 0.7697 - val_loss: 563.9896 - val_accuracy: 0.7992\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.0277 - accuracy: 0.7694 - val_loss: 563.2833 - val_accuracy: 0.8071\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.4418 - accuracy: 0.7669 - val_loss: 564.1600 - val_accuracy: 0.8044\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 732.6923 - accuracy: 0.7659 - val_loss: 563.4992 - val_accuracy: 0.8043\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.1323 - accuracy: 0.7687 - val_loss: 563.6088 - val_accuracy: 0.8141\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.6694 - accuracy: 0.7689 - val_loss: 562.1306 - val_accuracy: 0.8096\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.7692 - accuracy: 0.7701 - val_loss: 563.9670 - val_accuracy: 0.8064\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.3133 - accuracy: 0.7651 - val_loss: 567.9590 - val_accuracy: 0.8127\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.4861 - accuracy: 0.7709 - val_loss: 571.8147 - val_accuracy: 0.8044\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 736.6240 - accuracy: 0.7674 - val_loss: 564.0132 - val_accuracy: 0.8049\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.1542 - accuracy: 0.7693 - val_loss: 566.7866 - val_accuracy: 0.8066\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.3596 - accuracy: 0.7692 - val_loss: 564.1780 - val_accuracy: 0.8033\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.6796 - accuracy: 0.7668 - val_loss: 564.9457 - val_accuracy: 0.8109\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.2926 - accuracy: 0.7684 - val_loss: 563.7861 - val_accuracy: 0.8076\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.4445 - accuracy: 0.7676 - val_loss: 562.9291 - val_accuracy: 0.8083\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.0984 - accuracy: 0.7706 - val_loss: 562.6541 - val_accuracy: 0.8034\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.1891 - accuracy: 0.7676 - val_loss: 566.3977 - val_accuracy: 0.8099\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.8952 - accuracy: 0.7718 - val_loss: 563.6966 - val_accuracy: 0.8103\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.4657 - accuracy: 0.7720 - val_loss: 564.0523 - val_accuracy: 0.8017\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.7092 - accuracy: 0.7666 - val_loss: 562.2612 - val_accuracy: 0.8105\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.0261 - accuracy: 0.7709 - val_loss: 563.5944 - val_accuracy: 0.8036\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.1949 - accuracy: 0.7675 - val_loss: 565.9167 - val_accuracy: 0.8058\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 735.7061 - accuracy: 0.7691 - val_loss: 564.7878 - val_accuracy: 0.8032\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.5070 - accuracy: 0.7699 - val_loss: 567.5712 - val_accuracy: 0.8041\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 734.8130 - accuracy: 0.7685 - val_loss: 562.9802 - val_accuracy: 0.8055\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.5827 - accuracy: 0.7700 - val_loss: 571.6178 - val_accuracy: 0.8068\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.4590 - accuracy: 0.7703 - val_loss: 562.7478 - val_accuracy: 0.8098\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.9180 - accuracy: 0.7709 - val_loss: 564.2310 - val_accuracy: 0.8083\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.3121 - accuracy: 0.7705 - val_loss: 562.5317 - val_accuracy: 0.8129\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.0380 - accuracy: 0.7703 - val_loss: 561.7010 - val_accuracy: 0.8052\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.9388 - accuracy: 0.7683 - val_loss: 561.3917 - val_accuracy: 0.8083\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.7869 - accuracy: 0.7718 - val_loss: 562.1807 - val_accuracy: 0.8105\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.0693 - accuracy: 0.7696 - val_loss: 561.3380 - val_accuracy: 0.8088\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.2409 - accuracy: 0.7683 - val_loss: 561.8652 - val_accuracy: 0.8065\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.3889 - accuracy: 0.7733 - val_loss: 560.9138 - val_accuracy: 0.8096\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.9367 - accuracy: 0.7731 - val_loss: 563.4376 - val_accuracy: 0.8110\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.6673 - accuracy: 0.7675 - val_loss: 562.7523 - val_accuracy: 0.8006\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 741.5392 - accuracy: 0.7685 - val_loss: 566.0920 - val_accuracy: 0.8091\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.5012 - accuracy: 0.7694 - val_loss: 583.2822 - val_accuracy: 0.8174\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 739.1987 - accuracy: 0.7702 - val_loss: 563.5863 - val_accuracy: 0.8051\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.4118 - accuracy: 0.7701 - val_loss: 563.1100 - val_accuracy: 0.8087\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 731.0795 - accuracy: 0.7689 - val_loss: 563.9274 - val_accuracy: 0.8114\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.6669 - accuracy: 0.7702 - val_loss: 564.1489 - val_accuracy: 0.7958\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.3373 - accuracy: 0.7703 - val_loss: 562.0503 - val_accuracy: 0.8125\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.7675 - accuracy: 0.7702 - val_loss: 563.4998 - val_accuracy: 0.8112\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 731.8756 - accuracy: 0.7719 - val_loss: 561.7974 - val_accuracy: 0.8110\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 730.7983 - accuracy: 0.7691 - val_loss: 561.1838 - val_accuracy: 0.8062\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.7289 - accuracy: 0.7712 - val_loss: 561.2665 - val_accuracy: 0.8079\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 734.8554 - accuracy: 0.7696 - val_loss: 571.4453 - val_accuracy: 0.8099\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 741.9564 - accuracy: 0.7721 - val_loss: 574.7037 - val_accuracy: 0.8062\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.4256 - accuracy: 0.7720 - val_loss: 568.4998 - val_accuracy: 0.8141\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 745.4995 - accuracy: 0.7712 - val_loss: 564.7741 - val_accuracy: 0.8088\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.8219 - accuracy: 0.7734 - val_loss: 581.0055 - val_accuracy: 0.8089\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 739.1450 - accuracy: 0.7712 - val_loss: 564.4854 - val_accuracy: 0.8043\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.7605 - accuracy: 0.7692 - val_loss: 564.0352 - val_accuracy: 0.8096\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.0977 - accuracy: 0.7715 - val_loss: 561.2274 - val_accuracy: 0.7993\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.0321 - accuracy: 0.7725 - val_loss: 562.4725 - val_accuracy: 0.8075\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.2711 - accuracy: 0.7711 - val_loss: 561.5895 - val_accuracy: 0.8054\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.7255 - accuracy: 0.7698 - val_loss: 562.7280 - val_accuracy: 0.8078\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 730.6815 - accuracy: 0.7714 - val_loss: 561.5106 - val_accuracy: 0.8121\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 728.4819 - accuracy: 0.7722 - val_loss: 560.9766 - val_accuracy: 0.8089\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.0304 - accuracy: 0.7711 - val_loss: 560.5209 - val_accuracy: 0.8085\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.8178 - accuracy: 0.7713 - val_loss: 562.6362 - val_accuracy: 0.8136\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.7391 - accuracy: 0.7719 - val_loss: 560.8177 - val_accuracy: 0.8051\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.8480 - accuracy: 0.7713 - val_loss: 559.8134 - val_accuracy: 0.8085\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.6003 - accuracy: 0.7739 - val_loss: 560.1320 - val_accuracy: 0.8105\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.7050 - accuracy: 0.7711 - val_loss: 559.5878 - val_accuracy: 0.8103\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.4737 - accuracy: 0.7712 - val_loss: 560.1183 - val_accuracy: 0.8060\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.1188 - accuracy: 0.7739 - val_loss: 560.5959 - val_accuracy: 0.8093\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.1415 - accuracy: 0.7731 - val_loss: 559.3004 - val_accuracy: 0.8103\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.6440 - accuracy: 0.7734 - val_loss: 560.4263 - val_accuracy: 0.8011\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.1173 - accuracy: 0.7719 - val_loss: 562.9144 - val_accuracy: 0.8119\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.2352 - accuracy: 0.7724 - val_loss: 559.9136 - val_accuracy: 0.8078\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.6495 - accuracy: 0.7697 - val_loss: 567.4628 - val_accuracy: 0.8109\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.1630 - accuracy: 0.7703 - val_loss: 561.4994 - val_accuracy: 0.8068\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.1710 - accuracy: 0.7742 - val_loss: 561.3005 - val_accuracy: 0.8056\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.9612 - accuracy: 0.7727 - val_loss: 561.8663 - val_accuracy: 0.8125\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.2862 - accuracy: 0.7712 - val_loss: 560.7206 - val_accuracy: 0.8081\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.6436 - accuracy: 0.7698 - val_loss: 568.7847 - val_accuracy: 0.8118\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.9908 - accuracy: 0.7728 - val_loss: 559.3126 - val_accuracy: 0.8122\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 727.5704 - accuracy: 0.7724 - val_loss: 560.2157 - val_accuracy: 0.8095\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.2241 - accuracy: 0.7726 - val_loss: 561.1515 - val_accuracy: 0.8047\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.4508 - accuracy: 0.7674 - val_loss: 560.1035 - val_accuracy: 0.8072\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.0254 - accuracy: 0.7725 - val_loss: 561.4894 - val_accuracy: 0.8075\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.0909 - accuracy: 0.7720 - val_loss: 559.8668 - val_accuracy: 0.8067\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.3655 - accuracy: 0.7730 - val_loss: 561.2221 - val_accuracy: 0.8108\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 729.9083 - accuracy: 0.7746 - val_loss: 559.4386 - val_accuracy: 0.8030\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.2738 - accuracy: 0.7694 - val_loss: 560.3732 - val_accuracy: 0.8052\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.4994 - accuracy: 0.7724 - val_loss: 563.3291 - val_accuracy: 0.8133\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.6251 - accuracy: 0.7715 - val_loss: 565.7298 - val_accuracy: 0.8124\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.9648 - accuracy: 0.7710 - val_loss: 561.1486 - val_accuracy: 0.8123\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.5121 - accuracy: 0.7723 - val_loss: 561.6135 - val_accuracy: 0.8073\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.0637 - accuracy: 0.7714 - val_loss: 560.9299 - val_accuracy: 0.8089\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.6464 - accuracy: 0.7729 - val_loss: 559.5195 - val_accuracy: 0.8073\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.4592 - accuracy: 0.7730 - val_loss: 559.4335 - val_accuracy: 0.8068\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.5126 - accuracy: 0.7726 - val_loss: 558.8423 - val_accuracy: 0.8090\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.1055 - accuracy: 0.7734 - val_loss: 560.7851 - val_accuracy: 0.8140\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.1102 - accuracy: 0.7710 - val_loss: 567.0993 - val_accuracy: 0.8085\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 740.7314 - accuracy: 0.7714 - val_loss: 560.0241 - val_accuracy: 0.8121\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 734.7961 - accuracy: 0.7752 - val_loss: 574.3265 - val_accuracy: 0.8136\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.4889 - accuracy: 0.7707 - val_loss: 560.4610 - val_accuracy: 0.8119\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.8937 - accuracy: 0.7710 - val_loss: 560.0837 - val_accuracy: 0.8058\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.5916 - accuracy: 0.7706 - val_loss: 568.9293 - val_accuracy: 0.8085\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.6655 - accuracy: 0.7722 - val_loss: 563.9182 - val_accuracy: 0.8069\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.9764 - accuracy: 0.7734 - val_loss: 564.1185 - val_accuracy: 0.8137\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.1846 - accuracy: 0.7711 - val_loss: 560.4486 - val_accuracy: 0.8101\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.6903 - accuracy: 0.7725 - val_loss: 558.8329 - val_accuracy: 0.8073\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.3759 - accuracy: 0.7715 - val_loss: 559.2889 - val_accuracy: 0.8066\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.6013 - accuracy: 0.7737 - val_loss: 560.2264 - val_accuracy: 0.8142\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.0118 - accuracy: 0.7732 - val_loss: 565.0836 - val_accuracy: 0.8121\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 727.7509 - accuracy: 0.7718 - val_loss: 559.7672 - val_accuracy: 0.8077\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 726.9875 - accuracy: 0.7742 - val_loss: 557.9955 - val_accuracy: 0.8156\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 43ms/step - loss: 727.7202 - accuracy: 0.7733 - val_loss: 559.7389 - val_accuracy: 0.8117\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 728.0712 - accuracy: 0.7724 - val_loss: 562.2762 - val_accuracy: 0.8084\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 729.0588 - accuracy: 0.7721 - val_loss: 559.4036 - val_accuracy: 0.8145\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 727.6583 - accuracy: 0.7740 - val_loss: 558.7161 - val_accuracy: 0.8105\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 728.2806 - accuracy: 0.7754 - val_loss: 558.8738 - val_accuracy: 0.8113\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 726.0815 - accuracy: 0.7739 - val_loss: 558.3541 - val_accuracy: 0.8111\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 725.7550 - accuracy: 0.7710 - val_loss: 559.3422 - val_accuracy: 0.8135\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 726.7099 - accuracy: 0.7713 - val_loss: 558.5377 - val_accuracy: 0.8110\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 725.9602 - accuracy: 0.7748 - val_loss: 561.6854 - val_accuracy: 0.8133\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 730.5298 - accuracy: 0.7741 - val_loss: 559.9536 - val_accuracy: 0.8046\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 726.6465 - accuracy: 0.7728 - val_loss: 558.7644 - val_accuracy: 0.8143\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 726.1910 - accuracy: 0.7742 - val_loss: 562.8231 - val_accuracy: 0.8116\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 726.3175 - accuracy: 0.7730 - val_loss: 558.9014 - val_accuracy: 0.8066\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 728.2749 - accuracy: 0.7736 - val_loss: 561.0920 - val_accuracy: 0.8152\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 726.7891 - accuracy: 0.7750 - val_loss: 562.4060 - val_accuracy: 0.8123\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.1500 - accuracy: 0.7748 - val_loss: 559.1777 - val_accuracy: 0.8113\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.7411 - accuracy: 0.7740 - val_loss: 558.4453 - val_accuracy: 0.8127\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.5848 - accuracy: 0.7743 - val_loss: 560.6126 - val_accuracy: 0.8053\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.7407 - accuracy: 0.7719 - val_loss: 558.7515 - val_accuracy: 0.8098\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.8275 - accuracy: 0.7733 - val_loss: 561.7837 - val_accuracy: 0.8094\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.0397 - accuracy: 0.7734 - val_loss: 558.8431 - val_accuracy: 0.8140\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.9652 - accuracy: 0.7751 - val_loss: 562.9882 - val_accuracy: 0.8105\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.6017 - accuracy: 0.7713 - val_loss: 560.0558 - val_accuracy: 0.8088\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.8686 - accuracy: 0.7727 - val_loss: 564.2894 - val_accuracy: 0.8112\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.8345 - accuracy: 0.7709 - val_loss: 562.8637 - val_accuracy: 0.8059\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.6851 - accuracy: 0.7745 - val_loss: 562.3049 - val_accuracy: 0.8091\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.8096 - accuracy: 0.7733 - val_loss: 559.1743 - val_accuracy: 0.8111\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.6208 - accuracy: 0.7757 - val_loss: 571.2278 - val_accuracy: 0.8094\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.5228 - accuracy: 0.7739 - val_loss: 557.5270 - val_accuracy: 0.8059\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.3775 - accuracy: 0.7746 - val_loss: 557.3987 - val_accuracy: 0.8107\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 725.5525 - accuracy: 0.7735 - val_loss: 559.1028 - val_accuracy: 0.8086\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.8815 - accuracy: 0.7707 - val_loss: 558.7330 - val_accuracy: 0.8046\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 726.2590 - accuracy: 0.7743 - val_loss: 560.1569 - val_accuracy: 0.8152\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.5067 - accuracy: 0.7742 - val_loss: 565.6260 - val_accuracy: 0.8154\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 738.3892 - accuracy: 0.7736 - val_loss: 561.9846 - val_accuracy: 0.8115\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.8212 - accuracy: 0.7733 - val_loss: 565.3860 - val_accuracy: 0.8088\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 736.4289 - accuracy: 0.7739 - val_loss: 564.7469 - val_accuracy: 0.8079\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.6431 - accuracy: 0.7711 - val_loss: 570.0650 - val_accuracy: 0.8125\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.6774 - accuracy: 0.7726 - val_loss: 562.1319 - val_accuracy: 0.8143\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.2266 - accuracy: 0.7722 - val_loss: 570.9073 - val_accuracy: 0.8074\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 736.3901 - accuracy: 0.7720 - val_loss: 563.8411 - val_accuracy: 0.8052\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.2492 - accuracy: 0.7734 - val_loss: 563.5940 - val_accuracy: 0.8107\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 731.1382 - accuracy: 0.7707 - val_loss: 562.4042 - val_accuracy: 0.8049\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.0305 - accuracy: 0.7721 - val_loss: 559.2202 - val_accuracy: 0.8158\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.6467 - accuracy: 0.7744 - val_loss: 562.2267 - val_accuracy: 0.8113\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.7949 - accuracy: 0.7740 - val_loss: 558.1050 - val_accuracy: 0.8128\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.2820 - accuracy: 0.7734 - val_loss: 557.5193 - val_accuracy: 0.8100\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.9380 - accuracy: 0.7731 - val_loss: 557.4792 - val_accuracy: 0.8117\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.6273 - accuracy: 0.7757 - val_loss: 556.2332 - val_accuracy: 0.8116\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.1098 - accuracy: 0.7749 - val_loss: 557.1377 - val_accuracy: 0.8086\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.0804 - accuracy: 0.7736 - val_loss: 557.2936 - val_accuracy: 0.8116\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.4963 - accuracy: 0.7748 - val_loss: 558.4515 - val_accuracy: 0.8114\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.1619 - accuracy: 0.7774 - val_loss: 556.8232 - val_accuracy: 0.8137\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.2098 - accuracy: 0.7756 - val_loss: 557.2742 - val_accuracy: 0.8121\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.6077 - accuracy: 0.7739 - val_loss: 557.0886 - val_accuracy: 0.8129\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.0742 - accuracy: 0.7738 - val_loss: 557.1801 - val_accuracy: 0.8080\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.6714 - accuracy: 0.7738 - val_loss: 558.4972 - val_accuracy: 0.8098\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.3947 - accuracy: 0.7748 - val_loss: 557.7216 - val_accuracy: 0.8127\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.4429 - accuracy: 0.7733 - val_loss: 557.8889 - val_accuracy: 0.8155\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.9268 - accuracy: 0.7767 - val_loss: 558.8301 - val_accuracy: 0.8084\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 725.0571 - accuracy: 0.7745 - val_loss: 556.6778 - val_accuracy: 0.8129\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.4042 - accuracy: 0.7746 - val_loss: 558.1547 - val_accuracy: 0.8101\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.0366 - accuracy: 0.7725 - val_loss: 557.9573 - val_accuracy: 0.8093\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.9273 - accuracy: 0.7755 - val_loss: 563.5393 - val_accuracy: 0.8062\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.7849 - accuracy: 0.7741 - val_loss: 556.3257 - val_accuracy: 0.8074\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.6870 - accuracy: 0.7744 - val_loss: 556.6521 - val_accuracy: 0.8143\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.5346 - accuracy: 0.7752 - val_loss: 560.0590 - val_accuracy: 0.8135\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.2278 - accuracy: 0.7757 - val_loss: 558.7751 - val_accuracy: 0.8061\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.4841 - accuracy: 0.7720 - val_loss: 558.5703 - val_accuracy: 0.8108\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.6437 - accuracy: 0.7760 - val_loss: 558.3861 - val_accuracy: 0.8099\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.8148 - accuracy: 0.7764 - val_loss: 557.3964 - val_accuracy: 0.8123\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.8370 - accuracy: 0.7750 - val_loss: 557.8722 - val_accuracy: 0.8151\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.3455 - accuracy: 0.7749 - val_loss: 558.4926 - val_accuracy: 0.8121\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.7505 - accuracy: 0.7748 - val_loss: 557.4027 - val_accuracy: 0.8155\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.6686 - accuracy: 0.7771 - val_loss: 558.8082 - val_accuracy: 0.8047\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.8108 - accuracy: 0.7753 - val_loss: 559.5699 - val_accuracy: 0.8121\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.1026 - accuracy: 0.7758 - val_loss: 568.8660 - val_accuracy: 0.8047\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 732.5291 - accuracy: 0.7749 - val_loss: 557.1324 - val_accuracy: 0.8090\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.5997 - accuracy: 0.7750 - val_loss: 556.7455 - val_accuracy: 0.8113\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.5666 - accuracy: 0.7774 - val_loss: 556.8468 - val_accuracy: 0.8136\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.3331 - accuracy: 0.7769 - val_loss: 559.9695 - val_accuracy: 0.8084\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.2927 - accuracy: 0.7769 - val_loss: 557.9682 - val_accuracy: 0.8137\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.9145 - accuracy: 0.7757 - val_loss: 556.7258 - val_accuracy: 0.8091\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.1741 - accuracy: 0.7761 - val_loss: 557.5947 - val_accuracy: 0.8122\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.1473 - accuracy: 0.7765 - val_loss: 556.3375 - val_accuracy: 0.8127\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.0967 - accuracy: 0.7760 - val_loss: 556.1190 - val_accuracy: 0.8097\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.6384 - accuracy: 0.7770 - val_loss: 556.0692 - val_accuracy: 0.8111\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.2802 - accuracy: 0.7757 - val_loss: 557.3011 - val_accuracy: 0.8104\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.7419 - accuracy: 0.7768 - val_loss: 560.1965 - val_accuracy: 0.8098\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.8687 - accuracy: 0.7761 - val_loss: 556.2637 - val_accuracy: 0.8133\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 724.3808 - accuracy: 0.7777 - val_loss: 556.4580 - val_accuracy: 0.8077\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.0350 - accuracy: 0.7760 - val_loss: 558.8477 - val_accuracy: 0.8142\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.9042 - accuracy: 0.7748 - val_loss: 566.5958 - val_accuracy: 0.8113\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.7560 - accuracy: 0.7755 - val_loss: 557.0774 - val_accuracy: 0.8051\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.0616 - accuracy: 0.7744 - val_loss: 557.6785 - val_accuracy: 0.8118\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.6782 - accuracy: 0.7755 - val_loss: 556.3590 - val_accuracy: 0.8103\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.8831 - accuracy: 0.7752 - val_loss: 560.2491 - val_accuracy: 0.8140\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.5192 - accuracy: 0.7770 - val_loss: 559.0959 - val_accuracy: 0.8111\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.6704 - accuracy: 0.7756 - val_loss: 557.2540 - val_accuracy: 0.8094\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.3010 - accuracy: 0.7760 - val_loss: 565.9033 - val_accuracy: 0.8112\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.1563 - accuracy: 0.7732 - val_loss: 570.1185 - val_accuracy: 0.8106\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.8079 - accuracy: 0.7746 - val_loss: 561.3464 - val_accuracy: 0.8127\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.0582 - accuracy: 0.7738 - val_loss: 563.3350 - val_accuracy: 0.8074\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.0764 - accuracy: 0.7741 - val_loss: 562.2814 - val_accuracy: 0.8135\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.1924 - accuracy: 0.7764 - val_loss: 557.5377 - val_accuracy: 0.8096\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.9473 - accuracy: 0.7731 - val_loss: 558.3992 - val_accuracy: 0.8087\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.5453 - accuracy: 0.7756 - val_loss: 557.1673 - val_accuracy: 0.8160\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.6249 - accuracy: 0.7760 - val_loss: 556.5264 - val_accuracy: 0.8164\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.5367 - accuracy: 0.7763 - val_loss: 561.1376 - val_accuracy: 0.8123\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.6409 - accuracy: 0.7751 - val_loss: 558.5829 - val_accuracy: 0.8126\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.4769 - accuracy: 0.7742 - val_loss: 559.1255 - val_accuracy: 0.8081\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.3538 - accuracy: 0.7740 - val_loss: 556.3583 - val_accuracy: 0.8119\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.6589 - accuracy: 0.7752 - val_loss: 564.1478 - val_accuracy: 0.8104\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.3544 - accuracy: 0.7743 - val_loss: 557.5151 - val_accuracy: 0.8148\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.6509 - accuracy: 0.7741 - val_loss: 568.8955 - val_accuracy: 0.8137\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 753.7003 - accuracy: 0.7732 - val_loss: 571.7605 - val_accuracy: 0.8125\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 736.0198 - accuracy: 0.7762 - val_loss: 560.9514 - val_accuracy: 0.8100\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.7078 - accuracy: 0.7756 - val_loss: 560.2179 - val_accuracy: 0.8070\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.5468 - accuracy: 0.7780 - val_loss: 555.8109 - val_accuracy: 0.8169\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.4509 - accuracy: 0.7770 - val_loss: 556.4628 - val_accuracy: 0.8067\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.6782 - accuracy: 0.7780 - val_loss: 556.3002 - val_accuracy: 0.8134\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.7802 - accuracy: 0.7777 - val_loss: 555.9581 - val_accuracy: 0.8140\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.4957 - accuracy: 0.7778 - val_loss: 554.9712 - val_accuracy: 0.8159\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.9229 - accuracy: 0.7778 - val_loss: 560.1665 - val_accuracy: 0.8163\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.5674 - accuracy: 0.7789 - val_loss: 556.7767 - val_accuracy: 0.8126\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.0893 - accuracy: 0.7767 - val_loss: 556.4003 - val_accuracy: 0.8124\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.3771 - accuracy: 0.7756 - val_loss: 555.8733 - val_accuracy: 0.8142\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.4434 - accuracy: 0.7763 - val_loss: 554.9612 - val_accuracy: 0.8135\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.6326 - accuracy: 0.7774 - val_loss: 554.8609 - val_accuracy: 0.8132\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.3088 - accuracy: 0.7770 - val_loss: 555.5682 - val_accuracy: 0.8135\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.7155 - accuracy: 0.7780 - val_loss: 557.9166 - val_accuracy: 0.8149\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.5452 - accuracy: 0.7712 - val_loss: 560.5773 - val_accuracy: 0.8155\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.6224 - accuracy: 0.7761 - val_loss: 564.4100 - val_accuracy: 0.8148\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.7823 - accuracy: 0.7778 - val_loss: 555.7777 - val_accuracy: 0.8104\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.3506 - accuracy: 0.7756 - val_loss: 556.2039 - val_accuracy: 0.8107\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.0250 - accuracy: 0.7765 - val_loss: 555.7796 - val_accuracy: 0.8080\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.8638 - accuracy: 0.7753 - val_loss: 555.9605 - val_accuracy: 0.8165\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.8260 - accuracy: 0.7779 - val_loss: 555.3434 - val_accuracy: 0.8163\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.0167 - accuracy: 0.7754 - val_loss: 556.0343 - val_accuracy: 0.8100\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.2525 - accuracy: 0.7779 - val_loss: 555.7120 - val_accuracy: 0.8127\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.8931 - accuracy: 0.7768 - val_loss: 554.9954 - val_accuracy: 0.8140\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.0381 - accuracy: 0.7788 - val_loss: 555.0088 - val_accuracy: 0.8080\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.5146 - accuracy: 0.7789 - val_loss: 557.5620 - val_accuracy: 0.8105\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.6679 - accuracy: 0.7762 - val_loss: 556.4860 - val_accuracy: 0.8150\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.1560 - accuracy: 0.7771 - val_loss: 554.2220 - val_accuracy: 0.8148\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.0150 - accuracy: 0.7780 - val_loss: 558.6979 - val_accuracy: 0.8157\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.2376 - accuracy: 0.7746 - val_loss: 579.7772 - val_accuracy: 0.8076\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.1768 - accuracy: 0.7727 - val_loss: 575.9175 - val_accuracy: 0.8105\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 735.3792 - accuracy: 0.7742 - val_loss: 566.4515 - val_accuracy: 0.8059\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.9315 - accuracy: 0.7750 - val_loss: 562.9784 - val_accuracy: 0.8183\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.9328 - accuracy: 0.7752 - val_loss: 562.8733 - val_accuracy: 0.8162\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.4221 - accuracy: 0.7775 - val_loss: 568.9998 - val_accuracy: 0.8122\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 729.6273 - accuracy: 0.7769 - val_loss: 557.8527 - val_accuracy: 0.8078\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.1935 - accuracy: 0.7775 - val_loss: 555.2609 - val_accuracy: 0.8140\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.9158 - accuracy: 0.7729 - val_loss: 557.7950 - val_accuracy: 0.8126\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.7294 - accuracy: 0.7754 - val_loss: 556.1715 - val_accuracy: 0.8119\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.6512 - accuracy: 0.7766 - val_loss: 561.0820 - val_accuracy: 0.8156\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.4014 - accuracy: 0.7760 - val_loss: 557.1557 - val_accuracy: 0.8112\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.2199 - accuracy: 0.7762 - val_loss: 557.5752 - val_accuracy: 0.8113\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.7418 - accuracy: 0.7784 - val_loss: 562.3187 - val_accuracy: 0.8100\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.3499 - accuracy: 0.7767 - val_loss: 556.9048 - val_accuracy: 0.8112\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.3225 - accuracy: 0.7779 - val_loss: 554.6378 - val_accuracy: 0.8155\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.7422 - accuracy: 0.7781 - val_loss: 556.0020 - val_accuracy: 0.8158\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.1638 - accuracy: 0.7791 - val_loss: 555.2140 - val_accuracy: 0.8126\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.2542 - accuracy: 0.7784 - val_loss: 555.4792 - val_accuracy: 0.8125\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.9254 - accuracy: 0.7769 - val_loss: 556.8094 - val_accuracy: 0.8133\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.1383 - accuracy: 0.7773 - val_loss: 554.6309 - val_accuracy: 0.8139\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.5740 - accuracy: 0.7764 - val_loss: 553.9229 - val_accuracy: 0.8138\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.7351 - accuracy: 0.7772 - val_loss: 557.7494 - val_accuracy: 0.8125\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.7103 - accuracy: 0.7781 - val_loss: 555.7491 - val_accuracy: 0.8131\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.8898 - accuracy: 0.7789 - val_loss: 559.9744 - val_accuracy: 0.8135\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.5551 - accuracy: 0.7792 - val_loss: 554.4437 - val_accuracy: 0.8142\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.7827 - accuracy: 0.7788 - val_loss: 554.6006 - val_accuracy: 0.8111\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 720.5696 - accuracy: 0.7789 - val_loss: 557.9512 - val_accuracy: 0.8149\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.2260 - accuracy: 0.7770 - val_loss: 556.7986 - val_accuracy: 0.8127\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.8107 - accuracy: 0.7781 - val_loss: 555.6077 - val_accuracy: 0.8107\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.0802 - accuracy: 0.7774 - val_loss: 555.4021 - val_accuracy: 0.8156\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.9250 - accuracy: 0.7794 - val_loss: 555.5208 - val_accuracy: 0.8109\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.9682 - accuracy: 0.7788 - val_loss: 556.0953 - val_accuracy: 0.8129\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.6540 - accuracy: 0.7782 - val_loss: 555.0639 - val_accuracy: 0.8129\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.6048 - accuracy: 0.7778 - val_loss: 559.1873 - val_accuracy: 0.8115\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.6547 - accuracy: 0.7768 - val_loss: 556.5897 - val_accuracy: 0.8114\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.4794 - accuracy: 0.7772 - val_loss: 555.7156 - val_accuracy: 0.8145\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.1656 - accuracy: 0.7782 - val_loss: 555.0617 - val_accuracy: 0.8132\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.5835 - accuracy: 0.7766 - val_loss: 571.2352 - val_accuracy: 0.8091\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.0552 - accuracy: 0.7776 - val_loss: 556.2949 - val_accuracy: 0.8137\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.8865 - accuracy: 0.7767 - val_loss: 556.0211 - val_accuracy: 0.8128\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.5759 - accuracy: 0.7787 - val_loss: 555.4166 - val_accuracy: 0.8144\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.6216 - accuracy: 0.7785 - val_loss: 561.0472 - val_accuracy: 0.8121\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.6929 - accuracy: 0.7768 - val_loss: 555.7218 - val_accuracy: 0.8092\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.7357 - accuracy: 0.7768 - val_loss: 555.9626 - val_accuracy: 0.8054\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.9252 - accuracy: 0.7764 - val_loss: 555.8508 - val_accuracy: 0.8138\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.1300 - accuracy: 0.7780 - val_loss: 554.9713 - val_accuracy: 0.8139\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.7777 - accuracy: 0.7768 - val_loss: 555.4307 - val_accuracy: 0.8135\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.2676 - accuracy: 0.7782 - val_loss: 553.9623 - val_accuracy: 0.8156\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.5660 - accuracy: 0.7790 - val_loss: 555.7169 - val_accuracy: 0.8120\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.2140 - accuracy: 0.7775 - val_loss: 558.1412 - val_accuracy: 0.8125\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.6888 - accuracy: 0.7799 - val_loss: 556.5295 - val_accuracy: 0.8153\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.7203 - accuracy: 0.7803 - val_loss: 557.3021 - val_accuracy: 0.8124\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.6012 - accuracy: 0.7779 - val_loss: 563.2047 - val_accuracy: 0.8077\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.5031 - accuracy: 0.7788 - val_loss: 554.1764 - val_accuracy: 0.8108\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.8623 - accuracy: 0.7776 - val_loss: 557.0265 - val_accuracy: 0.8124\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.2922 - accuracy: 0.7778 - val_loss: 554.6891 - val_accuracy: 0.8147\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.6945 - accuracy: 0.7782 - val_loss: 555.6763 - val_accuracy: 0.8088\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.8926 - accuracy: 0.7755 - val_loss: 561.5991 - val_accuracy: 0.8131\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.5182 - accuracy: 0.7771 - val_loss: 557.5202 - val_accuracy: 0.8076\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.9744 - accuracy: 0.7794 - val_loss: 554.2932 - val_accuracy: 0.8123\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.5659 - accuracy: 0.7763 - val_loss: 561.6943 - val_accuracy: 0.8100\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.9068 - accuracy: 0.7787 - val_loss: 563.6666 - val_accuracy: 0.8080\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.7969 - accuracy: 0.7781 - val_loss: 555.9068 - val_accuracy: 0.8137\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.8963 - accuracy: 0.7792 - val_loss: 553.8508 - val_accuracy: 0.8138\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.9177 - accuracy: 0.7791 - val_loss: 553.1902 - val_accuracy: 0.8143\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.2906 - accuracy: 0.7785 - val_loss: 565.6000 - val_accuracy: 0.8130\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.0496 - accuracy: 0.7774 - val_loss: 574.5043 - val_accuracy: 0.8122\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 731.2329 - accuracy: 0.7764 - val_loss: 571.5302 - val_accuracy: 0.8101\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.5406 - accuracy: 0.7770 - val_loss: 555.3605 - val_accuracy: 0.8096\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.9167 - accuracy: 0.7784 - val_loss: 553.8851 - val_accuracy: 0.8170\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.8722 - accuracy: 0.7792 - val_loss: 554.4511 - val_accuracy: 0.8140\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.0845 - accuracy: 0.7795 - val_loss: 558.0688 - val_accuracy: 0.8132\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.8560 - accuracy: 0.7778 - val_loss: 557.3041 - val_accuracy: 0.8139\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.7163 - accuracy: 0.7791 - val_loss: 560.1710 - val_accuracy: 0.8126\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.6394 - accuracy: 0.7787 - val_loss: 560.2317 - val_accuracy: 0.8166\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.5017 - accuracy: 0.7768 - val_loss: 555.0197 - val_accuracy: 0.8109\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.3843 - accuracy: 0.7804 - val_loss: 555.2567 - val_accuracy: 0.8151\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.2688 - accuracy: 0.7779 - val_loss: 554.4484 - val_accuracy: 0.8105\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.9896 - accuracy: 0.7772 - val_loss: 554.1298 - val_accuracy: 0.8165\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.6816 - accuracy: 0.7798 - val_loss: 554.1267 - val_accuracy: 0.8126\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.4648 - accuracy: 0.7788 - val_loss: 554.6514 - val_accuracy: 0.8133\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.1121 - accuracy: 0.7805 - val_loss: 552.2888 - val_accuracy: 0.8122\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.4077 - accuracy: 0.7785 - val_loss: 553.9379 - val_accuracy: 0.8134\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.3156 - accuracy: 0.7785 - val_loss: 555.1529 - val_accuracy: 0.8104\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.7366 - accuracy: 0.7772 - val_loss: 556.1548 - val_accuracy: 0.8119\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.8224 - accuracy: 0.7790 - val_loss: 554.8900 - val_accuracy: 0.8140\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.5469 - accuracy: 0.7747 - val_loss: 557.7562 - val_accuracy: 0.8142\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.9543 - accuracy: 0.7765 - val_loss: 554.9689 - val_accuracy: 0.8143\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.1981 - accuracy: 0.7767 - val_loss: 556.9703 - val_accuracy: 0.8160\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.8032 - accuracy: 0.7787 - val_loss: 554.9068 - val_accuracy: 0.8131\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.9803 - accuracy: 0.7776 - val_loss: 555.4766 - val_accuracy: 0.8147\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.2468 - accuracy: 0.7784 - val_loss: 553.3661 - val_accuracy: 0.8137\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.3460 - accuracy: 0.7801 - val_loss: 561.2729 - val_accuracy: 0.8112\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.8333 - accuracy: 0.7774 - val_loss: 553.5463 - val_accuracy: 0.8125\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.7639 - accuracy: 0.7771 - val_loss: 556.4514 - val_accuracy: 0.8133\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.2880 - accuracy: 0.7792 - val_loss: 556.0057 - val_accuracy: 0.8139\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.8253 - accuracy: 0.7778 - val_loss: 553.6155 - val_accuracy: 0.8102\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.8564 - accuracy: 0.7786 - val_loss: 552.7706 - val_accuracy: 0.8139\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.2461 - accuracy: 0.7777 - val_loss: 552.7632 - val_accuracy: 0.8122\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.0222 - accuracy: 0.7798 - val_loss: 554.3808 - val_accuracy: 0.8129\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.8093 - accuracy: 0.7786 - val_loss: 555.1910 - val_accuracy: 0.8142\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.6341 - accuracy: 0.7783 - val_loss: 554.8029 - val_accuracy: 0.8106\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.0058 - accuracy: 0.7779 - val_loss: 553.3252 - val_accuracy: 0.8149\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 724.4945 - accuracy: 0.7778 - val_loss: 554.1429 - val_accuracy: 0.8137\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 719.8895 - accuracy: 0.7787 - val_loss: 553.7292 - val_accuracy: 0.8114\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.9622 - accuracy: 0.7785 - val_loss: 553.8657 - val_accuracy: 0.8152\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.4819 - accuracy: 0.7780 - val_loss: 553.3549 - val_accuracy: 0.8135\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.8051 - accuracy: 0.7783 - val_loss: 553.1245 - val_accuracy: 0.8120\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.2476 - accuracy: 0.7797 - val_loss: 554.3356 - val_accuracy: 0.8117\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.1696 - accuracy: 0.7775 - val_loss: 554.4807 - val_accuracy: 0.8129\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.0765 - accuracy: 0.7794 - val_loss: 554.6729 - val_accuracy: 0.8135\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.6877 - accuracy: 0.7780 - val_loss: 555.1406 - val_accuracy: 0.8108\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.9727 - accuracy: 0.7764 - val_loss: 555.6346 - val_accuracy: 0.8157\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.2062 - accuracy: 0.7765 - val_loss: 554.8234 - val_accuracy: 0.8145\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.5092 - accuracy: 0.7794 - val_loss: 555.1016 - val_accuracy: 0.8140\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.6614 - accuracy: 0.7784 - val_loss: 553.9212 - val_accuracy: 0.8128\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 718.4507 - accuracy: 0.7794 - val_loss: 552.2255 - val_accuracy: 0.8117\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.3454 - accuracy: 0.7765 - val_loss: 552.8114 - val_accuracy: 0.8114\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.1276 - accuracy: 0.7792 - val_loss: 560.7765 - val_accuracy: 0.8089\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.8546 - accuracy: 0.7792 - val_loss: 555.3976 - val_accuracy: 0.8114\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.6559 - accuracy: 0.7795 - val_loss: 554.8502 - val_accuracy: 0.8149\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.1022 - accuracy: 0.7800 - val_loss: 558.9290 - val_accuracy: 0.8108\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.3932 - accuracy: 0.7791 - val_loss: 556.5273 - val_accuracy: 0.8140\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.0978 - accuracy: 0.7798 - val_loss: 552.9781 - val_accuracy: 0.8120\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.4841 - accuracy: 0.7798 - val_loss: 554.3773 - val_accuracy: 0.8123\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.8253 - accuracy: 0.7794 - val_loss: 553.9730 - val_accuracy: 0.8143\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.9756 - accuracy: 0.7793 - val_loss: 554.0266 - val_accuracy: 0.8130\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.9771 - accuracy: 0.7783 - val_loss: 552.9941 - val_accuracy: 0.8117\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.6745 - accuracy: 0.7776 - val_loss: 559.4262 - val_accuracy: 0.8151\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.8486 - accuracy: 0.7804 - val_loss: 554.5964 - val_accuracy: 0.8139\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.1354 - accuracy: 0.7786 - val_loss: 553.9896 - val_accuracy: 0.8122\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.5756 - accuracy: 0.7805 - val_loss: 558.2238 - val_accuracy: 0.8121\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.2689 - accuracy: 0.7794 - val_loss: 556.9957 - val_accuracy: 0.8136\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.0214 - accuracy: 0.7798 - val_loss: 556.0632 - val_accuracy: 0.8154\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.3984 - accuracy: 0.7784 - val_loss: 569.2693 - val_accuracy: 0.8106\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.9894 - accuracy: 0.7800 - val_loss: 553.3802 - val_accuracy: 0.8136\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.4305 - accuracy: 0.7784 - val_loss: 556.2366 - val_accuracy: 0.8146\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.0085 - accuracy: 0.7777 - val_loss: 555.7115 - val_accuracy: 0.8172\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.8402 - accuracy: 0.7783 - val_loss: 553.9116 - val_accuracy: 0.8135\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.8749 - accuracy: 0.7774 - val_loss: 553.8842 - val_accuracy: 0.8146\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.2241 - accuracy: 0.7788 - val_loss: 559.3772 - val_accuracy: 0.8158\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.2765 - accuracy: 0.7782 - val_loss: 555.5932 - val_accuracy: 0.8156\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.5819 - accuracy: 0.7790 - val_loss: 552.3713 - val_accuracy: 0.8136\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.1225 - accuracy: 0.7796 - val_loss: 556.5062 - val_accuracy: 0.8139\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.7761 - accuracy: 0.7759 - val_loss: 555.9389 - val_accuracy: 0.8131\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.6132 - accuracy: 0.7813 - val_loss: 554.1306 - val_accuracy: 0.8134\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.5055 - accuracy: 0.7793 - val_loss: 561.9591 - val_accuracy: 0.8123\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.9051 - accuracy: 0.7756 - val_loss: 553.0020 - val_accuracy: 0.8118\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.8016 - accuracy: 0.7804 - val_loss: 553.6727 - val_accuracy: 0.8137\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.1930 - accuracy: 0.7785 - val_loss: 552.0372 - val_accuracy: 0.8140\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 718.2043 - accuracy: 0.7805 - val_loss: 554.3945 - val_accuracy: 0.8123\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.0871 - accuracy: 0.7784 - val_loss: 552.4409 - val_accuracy: 0.8140\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.0179 - accuracy: 0.7798 - val_loss: 552.3322 - val_accuracy: 0.8154\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.8822 - accuracy: 0.7786 - val_loss: 556.7722 - val_accuracy: 0.8149\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.8693 - accuracy: 0.7783 - val_loss: 558.1402 - val_accuracy: 0.8128\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 725.1604 - accuracy: 0.7785 - val_loss: 553.2765 - val_accuracy: 0.8130\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.3502 - accuracy: 0.7802 - val_loss: 562.8343 - val_accuracy: 0.8122\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.4437 - accuracy: 0.7787 - val_loss: 554.6331 - val_accuracy: 0.8108\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.5035 - accuracy: 0.7797 - val_loss: 555.1027 - val_accuracy: 0.8139\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.6263 - accuracy: 0.7759 - val_loss: 554.8641 - val_accuracy: 0.8145\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.0068 - accuracy: 0.7801 - val_loss: 551.7332 - val_accuracy: 0.8136\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.8358 - accuracy: 0.7793 - val_loss: 552.1660 - val_accuracy: 0.8129\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.5824 - accuracy: 0.7788 - val_loss: 559.7203 - val_accuracy: 0.8170\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.1956 - accuracy: 0.7786 - val_loss: 553.9703 - val_accuracy: 0.8110\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.7280 - accuracy: 0.7796 - val_loss: 559.7958 - val_accuracy: 0.8152\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.8077 - accuracy: 0.7804 - val_loss: 552.1361 - val_accuracy: 0.8133\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.1032 - accuracy: 0.7793 - val_loss: 553.2131 - val_accuracy: 0.8130\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.7810 - accuracy: 0.7803 - val_loss: 567.8380 - val_accuracy: 0.8150\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.0872 - accuracy: 0.7782 - val_loss: 568.6964 - val_accuracy: 0.8111\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.4043 - accuracy: 0.7782 - val_loss: 557.0777 - val_accuracy: 0.8098\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 720.8203 - accuracy: 0.7790 - val_loss: 554.9084 - val_accuracy: 0.8133\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.9141 - accuracy: 0.7784 - val_loss: 553.7864 - val_accuracy: 0.8139\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.2553 - accuracy: 0.7803 - val_loss: 552.2538 - val_accuracy: 0.8178\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.6038 - accuracy: 0.7795 - val_loss: 553.6254 - val_accuracy: 0.8155\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.2420 - accuracy: 0.7810 - val_loss: 554.8715 - val_accuracy: 0.8167\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.8730 - accuracy: 0.7791 - val_loss: 560.8384 - val_accuracy: 0.8148\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.8826 - accuracy: 0.7773 - val_loss: 553.1508 - val_accuracy: 0.8168\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.6487 - accuracy: 0.7780 - val_loss: 552.5262 - val_accuracy: 0.8134\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.7747 - accuracy: 0.7807 - val_loss: 552.6997 - val_accuracy: 0.8129\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.3207 - accuracy: 0.7793 - val_loss: 551.9418 - val_accuracy: 0.8141\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.9904 - accuracy: 0.7801 - val_loss: 567.1324 - val_accuracy: 0.8170\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.7379 - accuracy: 0.7778 - val_loss: 569.2642 - val_accuracy: 0.8125\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 739.7895 - accuracy: 0.7787 - val_loss: 569.9329 - val_accuracy: 0.8107\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.8865 - accuracy: 0.7784 - val_loss: 563.8267 - val_accuracy: 0.8167\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.3983 - accuracy: 0.7798 - val_loss: 556.8376 - val_accuracy: 0.8152\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.6979 - accuracy: 0.7769 - val_loss: 555.0440 - val_accuracy: 0.8158\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.5175 - accuracy: 0.7803 - val_loss: 556.6729 - val_accuracy: 0.8143\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.0195 - accuracy: 0.7792 - val_loss: 551.3540 - val_accuracy: 0.8155\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.8946 - accuracy: 0.7813 - val_loss: 554.5079 - val_accuracy: 0.8159\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.8163 - accuracy: 0.7802 - val_loss: 556.3515 - val_accuracy: 0.8154\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.4243 - accuracy: 0.7808 - val_loss: 554.8497 - val_accuracy: 0.8136\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 717.8596 - accuracy: 0.7789 - val_loss: 551.3734 - val_accuracy: 0.8135\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.8629 - accuracy: 0.7791 - val_loss: 551.3879 - val_accuracy: 0.8133\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.7161 - accuracy: 0.7807 - val_loss: 551.7059 - val_accuracy: 0.8155\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.9200 - accuracy: 0.7793 - val_loss: 554.1320 - val_accuracy: 0.8157\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.2721 - accuracy: 0.7795 - val_loss: 553.9769 - val_accuracy: 0.8132\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.8082 - accuracy: 0.7798 - val_loss: 551.3474 - val_accuracy: 0.8151\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.4677 - accuracy: 0.7788 - val_loss: 552.4672 - val_accuracy: 0.8167\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.1048 - accuracy: 0.7784 - val_loss: 551.9403 - val_accuracy: 0.8147\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.8456 - accuracy: 0.7807 - val_loss: 552.4107 - val_accuracy: 0.8114\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.8348 - accuracy: 0.7796 - val_loss: 553.1706 - val_accuracy: 0.8132\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.1925 - accuracy: 0.7792 - val_loss: 553.2608 - val_accuracy: 0.8145\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.4868 - accuracy: 0.7785 - val_loss: 552.8137 - val_accuracy: 0.8123\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.4463 - accuracy: 0.7782 - val_loss: 563.7885 - val_accuracy: 0.8171\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.7218 - accuracy: 0.7805 - val_loss: 553.0497 - val_accuracy: 0.8123\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.2197 - accuracy: 0.7781 - val_loss: 559.4548 - val_accuracy: 0.8174\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.4755 - accuracy: 0.7799 - val_loss: 554.1696 - val_accuracy: 0.8125\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.0525 - accuracy: 0.7784 - val_loss: 558.5737 - val_accuracy: 0.8125\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.2892 - accuracy: 0.7796 - val_loss: 563.5164 - val_accuracy: 0.8158\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.0790 - accuracy: 0.7794 - val_loss: 557.5399 - val_accuracy: 0.8119\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.7693 - accuracy: 0.7802 - val_loss: 558.1398 - val_accuracy: 0.8135\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.9261 - accuracy: 0.7779 - val_loss: 551.9903 - val_accuracy: 0.8106\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.3458 - accuracy: 0.7816 - val_loss: 550.7067 - val_accuracy: 0.8146\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.5032 - accuracy: 0.7789 - val_loss: 550.8892 - val_accuracy: 0.8128\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.4490 - accuracy: 0.7778 - val_loss: 551.6298 - val_accuracy: 0.8146\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.7809 - accuracy: 0.7807 - val_loss: 554.3638 - val_accuracy: 0.8126\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.4501 - accuracy: 0.7791 - val_loss: 555.5888 - val_accuracy: 0.8126\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.6238 - accuracy: 0.7779 - val_loss: 554.4865 - val_accuracy: 0.8129\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.6045 - accuracy: 0.7816 - val_loss: 550.9279 - val_accuracy: 0.8125\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.2817 - accuracy: 0.7799 - val_loss: 551.3141 - val_accuracy: 0.8160\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.1362 - accuracy: 0.7773 - val_loss: 555.3976 - val_accuracy: 0.8133\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 717.8804 - accuracy: 0.7787 - val_loss: 555.0552 - val_accuracy: 0.8156\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.7463 - accuracy: 0.7787 - val_loss: 557.0914 - val_accuracy: 0.8171\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.8897 - accuracy: 0.7787 - val_loss: 558.1505 - val_accuracy: 0.8135\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 724.7029 - accuracy: 0.7801 - val_loss: 564.1469 - val_accuracy: 0.8140\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.5317 - accuracy: 0.7767 - val_loss: 553.9281 - val_accuracy: 0.8140\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.8583 - accuracy: 0.7768 - val_loss: 552.7171 - val_accuracy: 0.8188\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 718.6300 - accuracy: 0.7784 - val_loss: 556.7382 - val_accuracy: 0.8134\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.3895 - accuracy: 0.7784 - val_loss: 552.6844 - val_accuracy: 0.8174\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.7006 - accuracy: 0.7789 - val_loss: 554.5214 - val_accuracy: 0.8154\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.7292 - accuracy: 0.7782 - val_loss: 551.9470 - val_accuracy: 0.8128\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.9362 - accuracy: 0.7777 - val_loss: 555.8873 - val_accuracy: 0.8140\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.9807 - accuracy: 0.7801 - val_loss: 552.3081 - val_accuracy: 0.8155\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.0391 - accuracy: 0.7795 - val_loss: 553.3117 - val_accuracy: 0.8115\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.8587 - accuracy: 0.7789 - val_loss: 550.4024 - val_accuracy: 0.8176\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.2302 - accuracy: 0.7797 - val_loss: 551.7039 - val_accuracy: 0.8164\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.5179 - accuracy: 0.7799 - val_loss: 550.5234 - val_accuracy: 0.8147\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.0195 - accuracy: 0.7790 - val_loss: 550.1412 - val_accuracy: 0.8147\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.8129 - accuracy: 0.7811 - val_loss: 553.8711 - val_accuracy: 0.8145\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.4485 - accuracy: 0.7796 - val_loss: 553.9277 - val_accuracy: 0.8127\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.8857 - accuracy: 0.7790 - val_loss: 556.2758 - val_accuracy: 0.8144\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.8095 - accuracy: 0.7781 - val_loss: 552.8492 - val_accuracy: 0.8143\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.0363 - accuracy: 0.7783 - val_loss: 552.1966 - val_accuracy: 0.8139\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.3671 - accuracy: 0.7796 - val_loss: 551.5816 - val_accuracy: 0.8170\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.2332 - accuracy: 0.7787 - val_loss: 550.5616 - val_accuracy: 0.8133\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.2604 - accuracy: 0.7761 - val_loss: 551.7288 - val_accuracy: 0.8160\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.3486 - accuracy: 0.7813 - val_loss: 558.1992 - val_accuracy: 0.8133\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.3617 - accuracy: 0.7791 - val_loss: 551.0639 - val_accuracy: 0.8122\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.2990 - accuracy: 0.7787 - val_loss: 550.3470 - val_accuracy: 0.8153\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.7137 - accuracy: 0.7794 - val_loss: 563.7338 - val_accuracy: 0.8123\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.6398 - accuracy: 0.7800 - val_loss: 552.2651 - val_accuracy: 0.8129\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.2979 - accuracy: 0.7784 - val_loss: 552.5436 - val_accuracy: 0.8158\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.7269 - accuracy: 0.7790 - val_loss: 553.7286 - val_accuracy: 0.8151\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.8820 - accuracy: 0.7793 - val_loss: 558.8226 - val_accuracy: 0.8137\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.9084 - accuracy: 0.7765 - val_loss: 553.3856 - val_accuracy: 0.8156\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.6497 - accuracy: 0.7806 - val_loss: 554.0147 - val_accuracy: 0.8122\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.9952 - accuracy: 0.7785 - val_loss: 553.1022 - val_accuracy: 0.8144\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.7029 - accuracy: 0.7804 - val_loss: 552.9463 - val_accuracy: 0.8151\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.3036 - accuracy: 0.7814 - val_loss: 555.1072 - val_accuracy: 0.8150\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.4138 - accuracy: 0.7788 - val_loss: 550.8785 - val_accuracy: 0.8143\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.1417 - accuracy: 0.7804 - val_loss: 552.0540 - val_accuracy: 0.8149\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.6702 - accuracy: 0.7804 - val_loss: 553.9564 - val_accuracy: 0.8144\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.8025 - accuracy: 0.7803 - val_loss: 551.1201 - val_accuracy: 0.8147\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.0476 - accuracy: 0.7798 - val_loss: 550.4219 - val_accuracy: 0.8166\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.4341 - accuracy: 0.7784 - val_loss: 554.5134 - val_accuracy: 0.8160\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.6191 - accuracy: 0.7799 - val_loss: 551.2890 - val_accuracy: 0.8157\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.7458 - accuracy: 0.7798 - val_loss: 550.8837 - val_accuracy: 0.8173\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.2615 - accuracy: 0.7788 - val_loss: 553.9089 - val_accuracy: 0.8161\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.0007 - accuracy: 0.7812 - val_loss: 551.7530 - val_accuracy: 0.8150\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.2564 - accuracy: 0.7799 - val_loss: 551.3270 - val_accuracy: 0.8120\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.4929 - accuracy: 0.7805 - val_loss: 550.7075 - val_accuracy: 0.8166\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.9653 - accuracy: 0.7790 - val_loss: 551.1314 - val_accuracy: 0.8146\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.8638 - accuracy: 0.7785 - val_loss: 552.6851 - val_accuracy: 0.8142\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.6023 - accuracy: 0.7779 - val_loss: 552.0783 - val_accuracy: 0.8140\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.3557 - accuracy: 0.7778 - val_loss: 557.1429 - val_accuracy: 0.8146\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.8431 - accuracy: 0.7770 - val_loss: 551.3619 - val_accuracy: 0.8141\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.0011 - accuracy: 0.7768 - val_loss: 557.7923 - val_accuracy: 0.8157\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.1544 - accuracy: 0.7776 - val_loss: 560.2238 - val_accuracy: 0.8092\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.5933 - accuracy: 0.7790 - val_loss: 552.7838 - val_accuracy: 0.8163\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.8381 - accuracy: 0.7769 - val_loss: 553.2087 - val_accuracy: 0.8169\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 718.3506 - accuracy: 0.7795 - val_loss: 551.0128 - val_accuracy: 0.8117\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.5079 - accuracy: 0.7813 - val_loss: 550.0065 - val_accuracy: 0.8157\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 716.2682 - accuracy: 0.7788 - val_loss: 551.4182 - val_accuracy: 0.8131\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.6075 - accuracy: 0.7800 - val_loss: 549.8878 - val_accuracy: 0.8151\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.4899 - accuracy: 0.7789 - val_loss: 549.9434 - val_accuracy: 0.8141\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.8558 - accuracy: 0.7791 - val_loss: 554.3666 - val_accuracy: 0.8150\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.3981 - accuracy: 0.7769 - val_loss: 553.8155 - val_accuracy: 0.8165\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 723.7712 - accuracy: 0.7799 - val_loss: 557.8108 - val_accuracy: 0.8171\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.8143 - accuracy: 0.7781 - val_loss: 558.9669 - val_accuracy: 0.8162\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.9672 - accuracy: 0.7773 - val_loss: 556.7505 - val_accuracy: 0.8150\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 716.5999 - accuracy: 0.7789 - val_loss: 550.5995 - val_accuracy: 0.8142\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.4217 - accuracy: 0.7796 - val_loss: 551.4581 - val_accuracy: 0.8136\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.1015 - accuracy: 0.7790 - val_loss: 551.6077 - val_accuracy: 0.8147\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "# Upsample the second input image\n",
        "upsampled = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Combine the two input images using a convolutional layer\n",
        "combined = layers.Conv2D(31, kernel_size=1, activation='relu')(upsampled)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(128, kernel_size=1, activation='relu')(combined)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "#conv2 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool1)\n",
        "#pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "#conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "#pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer = layers.Conv2D(31, kernel_size=1, activation='relu')(pool1)\n",
        "# Define the model\n",
        "modelnew = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "# Compile the model\n",
        "modelnew.compile(optimizer='adam',\n",
        "loss='mean_absolute_error',\n",
        "metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = modelnew.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "XUagbt0Zrbkb",
        "outputId": "e1ec4f6c-9b78-4ed1-b0c6-f4cbb74ae2ae"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Extract the accuracy and loss values from the history object\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the first graph in the first subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(acc, label='Training accuracy')\n",
        "plt.plot(val_acc, label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Plot the second graph in the second subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRRTzCFAr01E",
        "outputId": "45eb9695-40f4-4449-a6e4-76462c4eddc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 8505.1357 - accuracy: 0.0060 - val_loss: 5447.0801 - val_accuracy: 0.0044\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 6138.0791 - accuracy: 0.0116 - val_loss: 4114.6748 - val_accuracy: 0.0303\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 4974.9863 - accuracy: 0.0318 - val_loss: 3511.6677 - val_accuracy: 0.0897\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 4223.0000 - accuracy: 0.0640 - val_loss: 3141.6250 - val_accuracy: 0.1144\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 3598.3706 - accuracy: 0.1163 - val_loss: 2598.6692 - val_accuracy: 0.0445\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3231.6848 - accuracy: 0.1576 - val_loss: 2442.7312 - val_accuracy: 0.3598\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3020.7395 - accuracy: 0.3098 - val_loss: 2329.4277 - val_accuracy: 0.3946\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 2854.3984 - accuracy: 0.3013 - val_loss: 2220.9851 - val_accuracy: 0.1899\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 2679.2139 - accuracy: 0.2812 - val_loss: 2024.8894 - val_accuracy: 0.2331\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 2432.8359 - accuracy: 0.2849 - val_loss: 1689.3035 - val_accuracy: 0.1273\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 2128.7334 - accuracy: 0.2454 - val_loss: 1370.1697 - val_accuracy: 0.2481\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1903.7899 - accuracy: 0.3090 - val_loss: 1379.3872 - val_accuracy: 0.3689\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1794.1656 - accuracy: 0.3897 - val_loss: 1309.4706 - val_accuracy: 0.1960\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1731.5016 - accuracy: 0.3812 - val_loss: 1277.8698 - val_accuracy: 0.1937\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1699.1987 - accuracy: 0.3904 - val_loss: 1254.1257 - val_accuracy: 0.1962\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1678.3932 - accuracy: 0.3928 - val_loss: 1241.7710 - val_accuracy: 0.1979\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1662.1266 - accuracy: 0.3994 - val_loss: 1210.5308 - val_accuracy: 0.1959\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1634.2092 - accuracy: 0.3953 - val_loss: 1182.6146 - val_accuracy: 0.2134\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1616.3552 - accuracy: 0.4052 - val_loss: 1154.6467 - val_accuracy: 0.2081\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1591.3688 - accuracy: 0.4216 - val_loss: 1140.1985 - val_accuracy: 0.2212\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1579.1309 - accuracy: 0.4362 - val_loss: 1110.5609 - val_accuracy: 0.2439\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1567.9851 - accuracy: 0.4295 - val_loss: 1109.4795 - val_accuracy: 0.2225\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1572.5892 - accuracy: 0.4462 - val_loss: 1082.8439 - val_accuracy: 0.2338\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1474.5334 - accuracy: 0.4690 - val_loss: 979.2444 - val_accuracy: 0.4566\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1323.0774 - accuracy: 0.4738 - val_loss: 1007.7618 - val_accuracy: 0.2840\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1287.5702 - accuracy: 0.5202 - val_loss: 924.8734 - val_accuracy: 0.5327\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1262.3711 - accuracy: 0.6104 - val_loss: 919.0140 - val_accuracy: 0.5982\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1242.1190 - accuracy: 0.6135 - val_loss: 897.4319 - val_accuracy: 0.5971\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1231.3175 - accuracy: 0.6601 - val_loss: 898.1956 - val_accuracy: 0.6467\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1224.2521 - accuracy: 0.6577 - val_loss: 892.8328 - val_accuracy: 0.6411\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1215.3564 - accuracy: 0.6731 - val_loss: 903.4202 - val_accuracy: 0.6299\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1209.6533 - accuracy: 0.6622 - val_loss: 872.9540 - val_accuracy: 0.6614\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1204.8295 - accuracy: 0.6751 - val_loss: 887.7710 - val_accuracy: 0.6248\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1215.6268 - accuracy: 0.6677 - val_loss: 876.1892 - val_accuracy: 0.6692\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1204.1504 - accuracy: 0.6767 - val_loss: 904.1609 - val_accuracy: 0.6680\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1215.1805 - accuracy: 0.6672 - val_loss: 880.1005 - val_accuracy: 0.6286\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1202.7732 - accuracy: 0.6830 - val_loss: 820.9493 - val_accuracy: 0.6499\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1055.3387 - accuracy: 0.6870 - val_loss: 774.1340 - val_accuracy: 0.6608\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 978.7846 - accuracy: 0.6256 - val_loss: 726.6304 - val_accuracy: 0.6428\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 928.5984 - accuracy: 0.6706 - val_loss: 705.5861 - val_accuracy: 0.6702\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 904.6873 - accuracy: 0.6379 - val_loss: 691.3287 - val_accuracy: 0.6593\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 890.3941 - accuracy: 0.6575 - val_loss: 667.0490 - val_accuracy: 0.6469\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 885.6758 - accuracy: 0.6580 - val_loss: 729.3236 - val_accuracy: 0.6615\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 888.5688 - accuracy: 0.6664 - val_loss: 680.9395 - val_accuracy: 0.6527\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 875.8845 - accuracy: 0.6553 - val_loss: 667.8103 - val_accuracy: 0.6568\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 865.7221 - accuracy: 0.6606 - val_loss: 655.5133 - val_accuracy: 0.6504\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 859.7204 - accuracy: 0.6800 - val_loss: 657.6736 - val_accuracy: 0.6644\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 861.7296 - accuracy: 0.6736 - val_loss: 656.8884 - val_accuracy: 0.6521\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 859.1999 - accuracy: 0.6846 - val_loss: 670.1817 - val_accuracy: 0.6488\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 860.0709 - accuracy: 0.6769 - val_loss: 652.2849 - val_accuracy: 0.6627\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 850.1053 - accuracy: 0.6861 - val_loss: 648.1373 - val_accuracy: 0.6703\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 846.2458 - accuracy: 0.6925 - val_loss: 662.9274 - val_accuracy: 0.6821\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 852.8467 - accuracy: 0.6872 - val_loss: 651.3242 - val_accuracy: 0.6811\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 868.8179 - accuracy: 0.6938 - val_loss: 658.7368 - val_accuracy: 0.6898\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 855.2574 - accuracy: 0.6963 - val_loss: 647.8040 - val_accuracy: 0.6591\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 844.7853 - accuracy: 0.6919 - val_loss: 642.4438 - val_accuracy: 0.6746\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 840.1998 - accuracy: 0.6969 - val_loss: 640.7449 - val_accuracy: 0.6814\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 837.0428 - accuracy: 0.6995 - val_loss: 646.7604 - val_accuracy: 0.7008\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 850.0911 - accuracy: 0.7036 - val_loss: 650.7139 - val_accuracy: 0.6817\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 850.5331 - accuracy: 0.7010 - val_loss: 671.8532 - val_accuracy: 0.6957\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 873.5611 - accuracy: 0.7014 - val_loss: 637.2667 - val_accuracy: 0.6988\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 874.8845 - accuracy: 0.7010 - val_loss: 637.9356 - val_accuracy: 0.6948\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 853.3159 - accuracy: 0.7010 - val_loss: 632.0037 - val_accuracy: 0.7018\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 850.9457 - accuracy: 0.7081 - val_loss: 640.6697 - val_accuracy: 0.7150\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 839.5134 - accuracy: 0.7031 - val_loss: 633.6317 - val_accuracy: 0.7310\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 828.8812 - accuracy: 0.7070 - val_loss: 633.3420 - val_accuracy: 0.6975\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 828.2155 - accuracy: 0.7122 - val_loss: 631.3245 - val_accuracy: 0.7029\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 828.4581 - accuracy: 0.7094 - val_loss: 629.2198 - val_accuracy: 0.7194\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 824.2245 - accuracy: 0.7121 - val_loss: 627.8314 - val_accuracy: 0.7233\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 823.0333 - accuracy: 0.7088 - val_loss: 637.5701 - val_accuracy: 0.7225\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 823.6027 - accuracy: 0.7142 - val_loss: 624.3341 - val_accuracy: 0.7104\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 823.2031 - accuracy: 0.7119 - val_loss: 633.7552 - val_accuracy: 0.7220\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 825.0397 - accuracy: 0.7102 - val_loss: 625.5207 - val_accuracy: 0.7267\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 820.3940 - accuracy: 0.7161 - val_loss: 624.1245 - val_accuracy: 0.7212\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 816.1959 - accuracy: 0.7141 - val_loss: 625.3709 - val_accuracy: 0.7259\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 819.8444 - accuracy: 0.7159 - val_loss: 624.4456 - val_accuracy: 0.7343\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 816.6879 - accuracy: 0.7131 - val_loss: 630.4630 - val_accuracy: 0.7291\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 815.8032 - accuracy: 0.7171 - val_loss: 622.2435 - val_accuracy: 0.7097\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 814.8721 - accuracy: 0.7163 - val_loss: 626.8972 - val_accuracy: 0.7355\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 813.8495 - accuracy: 0.7209 - val_loss: 624.9687 - val_accuracy: 0.7339\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 821.1053 - accuracy: 0.7184 - val_loss: 622.7236 - val_accuracy: 0.7381\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 812.4489 - accuracy: 0.7213 - val_loss: 627.8428 - val_accuracy: 0.7351\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 813.4188 - accuracy: 0.7210 - val_loss: 624.1003 - val_accuracy: 0.7345\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 810.3946 - accuracy: 0.7171 - val_loss: 627.9521 - val_accuracy: 0.7335\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 810.7148 - accuracy: 0.7201 - val_loss: 621.6861 - val_accuracy: 0.7270\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 809.9102 - accuracy: 0.7233 - val_loss: 619.6198 - val_accuracy: 0.7293\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 806.3463 - accuracy: 0.7202 - val_loss: 625.9238 - val_accuracy: 0.7410\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 812.1553 - accuracy: 0.7231 - val_loss: 624.6490 - val_accuracy: 0.7339\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 813.9408 - accuracy: 0.7230 - val_loss: 617.8764 - val_accuracy: 0.7314\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 807.3401 - accuracy: 0.7250 - val_loss: 618.1313 - val_accuracy: 0.7253\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 802.0243 - accuracy: 0.7233 - val_loss: 615.7349 - val_accuracy: 0.7388\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 804.1279 - accuracy: 0.7253 - val_loss: 623.2723 - val_accuracy: 0.7413\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 804.8662 - accuracy: 0.7285 - val_loss: 629.1879 - val_accuracy: 0.7302\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 806.2339 - accuracy: 0.7285 - val_loss: 615.0574 - val_accuracy: 0.7325\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 799.6420 - accuracy: 0.7271 - val_loss: 615.5726 - val_accuracy: 0.7410\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 799.4583 - accuracy: 0.7304 - val_loss: 615.3621 - val_accuracy: 0.7522\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 801.9537 - accuracy: 0.7278 - val_loss: 611.8467 - val_accuracy: 0.7286\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 801.1196 - accuracy: 0.7261 - val_loss: 618.7292 - val_accuracy: 0.7489\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 802.0011 - accuracy: 0.7309 - val_loss: 611.3829 - val_accuracy: 0.7359\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 799.3469 - accuracy: 0.7272 - val_loss: 610.5618 - val_accuracy: 0.7358\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 797.4471 - accuracy: 0.7284 - val_loss: 615.6584 - val_accuracy: 0.7508\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 797.7436 - accuracy: 0.7281 - val_loss: 616.0908 - val_accuracy: 0.7482\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 802.8668 - accuracy: 0.7318 - val_loss: 624.4756 - val_accuracy: 0.7549\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 813.2366 - accuracy: 0.7314 - val_loss: 613.7343 - val_accuracy: 0.7530\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 803.1392 - accuracy: 0.7319 - val_loss: 622.3890 - val_accuracy: 0.7469\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 801.8538 - accuracy: 0.7274 - val_loss: 612.6947 - val_accuracy: 0.7375\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 802.2130 - accuracy: 0.7339 - val_loss: 616.8456 - val_accuracy: 0.7462\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 796.7333 - accuracy: 0.7313 - val_loss: 610.9206 - val_accuracy: 0.7542\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 794.7249 - accuracy: 0.7346 - val_loss: 612.8868 - val_accuracy: 0.7563\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 795.7604 - accuracy: 0.7339 - val_loss: 606.1679 - val_accuracy: 0.7488\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 793.7286 - accuracy: 0.7330 - val_loss: 610.1790 - val_accuracy: 0.7469\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 802.4149 - accuracy: 0.7345 - val_loss: 608.1350 - val_accuracy: 0.7445\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 794.7646 - accuracy: 0.7350 - val_loss: 619.9119 - val_accuracy: 0.7546\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 794.6071 - accuracy: 0.7361 - val_loss: 607.5357 - val_accuracy: 0.7626\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 793.4031 - accuracy: 0.7355 - val_loss: 606.6489 - val_accuracy: 0.7545\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 791.6018 - accuracy: 0.7385 - val_loss: 608.5330 - val_accuracy: 0.7533\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 793.3325 - accuracy: 0.7333 - val_loss: 611.3862 - val_accuracy: 0.7649\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 790.5369 - accuracy: 0.7360 - val_loss: 603.0138 - val_accuracy: 0.7539\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 793.4270 - accuracy: 0.7371 - val_loss: 603.3718 - val_accuracy: 0.7535\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 787.3611 - accuracy: 0.7362 - val_loss: 613.2097 - val_accuracy: 0.7621\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 785.8647 - accuracy: 0.7400 - val_loss: 610.0507 - val_accuracy: 0.7578\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 785.6814 - accuracy: 0.7408 - val_loss: 603.7410 - val_accuracy: 0.7625\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 784.2642 - accuracy: 0.7352 - val_loss: 604.5698 - val_accuracy: 0.7705\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 783.7554 - accuracy: 0.7394 - val_loss: 602.2181 - val_accuracy: 0.7514\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 783.8811 - accuracy: 0.7359 - val_loss: 611.7774 - val_accuracy: 0.7630\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 786.8564 - accuracy: 0.7389 - val_loss: 602.3456 - val_accuracy: 0.7545\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 784.7567 - accuracy: 0.7398 - val_loss: 601.3120 - val_accuracy: 0.7623\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 783.1189 - accuracy: 0.7385 - val_loss: 601.2598 - val_accuracy: 0.7623\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 781.9474 - accuracy: 0.7410 - val_loss: 606.9727 - val_accuracy: 0.7561\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 781.1749 - accuracy: 0.7418 - val_loss: 602.2021 - val_accuracy: 0.7673\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 782.3254 - accuracy: 0.7426 - val_loss: 603.6469 - val_accuracy: 0.7583\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 781.4709 - accuracy: 0.7407 - val_loss: 604.7741 - val_accuracy: 0.7587\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 780.5288 - accuracy: 0.7399 - val_loss: 606.4329 - val_accuracy: 0.7683\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 785.4371 - accuracy: 0.7402 - val_loss: 608.8051 - val_accuracy: 0.7657\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 782.8812 - accuracy: 0.7430 - val_loss: 606.3737 - val_accuracy: 0.7577\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 781.6786 - accuracy: 0.7403 - val_loss: 601.5025 - val_accuracy: 0.7583\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 786.7767 - accuracy: 0.7404 - val_loss: 609.0728 - val_accuracy: 0.7677\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 785.1499 - accuracy: 0.7422 - val_loss: 598.1266 - val_accuracy: 0.7705\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 778.2432 - accuracy: 0.7422 - val_loss: 598.1903 - val_accuracy: 0.7684\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 778.0390 - accuracy: 0.7428 - val_loss: 598.0585 - val_accuracy: 0.7594\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 777.1713 - accuracy: 0.7461 - val_loss: 598.9766 - val_accuracy: 0.7603\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 777.1673 - accuracy: 0.7418 - val_loss: 596.8134 - val_accuracy: 0.7696\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 776.4541 - accuracy: 0.7450 - val_loss: 603.6994 - val_accuracy: 0.7636\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 784.6744 - accuracy: 0.7444 - val_loss: 603.0701 - val_accuracy: 0.7588\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 787.3569 - accuracy: 0.7453 - val_loss: 602.2784 - val_accuracy: 0.7667\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 787.6133 - accuracy: 0.7441 - val_loss: 602.7675 - val_accuracy: 0.7668\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 784.9242 - accuracy: 0.7428 - val_loss: 597.3312 - val_accuracy: 0.7678\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 774.9451 - accuracy: 0.7434 - val_loss: 595.4924 - val_accuracy: 0.7670\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 775.1768 - accuracy: 0.7468 - val_loss: 597.6588 - val_accuracy: 0.7637\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 778.7485 - accuracy: 0.7435 - val_loss: 601.9152 - val_accuracy: 0.7612\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 781.6513 - accuracy: 0.7424 - val_loss: 596.9258 - val_accuracy: 0.7672\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 778.7500 - accuracy: 0.7443 - val_loss: 595.8284 - val_accuracy: 0.7732\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 773.7684 - accuracy: 0.7478 - val_loss: 596.5708 - val_accuracy: 0.7644\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 772.4872 - accuracy: 0.7461 - val_loss: 594.6490 - val_accuracy: 0.7597\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 772.0459 - accuracy: 0.7455 - val_loss: 592.2836 - val_accuracy: 0.7682\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 771.9046 - accuracy: 0.7467 - val_loss: 595.8563 - val_accuracy: 0.7724\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 772.0208 - accuracy: 0.7441 - val_loss: 593.4780 - val_accuracy: 0.7585\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 772.9161 - accuracy: 0.7451 - val_loss: 597.2322 - val_accuracy: 0.7704\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 776.2756 - accuracy: 0.7467 - val_loss: 600.4673 - val_accuracy: 0.7645\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 790.6008 - accuracy: 0.7433 - val_loss: 595.0731 - val_accuracy: 0.7686\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 776.8421 - accuracy: 0.7471 - val_loss: 592.2358 - val_accuracy: 0.7744\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 772.2460 - accuracy: 0.7429 - val_loss: 592.4090 - val_accuracy: 0.7684\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 775.1104 - accuracy: 0.7467 - val_loss: 601.7406 - val_accuracy: 0.7708\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 773.1055 - accuracy: 0.7439 - val_loss: 595.5941 - val_accuracy: 0.7769\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 771.2586 - accuracy: 0.7477 - val_loss: 590.7491 - val_accuracy: 0.7695\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 769.2787 - accuracy: 0.7453 - val_loss: 590.5673 - val_accuracy: 0.7660\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 768.8461 - accuracy: 0.7471 - val_loss: 589.6147 - val_accuracy: 0.7674\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 765.3961 - accuracy: 0.7459 - val_loss: 590.5916 - val_accuracy: 0.7730\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 766.1083 - accuracy: 0.7461 - val_loss: 591.6663 - val_accuracy: 0.7747\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 769.2336 - accuracy: 0.7462 - val_loss: 596.9108 - val_accuracy: 0.7707\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 768.7728 - accuracy: 0.7450 - val_loss: 591.8747 - val_accuracy: 0.7654\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 766.4731 - accuracy: 0.7466 - val_loss: 591.3342 - val_accuracy: 0.7736\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 767.1503 - accuracy: 0.7461 - val_loss: 590.9941 - val_accuracy: 0.7683\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 767.8398 - accuracy: 0.7510 - val_loss: 588.8821 - val_accuracy: 0.7701\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 765.3176 - accuracy: 0.7435 - val_loss: 590.8114 - val_accuracy: 0.7749\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 766.3240 - accuracy: 0.7459 - val_loss: 588.6083 - val_accuracy: 0.7720\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 765.9751 - accuracy: 0.7449 - val_loss: 593.1394 - val_accuracy: 0.7783\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 766.5760 - accuracy: 0.7453 - val_loss: 589.4193 - val_accuracy: 0.7732\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 764.8619 - accuracy: 0.7449 - val_loss: 591.4841 - val_accuracy: 0.7739\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 762.4710 - accuracy: 0.7470 - val_loss: 588.5313 - val_accuracy: 0.7717\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 763.7329 - accuracy: 0.7465 - val_loss: 590.6439 - val_accuracy: 0.7737\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 764.0253 - accuracy: 0.7457 - val_loss: 587.5530 - val_accuracy: 0.7789\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 763.8285 - accuracy: 0.7463 - val_loss: 595.1141 - val_accuracy: 0.7710\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 769.8961 - accuracy: 0.7460 - val_loss: 594.6078 - val_accuracy: 0.7746\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 776.6404 - accuracy: 0.7488 - val_loss: 588.0263 - val_accuracy: 0.7779\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 764.0452 - accuracy: 0.7451 - val_loss: 588.1797 - val_accuracy: 0.7709\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 765.0357 - accuracy: 0.7459 - val_loss: 586.2617 - val_accuracy: 0.7745\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 763.0794 - accuracy: 0.7457 - val_loss: 587.6106 - val_accuracy: 0.7724\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 762.6313 - accuracy: 0.7475 - val_loss: 589.1794 - val_accuracy: 0.7762\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 762.2563 - accuracy: 0.7487 - val_loss: 593.9481 - val_accuracy: 0.7693\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 769.5389 - accuracy: 0.7485 - val_loss: 587.8437 - val_accuracy: 0.7752\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 762.3775 - accuracy: 0.7446 - val_loss: 587.7952 - val_accuracy: 0.7812\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 762.0329 - accuracy: 0.7469 - val_loss: 584.6996 - val_accuracy: 0.7760\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 760.8320 - accuracy: 0.7463 - val_loss: 585.4989 - val_accuracy: 0.7762\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 761.0477 - accuracy: 0.7447 - val_loss: 586.5543 - val_accuracy: 0.7803\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 760.0489 - accuracy: 0.7460 - val_loss: 584.2181 - val_accuracy: 0.7807\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 764.4791 - accuracy: 0.7491 - val_loss: 586.9673 - val_accuracy: 0.7799\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 760.3550 - accuracy: 0.7461 - val_loss: 586.4053 - val_accuracy: 0.7795\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 759.0848 - accuracy: 0.7473 - val_loss: 585.6051 - val_accuracy: 0.7783\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 761.9922 - accuracy: 0.7485 - val_loss: 586.2538 - val_accuracy: 0.7784\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 761.9490 - accuracy: 0.7475 - val_loss: 588.3932 - val_accuracy: 0.7791\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 760.4128 - accuracy: 0.7449 - val_loss: 587.9493 - val_accuracy: 0.7779\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 762.8878 - accuracy: 0.7456 - val_loss: 586.7134 - val_accuracy: 0.7764\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 761.7560 - accuracy: 0.7492 - val_loss: 584.2720 - val_accuracy: 0.7789\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 757.9876 - accuracy: 0.7444 - val_loss: 586.5284 - val_accuracy: 0.7831\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 759.0363 - accuracy: 0.7470 - val_loss: 584.9889 - val_accuracy: 0.7798\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 760.2260 - accuracy: 0.7475 - val_loss: 584.9112 - val_accuracy: 0.7819\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 761.5703 - accuracy: 0.7464 - val_loss: 588.4062 - val_accuracy: 0.7740\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 758.9505 - accuracy: 0.7486 - val_loss: 584.9493 - val_accuracy: 0.7804\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 757.6820 - accuracy: 0.7485 - val_loss: 584.4282 - val_accuracy: 0.7806\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 762.9865 - accuracy: 0.7478 - val_loss: 597.7767 - val_accuracy: 0.7841\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 768.2759 - accuracy: 0.7438 - val_loss: 584.2944 - val_accuracy: 0.7833\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 759.5551 - accuracy: 0.7463 - val_loss: 581.5678 - val_accuracy: 0.7814\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 757.7243 - accuracy: 0.7473 - val_loss: 584.4032 - val_accuracy: 0.7771\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 764.2534 - accuracy: 0.7473 - val_loss: 583.6393 - val_accuracy: 0.7884\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 758.2767 - accuracy: 0.7483 - val_loss: 582.4908 - val_accuracy: 0.7845\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 762.9246 - accuracy: 0.7491 - val_loss: 588.1917 - val_accuracy: 0.7857\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 775.5929 - accuracy: 0.7472 - val_loss: 593.4285 - val_accuracy: 0.7943\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 789.3450 - accuracy: 0.7480 - val_loss: 587.5966 - val_accuracy: 0.7829\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 767.2481 - accuracy: 0.7424 - val_loss: 585.3231 - val_accuracy: 0.7844\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 763.2469 - accuracy: 0.7466 - val_loss: 605.7723 - val_accuracy: 0.7812\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 761.3770 - accuracy: 0.7477 - val_loss: 583.3031 - val_accuracy: 0.7790\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 760.1859 - accuracy: 0.7471 - val_loss: 588.5452 - val_accuracy: 0.7814\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 781.9412 - accuracy: 0.7468 - val_loss: 601.0742 - val_accuracy: 0.7815\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 804.9948 - accuracy: 0.7384 - val_loss: 659.4159 - val_accuracy: 0.7817\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 788.6075 - accuracy: 0.7446 - val_loss: 595.9413 - val_accuracy: 0.7813\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 773.3551 - accuracy: 0.7425 - val_loss: 592.7091 - val_accuracy: 0.7851\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 766.6674 - accuracy: 0.7485 - val_loss: 583.6120 - val_accuracy: 0.7878\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 759.3431 - accuracy: 0.7487 - val_loss: 583.8812 - val_accuracy: 0.7859\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 754.2930 - accuracy: 0.7478 - val_loss: 581.3458 - val_accuracy: 0.7882\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.8600 - accuracy: 0.7502 - val_loss: 580.6044 - val_accuracy: 0.7847\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 753.0073 - accuracy: 0.7471 - val_loss: 580.9312 - val_accuracy: 0.7858\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 753.9782 - accuracy: 0.7461 - val_loss: 580.0383 - val_accuracy: 0.7874\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 755.3868 - accuracy: 0.7479 - val_loss: 581.4706 - val_accuracy: 0.7833\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 752.8607 - accuracy: 0.7459 - val_loss: 581.5334 - val_accuracy: 0.7866\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.6097 - accuracy: 0.7493 - val_loss: 580.4410 - val_accuracy: 0.7886\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 756.3730 - accuracy: 0.7498 - val_loss: 583.4269 - val_accuracy: 0.7862\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 761.2539 - accuracy: 0.7448 - val_loss: 583.7475 - val_accuracy: 0.7878\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.0498 - accuracy: 0.7487 - val_loss: 579.1635 - val_accuracy: 0.7896\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.1609 - accuracy: 0.7471 - val_loss: 578.9296 - val_accuracy: 0.7871\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 756.0519 - accuracy: 0.7490 - val_loss: 583.0560 - val_accuracy: 0.7841\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 758.1458 - accuracy: 0.7485 - val_loss: 594.2074 - val_accuracy: 0.7871\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 756.8510 - accuracy: 0.7454 - val_loss: 579.3663 - val_accuracy: 0.7878\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.7041 - accuracy: 0.7492 - val_loss: 580.7029 - val_accuracy: 0.7849\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 752.3851 - accuracy: 0.7468 - val_loss: 581.7020 - val_accuracy: 0.7874\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 752.9451 - accuracy: 0.7455 - val_loss: 584.0300 - val_accuracy: 0.7867\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.3204 - accuracy: 0.7465 - val_loss: 583.5319 - val_accuracy: 0.7834\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 753.9865 - accuracy: 0.7490 - val_loss: 587.6951 - val_accuracy: 0.7861\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 754.4860 - accuracy: 0.7470 - val_loss: 580.3589 - val_accuracy: 0.7898\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.8333 - accuracy: 0.7492 - val_loss: 589.3949 - val_accuracy: 0.7872\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 757.5178 - accuracy: 0.7496 - val_loss: 579.4442 - val_accuracy: 0.7871\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 755.2820 - accuracy: 0.7489 - val_loss: 581.7434 - val_accuracy: 0.7897\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.5029 - accuracy: 0.7433 - val_loss: 577.7184 - val_accuracy: 0.7876\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.7539 - accuracy: 0.7503 - val_loss: 579.5471 - val_accuracy: 0.7871\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.0101 - accuracy: 0.7482 - val_loss: 580.3997 - val_accuracy: 0.7917\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 759.8740 - accuracy: 0.7491 - val_loss: 598.1475 - val_accuracy: 0.7925\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 758.2574 - accuracy: 0.7475 - val_loss: 578.1324 - val_accuracy: 0.7843\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.2756 - accuracy: 0.7516 - val_loss: 577.7941 - val_accuracy: 0.7873\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 753.8079 - accuracy: 0.7480 - val_loss: 582.0123 - val_accuracy: 0.7873\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 756.6249 - accuracy: 0.7490 - val_loss: 588.4633 - val_accuracy: 0.7859\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 761.9241 - accuracy: 0.7506 - val_loss: 608.7814 - val_accuracy: 0.7939\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 759.3577 - accuracy: 0.7506 - val_loss: 582.4996 - val_accuracy: 0.7947\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.5649 - accuracy: 0.7498 - val_loss: 597.0273 - val_accuracy: 0.7905\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 752.2183 - accuracy: 0.7510 - val_loss: 579.5015 - val_accuracy: 0.7944\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 749.9819 - accuracy: 0.7530 - val_loss: 576.8577 - val_accuracy: 0.7969\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.2362 - accuracy: 0.7503 - val_loss: 580.0062 - val_accuracy: 0.7919\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.1567 - accuracy: 0.7522 - val_loss: 575.7534 - val_accuracy: 0.7954\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 747.6712 - accuracy: 0.7519 - val_loss: 578.1186 - val_accuracy: 0.7962\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.7677 - accuracy: 0.7514 - val_loss: 577.3726 - val_accuracy: 0.7961\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 748.4719 - accuracy: 0.7537 - val_loss: 575.8859 - val_accuracy: 0.7962\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.4846 - accuracy: 0.7505 - val_loss: 603.5993 - val_accuracy: 0.7964\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 761.1507 - accuracy: 0.7510 - val_loss: 593.0196 - val_accuracy: 0.8024\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 765.1632 - accuracy: 0.7475 - val_loss: 587.8378 - val_accuracy: 0.7955\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.2580 - accuracy: 0.7526 - val_loss: 587.6241 - val_accuracy: 0.7961\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.1616 - accuracy: 0.7529 - val_loss: 586.7322 - val_accuracy: 0.7966\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 751.4790 - accuracy: 0.7528 - val_loss: 574.8038 - val_accuracy: 0.7950\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 748.1663 - accuracy: 0.7523 - val_loss: 578.8099 - val_accuracy: 0.7971\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 760.1172 - accuracy: 0.7524 - val_loss: 594.6149 - val_accuracy: 0.7991\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 753.8219 - accuracy: 0.7511 - val_loss: 575.8200 - val_accuracy: 0.7970\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.3422 - accuracy: 0.7502 - val_loss: 575.5082 - val_accuracy: 0.7952\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.8308 - accuracy: 0.7522 - val_loss: 572.9947 - val_accuracy: 0.8005\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 746.2770 - accuracy: 0.7530 - val_loss: 572.7261 - val_accuracy: 0.7982\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 745.6865 - accuracy: 0.7525 - val_loss: 577.5838 - val_accuracy: 0.8009\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.0776 - accuracy: 0.7519 - val_loss: 578.0182 - val_accuracy: 0.8020\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.2407 - accuracy: 0.7529 - val_loss: 573.6415 - val_accuracy: 0.7978\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.0522 - accuracy: 0.7535 - val_loss: 574.4025 - val_accuracy: 0.8022\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 745.4897 - accuracy: 0.7522 - val_loss: 573.1510 - val_accuracy: 0.8021\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 745.7981 - accuracy: 0.7519 - val_loss: 574.1231 - val_accuracy: 0.8002\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 744.6299 - accuracy: 0.7513 - val_loss: 576.1673 - val_accuracy: 0.7985\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 746.3853 - accuracy: 0.7524 - val_loss: 573.7990 - val_accuracy: 0.7998\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.9647 - accuracy: 0.7516 - val_loss: 580.7654 - val_accuracy: 0.8003\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 744.6877 - accuracy: 0.7503 - val_loss: 573.5665 - val_accuracy: 0.8008\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 746.6383 - accuracy: 0.7540 - val_loss: 573.8025 - val_accuracy: 0.8022\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.8053 - accuracy: 0.7528 - val_loss: 575.2040 - val_accuracy: 0.7973\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.5195 - accuracy: 0.7523 - val_loss: 574.0775 - val_accuracy: 0.7980\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.4863 - accuracy: 0.7508 - val_loss: 583.1269 - val_accuracy: 0.7971\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 749.7866 - accuracy: 0.7538 - val_loss: 581.1136 - val_accuracy: 0.7980\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.8521 - accuracy: 0.7492 - val_loss: 576.6787 - val_accuracy: 0.7951\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.5010 - accuracy: 0.7522 - val_loss: 583.9596 - val_accuracy: 0.8016\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.3063 - accuracy: 0.7523 - val_loss: 573.0170 - val_accuracy: 0.8030\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 747.4022 - accuracy: 0.7525 - val_loss: 580.7285 - val_accuracy: 0.7970\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 750.3672 - accuracy: 0.7511 - val_loss: 573.6265 - val_accuracy: 0.7972\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.9854 - accuracy: 0.7537 - val_loss: 576.0385 - val_accuracy: 0.7952\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.5657 - accuracy: 0.7515 - val_loss: 573.1351 - val_accuracy: 0.8021\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.2411 - accuracy: 0.7515 - val_loss: 574.8229 - val_accuracy: 0.7978\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.2395 - accuracy: 0.7525 - val_loss: 575.3973 - val_accuracy: 0.8010\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 747.0085 - accuracy: 0.7509 - val_loss: 574.4920 - val_accuracy: 0.8002\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 743.4990 - accuracy: 0.7538 - val_loss: 572.2236 - val_accuracy: 0.8002\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.3384 - accuracy: 0.7542 - val_loss: 575.5743 - val_accuracy: 0.8021\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.2917 - accuracy: 0.7538 - val_loss: 573.0298 - val_accuracy: 0.8030\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 744.7100 - accuracy: 0.7512 - val_loss: 579.2012 - val_accuracy: 0.8049\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 745.2781 - accuracy: 0.7534 - val_loss: 585.0463 - val_accuracy: 0.7996\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 748.2786 - accuracy: 0.7544 - val_loss: 584.8446 - val_accuracy: 0.8023\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 747.0859 - accuracy: 0.7538 - val_loss: 574.5530 - val_accuracy: 0.8049\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 746.2681 - accuracy: 0.7550 - val_loss: 571.0117 - val_accuracy: 0.8033\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 744.6713 - accuracy: 0.7537 - val_loss: 586.2478 - val_accuracy: 0.8041\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.1961 - accuracy: 0.7543 - val_loss: 570.0880 - val_accuracy: 0.8033\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.7806 - accuracy: 0.7535 - val_loss: 577.1183 - val_accuracy: 0.8034\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.2136 - accuracy: 0.7526 - val_loss: 572.4075 - val_accuracy: 0.7996\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.6425 - accuracy: 0.7525 - val_loss: 571.2390 - val_accuracy: 0.8027\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 741.1859 - accuracy: 0.7520 - val_loss: 574.0788 - val_accuracy: 0.8015\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.0378 - accuracy: 0.7524 - val_loss: 571.1790 - val_accuracy: 0.8016\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.4086 - accuracy: 0.7501 - val_loss: 579.7377 - val_accuracy: 0.7990\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 747.4402 - accuracy: 0.7531 - val_loss: 571.4597 - val_accuracy: 0.8011\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 754.7629 - accuracy: 0.7519 - val_loss: 584.4470 - val_accuracy: 0.8044\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.7603 - accuracy: 0.7534 - val_loss: 574.6784 - val_accuracy: 0.8066\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 743.1207 - accuracy: 0.7540 - val_loss: 571.2891 - val_accuracy: 0.8029\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.5524 - accuracy: 0.7529 - val_loss: 571.8622 - val_accuracy: 0.8036\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.1642 - accuracy: 0.7522 - val_loss: 572.8084 - val_accuracy: 0.8007\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.2786 - accuracy: 0.7530 - val_loss: 571.6913 - val_accuracy: 0.8055\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.2957 - accuracy: 0.7511 - val_loss: 572.6941 - val_accuracy: 0.8020\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.5256 - accuracy: 0.7554 - val_loss: 573.4429 - val_accuracy: 0.8015\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 747.9766 - accuracy: 0.7519 - val_loss: 577.6891 - val_accuracy: 0.8030\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.3448 - accuracy: 0.7516 - val_loss: 571.6164 - val_accuracy: 0.8012\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.4048 - accuracy: 0.7489 - val_loss: 589.8529 - val_accuracy: 0.8003\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.8259 - accuracy: 0.7536 - val_loss: 574.1465 - val_accuracy: 0.8008\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 743.8182 - accuracy: 0.7568 - val_loss: 571.0186 - val_accuracy: 0.7997\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 739.4223 - accuracy: 0.7551 - val_loss: 569.6743 - val_accuracy: 0.8037\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.2189 - accuracy: 0.7538 - val_loss: 571.6934 - val_accuracy: 0.8045\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 745.3937 - accuracy: 0.7549 - val_loss: 572.3655 - val_accuracy: 0.8037\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 747.0527 - accuracy: 0.7537 - val_loss: 576.5944 - val_accuracy: 0.8028\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.8438 - accuracy: 0.7538 - val_loss: 572.3340 - val_accuracy: 0.8050\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.0309 - accuracy: 0.7548 - val_loss: 570.3738 - val_accuracy: 0.8051\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.3694 - accuracy: 0.7541 - val_loss: 569.5315 - val_accuracy: 0.8054\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.2330 - accuracy: 0.7538 - val_loss: 568.7133 - val_accuracy: 0.8023\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 738.9375 - accuracy: 0.7548 - val_loss: 574.9786 - val_accuracy: 0.8034\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.7875 - accuracy: 0.7522 - val_loss: 579.3416 - val_accuracy: 0.8051\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.0259 - accuracy: 0.7533 - val_loss: 570.7435 - val_accuracy: 0.8036\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.0436 - accuracy: 0.7536 - val_loss: 578.5950 - val_accuracy: 0.8031\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 744.5806 - accuracy: 0.7536 - val_loss: 569.7402 - val_accuracy: 0.8026\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.9603 - accuracy: 0.7537 - val_loss: 576.1705 - val_accuracy: 0.8022\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.5735 - accuracy: 0.7568 - val_loss: 580.8458 - val_accuracy: 0.8021\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.8789 - accuracy: 0.7532 - val_loss: 582.0630 - val_accuracy: 0.8017\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 743.1459 - accuracy: 0.7542 - val_loss: 573.0925 - val_accuracy: 0.8002\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.1547 - accuracy: 0.7542 - val_loss: 568.9802 - val_accuracy: 0.8058\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.2841 - accuracy: 0.7566 - val_loss: 568.6951 - val_accuracy: 0.8050\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.4592 - accuracy: 0.7541 - val_loss: 568.1859 - val_accuracy: 0.8053\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.4957 - accuracy: 0.7540 - val_loss: 568.9980 - val_accuracy: 0.8040\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 736.8571 - accuracy: 0.7561 - val_loss: 568.0686 - val_accuracy: 0.8025\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 736.5742 - accuracy: 0.7550 - val_loss: 567.8256 - val_accuracy: 0.8030\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.6054 - accuracy: 0.7545 - val_loss: 566.7648 - val_accuracy: 0.8032\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.2053 - accuracy: 0.7547 - val_loss: 581.9872 - val_accuracy: 0.8045\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.6503 - accuracy: 0.7542 - val_loss: 571.1390 - val_accuracy: 0.8018\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 741.0331 - accuracy: 0.7554 - val_loss: 572.0397 - val_accuracy: 0.8024\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.4733 - accuracy: 0.7535 - val_loss: 569.8273 - val_accuracy: 0.8015\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.2558 - accuracy: 0.7546 - val_loss: 569.3516 - val_accuracy: 0.8042\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.8467 - accuracy: 0.7556 - val_loss: 566.8076 - val_accuracy: 0.8042\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 736.2209 - accuracy: 0.7586 - val_loss: 569.8251 - val_accuracy: 0.8046\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.0181 - accuracy: 0.7534 - val_loss: 572.0031 - val_accuracy: 0.8044\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.0636 - accuracy: 0.7545 - val_loss: 570.3213 - val_accuracy: 0.8033\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.3763 - accuracy: 0.7535 - val_loss: 583.9947 - val_accuracy: 0.8040\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.2941 - accuracy: 0.7540 - val_loss: 569.2902 - val_accuracy: 0.8022\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 747.3315 - accuracy: 0.7535 - val_loss: 591.1069 - val_accuracy: 0.8031\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 756.0492 - accuracy: 0.7518 - val_loss: 583.4626 - val_accuracy: 0.8007\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 765.3970 - accuracy: 0.7528 - val_loss: 587.9462 - val_accuracy: 0.8020\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 765.4586 - accuracy: 0.7534 - val_loss: 591.2853 - val_accuracy: 0.8029\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.6538 - accuracy: 0.7515 - val_loss: 590.8345 - val_accuracy: 0.8013\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 744.5128 - accuracy: 0.7511 - val_loss: 567.5603 - val_accuracy: 0.8055\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 736.4763 - accuracy: 0.7540 - val_loss: 568.3909 - val_accuracy: 0.8013\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 737.8080 - accuracy: 0.7559 - val_loss: 584.6808 - val_accuracy: 0.8012\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.2883 - accuracy: 0.7548 - val_loss: 567.7587 - val_accuracy: 0.8046\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.4934 - accuracy: 0.7571 - val_loss: 567.4747 - val_accuracy: 0.8037\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 738.7706 - accuracy: 0.7545 - val_loss: 569.4775 - val_accuracy: 0.8037\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 738.1651 - accuracy: 0.7544 - val_loss: 567.8627 - val_accuracy: 0.8031\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.4070 - accuracy: 0.7557 - val_loss: 581.2584 - val_accuracy: 0.8007\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 738.7175 - accuracy: 0.7542 - val_loss: 570.0416 - val_accuracy: 0.8033\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.7681 - accuracy: 0.7552 - val_loss: 570.2961 - val_accuracy: 0.8022\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.2373 - accuracy: 0.7549 - val_loss: 567.4380 - val_accuracy: 0.8045\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.5374 - accuracy: 0.7556 - val_loss: 567.1483 - val_accuracy: 0.8019\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.9262 - accuracy: 0.7560 - val_loss: 567.2019 - val_accuracy: 0.8039\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 734.1685 - accuracy: 0.7565 - val_loss: 567.3455 - val_accuracy: 0.8038\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.7234 - accuracy: 0.7554 - val_loss: 571.0947 - val_accuracy: 0.8056\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.5182 - accuracy: 0.7546 - val_loss: 567.2563 - val_accuracy: 0.8052\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.8230 - accuracy: 0.7563 - val_loss: 570.2056 - val_accuracy: 0.8038\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.5099 - accuracy: 0.7525 - val_loss: 568.9447 - val_accuracy: 0.8063\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.2154 - accuracy: 0.7581 - val_loss: 571.1898 - val_accuracy: 0.8038\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.7886 - accuracy: 0.7527 - val_loss: 571.9438 - val_accuracy: 0.8036\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 738.1719 - accuracy: 0.7551 - val_loss: 569.5920 - val_accuracy: 0.8051\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.6168 - accuracy: 0.7570 - val_loss: 566.7380 - val_accuracy: 0.8018\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.9557 - accuracy: 0.7565 - val_loss: 566.9320 - val_accuracy: 0.8041\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.1613 - accuracy: 0.7553 - val_loss: 567.4966 - val_accuracy: 0.8054\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.0179 - accuracy: 0.7529 - val_loss: 567.8304 - val_accuracy: 0.8053\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.4597 - accuracy: 0.7572 - val_loss: 567.9604 - val_accuracy: 0.8053\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 734.6620 - accuracy: 0.7560 - val_loss: 569.8956 - val_accuracy: 0.8055\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.4038 - accuracy: 0.7548 - val_loss: 566.2804 - val_accuracy: 0.8078\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.2062 - accuracy: 0.7550 - val_loss: 565.5004 - val_accuracy: 0.8038\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.9404 - accuracy: 0.7548 - val_loss: 568.4434 - val_accuracy: 0.8072\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.6929 - accuracy: 0.7550 - val_loss: 566.4056 - val_accuracy: 0.8012\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.1625 - accuracy: 0.7568 - val_loss: 565.5889 - val_accuracy: 0.8017\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.3979 - accuracy: 0.7552 - val_loss: 567.7470 - val_accuracy: 0.8041\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.7079 - accuracy: 0.7559 - val_loss: 572.8339 - val_accuracy: 0.8030\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.1153 - accuracy: 0.7554 - val_loss: 568.9570 - val_accuracy: 0.8029\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.6435 - accuracy: 0.7572 - val_loss: 570.4785 - val_accuracy: 0.8035\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 740.5277 - accuracy: 0.7549 - val_loss: 571.1028 - val_accuracy: 0.8032\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 738.1580 - accuracy: 0.7555 - val_loss: 567.8608 - val_accuracy: 0.8043\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 742.6691 - accuracy: 0.7566 - val_loss: 578.6002 - val_accuracy: 0.8045\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 761.7344 - accuracy: 0.7556 - val_loss: 576.7894 - val_accuracy: 0.8034\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 779.9122 - accuracy: 0.7513 - val_loss: 585.6028 - val_accuracy: 0.8022\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 766.4139 - accuracy: 0.7545 - val_loss: 576.1624 - val_accuracy: 0.8053\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 746.6013 - accuracy: 0.7540 - val_loss: 575.7043 - val_accuracy: 0.8070\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.0458 - accuracy: 0.7560 - val_loss: 585.0247 - val_accuracy: 0.8028\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 744.8316 - accuracy: 0.7578 - val_loss: 567.7421 - val_accuracy: 0.8038\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.8321 - accuracy: 0.7580 - val_loss: 564.7300 - val_accuracy: 0.8072\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.9944 - accuracy: 0.7533 - val_loss: 569.0395 - val_accuracy: 0.8039\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.6553 - accuracy: 0.7589 - val_loss: 566.5355 - val_accuracy: 0.8067\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 731.0514 - accuracy: 0.7565 - val_loss: 565.4778 - val_accuracy: 0.8040\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.4258 - accuracy: 0.7567 - val_loss: 568.4117 - val_accuracy: 0.8064\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.4116 - accuracy: 0.7576 - val_loss: 566.9781 - val_accuracy: 0.8046\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.3253 - accuracy: 0.7556 - val_loss: 566.1641 - val_accuracy: 0.8035\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.2852 - accuracy: 0.7590 - val_loss: 564.1508 - val_accuracy: 0.8057\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.4287 - accuracy: 0.7562 - val_loss: 564.0441 - val_accuracy: 0.8057\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.4364 - accuracy: 0.7572 - val_loss: 567.6787 - val_accuracy: 0.8055\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.7652 - accuracy: 0.7573 - val_loss: 564.7453 - val_accuracy: 0.8045\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.4578 - accuracy: 0.7577 - val_loss: 564.7661 - val_accuracy: 0.8063\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.7169 - accuracy: 0.7530 - val_loss: 565.7407 - val_accuracy: 0.8068\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.5040 - accuracy: 0.7567 - val_loss: 566.5913 - val_accuracy: 0.8062\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.2272 - accuracy: 0.7551 - val_loss: 567.5296 - val_accuracy: 0.8053\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.7266 - accuracy: 0.7553 - val_loss: 567.8118 - val_accuracy: 0.8002\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.0321 - accuracy: 0.7573 - val_loss: 569.4753 - val_accuracy: 0.8042\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.9677 - accuracy: 0.7522 - val_loss: 566.5504 - val_accuracy: 0.8055\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.2363 - accuracy: 0.7573 - val_loss: 567.9690 - val_accuracy: 0.8031\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.1036 - accuracy: 0.7559 - val_loss: 565.3115 - val_accuracy: 0.8052\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 736.5925 - accuracy: 0.7579 - val_loss: 577.9688 - val_accuracy: 0.8048\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.9482 - accuracy: 0.7585 - val_loss: 566.7005 - val_accuracy: 0.8075\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 748.5043 - accuracy: 0.7525 - val_loss: 567.1479 - val_accuracy: 0.8028\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 742.1993 - accuracy: 0.7576 - val_loss: 566.4939 - val_accuracy: 0.8038\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.0886 - accuracy: 0.7562 - val_loss: 570.3320 - val_accuracy: 0.8066\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.8565 - accuracy: 0.7592 - val_loss: 570.3921 - val_accuracy: 0.8046\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 747.7365 - accuracy: 0.7566 - val_loss: 588.9786 - val_accuracy: 0.7996\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 743.5099 - accuracy: 0.7557 - val_loss: 586.8204 - val_accuracy: 0.8082\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.0281 - accuracy: 0.7576 - val_loss: 570.8616 - val_accuracy: 0.8035\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 743.6595 - accuracy: 0.7513 - val_loss: 576.1815 - val_accuracy: 0.8110\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.1978 - accuracy: 0.7573 - val_loss: 568.9406 - val_accuracy: 0.8072\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.2446 - accuracy: 0.7580 - val_loss: 564.9292 - val_accuracy: 0.8067\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.5117 - accuracy: 0.7559 - val_loss: 564.6065 - val_accuracy: 0.8075\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.8288 - accuracy: 0.7566 - val_loss: 572.0868 - val_accuracy: 0.8070\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.0500 - accuracy: 0.7558 - val_loss: 563.3826 - val_accuracy: 0.8068\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.0989 - accuracy: 0.7573 - val_loss: 565.6230 - val_accuracy: 0.8066\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.3421 - accuracy: 0.7592 - val_loss: 563.6964 - val_accuracy: 0.8079\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.3334 - accuracy: 0.7565 - val_loss: 564.1925 - val_accuracy: 0.8070\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.2389 - accuracy: 0.7592 - val_loss: 564.0973 - val_accuracy: 0.8059\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.3278 - accuracy: 0.7578 - val_loss: 563.8785 - val_accuracy: 0.8081\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 730.5231 - accuracy: 0.7567 - val_loss: 564.0106 - val_accuracy: 0.8035\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.3931 - accuracy: 0.7569 - val_loss: 564.2463 - val_accuracy: 0.8069\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.9056 - accuracy: 0.7568 - val_loss: 568.2470 - val_accuracy: 0.8072\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 753.0677 - accuracy: 0.7583 - val_loss: 612.0200 - val_accuracy: 0.8013\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 758.5459 - accuracy: 0.7570 - val_loss: 567.3329 - val_accuracy: 0.8059\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.4019 - accuracy: 0.7604 - val_loss: 564.8853 - val_accuracy: 0.8083\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.9193 - accuracy: 0.7613 - val_loss: 564.2131 - val_accuracy: 0.8079\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.0054 - accuracy: 0.7594 - val_loss: 566.7235 - val_accuracy: 0.8061\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.5674 - accuracy: 0.7569 - val_loss: 563.4572 - val_accuracy: 0.8076\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.1802 - accuracy: 0.7599 - val_loss: 564.0363 - val_accuracy: 0.8080\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.2354 - accuracy: 0.7620 - val_loss: 565.4188 - val_accuracy: 0.8051\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.7397 - accuracy: 0.7589 - val_loss: 566.0768 - val_accuracy: 0.8077\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.7181 - accuracy: 0.7603 - val_loss: 565.1718 - val_accuracy: 0.8077\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.7307 - accuracy: 0.7584 - val_loss: 562.3292 - val_accuracy: 0.8112\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.8480 - accuracy: 0.7586 - val_loss: 563.3795 - val_accuracy: 0.8105\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.8883 - accuracy: 0.7592 - val_loss: 563.7985 - val_accuracy: 0.8082\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.8499 - accuracy: 0.7597 - val_loss: 564.9274 - val_accuracy: 0.8078\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.4188 - accuracy: 0.7596 - val_loss: 562.0648 - val_accuracy: 0.8080\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.1530 - accuracy: 0.7581 - val_loss: 562.6317 - val_accuracy: 0.8063\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.9985 - accuracy: 0.7598 - val_loss: 563.2759 - val_accuracy: 0.8072\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.6079 - accuracy: 0.7582 - val_loss: 569.6841 - val_accuracy: 0.8045\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.3525 - accuracy: 0.7609 - val_loss: 561.9749 - val_accuracy: 0.8076\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.1518 - accuracy: 0.7594 - val_loss: 561.2258 - val_accuracy: 0.8086\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.2818 - accuracy: 0.7580 - val_loss: 564.3152 - val_accuracy: 0.8100\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.0100 - accuracy: 0.7595 - val_loss: 561.8516 - val_accuracy: 0.8054\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.1087 - accuracy: 0.7608 - val_loss: 563.0097 - val_accuracy: 0.8072\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.4222 - accuracy: 0.7575 - val_loss: 561.7163 - val_accuracy: 0.8086\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.8702 - accuracy: 0.7610 - val_loss: 561.9232 - val_accuracy: 0.8088\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.6240 - accuracy: 0.7584 - val_loss: 562.3078 - val_accuracy: 0.8091\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.2277 - accuracy: 0.7590 - val_loss: 561.1208 - val_accuracy: 0.8058\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.9062 - accuracy: 0.7611 - val_loss: 563.3787 - val_accuracy: 0.8073\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.0407 - accuracy: 0.7568 - val_loss: 562.8569 - val_accuracy: 0.8062\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.7131 - accuracy: 0.7602 - val_loss: 563.0678 - val_accuracy: 0.8091\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.3832 - accuracy: 0.7581 - val_loss: 563.2913 - val_accuracy: 0.8087\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.7020 - accuracy: 0.7599 - val_loss: 562.4479 - val_accuracy: 0.8063\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 729.9895 - accuracy: 0.7603 - val_loss: 568.8735 - val_accuracy: 0.8083\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.6417 - accuracy: 0.7595 - val_loss: 570.9243 - val_accuracy: 0.8068\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.2899 - accuracy: 0.7575 - val_loss: 567.3792 - val_accuracy: 0.8066\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.9966 - accuracy: 0.7602 - val_loss: 566.3177 - val_accuracy: 0.8062\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.2639 - accuracy: 0.7568 - val_loss: 571.3873 - val_accuracy: 0.8092\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.4186 - accuracy: 0.7583 - val_loss: 571.5492 - val_accuracy: 0.8080\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.2276 - accuracy: 0.7606 - val_loss: 574.0349 - val_accuracy: 0.8051\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 749.9901 - accuracy: 0.7602 - val_loss: 572.4700 - val_accuracy: 0.8106\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 745.7430 - accuracy: 0.7588 - val_loss: 564.8904 - val_accuracy: 0.8070\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 732.3497 - accuracy: 0.7600 - val_loss: 575.7352 - val_accuracy: 0.8085\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.5967 - accuracy: 0.7591 - val_loss: 563.3171 - val_accuracy: 0.8096\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.5469 - accuracy: 0.7615 - val_loss: 566.8321 - val_accuracy: 0.8069\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.1350 - accuracy: 0.7594 - val_loss: 563.5494 - val_accuracy: 0.8069\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.5214 - accuracy: 0.7597 - val_loss: 562.7939 - val_accuracy: 0.8101\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.3114 - accuracy: 0.7601 - val_loss: 562.0408 - val_accuracy: 0.8102\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.5827 - accuracy: 0.7596 - val_loss: 565.0916 - val_accuracy: 0.8101\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 732.0986 - accuracy: 0.7596 - val_loss: 569.0362 - val_accuracy: 0.8093\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 733.4357 - accuracy: 0.7557 - val_loss: 564.1680 - val_accuracy: 0.8073\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.9827 - accuracy: 0.7608 - val_loss: 567.4032 - val_accuracy: 0.8099\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.1151 - accuracy: 0.7606 - val_loss: 568.3442 - val_accuracy: 0.8095\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.7462 - accuracy: 0.7627 - val_loss: 563.5734 - val_accuracy: 0.8081\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 730.6632 - accuracy: 0.7602 - val_loss: 561.6314 - val_accuracy: 0.8085\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 730.6011 - accuracy: 0.7619 - val_loss: 562.5016 - val_accuracy: 0.8075\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.1674 - accuracy: 0.7588 - val_loss: 562.5495 - val_accuracy: 0.8075\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.9984 - accuracy: 0.7612 - val_loss: 560.9297 - val_accuracy: 0.8081\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 726.7109 - accuracy: 0.7614 - val_loss: 563.7831 - val_accuracy: 0.8099\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.1782 - accuracy: 0.7629 - val_loss: 561.0569 - val_accuracy: 0.8090\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.5093 - accuracy: 0.7603 - val_loss: 564.6284 - val_accuracy: 0.8067\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.3216 - accuracy: 0.7618 - val_loss: 562.1401 - val_accuracy: 0.8087\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.1426 - accuracy: 0.7596 - val_loss: 561.7136 - val_accuracy: 0.8093\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.1462 - accuracy: 0.7597 - val_loss: 561.3225 - val_accuracy: 0.8076\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 728.7012 - accuracy: 0.7606 - val_loss: 565.4437 - val_accuracy: 0.8093\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.3488 - accuracy: 0.7601 - val_loss: 560.3254 - val_accuracy: 0.8104\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.7236 - accuracy: 0.7598 - val_loss: 562.2502 - val_accuracy: 0.8097\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.5974 - accuracy: 0.7610 - val_loss: 566.7673 - val_accuracy: 0.8086\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.2529 - accuracy: 0.7614 - val_loss: 569.1057 - val_accuracy: 0.8085\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.3386 - accuracy: 0.7627 - val_loss: 561.6858 - val_accuracy: 0.8118\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 734.6143 - accuracy: 0.7595 - val_loss: 574.9508 - val_accuracy: 0.8079\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.8839 - accuracy: 0.7592 - val_loss: 566.3336 - val_accuracy: 0.8100\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.4384 - accuracy: 0.7631 - val_loss: 564.3238 - val_accuracy: 0.8087\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 725.5062 - accuracy: 0.7644 - val_loss: 561.9915 - val_accuracy: 0.8093\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.5099 - accuracy: 0.7613 - val_loss: 561.3045 - val_accuracy: 0.8075\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.9776 - accuracy: 0.7662 - val_loss: 560.7078 - val_accuracy: 0.8093\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.5726 - accuracy: 0.7612 - val_loss: 563.1230 - val_accuracy: 0.8088\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.8592 - accuracy: 0.7636 - val_loss: 572.6481 - val_accuracy: 0.8133\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.9077 - accuracy: 0.7574 - val_loss: 562.3311 - val_accuracy: 0.8088\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.6110 - accuracy: 0.7608 - val_loss: 561.3635 - val_accuracy: 0.8118\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.0291 - accuracy: 0.7631 - val_loss: 560.6069 - val_accuracy: 0.8101\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.1216 - accuracy: 0.7640 - val_loss: 559.0341 - val_accuracy: 0.8115\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.7574 - accuracy: 0.7634 - val_loss: 563.6370 - val_accuracy: 0.8130\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.7617 - accuracy: 0.7623 - val_loss: 559.1132 - val_accuracy: 0.8091\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.5768 - accuracy: 0.7619 - val_loss: 560.5964 - val_accuracy: 0.8137\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.9199 - accuracy: 0.7636 - val_loss: 565.5240 - val_accuracy: 0.8102\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.0338 - accuracy: 0.7619 - val_loss: 562.2212 - val_accuracy: 0.8132\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.1149 - accuracy: 0.7631 - val_loss: 559.0100 - val_accuracy: 0.8113\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.9834 - accuracy: 0.7648 - val_loss: 558.6742 - val_accuracy: 0.8132\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.6160 - accuracy: 0.7636 - val_loss: 560.3312 - val_accuracy: 0.8117\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.9506 - accuracy: 0.7612 - val_loss: 559.0174 - val_accuracy: 0.8108\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.4816 - accuracy: 0.7643 - val_loss: 559.7836 - val_accuracy: 0.8113\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 724.7338 - accuracy: 0.7644 - val_loss: 562.2523 - val_accuracy: 0.8114\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 728.2097 - accuracy: 0.7658 - val_loss: 562.7647 - val_accuracy: 0.8123\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.7575 - accuracy: 0.7654 - val_loss: 567.4813 - val_accuracy: 0.8111\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.3082 - accuracy: 0.7636 - val_loss: 561.7800 - val_accuracy: 0.8119\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.4439 - accuracy: 0.7635 - val_loss: 571.1099 - val_accuracy: 0.8097\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 741.9620 - accuracy: 0.7607 - val_loss: 560.9775 - val_accuracy: 0.8132\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.9996 - accuracy: 0.7618 - val_loss: 564.0696 - val_accuracy: 0.8102\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.5545 - accuracy: 0.7633 - val_loss: 573.8475 - val_accuracy: 0.8121\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.9471 - accuracy: 0.7633 - val_loss: 562.7056 - val_accuracy: 0.8084\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.6744 - accuracy: 0.7624 - val_loss: 561.1395 - val_accuracy: 0.8114\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 727.4916 - accuracy: 0.7651 - val_loss: 564.6035 - val_accuracy: 0.8113\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.6194 - accuracy: 0.7619 - val_loss: 560.5776 - val_accuracy: 0.8121\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.5613 - accuracy: 0.7646 - val_loss: 562.1378 - val_accuracy: 0.8101\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.2905 - accuracy: 0.7663 - val_loss: 559.6164 - val_accuracy: 0.8142\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.8668 - accuracy: 0.7637 - val_loss: 559.4205 - val_accuracy: 0.8121\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.0294 - accuracy: 0.7638 - val_loss: 561.5455 - val_accuracy: 0.8111\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.1873 - accuracy: 0.7628 - val_loss: 563.9131 - val_accuracy: 0.8098\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.4573 - accuracy: 0.7639 - val_loss: 561.2608 - val_accuracy: 0.8128\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.3705 - accuracy: 0.7637 - val_loss: 563.6530 - val_accuracy: 0.8135\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 723.9739 - accuracy: 0.7660 - val_loss: 560.8660 - val_accuracy: 0.8127\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.8306 - accuracy: 0.7641 - val_loss: 562.5923 - val_accuracy: 0.8132\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.4358 - accuracy: 0.7615 - val_loss: 575.7193 - val_accuracy: 0.8118\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.2907 - accuracy: 0.7630 - val_loss: 561.2549 - val_accuracy: 0.8100\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.1339 - accuracy: 0.7648 - val_loss: 558.8353 - val_accuracy: 0.8145\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.6395 - accuracy: 0.7668 - val_loss: 559.4374 - val_accuracy: 0.8098\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.9532 - accuracy: 0.7612 - val_loss: 561.7770 - val_accuracy: 0.8144\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.4684 - accuracy: 0.7637 - val_loss: 563.2742 - val_accuracy: 0.8123\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.1774 - accuracy: 0.7609 - val_loss: 563.8263 - val_accuracy: 0.8120\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.4141 - accuracy: 0.7653 - val_loss: 564.8340 - val_accuracy: 0.8140\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.8282 - accuracy: 0.7655 - val_loss: 561.1048 - val_accuracy: 0.8122\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.6144 - accuracy: 0.7611 - val_loss: 563.2628 - val_accuracy: 0.8144\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.2687 - accuracy: 0.7632 - val_loss: 568.9379 - val_accuracy: 0.8115\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 727.5822 - accuracy: 0.7636 - val_loss: 562.9166 - val_accuracy: 0.8149\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.2778 - accuracy: 0.7651 - val_loss: 558.9052 - val_accuracy: 0.8127\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.4926 - accuracy: 0.7617 - val_loss: 559.4550 - val_accuracy: 0.8125\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.9399 - accuracy: 0.7640 - val_loss: 559.9203 - val_accuracy: 0.8125\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.8057 - accuracy: 0.7630 - val_loss: 561.0671 - val_accuracy: 0.8130\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.5557 - accuracy: 0.7619 - val_loss: 559.1505 - val_accuracy: 0.8130\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.2334 - accuracy: 0.7673 - val_loss: 573.4792 - val_accuracy: 0.8096\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 736.0463 - accuracy: 0.7614 - val_loss: 565.9177 - val_accuracy: 0.8114\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.7990 - accuracy: 0.7675 - val_loss: 561.0430 - val_accuracy: 0.8140\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.4120 - accuracy: 0.7642 - val_loss: 561.1277 - val_accuracy: 0.8119\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.6964 - accuracy: 0.7655 - val_loss: 582.5158 - val_accuracy: 0.8073\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.9193 - accuracy: 0.7636 - val_loss: 560.9219 - val_accuracy: 0.8125\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.8845 - accuracy: 0.7648 - val_loss: 559.1191 - val_accuracy: 0.8133\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.0815 - accuracy: 0.7641 - val_loss: 563.6437 - val_accuracy: 0.8139\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 728.2666 - accuracy: 0.7660 - val_loss: 563.4016 - val_accuracy: 0.8129\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.9114 - accuracy: 0.7624 - val_loss: 569.2728 - val_accuracy: 0.8133\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.6935 - accuracy: 0.7656 - val_loss: 562.0314 - val_accuracy: 0.8095\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 731.5380 - accuracy: 0.7647 - val_loss: 567.7966 - val_accuracy: 0.8125\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.0952 - accuracy: 0.7624 - val_loss: 580.8785 - val_accuracy: 0.8118\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.7582 - accuracy: 0.7630 - val_loss: 562.4953 - val_accuracy: 0.8115\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 736.9169 - accuracy: 0.7641 - val_loss: 570.7683 - val_accuracy: 0.8140\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.6497 - accuracy: 0.7650 - val_loss: 581.2420 - val_accuracy: 0.8084\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.4541 - accuracy: 0.7630 - val_loss: 559.0815 - val_accuracy: 0.8118\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.9915 - accuracy: 0.7630 - val_loss: 561.2564 - val_accuracy: 0.8135\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.7637 - accuracy: 0.7661 - val_loss: 562.4998 - val_accuracy: 0.8121\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.5563 - accuracy: 0.7629 - val_loss: 577.0738 - val_accuracy: 0.8104\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.6048 - accuracy: 0.7637 - val_loss: 562.4502 - val_accuracy: 0.8153\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.6523 - accuracy: 0.7640 - val_loss: 560.6443 - val_accuracy: 0.8081\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.2369 - accuracy: 0.7642 - val_loss: 579.6536 - val_accuracy: 0.8077\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 736.0029 - accuracy: 0.7643 - val_loss: 581.7847 - val_accuracy: 0.8104\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.6209 - accuracy: 0.7655 - val_loss: 562.1772 - val_accuracy: 0.8101\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 726.9844 - accuracy: 0.7660 - val_loss: 561.2313 - val_accuracy: 0.8147\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 726.0332 - accuracy: 0.7652 - val_loss: 558.3986 - val_accuracy: 0.8121\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.2314 - accuracy: 0.7659 - val_loss: 559.6819 - val_accuracy: 0.8133\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.9395 - accuracy: 0.7618 - val_loss: 572.8395 - val_accuracy: 0.8100\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 726.2921 - accuracy: 0.7631 - val_loss: 558.8389 - val_accuracy: 0.8110\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.0854 - accuracy: 0.7680 - val_loss: 557.3785 - val_accuracy: 0.8139\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.5093 - accuracy: 0.7652 - val_loss: 557.8431 - val_accuracy: 0.8126\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 721.7964 - accuracy: 0.7659 - val_loss: 559.6009 - val_accuracy: 0.8122\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.7036 - accuracy: 0.7646 - val_loss: 557.5681 - val_accuracy: 0.8143\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.7232 - accuracy: 0.7668 - val_loss: 560.1992 - val_accuracy: 0.8147\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.2993 - accuracy: 0.7632 - val_loss: 560.8387 - val_accuracy: 0.8117\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.9305 - accuracy: 0.7669 - val_loss: 558.1799 - val_accuracy: 0.8135\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 722.1992 - accuracy: 0.7640 - val_loss: 562.4717 - val_accuracy: 0.8095\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.3412 - accuracy: 0.7655 - val_loss: 556.8201 - val_accuracy: 0.8152\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.8200 - accuracy: 0.7655 - val_loss: 560.2804 - val_accuracy: 0.8153\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 732.9169 - accuracy: 0.7644 - val_loss: 558.2280 - val_accuracy: 0.8099\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.5196 - accuracy: 0.7654 - val_loss: 566.7075 - val_accuracy: 0.8135\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.3159 - accuracy: 0.7667 - val_loss: 557.4937 - val_accuracy: 0.8140\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 719.5129 - accuracy: 0.7668 - val_loss: 556.4092 - val_accuracy: 0.8143\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.6190 - accuracy: 0.7657 - val_loss: 557.7865 - val_accuracy: 0.8145\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.2242 - accuracy: 0.7655 - val_loss: 558.5623 - val_accuracy: 0.8113\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.5722 - accuracy: 0.7656 - val_loss: 567.3795 - val_accuracy: 0.8160\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.0571 - accuracy: 0.7647 - val_loss: 558.2455 - val_accuracy: 0.8124\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.5289 - accuracy: 0.7634 - val_loss: 561.9633 - val_accuracy: 0.8129\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.4481 - accuracy: 0.7646 - val_loss: 556.5243 - val_accuracy: 0.8141\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.1222 - accuracy: 0.7671 - val_loss: 557.4726 - val_accuracy: 0.8145\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.1172 - accuracy: 0.7641 - val_loss: 555.9805 - val_accuracy: 0.8123\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.2773 - accuracy: 0.7660 - val_loss: 557.2557 - val_accuracy: 0.8110\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.7511 - accuracy: 0.7630 - val_loss: 556.5956 - val_accuracy: 0.8113\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.6904 - accuracy: 0.7669 - val_loss: 556.9428 - val_accuracy: 0.8148\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.7164 - accuracy: 0.7681 - val_loss: 556.7454 - val_accuracy: 0.8135\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.9750 - accuracy: 0.7664 - val_loss: 558.0193 - val_accuracy: 0.8152\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.0464 - accuracy: 0.7675 - val_loss: 561.0972 - val_accuracy: 0.8125\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.7444 - accuracy: 0.7642 - val_loss: 556.3809 - val_accuracy: 0.8144\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.7997 - accuracy: 0.7659 - val_loss: 561.8567 - val_accuracy: 0.8119\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 724.8090 - accuracy: 0.7668 - val_loss: 562.2670 - val_accuracy: 0.8096\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 741.3973 - accuracy: 0.7633 - val_loss: 617.8919 - val_accuracy: 0.8100\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.3719 - accuracy: 0.7645 - val_loss: 560.8745 - val_accuracy: 0.8159\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.2202 - accuracy: 0.7644 - val_loss: 563.3968 - val_accuracy: 0.8144\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.8713 - accuracy: 0.7655 - val_loss: 557.6635 - val_accuracy: 0.8122\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.9830 - accuracy: 0.7651 - val_loss: 558.0999 - val_accuracy: 0.8133\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.3723 - accuracy: 0.7660 - val_loss: 557.7646 - val_accuracy: 0.8128\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.9761 - accuracy: 0.7665 - val_loss: 565.4933 - val_accuracy: 0.8098\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.5645 - accuracy: 0.7644 - val_loss: 565.9756 - val_accuracy: 0.8129\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 725.6830 - accuracy: 0.7644 - val_loss: 564.1765 - val_accuracy: 0.8107\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.8249 - accuracy: 0.7670 - val_loss: 576.9987 - val_accuracy: 0.8127\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 740.0146 - accuracy: 0.7670 - val_loss: 577.6711 - val_accuracy: 0.8148\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.2668 - accuracy: 0.7624 - val_loss: 569.9876 - val_accuracy: 0.8118\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 727.3876 - accuracy: 0.7680 - val_loss: 559.7379 - val_accuracy: 0.8145\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.0533 - accuracy: 0.7673 - val_loss: 556.0315 - val_accuracy: 0.8136\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.1614 - accuracy: 0.7677 - val_loss: 555.7321 - val_accuracy: 0.8135\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.3058 - accuracy: 0.7651 - val_loss: 563.5992 - val_accuracy: 0.8117\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.0015 - accuracy: 0.7668 - val_loss: 558.1505 - val_accuracy: 0.8126\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.8815 - accuracy: 0.7681 - val_loss: 556.5172 - val_accuracy: 0.8132\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.0204 - accuracy: 0.7672 - val_loss: 560.7288 - val_accuracy: 0.8140\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.2776 - accuracy: 0.7653 - val_loss: 557.8620 - val_accuracy: 0.8104\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.6696 - accuracy: 0.7663 - val_loss: 560.4609 - val_accuracy: 0.8133\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.0462 - accuracy: 0.7668 - val_loss: 555.5859 - val_accuracy: 0.8145\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.7830 - accuracy: 0.7671 - val_loss: 556.1312 - val_accuracy: 0.8145\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.5813 - accuracy: 0.7653 - val_loss: 556.9688 - val_accuracy: 0.8139\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.7097 - accuracy: 0.7672 - val_loss: 556.1486 - val_accuracy: 0.8149\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.3622 - accuracy: 0.7677 - val_loss: 555.3887 - val_accuracy: 0.8141\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.4452 - accuracy: 0.7645 - val_loss: 561.3255 - val_accuracy: 0.8134\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.7587 - accuracy: 0.7654 - val_loss: 560.3475 - val_accuracy: 0.8115\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.0367 - accuracy: 0.7656 - val_loss: 556.7037 - val_accuracy: 0.8158\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.7446 - accuracy: 0.7657 - val_loss: 560.5582 - val_accuracy: 0.8130\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.9169 - accuracy: 0.7678 - val_loss: 563.4692 - val_accuracy: 0.8153\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.1279 - accuracy: 0.7678 - val_loss: 557.6999 - val_accuracy: 0.8134\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.2166 - accuracy: 0.7671 - val_loss: 555.8846 - val_accuracy: 0.8125\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.1064 - accuracy: 0.7637 - val_loss: 556.4764 - val_accuracy: 0.8137\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 721.1021 - accuracy: 0.7662 - val_loss: 568.2354 - val_accuracy: 0.8116\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.2676 - accuracy: 0.7658 - val_loss: 573.2753 - val_accuracy: 0.8119\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 733.2070 - accuracy: 0.7648 - val_loss: 565.8047 - val_accuracy: 0.8122\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.9329 - accuracy: 0.7651 - val_loss: 559.3245 - val_accuracy: 0.8149\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.9515 - accuracy: 0.7681 - val_loss: 557.7272 - val_accuracy: 0.8149\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.1392 - accuracy: 0.7676 - val_loss: 556.2589 - val_accuracy: 0.8151\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.7271 - accuracy: 0.7666 - val_loss: 556.0194 - val_accuracy: 0.8128\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.5195 - accuracy: 0.7662 - val_loss: 558.4008 - val_accuracy: 0.8127\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.5688 - accuracy: 0.7632 - val_loss: 558.8945 - val_accuracy: 0.8131\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.5822 - accuracy: 0.7672 - val_loss: 557.4661 - val_accuracy: 0.8128\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 721.9274 - accuracy: 0.7648 - val_loss: 555.2733 - val_accuracy: 0.8149\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.2264 - accuracy: 0.7686 - val_loss: 554.7894 - val_accuracy: 0.8120\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.5543 - accuracy: 0.7681 - val_loss: 554.6317 - val_accuracy: 0.8136\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.4358 - accuracy: 0.7680 - val_loss: 556.0791 - val_accuracy: 0.8136\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.3695 - accuracy: 0.7621 - val_loss: 556.6495 - val_accuracy: 0.8155\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.3265 - accuracy: 0.7668 - val_loss: 558.0974 - val_accuracy: 0.8131\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.8624 - accuracy: 0.7654 - val_loss: 562.4912 - val_accuracy: 0.8115\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 725.4940 - accuracy: 0.7689 - val_loss: 556.1185 - val_accuracy: 0.8149\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.6677 - accuracy: 0.7656 - val_loss: 564.9741 - val_accuracy: 0.8126\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.0848 - accuracy: 0.7662 - val_loss: 565.9485 - val_accuracy: 0.8151\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.9841 - accuracy: 0.7669 - val_loss: 556.5363 - val_accuracy: 0.8134\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.7460 - accuracy: 0.7645 - val_loss: 557.2662 - val_accuracy: 0.8131\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.1987 - accuracy: 0.7653 - val_loss: 560.1022 - val_accuracy: 0.8150\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 722.3638 - accuracy: 0.7640 - val_loss: 556.4191 - val_accuracy: 0.8140\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.9804 - accuracy: 0.7658 - val_loss: 557.8931 - val_accuracy: 0.8099\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.5220 - accuracy: 0.7661 - val_loss: 555.9222 - val_accuracy: 0.8140\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.6676 - accuracy: 0.7666 - val_loss: 556.3280 - val_accuracy: 0.8141\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.1290 - accuracy: 0.7674 - val_loss: 554.4182 - val_accuracy: 0.8141\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.7986 - accuracy: 0.7682 - val_loss: 558.5425 - val_accuracy: 0.8170\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.5275 - accuracy: 0.7684 - val_loss: 556.1382 - val_accuracy: 0.8158\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.4595 - accuracy: 0.7653 - val_loss: 556.6802 - val_accuracy: 0.8139\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.7407 - accuracy: 0.7676 - val_loss: 560.8008 - val_accuracy: 0.8155\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 720.8179 - accuracy: 0.7645 - val_loss: 555.2776 - val_accuracy: 0.8130\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.1813 - accuracy: 0.7664 - val_loss: 554.7726 - val_accuracy: 0.8151\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.9504 - accuracy: 0.7669 - val_loss: 554.3368 - val_accuracy: 0.8149\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.6088 - accuracy: 0.7660 - val_loss: 554.1732 - val_accuracy: 0.8155\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.9959 - accuracy: 0.7693 - val_loss: 555.5472 - val_accuracy: 0.8160\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.2749 - accuracy: 0.7667 - val_loss: 560.4972 - val_accuracy: 0.8141\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.1854 - accuracy: 0.7683 - val_loss: 554.4896 - val_accuracy: 0.8148\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.3997 - accuracy: 0.7671 - val_loss: 555.9519 - val_accuracy: 0.8136\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.8638 - accuracy: 0.7662 - val_loss: 555.4017 - val_accuracy: 0.8127\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.7488 - accuracy: 0.7691 - val_loss: 554.9574 - val_accuracy: 0.8150\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 715.9417 - accuracy: 0.7652 - val_loss: 554.4482 - val_accuracy: 0.8149\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.8147 - accuracy: 0.7683 - val_loss: 554.6189 - val_accuracy: 0.8149\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.4920 - accuracy: 0.7675 - val_loss: 555.1595 - val_accuracy: 0.8133\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.1140 - accuracy: 0.7671 - val_loss: 559.5095 - val_accuracy: 0.8162\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.4725 - accuracy: 0.7675 - val_loss: 583.0399 - val_accuracy: 0.8144\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.5446 - accuracy: 0.7682 - val_loss: 556.1741 - val_accuracy: 0.8143\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 745.8746 - accuracy: 0.7651 - val_loss: 573.2726 - val_accuracy: 0.8151\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 737.7465 - accuracy: 0.7626 - val_loss: 565.0048 - val_accuracy: 0.8141\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.0040 - accuracy: 0.7660 - val_loss: 580.9311 - val_accuracy: 0.8158\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.8744 - accuracy: 0.7627 - val_loss: 558.3839 - val_accuracy: 0.8130\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.3736 - accuracy: 0.7678 - val_loss: 559.5168 - val_accuracy: 0.8124\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.8934 - accuracy: 0.7680 - val_loss: 554.0603 - val_accuracy: 0.8148\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.3596 - accuracy: 0.7694 - val_loss: 554.0988 - val_accuracy: 0.8143\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.6459 - accuracy: 0.7670 - val_loss: 553.9797 - val_accuracy: 0.8149\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.1191 - accuracy: 0.7673 - val_loss: 553.8275 - val_accuracy: 0.8152\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.7361 - accuracy: 0.7680 - val_loss: 553.6279 - val_accuracy: 0.8143\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.9951 - accuracy: 0.7684 - val_loss: 554.0529 - val_accuracy: 0.8155\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 715.7000 - accuracy: 0.7681 - val_loss: 552.8385 - val_accuracy: 0.8141\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.4897 - accuracy: 0.7691 - val_loss: 551.9913 - val_accuracy: 0.8139\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.6602 - accuracy: 0.7673 - val_loss: 553.5603 - val_accuracy: 0.8149\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.4767 - accuracy: 0.7702 - val_loss: 556.2202 - val_accuracy: 0.8146\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.5169 - accuracy: 0.7681 - val_loss: 557.8404 - val_accuracy: 0.8139\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.8002 - accuracy: 0.7680 - val_loss: 558.1061 - val_accuracy: 0.8112\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 719.7477 - accuracy: 0.7688 - val_loss: 556.6005 - val_accuracy: 0.8152\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 718.5408 - accuracy: 0.7659 - val_loss: 555.7008 - val_accuracy: 0.8161\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.5629 - accuracy: 0.7685 - val_loss: 557.1034 - val_accuracy: 0.8147\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 723.6718 - accuracy: 0.7666 - val_loss: 554.6020 - val_accuracy: 0.8123\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.3467 - accuracy: 0.7675 - val_loss: 555.7011 - val_accuracy: 0.8151\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.3362 - accuracy: 0.7676 - val_loss: 555.7781 - val_accuracy: 0.8148\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.0530 - accuracy: 0.7665 - val_loss: 553.4340 - val_accuracy: 0.8120\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.5304 - accuracy: 0.7684 - val_loss: 561.0572 - val_accuracy: 0.8128\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.9326 - accuracy: 0.7664 - val_loss: 555.2693 - val_accuracy: 0.8140\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.0540 - accuracy: 0.7697 - val_loss: 553.9927 - val_accuracy: 0.8139\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.0908 - accuracy: 0.7711 - val_loss: 555.7170 - val_accuracy: 0.8159\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.9684 - accuracy: 0.7674 - val_loss: 558.6121 - val_accuracy: 0.8146\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.3939 - accuracy: 0.7703 - val_loss: 554.0643 - val_accuracy: 0.8147\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.7038 - accuracy: 0.7684 - val_loss: 557.0547 - val_accuracy: 0.8143\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.6982 - accuracy: 0.7712 - val_loss: 554.0045 - val_accuracy: 0.8141\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.1194 - accuracy: 0.7696 - val_loss: 557.4379 - val_accuracy: 0.8118\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.5458 - accuracy: 0.7683 - val_loss: 554.8446 - val_accuracy: 0.8148\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 717.1691 - accuracy: 0.7691 - val_loss: 563.5872 - val_accuracy: 0.8147\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.2866 - accuracy: 0.7681 - val_loss: 556.2346 - val_accuracy: 0.8158\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.7944 - accuracy: 0.7683 - val_loss: 562.2097 - val_accuracy: 0.8150\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 728.1669 - accuracy: 0.7670 - val_loss: 566.9463 - val_accuracy: 0.8124\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.3812 - accuracy: 0.7691 - val_loss: 555.5345 - val_accuracy: 0.8162\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.1613 - accuracy: 0.7701 - val_loss: 552.7047 - val_accuracy: 0.8144\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 715.5498 - accuracy: 0.7695 - val_loss: 556.1118 - val_accuracy: 0.8137\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.2406 - accuracy: 0.7707 - val_loss: 554.2772 - val_accuracy: 0.8161\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.7861 - accuracy: 0.7702 - val_loss: 557.1329 - val_accuracy: 0.8130\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.1768 - accuracy: 0.7696 - val_loss: 553.7152 - val_accuracy: 0.8148\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.8834 - accuracy: 0.7698 - val_loss: 558.7194 - val_accuracy: 0.8121\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.2243 - accuracy: 0.7678 - val_loss: 553.1818 - val_accuracy: 0.8155\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.1707 - accuracy: 0.7678 - val_loss: 554.4102 - val_accuracy: 0.8149\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.7958 - accuracy: 0.7680 - val_loss: 553.4255 - val_accuracy: 0.8135\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.7220 - accuracy: 0.7699 - val_loss: 552.8229 - val_accuracy: 0.8147\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.9479 - accuracy: 0.7705 - val_loss: 555.8110 - val_accuracy: 0.8157\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.5684 - accuracy: 0.7698 - val_loss: 575.4863 - val_accuracy: 0.8151\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 744.1132 - accuracy: 0.7693 - val_loss: 557.2621 - val_accuracy: 0.8111\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.2357 - accuracy: 0.7657 - val_loss: 556.9429 - val_accuracy: 0.8147\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.0778 - accuracy: 0.7676 - val_loss: 562.7291 - val_accuracy: 0.8133\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.8095 - accuracy: 0.7692 - val_loss: 553.2841 - val_accuracy: 0.8121\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 720.4460 - accuracy: 0.7687 - val_loss: 557.9042 - val_accuracy: 0.8112\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.8676 - accuracy: 0.7692 - val_loss: 555.0090 - val_accuracy: 0.8150\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.3979 - accuracy: 0.7700 - val_loss: 555.1008 - val_accuracy: 0.8135\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.5986 - accuracy: 0.7698 - val_loss: 552.4208 - val_accuracy: 0.8141\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.3911 - accuracy: 0.7694 - val_loss: 553.3843 - val_accuracy: 0.8154\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.6181 - accuracy: 0.7714 - val_loss: 551.6052 - val_accuracy: 0.8145\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.1185 - accuracy: 0.7692 - val_loss: 555.6830 - val_accuracy: 0.8153\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 719.6113 - accuracy: 0.7713 - val_loss: 567.9774 - val_accuracy: 0.8142\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.0784 - accuracy: 0.7690 - val_loss: 554.0325 - val_accuracy: 0.8133\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.6107 - accuracy: 0.7677 - val_loss: 552.5455 - val_accuracy: 0.8171\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.0613 - accuracy: 0.7701 - val_loss: 553.1501 - val_accuracy: 0.8155\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 713.9424 - accuracy: 0.7698 - val_loss: 551.3654 - val_accuracy: 0.8128\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 713.5952 - accuracy: 0.7711 - val_loss: 551.7114 - val_accuracy: 0.8139\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.3615 - accuracy: 0.7704 - val_loss: 550.3466 - val_accuracy: 0.8159\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.6719 - accuracy: 0.7700 - val_loss: 551.7573 - val_accuracy: 0.8144\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.5179 - accuracy: 0.7705 - val_loss: 552.8332 - val_accuracy: 0.8130\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.7701 - accuracy: 0.7690 - val_loss: 568.1046 - val_accuracy: 0.8118\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 723.5606 - accuracy: 0.7713 - val_loss: 554.0471 - val_accuracy: 0.8141\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 718.7097 - accuracy: 0.7678 - val_loss: 554.7594 - val_accuracy: 0.8145\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.8696 - accuracy: 0.7713 - val_loss: 568.0903 - val_accuracy: 0.8120\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 721.5534 - accuracy: 0.7716 - val_loss: 555.1685 - val_accuracy: 0.8119\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.8154 - accuracy: 0.7698 - val_loss: 554.1335 - val_accuracy: 0.8136\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 717.7921 - accuracy: 0.7700 - val_loss: 560.9943 - val_accuracy: 0.8179\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 722.9036 - accuracy: 0.7670 - val_loss: 559.5012 - val_accuracy: 0.8151\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.3630 - accuracy: 0.7702 - val_loss: 553.0837 - val_accuracy: 0.8106\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.4791 - accuracy: 0.7699 - val_loss: 575.1266 - val_accuracy: 0.8110\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 728.3261 - accuracy: 0.7679 - val_loss: 555.7516 - val_accuracy: 0.8123\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 723.2761 - accuracy: 0.7683 - val_loss: 553.8245 - val_accuracy: 0.8156\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.4588 - accuracy: 0.7711 - val_loss: 551.0547 - val_accuracy: 0.8165\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.8865 - accuracy: 0.7716 - val_loss: 551.9053 - val_accuracy: 0.8139\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.8544 - accuracy: 0.7701 - val_loss: 555.6048 - val_accuracy: 0.8139\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 717.1042 - accuracy: 0.7707 - val_loss: 553.2579 - val_accuracy: 0.8166\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.4016 - accuracy: 0.7698 - val_loss: 552.6970 - val_accuracy: 0.8142\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.0387 - accuracy: 0.7725 - val_loss: 551.3541 - val_accuracy: 0.8150\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.9448 - accuracy: 0.7712 - val_loss: 550.6190 - val_accuracy: 0.8151\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.1758 - accuracy: 0.7718 - val_loss: 550.7426 - val_accuracy: 0.8156\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.2735 - accuracy: 0.7733 - val_loss: 551.1515 - val_accuracy: 0.8141\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.7595 - accuracy: 0.7718 - val_loss: 552.4642 - val_accuracy: 0.8161\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.2943 - accuracy: 0.7711 - val_loss: 554.8814 - val_accuracy: 0.8150\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.2835 - accuracy: 0.7715 - val_loss: 572.0067 - val_accuracy: 0.8145\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.4714 - accuracy: 0.7710 - val_loss: 553.2596 - val_accuracy: 0.8138\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.6705 - accuracy: 0.7684 - val_loss: 564.5132 - val_accuracy: 0.8125\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 724.5232 - accuracy: 0.7710 - val_loss: 564.5939 - val_accuracy: 0.8151\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.5235 - accuracy: 0.7708 - val_loss: 556.2375 - val_accuracy: 0.8152\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.6083 - accuracy: 0.7693 - val_loss: 551.5319 - val_accuracy: 0.8154\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.1909 - accuracy: 0.7693 - val_loss: 559.4007 - val_accuracy: 0.8157\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.4156 - accuracy: 0.7686 - val_loss: 553.5964 - val_accuracy: 0.8148\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.3691 - accuracy: 0.7714 - val_loss: 552.7433 - val_accuracy: 0.8164\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.1473 - accuracy: 0.7678 - val_loss: 552.4191 - val_accuracy: 0.8171\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.4737 - accuracy: 0.7711 - val_loss: 551.3336 - val_accuracy: 0.8147\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.9044 - accuracy: 0.7726 - val_loss: 554.1156 - val_accuracy: 0.8147\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.3737 - accuracy: 0.7707 - val_loss: 552.3708 - val_accuracy: 0.8131\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 719.4682 - accuracy: 0.7715 - val_loss: 553.9127 - val_accuracy: 0.8147\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 725.4772 - accuracy: 0.7716 - val_loss: 560.7820 - val_accuracy: 0.8162\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 718.1783 - accuracy: 0.7708 - val_loss: 553.2217 - val_accuracy: 0.8130\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 719.7300 - accuracy: 0.7704 - val_loss: 551.4196 - val_accuracy: 0.8159\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 730.8179 - accuracy: 0.7649 - val_loss: 581.6423 - val_accuracy: 0.8114\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 721.6172 - accuracy: 0.7673 - val_loss: 551.7711 - val_accuracy: 0.8156\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 714.9327 - accuracy: 0.7719 - val_loss: 554.7445 - val_accuracy: 0.8144\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 714.6284 - accuracy: 0.7718 - val_loss: 550.4567 - val_accuracy: 0.8155\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 718.3358 - accuracy: 0.7740 - val_loss: 557.7187 - val_accuracy: 0.8137\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 717.3647 - accuracy: 0.7703 - val_loss: 551.5671 - val_accuracy: 0.8163\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 715.8138 - accuracy: 0.7737 - val_loss: 556.0276 - val_accuracy: 0.8160\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 727.4805 - accuracy: 0.7716 - val_loss: 570.5941 - val_accuracy: 0.8155\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 730.0575 - accuracy: 0.7699 - val_loss: 580.4201 - val_accuracy: 0.8133\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 721.2484 - accuracy: 0.7714 - val_loss: 551.8844 - val_accuracy: 0.8152\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 715.2913 - accuracy: 0.7715 - val_loss: 558.2230 - val_accuracy: 0.8150\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 714.0029 - accuracy: 0.7734 - val_loss: 550.8002 - val_accuracy: 0.8148\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 712.3697 - accuracy: 0.7722 - val_loss: 550.3636 - val_accuracy: 0.8158\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 712.0515 - accuracy: 0.7714 - val_loss: 552.0319 - val_accuracy: 0.8143\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 712.0597 - accuracy: 0.7739 - val_loss: 550.9392 - val_accuracy: 0.8153\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.4646 - accuracy: 0.7741 - val_loss: 549.8530 - val_accuracy: 0.8147\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.2203 - accuracy: 0.7726 - val_loss: 558.6679 - val_accuracy: 0.8158\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.4439 - accuracy: 0.7745 - val_loss: 553.5148 - val_accuracy: 0.8161\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 714.0138 - accuracy: 0.7706 - val_loss: 553.7690 - val_accuracy: 0.8174\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.6858 - accuracy: 0.7732 - val_loss: 552.6249 - val_accuracy: 0.8150\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.7020 - accuracy: 0.7731 - val_loss: 551.0061 - val_accuracy: 0.8186\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.9221 - accuracy: 0.7729 - val_loss: 553.2440 - val_accuracy: 0.8152\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.6300 - accuracy: 0.7732 - val_loss: 551.6308 - val_accuracy: 0.8159\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.4103 - accuracy: 0.7742 - val_loss: 553.0339 - val_accuracy: 0.8167\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 713.5746 - accuracy: 0.7734 - val_loss: 549.4368 - val_accuracy: 0.8162\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 712.0734 - accuracy: 0.7744 - val_loss: 550.8080 - val_accuracy: 0.8164\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.9709 - accuracy: 0.7716 - val_loss: 555.6536 - val_accuracy: 0.8139\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.9455 - accuracy: 0.7720 - val_loss: 562.5078 - val_accuracy: 0.8121\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.6808 - accuracy: 0.7720 - val_loss: 551.1453 - val_accuracy: 0.8150\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.0465 - accuracy: 0.7707 - val_loss: 555.7009 - val_accuracy: 0.8136\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 720.6783 - accuracy: 0.7716 - val_loss: 555.1209 - val_accuracy: 0.8129\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.9229 - accuracy: 0.7707 - val_loss: 550.0839 - val_accuracy: 0.8158\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.1790 - accuracy: 0.7715 - val_loss: 549.5354 - val_accuracy: 0.8156\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 712.0447 - accuracy: 0.7733 - val_loss: 549.7878 - val_accuracy: 0.8167\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.2418 - accuracy: 0.7725 - val_loss: 550.5278 - val_accuracy: 0.8177\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.0488 - accuracy: 0.7757 - val_loss: 549.9286 - val_accuracy: 0.8152\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.7374 - accuracy: 0.7729 - val_loss: 552.0880 - val_accuracy: 0.8144\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.7448 - accuracy: 0.7719 - val_loss: 551.7852 - val_accuracy: 0.8156\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.6564 - accuracy: 0.7714 - val_loss: 552.1946 - val_accuracy: 0.8140\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.4761 - accuracy: 0.7721 - val_loss: 552.0732 - val_accuracy: 0.8144\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.4226 - accuracy: 0.7753 - val_loss: 550.0168 - val_accuracy: 0.8145\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.4675 - accuracy: 0.7708 - val_loss: 560.9564 - val_accuracy: 0.8143\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.2442 - accuracy: 0.7721 - val_loss: 549.8359 - val_accuracy: 0.8164\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 712.1947 - accuracy: 0.7735 - val_loss: 549.8688 - val_accuracy: 0.8172\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 713.3003 - accuracy: 0.7734 - val_loss: 550.2629 - val_accuracy: 0.8161\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.1624 - accuracy: 0.7728 - val_loss: 551.4659 - val_accuracy: 0.8139\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.7054 - accuracy: 0.7735 - val_loss: 548.7399 - val_accuracy: 0.8163\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 710.4320 - accuracy: 0.7750 - val_loss: 551.6475 - val_accuracy: 0.8130\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 711.3457 - accuracy: 0.7737 - val_loss: 548.6633 - val_accuracy: 0.8163\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 710.4180 - accuracy: 0.7742 - val_loss: 549.9887 - val_accuracy: 0.8166\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.5421 - accuracy: 0.7730 - val_loss: 562.5797 - val_accuracy: 0.8131\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.1482 - accuracy: 0.7726 - val_loss: 549.8511 - val_accuracy: 0.8138\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.9932 - accuracy: 0.7710 - val_loss: 551.7101 - val_accuracy: 0.8175\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.2134 - accuracy: 0.7726 - val_loss: 550.9683 - val_accuracy: 0.8180\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 712.0265 - accuracy: 0.7748 - val_loss: 552.3058 - val_accuracy: 0.8166\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.3993 - accuracy: 0.7723 - val_loss: 551.0320 - val_accuracy: 0.8139\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.1739 - accuracy: 0.7749 - val_loss: 561.7169 - val_accuracy: 0.8131\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 724.3733 - accuracy: 0.7723 - val_loss: 555.0839 - val_accuracy: 0.8139\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.1719 - accuracy: 0.7731 - val_loss: 553.5363 - val_accuracy: 0.8167\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.1635 - accuracy: 0.7716 - val_loss: 551.9636 - val_accuracy: 0.8138\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.6488 - accuracy: 0.7743 - val_loss: 550.9662 - val_accuracy: 0.8134\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.5537 - accuracy: 0.7709 - val_loss: 549.7898 - val_accuracy: 0.8148\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 713.0303 - accuracy: 0.7739 - val_loss: 549.9904 - val_accuracy: 0.8145\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 711.5013 - accuracy: 0.7726 - val_loss: 548.9779 - val_accuracy: 0.8162\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 710.1982 - accuracy: 0.7752 - val_loss: 548.4381 - val_accuracy: 0.8170\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.5893 - accuracy: 0.7739 - val_loss: 551.5079 - val_accuracy: 0.8153\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.5258 - accuracy: 0.7739 - val_loss: 551.2076 - val_accuracy: 0.8164\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.2012 - accuracy: 0.7743 - val_loss: 554.7516 - val_accuracy: 0.8167\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.1894 - accuracy: 0.7728 - val_loss: 553.1088 - val_accuracy: 0.8168\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 718.2629 - accuracy: 0.7731 - val_loss: 551.5182 - val_accuracy: 0.8181\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.2203 - accuracy: 0.7732 - val_loss: 551.2438 - val_accuracy: 0.8140\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.5176 - accuracy: 0.7714 - val_loss: 550.3172 - val_accuracy: 0.8141\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.7386 - accuracy: 0.7726 - val_loss: 551.0235 - val_accuracy: 0.8136\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.1485 - accuracy: 0.7735 - val_loss: 556.2706 - val_accuracy: 0.8139\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.5071 - accuracy: 0.7744 - val_loss: 551.7723 - val_accuracy: 0.8157\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.5538 - accuracy: 0.7742 - val_loss: 550.3450 - val_accuracy: 0.8177\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.8545 - accuracy: 0.7747 - val_loss: 549.4041 - val_accuracy: 0.8139\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.3014 - accuracy: 0.7740 - val_loss: 549.9183 - val_accuracy: 0.8157\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 712.5381 - accuracy: 0.7743 - val_loss: 553.5820 - val_accuracy: 0.8120\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.3196 - accuracy: 0.7707 - val_loss: 547.9377 - val_accuracy: 0.8174\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.7424 - accuracy: 0.7751 - val_loss: 550.9470 - val_accuracy: 0.8166\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 711.0970 - accuracy: 0.7734 - val_loss: 548.0958 - val_accuracy: 0.8178\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.6983 - accuracy: 0.7750 - val_loss: 550.4890 - val_accuracy: 0.8179\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 713.6787 - accuracy: 0.7732 - val_loss: 552.9317 - val_accuracy: 0.8165\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.1064 - accuracy: 0.7726 - val_loss: 551.6190 - val_accuracy: 0.8133\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.8524 - accuracy: 0.7737 - val_loss: 554.6859 - val_accuracy: 0.8178\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 715.7158 - accuracy: 0.7749 - val_loss: 553.4964 - val_accuracy: 0.8166\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.5388 - accuracy: 0.7734 - val_loss: 550.5801 - val_accuracy: 0.8142\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.2628 - accuracy: 0.7745 - val_loss: 569.0563 - val_accuracy: 0.8141\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 725.1840 - accuracy: 0.7725 - val_loss: 556.9570 - val_accuracy: 0.8169\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.3922 - accuracy: 0.7735 - val_loss: 551.4026 - val_accuracy: 0.8115\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.9089 - accuracy: 0.7733 - val_loss: 548.8832 - val_accuracy: 0.8161\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.1265 - accuracy: 0.7750 - val_loss: 565.5599 - val_accuracy: 0.8135\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 729.8427 - accuracy: 0.7730 - val_loss: 582.3505 - val_accuracy: 0.8123\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 725.5830 - accuracy: 0.7744 - val_loss: 554.6786 - val_accuracy: 0.8159\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 729.5273 - accuracy: 0.7738 - val_loss: 554.5878 - val_accuracy: 0.8159\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.3312 - accuracy: 0.7729 - val_loss: 562.0944 - val_accuracy: 0.8170\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 719.9794 - accuracy: 0.7721 - val_loss: 554.9390 - val_accuracy: 0.8134\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.7271 - accuracy: 0.7743 - val_loss: 552.6813 - val_accuracy: 0.8134\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 715.3817 - accuracy: 0.7752 - val_loss: 551.1669 - val_accuracy: 0.8164\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.0823 - accuracy: 0.7753 - val_loss: 554.5055 - val_accuracy: 0.8167\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 713.3307 - accuracy: 0.7747 - val_loss: 548.6832 - val_accuracy: 0.8164\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 712.0484 - accuracy: 0.7742 - val_loss: 554.5553 - val_accuracy: 0.8146\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.9070 - accuracy: 0.7718 - val_loss: 552.9386 - val_accuracy: 0.8138\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.2303 - accuracy: 0.7734 - val_loss: 553.8643 - val_accuracy: 0.8150\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.3859 - accuracy: 0.7740 - val_loss: 549.7996 - val_accuracy: 0.8172\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 714.1177 - accuracy: 0.7743 - val_loss: 551.4023 - val_accuracy: 0.8158\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.8700 - accuracy: 0.7753 - val_loss: 548.9134 - val_accuracy: 0.8149\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.0608 - accuracy: 0.7765 - val_loss: 549.9822 - val_accuracy: 0.8187\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 713.4693 - accuracy: 0.7729 - val_loss: 562.4688 - val_accuracy: 0.8175\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 730.9498 - accuracy: 0.7720 - val_loss: 554.0609 - val_accuracy: 0.8140\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.9655 - accuracy: 0.7723 - val_loss: 552.5274 - val_accuracy: 0.8142\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.2923 - accuracy: 0.7703 - val_loss: 549.6812 - val_accuracy: 0.8153\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 711.9720 - accuracy: 0.7767 - val_loss: 549.0762 - val_accuracy: 0.8119\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.6266 - accuracy: 0.7734 - val_loss: 552.6739 - val_accuracy: 0.8173\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 716.8375 - accuracy: 0.7740 - val_loss: 559.3120 - val_accuracy: 0.8140\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.6637 - accuracy: 0.7751 - val_loss: 550.3359 - val_accuracy: 0.8172\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.1126 - accuracy: 0.7753 - val_loss: 549.5876 - val_accuracy: 0.8134\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 710.9322 - accuracy: 0.7749 - val_loss: 549.1373 - val_accuracy: 0.8167\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 710.5265 - accuracy: 0.7753 - val_loss: 551.5113 - val_accuracy: 0.8155\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.4741 - accuracy: 0.7737 - val_loss: 557.3015 - val_accuracy: 0.8182\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 716.2640 - accuracy: 0.7741 - val_loss: 553.4092 - val_accuracy: 0.8169\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.7844 - accuracy: 0.7746 - val_loss: 549.2226 - val_accuracy: 0.8165\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 713.1180 - accuracy: 0.7742 - val_loss: 549.8341 - val_accuracy: 0.8150\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 710.9156 - accuracy: 0.7762 - val_loss: 549.7618 - val_accuracy: 0.8167\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 713.6132 - accuracy: 0.7743 - val_loss: 549.3098 - val_accuracy: 0.8175\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 713.0939 - accuracy: 0.7739 - val_loss: 553.5948 - val_accuracy: 0.8162\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.1179 - accuracy: 0.7730 - val_loss: 553.3359 - val_accuracy: 0.8142\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.1842 - accuracy: 0.7753 - val_loss: 548.8627 - val_accuracy: 0.8145\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.2322 - accuracy: 0.7721 - val_loss: 556.2038 - val_accuracy: 0.8160\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.2783 - accuracy: 0.7742 - val_loss: 548.4241 - val_accuracy: 0.8165\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.1064 - accuracy: 0.7745 - val_loss: 548.9466 - val_accuracy: 0.8178\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.1708 - accuracy: 0.7753 - val_loss: 549.8766 - val_accuracy: 0.8181\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 714.5660 - accuracy: 0.7736 - val_loss: 550.5797 - val_accuracy: 0.8150\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.6299 - accuracy: 0.7722 - val_loss: 555.6813 - val_accuracy: 0.8162\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.4978 - accuracy: 0.7743 - val_loss: 552.7412 - val_accuracy: 0.8150\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 711.7546 - accuracy: 0.7763 - val_loss: 550.3443 - val_accuracy: 0.8177\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.3447 - accuracy: 0.7757 - val_loss: 548.6823 - val_accuracy: 0.8150\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 711.7571 - accuracy: 0.7732 - val_loss: 597.9013 - val_accuracy: 0.8078\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 731.2560 - accuracy: 0.7702 - val_loss: 558.8533 - val_accuracy: 0.8149\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 719.0352 - accuracy: 0.7732 - val_loss: 551.0563 - val_accuracy: 0.8162\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.5704 - accuracy: 0.7755 - val_loss: 553.0579 - val_accuracy: 0.8167\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 713.3686 - accuracy: 0.7728 - val_loss: 549.9012 - val_accuracy: 0.8178\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 712.9051 - accuracy: 0.7734 - val_loss: 559.6273 - val_accuracy: 0.8184\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.6415 - accuracy: 0.7746 - val_loss: 557.5630 - val_accuracy: 0.8128\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.5943 - accuracy: 0.7756 - val_loss: 550.5204 - val_accuracy: 0.8151\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.0342 - accuracy: 0.7746 - val_loss: 548.1484 - val_accuracy: 0.8144\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.2065 - accuracy: 0.7681 - val_loss: 557.4390 - val_accuracy: 0.8188\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.7914 - accuracy: 0.7752 - val_loss: 553.8748 - val_accuracy: 0.8132\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 712.3991 - accuracy: 0.7754 - val_loss: 548.4313 - val_accuracy: 0.8163\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 709.9636 - accuracy: 0.7742 - val_loss: 547.3885 - val_accuracy: 0.8173\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.2878 - accuracy: 0.7739 - val_loss: 547.3493 - val_accuracy: 0.8160\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "# Upsample the second input image\n",
        "upsampled = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Combine the two input images using a convolutional layer\n",
        "combined = layers.Conv2D(31, kernel_size=1, activation='relu')(upsampled)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(combined)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "#conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "#pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer = layers.Conv2D(31, kernel_size=1, activation='relu')(pool2)\n",
        "# Define the model\n",
        "modelnew = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "# Compile the model\n",
        "modelnew.compile(optimizer='adam',\n",
        "loss='mean_absolute_error',\n",
        "metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = modelnew.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luHE9wSGtbJt",
        "outputId": "e84b7cfa-bed9-45de-985f-f1f7ee063fde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 8205.8887 - accuracy: 0.1756 - val_loss: 5133.1982 - val_accuracy: 0.4311\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 5697.8594 - accuracy: 0.1856 - val_loss: 3845.3735 - val_accuracy: 0.0637\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 3660.8098 - accuracy: 0.0735 - val_loss: 2418.3186 - val_accuracy: 0.0130\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 2599.0193 - accuracy: 0.0389 - val_loss: 2033.6927 - val_accuracy: 0.4663\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 2073.4456 - accuracy: 0.3346 - val_loss: 1557.4309 - val_accuracy: 0.5234\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1601.0797 - accuracy: 0.3709 - val_loss: 1193.1044 - val_accuracy: 0.5077\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1377.4703 - accuracy: 0.2665 - val_loss: 1033.9315 - val_accuracy: 0.4799\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1201.1017 - accuracy: 0.4585 - val_loss: 921.3199 - val_accuracy: 0.5668\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1075.7788 - accuracy: 0.5244 - val_loss: 827.2490 - val_accuracy: 0.5829\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 985.4811 - accuracy: 0.5021 - val_loss: 790.1908 - val_accuracy: 0.6254\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 924.8333 - accuracy: 0.5729 - val_loss: 767.6396 - val_accuracy: 0.6126\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 901.3779 - accuracy: 0.5875 - val_loss: 731.0128 - val_accuracy: 0.6073\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 881.8832 - accuracy: 0.6047 - val_loss: 702.7578 - val_accuracy: 0.6120\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 854.4457 - accuracy: 0.6127 - val_loss: 680.6201 - val_accuracy: 0.6384\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 827.0902 - accuracy: 0.6202 - val_loss: 668.2235 - val_accuracy: 0.6196\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 812.6760 - accuracy: 0.6422 - val_loss: 640.3068 - val_accuracy: 0.6122\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 802.8680 - accuracy: 0.6405 - val_loss: 666.3832 - val_accuracy: 0.6163\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 800.9626 - accuracy: 0.6457 - val_loss: 630.1494 - val_accuracy: 0.6657\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 773.1241 - accuracy: 0.6706 - val_loss: 612.6984 - val_accuracy: 0.6932\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 761.3587 - accuracy: 0.6878 - val_loss: 604.5043 - val_accuracy: 0.7114\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 750.2997 - accuracy: 0.6791 - val_loss: 601.4762 - val_accuracy: 0.6999\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 742.0931 - accuracy: 0.6914 - val_loss: 592.5419 - val_accuracy: 0.7210\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 736.3701 - accuracy: 0.6963 - val_loss: 581.8472 - val_accuracy: 0.7156\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 727.8378 - accuracy: 0.6920 - val_loss: 579.7728 - val_accuracy: 0.7286\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.9794 - accuracy: 0.6949 - val_loss: 570.0951 - val_accuracy: 0.7369\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 712.9557 - accuracy: 0.6946 - val_loss: 567.6254 - val_accuracy: 0.7165\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 707.7576 - accuracy: 0.6968 - val_loss: 568.8805 - val_accuracy: 0.7357\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.4356 - accuracy: 0.6901 - val_loss: 565.2913 - val_accuracy: 0.7470\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 694.4705 - accuracy: 0.7026 - val_loss: 564.5053 - val_accuracy: 0.7465\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 696.0199 - accuracy: 0.6998 - val_loss: 554.2305 - val_accuracy: 0.7022\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 691.3667 - accuracy: 0.6972 - val_loss: 555.5079 - val_accuracy: 0.7400\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 686.6636 - accuracy: 0.7009 - val_loss: 554.1176 - val_accuracy: 0.7333\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 688.8606 - accuracy: 0.6926 - val_loss: 554.2871 - val_accuracy: 0.7334\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 673.2569 - accuracy: 0.7043 - val_loss: 550.4391 - val_accuracy: 0.7494\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 670.2995 - accuracy: 0.7005 - val_loss: 553.7836 - val_accuracy: 0.7444\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 664.2511 - accuracy: 0.7094 - val_loss: 543.8376 - val_accuracy: 0.7436\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 680.2887 - accuracy: 0.7064 - val_loss: 571.5488 - val_accuracy: 0.7246\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 666.1310 - accuracy: 0.7054 - val_loss: 542.8664 - val_accuracy: 0.7349\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 654.7164 - accuracy: 0.7119 - val_loss: 532.6614 - val_accuracy: 0.7435\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 645.5001 - accuracy: 0.7135 - val_loss: 531.0709 - val_accuracy: 0.7381\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 642.6196 - accuracy: 0.7052 - val_loss: 528.6445 - val_accuracy: 0.7464\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 640.7937 - accuracy: 0.7130 - val_loss: 526.6445 - val_accuracy: 0.7374\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 636.7638 - accuracy: 0.7170 - val_loss: 524.7932 - val_accuracy: 0.7587\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 629.3769 - accuracy: 0.7220 - val_loss: 522.1984 - val_accuracy: 0.7309\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 625.7631 - accuracy: 0.7149 - val_loss: 517.0107 - val_accuracy: 0.7632\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 620.3013 - accuracy: 0.7208 - val_loss: 520.0055 - val_accuracy: 0.6953\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 618.2692 - accuracy: 0.7149 - val_loss: 513.5895 - val_accuracy: 0.7558\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 614.4120 - accuracy: 0.7211 - val_loss: 511.7010 - val_accuracy: 0.7457\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 613.2327 - accuracy: 0.7176 - val_loss: 515.4541 - val_accuracy: 0.7447\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 612.6593 - accuracy: 0.7230 - val_loss: 512.4288 - val_accuracy: 0.7638\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 613.2896 - accuracy: 0.7242 - val_loss: 509.8133 - val_accuracy: 0.7349\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 604.9941 - accuracy: 0.7169 - val_loss: 511.8862 - val_accuracy: 0.7632\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 607.4033 - accuracy: 0.7248 - val_loss: 507.6754 - val_accuracy: 0.7259\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 605.1154 - accuracy: 0.7186 - val_loss: 511.2139 - val_accuracy: 0.7203\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 603.1847 - accuracy: 0.7189 - val_loss: 506.6681 - val_accuracy: 0.7643\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 595.5671 - accuracy: 0.7278 - val_loss: 501.6921 - val_accuracy: 0.7273\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 593.1669 - accuracy: 0.7213 - val_loss: 503.5459 - val_accuracy: 0.7636\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 611.7897 - accuracy: 0.7222 - val_loss: 503.4664 - val_accuracy: 0.7684\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 590.2790 - accuracy: 0.7302 - val_loss: 497.4795 - val_accuracy: 0.7518\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 585.3211 - accuracy: 0.7269 - val_loss: 495.7200 - val_accuracy: 0.7512\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 583.2825 - accuracy: 0.7261 - val_loss: 495.3000 - val_accuracy: 0.7317\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 585.1894 - accuracy: 0.7267 - val_loss: 496.2034 - val_accuracy: 0.7723\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 577.4849 - accuracy: 0.7282 - val_loss: 491.6352 - val_accuracy: 0.7730\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 573.8002 - accuracy: 0.7289 - val_loss: 491.6291 - val_accuracy: 0.7576\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 580.6078 - accuracy: 0.7309 - val_loss: 495.3022 - val_accuracy: 0.7700\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 580.7455 - accuracy: 0.7330 - val_loss: 495.7151 - val_accuracy: 0.7702\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 576.2433 - accuracy: 0.7299 - val_loss: 492.5986 - val_accuracy: 0.7606\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 590.3069 - accuracy: 0.7361 - val_loss: 527.3890 - val_accuracy: 0.7523\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 595.2487 - accuracy: 0.7319 - val_loss: 521.2004 - val_accuracy: 0.7779\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 582.0689 - accuracy: 0.7299 - val_loss: 498.9304 - val_accuracy: 0.7703\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 569.8972 - accuracy: 0.7352 - val_loss: 483.7426 - val_accuracy: 0.7701\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 564.6182 - accuracy: 0.7323 - val_loss: 492.0981 - val_accuracy: 0.7614\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 566.1042 - accuracy: 0.7295 - val_loss: 508.2180 - val_accuracy: 0.7696\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 569.7998 - accuracy: 0.7347 - val_loss: 481.6102 - val_accuracy: 0.7790\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 559.9540 - accuracy: 0.7362 - val_loss: 483.2208 - val_accuracy: 0.7621\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 556.2158 - accuracy: 0.7385 - val_loss: 483.3989 - val_accuracy: 0.7777\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 557.8864 - accuracy: 0.7323 - val_loss: 490.4656 - val_accuracy: 0.7699\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 555.1470 - accuracy: 0.7404 - val_loss: 483.2676 - val_accuracy: 0.7703\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 551.5317 - accuracy: 0.7368 - val_loss: 478.9669 - val_accuracy: 0.7796\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 549.8248 - accuracy: 0.7398 - val_loss: 486.8923 - val_accuracy: 0.7727\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 562.7175 - accuracy: 0.7320 - val_loss: 477.8923 - val_accuracy: 0.7783\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 573.5355 - accuracy: 0.7333 - val_loss: 496.2781 - val_accuracy: 0.7829\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 567.0923 - accuracy: 0.7426 - val_loss: 485.4282 - val_accuracy: 0.7763\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 569.9755 - accuracy: 0.7344 - val_loss: 494.2231 - val_accuracy: 0.7737\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 564.4193 - accuracy: 0.7403 - val_loss: 507.4842 - val_accuracy: 0.7787\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 552.0095 - accuracy: 0.7423 - val_loss: 475.6334 - val_accuracy: 0.7865\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 542.9796 - accuracy: 0.7418 - val_loss: 473.9866 - val_accuracy: 0.7824\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 538.8033 - accuracy: 0.7386 - val_loss: 471.4698 - val_accuracy: 0.7822\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 537.2706 - accuracy: 0.7394 - val_loss: 474.0480 - val_accuracy: 0.7815\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 536.6159 - accuracy: 0.7426 - val_loss: 471.0274 - val_accuracy: 0.7869\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 537.9493 - accuracy: 0.7438 - val_loss: 475.6237 - val_accuracy: 0.7831\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 535.5823 - accuracy: 0.7437 - val_loss: 469.0092 - val_accuracy: 0.7788\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 548.6643 - accuracy: 0.7454 - val_loss: 501.2149 - val_accuracy: 0.7736\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 556.5736 - accuracy: 0.7477 - val_loss: 488.7798 - val_accuracy: 0.7847\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 537.8042 - accuracy: 0.7444 - val_loss: 472.7706 - val_accuracy: 0.7833\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 542.0942 - accuracy: 0.7458 - val_loss: 478.6806 - val_accuracy: 0.7828\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 550.4080 - accuracy: 0.7438 - val_loss: 467.5399 - val_accuracy: 0.7865\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 530.5830 - accuracy: 0.7469 - val_loss: 460.9061 - val_accuracy: 0.7849\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 523.9551 - accuracy: 0.7489 - val_loss: 461.6275 - val_accuracy: 0.7876\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 525.7559 - accuracy: 0.7483 - val_loss: 461.5038 - val_accuracy: 0.7817\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 528.4034 - accuracy: 0.7395 - val_loss: 458.4691 - val_accuracy: 0.7883\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 519.4299 - accuracy: 0.7493 - val_loss: 466.2812 - val_accuracy: 0.7874\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 521.2158 - accuracy: 0.7512 - val_loss: 456.7848 - val_accuracy: 0.7870\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 520.9252 - accuracy: 0.7478 - val_loss: 463.3727 - val_accuracy: 0.7788\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 520.8702 - accuracy: 0.7496 - val_loss: 459.8668 - val_accuracy: 0.7851\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 520.7722 - accuracy: 0.7511 - val_loss: 459.7596 - val_accuracy: 0.7845\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 514.8224 - accuracy: 0.7528 - val_loss: 453.1184 - val_accuracy: 0.7872\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 512.9650 - accuracy: 0.7490 - val_loss: 455.9948 - val_accuracy: 0.7868\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 514.0172 - accuracy: 0.7454 - val_loss: 454.0199 - val_accuracy: 0.7946\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 513.0074 - accuracy: 0.7500 - val_loss: 451.5853 - val_accuracy: 0.7823\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 523.9749 - accuracy: 0.7474 - val_loss: 498.3143 - val_accuracy: 0.7860\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 525.3787 - accuracy: 0.7522 - val_loss: 464.2895 - val_accuracy: 0.7861\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 519.7889 - accuracy: 0.7539 - val_loss: 455.6572 - val_accuracy: 0.7880\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 510.4764 - accuracy: 0.7502 - val_loss: 450.0910 - val_accuracy: 0.7953\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 508.3250 - accuracy: 0.7529 - val_loss: 450.2374 - val_accuracy: 0.7869\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 507.1968 - accuracy: 0.7534 - val_loss: 448.4319 - val_accuracy: 0.7792\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 505.6082 - accuracy: 0.7521 - val_loss: 447.9286 - val_accuracy: 0.7904\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 504.2214 - accuracy: 0.7526 - val_loss: 445.1811 - val_accuracy: 0.7917\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 504.1186 - accuracy: 0.7532 - val_loss: 446.5680 - val_accuracy: 0.7888\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 508.7310 - accuracy: 0.7546 - val_loss: 464.1556 - val_accuracy: 0.7921\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 520.6366 - accuracy: 0.7525 - val_loss: 553.7827 - val_accuracy: 0.7936\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 568.7242 - accuracy: 0.7524 - val_loss: 534.3359 - val_accuracy: 0.7842\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 561.3593 - accuracy: 0.7488 - val_loss: 481.0165 - val_accuracy: 0.7922\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 548.9175 - accuracy: 0.7439 - val_loss: 578.9785 - val_accuracy: 0.7887\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 559.6223 - accuracy: 0.7566 - val_loss: 471.5999 - val_accuracy: 0.7954\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 519.3585 - accuracy: 0.7467 - val_loss: 448.3640 - val_accuracy: 0.7909\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 511.7986 - accuracy: 0.7538 - val_loss: 452.4120 - val_accuracy: 0.7945\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 505.5196 - accuracy: 0.7535 - val_loss: 441.4276 - val_accuracy: 0.7920\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 501.2207 - accuracy: 0.7566 - val_loss: 443.2886 - val_accuracy: 0.7925\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 505.4449 - accuracy: 0.7565 - val_loss: 442.9500 - val_accuracy: 0.7919\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 504.1892 - accuracy: 0.7570 - val_loss: 443.9144 - val_accuracy: 0.7935\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 500.3680 - accuracy: 0.7555 - val_loss: 441.6243 - val_accuracy: 0.7925\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 495.3912 - accuracy: 0.7546 - val_loss: 438.2689 - val_accuracy: 0.7891\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 495.3082 - accuracy: 0.7583 - val_loss: 441.7076 - val_accuracy: 0.7878\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 512.0600 - accuracy: 0.7549 - val_loss: 449.3964 - val_accuracy: 0.7869\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 497.6141 - accuracy: 0.7577 - val_loss: 437.7062 - val_accuracy: 0.7929\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 493.8128 - accuracy: 0.7591 - val_loss: 440.5869 - val_accuracy: 0.7956\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 501.6024 - accuracy: 0.7594 - val_loss: 445.2526 - val_accuracy: 0.7882\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 507.4945 - accuracy: 0.7556 - val_loss: 457.3245 - val_accuracy: 0.7974\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 521.1259 - accuracy: 0.7560 - val_loss: 461.3072 - val_accuracy: 0.7898\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 508.6074 - accuracy: 0.7494 - val_loss: 448.5940 - val_accuracy: 0.7844\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 511.0524 - accuracy: 0.7604 - val_loss: 436.3995 - val_accuracy: 0.7909\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 496.9069 - accuracy: 0.7611 - val_loss: 442.5641 - val_accuracy: 0.7939\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 493.7379 - accuracy: 0.7585 - val_loss: 433.0477 - val_accuracy: 0.7925\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 491.2419 - accuracy: 0.7600 - val_loss: 435.4123 - val_accuracy: 0.7931\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 490.2435 - accuracy: 0.7580 - val_loss: 435.5353 - val_accuracy: 0.7928\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 490.8726 - accuracy: 0.7615 - val_loss: 434.1618 - val_accuracy: 0.7937\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 489.9115 - accuracy: 0.7582 - val_loss: 433.6052 - val_accuracy: 0.7925\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 498.1165 - accuracy: 0.7587 - val_loss: 440.6324 - val_accuracy: 0.7840\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 498.5717 - accuracy: 0.7572 - val_loss: 442.0249 - val_accuracy: 0.7897\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 493.3831 - accuracy: 0.7593 - val_loss: 441.8023 - val_accuracy: 0.7902\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 491.1135 - accuracy: 0.7597 - val_loss: 437.9471 - val_accuracy: 0.7908\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 488.0872 - accuracy: 0.7592 - val_loss: 431.1482 - val_accuracy: 0.7911\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 486.1036 - accuracy: 0.7623 - val_loss: 435.1732 - val_accuracy: 0.7959\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 489.2585 - accuracy: 0.7572 - val_loss: 469.4535 - val_accuracy: 0.7897\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 499.7418 - accuracy: 0.7602 - val_loss: 459.3126 - val_accuracy: 0.7946\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 497.5025 - accuracy: 0.7583 - val_loss: 447.6245 - val_accuracy: 0.7941\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 495.6666 - accuracy: 0.7569 - val_loss: 431.3776 - val_accuracy: 0.7928\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 486.1289 - accuracy: 0.7590 - val_loss: 433.1536 - val_accuracy: 0.7941\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 484.3273 - accuracy: 0.7608 - val_loss: 428.3105 - val_accuracy: 0.7918\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 484.1893 - accuracy: 0.7578 - val_loss: 432.0545 - val_accuracy: 0.7910\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 482.8221 - accuracy: 0.7626 - val_loss: 440.0051 - val_accuracy: 0.7933\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 487.4471 - accuracy: 0.7618 - val_loss: 430.3534 - val_accuracy: 0.7950\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 479.9314 - accuracy: 0.7627 - val_loss: 426.5249 - val_accuracy: 0.7911\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 481.6797 - accuracy: 0.7599 - val_loss: 427.2964 - val_accuracy: 0.7961\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 480.2277 - accuracy: 0.7620 - val_loss: 427.0493 - val_accuracy: 0.7954\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 478.6910 - accuracy: 0.7604 - val_loss: 427.0937 - val_accuracy: 0.7947\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 478.7549 - accuracy: 0.7601 - val_loss: 431.1124 - val_accuracy: 0.7946\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 478.4571 - accuracy: 0.7625 - val_loss: 428.6367 - val_accuracy: 0.8007\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 480.4793 - accuracy: 0.7603 - val_loss: 422.5966 - val_accuracy: 0.7921\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 476.4052 - accuracy: 0.7637 - val_loss: 430.6309 - val_accuracy: 0.7970\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 480.5750 - accuracy: 0.7643 - val_loss: 425.5056 - val_accuracy: 0.7953\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 485.8698 - accuracy: 0.7654 - val_loss: 424.9159 - val_accuracy: 0.7932\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 483.9299 - accuracy: 0.7623 - val_loss: 426.6900 - val_accuracy: 0.7868\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 482.7612 - accuracy: 0.7634 - val_loss: 436.6028 - val_accuracy: 0.7947\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 507.1459 - accuracy: 0.7606 - val_loss: 432.5280 - val_accuracy: 0.7952\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 489.2790 - accuracy: 0.7645 - val_loss: 439.9980 - val_accuracy: 0.7933\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 484.5987 - accuracy: 0.7641 - val_loss: 430.6871 - val_accuracy: 0.7999\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 485.1928 - accuracy: 0.7606 - val_loss: 428.9720 - val_accuracy: 0.7900\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 493.6198 - accuracy: 0.7638 - val_loss: 461.7016 - val_accuracy: 0.7930\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 507.4012 - accuracy: 0.7636 - val_loss: 425.0053 - val_accuracy: 0.7910\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 483.8969 - accuracy: 0.7640 - val_loss: 427.6160 - val_accuracy: 0.7973\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 475.2294 - accuracy: 0.7631 - val_loss: 434.3178 - val_accuracy: 0.7934\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 492.4149 - accuracy: 0.7649 - val_loss: 435.2285 - val_accuracy: 0.7899\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 487.3375 - accuracy: 0.7646 - val_loss: 435.3078 - val_accuracy: 0.7979\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 483.9630 - accuracy: 0.7626 - val_loss: 429.8864 - val_accuracy: 0.7955\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 479.4861 - accuracy: 0.7637 - val_loss: 421.4403 - val_accuracy: 0.7912\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 480.1495 - accuracy: 0.7620 - val_loss: 420.5812 - val_accuracy: 0.7926\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 479.4806 - accuracy: 0.7649 - val_loss: 423.1585 - val_accuracy: 0.7973\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 473.5043 - accuracy: 0.7640 - val_loss: 433.2064 - val_accuracy: 0.7920\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 492.7487 - accuracy: 0.7666 - val_loss: 424.7418 - val_accuracy: 0.7976\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 477.6137 - accuracy: 0.7607 - val_loss: 423.4389 - val_accuracy: 0.7944\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 472.3672 - accuracy: 0.7655 - val_loss: 417.8949 - val_accuracy: 0.7929\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 472.0738 - accuracy: 0.7639 - val_loss: 422.5776 - val_accuracy: 0.7918\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 469.8557 - accuracy: 0.7648 - val_loss: 417.5639 - val_accuracy: 0.7924\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 468.6177 - accuracy: 0.7643 - val_loss: 421.2227 - val_accuracy: 0.7947\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 480.6831 - accuracy: 0.7646 - val_loss: 417.2444 - val_accuracy: 0.7974\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 474.2355 - accuracy: 0.7666 - val_loss: 421.1245 - val_accuracy: 0.7925\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 470.3264 - accuracy: 0.7638 - val_loss: 416.3265 - val_accuracy: 0.7948\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 469.6208 - accuracy: 0.7642 - val_loss: 416.7844 - val_accuracy: 0.7944\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 468.4404 - accuracy: 0.7664 - val_loss: 416.3613 - val_accuracy: 0.7963\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 468.9079 - accuracy: 0.7652 - val_loss: 415.2489 - val_accuracy: 0.7955\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 466.8378 - accuracy: 0.7660 - val_loss: 415.6777 - val_accuracy: 0.7929\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 467.7851 - accuracy: 0.7637 - val_loss: 419.0624 - val_accuracy: 0.7978\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 469.5538 - accuracy: 0.7675 - val_loss: 415.6430 - val_accuracy: 0.7933\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 468.0223 - accuracy: 0.7644 - val_loss: 420.6160 - val_accuracy: 0.7940\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 470.4960 - accuracy: 0.7668 - val_loss: 420.7691 - val_accuracy: 0.7943\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 470.3699 - accuracy: 0.7639 - val_loss: 419.9933 - val_accuracy: 0.7954\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 469.7668 - accuracy: 0.7643 - val_loss: 415.6655 - val_accuracy: 0.7964\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 472.7781 - accuracy: 0.7660 - val_loss: 415.6369 - val_accuracy: 0.7976\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 470.7066 - accuracy: 0.7685 - val_loss: 422.2689 - val_accuracy: 0.7984\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 467.6793 - accuracy: 0.7648 - val_loss: 414.6519 - val_accuracy: 0.8009\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 467.5506 - accuracy: 0.7659 - val_loss: 413.4816 - val_accuracy: 0.7927\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 464.4981 - accuracy: 0.7650 - val_loss: 416.5535 - val_accuracy: 0.7941\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 465.5569 - accuracy: 0.7670 - val_loss: 413.8728 - val_accuracy: 0.7941\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 465.5193 - accuracy: 0.7664 - val_loss: 414.5027 - val_accuracy: 0.7953\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 463.0165 - accuracy: 0.7671 - val_loss: 415.7332 - val_accuracy: 0.7960\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 462.5782 - accuracy: 0.7659 - val_loss: 411.6165 - val_accuracy: 0.7943\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 463.0449 - accuracy: 0.7658 - val_loss: 410.4817 - val_accuracy: 0.7931\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 460.9912 - accuracy: 0.7673 - val_loss: 411.1259 - val_accuracy: 0.7959\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 460.2013 - accuracy: 0.7674 - val_loss: 411.4282 - val_accuracy: 0.7958\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 464.7080 - accuracy: 0.7668 - val_loss: 412.5662 - val_accuracy: 0.7945\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 463.9987 - accuracy: 0.7675 - val_loss: 419.7484 - val_accuracy: 0.7868\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 464.6325 - accuracy: 0.7663 - val_loss: 426.8206 - val_accuracy: 0.7944\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 467.4599 - accuracy: 0.7670 - val_loss: 411.2336 - val_accuracy: 0.7962\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 472.4909 - accuracy: 0.7671 - val_loss: 459.4150 - val_accuracy: 0.7906\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 494.4843 - accuracy: 0.7639 - val_loss: 424.0057 - val_accuracy: 0.8008\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 493.9121 - accuracy: 0.7626 - val_loss: 416.3797 - val_accuracy: 0.7979\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 493.8450 - accuracy: 0.7680 - val_loss: 449.5772 - val_accuracy: 0.7991\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 498.1825 - accuracy: 0.7627 - val_loss: 427.7285 - val_accuracy: 0.7904\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 480.4185 - accuracy: 0.7651 - val_loss: 420.1884 - val_accuracy: 0.8001\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 468.7053 - accuracy: 0.7668 - val_loss: 412.5106 - val_accuracy: 0.7953\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 461.9418 - accuracy: 0.7610 - val_loss: 412.0417 - val_accuracy: 0.7993\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 460.7423 - accuracy: 0.7660 - val_loss: 409.5836 - val_accuracy: 0.7979\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 457.8777 - accuracy: 0.7684 - val_loss: 408.7098 - val_accuracy: 0.7989\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 460.9937 - accuracy: 0.7676 - val_loss: 413.4311 - val_accuracy: 0.8003\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 462.9232 - accuracy: 0.7687 - val_loss: 409.5134 - val_accuracy: 0.7907\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 462.6714 - accuracy: 0.7639 - val_loss: 412.0203 - val_accuracy: 0.7970\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 469.1601 - accuracy: 0.7674 - val_loss: 418.0610 - val_accuracy: 0.8001\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 466.6136 - accuracy: 0.7663 - val_loss: 414.3867 - val_accuracy: 0.7968\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 465.2044 - accuracy: 0.7687 - val_loss: 413.5969 - val_accuracy: 0.7993\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 460.6378 - accuracy: 0.7658 - val_loss: 408.1669 - val_accuracy: 0.7907\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 462.6157 - accuracy: 0.7680 - val_loss: 418.8215 - val_accuracy: 0.7973\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 461.3471 - accuracy: 0.7668 - val_loss: 408.4722 - val_accuracy: 0.7952\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 458.7751 - accuracy: 0.7671 - val_loss: 406.3844 - val_accuracy: 0.7985\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 457.1740 - accuracy: 0.7690 - val_loss: 406.7327 - val_accuracy: 0.7950\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 456.6866 - accuracy: 0.7661 - val_loss: 406.7730 - val_accuracy: 0.7943\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 455.9889 - accuracy: 0.7674 - val_loss: 406.1709 - val_accuracy: 0.7929\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 456.7222 - accuracy: 0.7678 - val_loss: 409.7376 - val_accuracy: 0.7978\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 458.7634 - accuracy: 0.7671 - val_loss: 406.6300 - val_accuracy: 0.7933\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 456.2066 - accuracy: 0.7686 - val_loss: 406.9085 - val_accuracy: 0.7933\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 458.0285 - accuracy: 0.7659 - val_loss: 407.6724 - val_accuracy: 0.7933\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 456.0407 - accuracy: 0.7679 - val_loss: 414.9490 - val_accuracy: 0.7934\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 461.9496 - accuracy: 0.7682 - val_loss: 410.6556 - val_accuracy: 0.7952\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 466.8810 - accuracy: 0.7663 - val_loss: 452.7783 - val_accuracy: 0.7963\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 494.4926 - accuracy: 0.7642 - val_loss: 522.3629 - val_accuracy: 0.7926\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 504.0023 - accuracy: 0.7662 - val_loss: 423.9080 - val_accuracy: 0.7918\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 470.7129 - accuracy: 0.7594 - val_loss: 430.3234 - val_accuracy: 0.8036\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 479.2893 - accuracy: 0.7665 - val_loss: 407.9484 - val_accuracy: 0.8017\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 467.8167 - accuracy: 0.7618 - val_loss: 408.3710 - val_accuracy: 0.7960\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 459.0468 - accuracy: 0.7647 - val_loss: 408.7441 - val_accuracy: 0.7968\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 456.3754 - accuracy: 0.7673 - val_loss: 420.7874 - val_accuracy: 0.7917\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 459.5405 - accuracy: 0.7662 - val_loss: 404.5852 - val_accuracy: 0.7932\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 456.1464 - accuracy: 0.7660 - val_loss: 406.2540 - val_accuracy: 0.8018\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 455.9922 - accuracy: 0.7638 - val_loss: 407.9336 - val_accuracy: 0.7954\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 456.2818 - accuracy: 0.7681 - val_loss: 406.5380 - val_accuracy: 0.7857\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 457.1676 - accuracy: 0.7652 - val_loss: 416.5754 - val_accuracy: 0.7958\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 454.1595 - accuracy: 0.7656 - val_loss: 409.2572 - val_accuracy: 0.7846\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 453.0503 - accuracy: 0.7622 - val_loss: 407.5033 - val_accuracy: 0.7926\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 462.2965 - accuracy: 0.7664 - val_loss: 408.3937 - val_accuracy: 0.7931\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 465.2075 - accuracy: 0.7692 - val_loss: 425.1038 - val_accuracy: 0.7929\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 472.1727 - accuracy: 0.7660 - val_loss: 406.1280 - val_accuracy: 0.7941\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 459.2730 - accuracy: 0.7683 - val_loss: 416.1028 - val_accuracy: 0.7872\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 458.8555 - accuracy: 0.7679 - val_loss: 403.3589 - val_accuracy: 0.7893\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 453.3636 - accuracy: 0.7676 - val_loss: 416.4634 - val_accuracy: 0.7946\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 459.4828 - accuracy: 0.7648 - val_loss: 403.0368 - val_accuracy: 0.8002\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 455.0757 - accuracy: 0.7688 - val_loss: 404.0398 - val_accuracy: 0.7925\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 452.3493 - accuracy: 0.7675 - val_loss: 405.7957 - val_accuracy: 0.7939\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 451.3326 - accuracy: 0.7663 - val_loss: 402.5497 - val_accuracy: 0.7918\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 452.6744 - accuracy: 0.7673 - val_loss: 414.5951 - val_accuracy: 0.7974\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 454.2416 - accuracy: 0.7686 - val_loss: 404.8357 - val_accuracy: 0.8005\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 454.8349 - accuracy: 0.7698 - val_loss: 402.8544 - val_accuracy: 0.7948\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 448.9517 - accuracy: 0.7701 - val_loss: 406.8530 - val_accuracy: 0.7949\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 451.2065 - accuracy: 0.7702 - val_loss: 409.6284 - val_accuracy: 0.7985\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 453.3689 - accuracy: 0.7686 - val_loss: 405.1426 - val_accuracy: 0.7975\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 463.9366 - accuracy: 0.7661 - val_loss: 413.4579 - val_accuracy: 0.7923\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 453.7612 - accuracy: 0.7686 - val_loss: 402.6331 - val_accuracy: 0.7974\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 454.2328 - accuracy: 0.7676 - val_loss: 408.1545 - val_accuracy: 0.8018\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 462.2723 - accuracy: 0.7714 - val_loss: 407.3628 - val_accuracy: 0.7949\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 455.0228 - accuracy: 0.7675 - val_loss: 405.3102 - val_accuracy: 0.7892\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 450.9430 - accuracy: 0.7659 - val_loss: 403.3466 - val_accuracy: 0.7956\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 455.5769 - accuracy: 0.7684 - val_loss: 401.8262 - val_accuracy: 0.7848\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 449.4229 - accuracy: 0.7677 - val_loss: 418.2206 - val_accuracy: 0.7959\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 453.2589 - accuracy: 0.7676 - val_loss: 401.0372 - val_accuracy: 0.7982\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 450.3519 - accuracy: 0.7694 - val_loss: 405.6221 - val_accuracy: 0.7966\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 456.5931 - accuracy: 0.7704 - val_loss: 402.7768 - val_accuracy: 0.7925\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 460.6050 - accuracy: 0.7694 - val_loss: 421.6577 - val_accuracy: 0.7977\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 459.4026 - accuracy: 0.7687 - val_loss: 403.7013 - val_accuracy: 0.7980\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 452.4232 - accuracy: 0.7714 - val_loss: 404.9261 - val_accuracy: 0.7964\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 454.5847 - accuracy: 0.7678 - val_loss: 400.0471 - val_accuracy: 0.8011\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 451.3974 - accuracy: 0.7698 - val_loss: 401.6681 - val_accuracy: 0.7912\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 445.6727 - accuracy: 0.7689 - val_loss: 400.0168 - val_accuracy: 0.7923\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 447.7693 - accuracy: 0.7676 - val_loss: 399.8916 - val_accuracy: 0.7929\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 445.7299 - accuracy: 0.7694 - val_loss: 398.6993 - val_accuracy: 0.7936\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 443.7394 - accuracy: 0.7700 - val_loss: 401.2880 - val_accuracy: 0.7900\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 448.0589 - accuracy: 0.7697 - val_loss: 415.8726 - val_accuracy: 0.7991\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 472.0700 - accuracy: 0.7710 - val_loss: 404.8047 - val_accuracy: 0.8003\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 462.2256 - accuracy: 0.7695 - val_loss: 401.8424 - val_accuracy: 0.7872\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 455.5251 - accuracy: 0.7681 - val_loss: 430.1203 - val_accuracy: 0.7981\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 467.8151 - accuracy: 0.7684 - val_loss: 421.8116 - val_accuracy: 0.7922\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 467.1328 - accuracy: 0.7720 - val_loss: 415.8678 - val_accuracy: 0.7986\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 465.0956 - accuracy: 0.7693 - val_loss: 401.4633 - val_accuracy: 0.7946\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 461.0014 - accuracy: 0.7681 - val_loss: 409.2513 - val_accuracy: 0.7922\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 466.4500 - accuracy: 0.7689 - val_loss: 404.2558 - val_accuracy: 0.7920\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 458.4159 - accuracy: 0.7710 - val_loss: 405.9437 - val_accuracy: 0.8037\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 450.2839 - accuracy: 0.7686 - val_loss: 401.2533 - val_accuracy: 0.7939\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 448.7188 - accuracy: 0.7688 - val_loss: 408.5010 - val_accuracy: 0.7934\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 447.5869 - accuracy: 0.7685 - val_loss: 397.7344 - val_accuracy: 0.7983\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 443.4319 - accuracy: 0.7686 - val_loss: 397.3383 - val_accuracy: 0.7927\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 443.5014 - accuracy: 0.7703 - val_loss: 397.8157 - val_accuracy: 0.7926\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 444.0375 - accuracy: 0.7699 - val_loss: 397.2588 - val_accuracy: 0.7897\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 443.6219 - accuracy: 0.7682 - val_loss: 399.9331 - val_accuracy: 0.7984\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 445.4536 - accuracy: 0.7712 - val_loss: 399.8130 - val_accuracy: 0.7978\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 447.4181 - accuracy: 0.7671 - val_loss: 402.2893 - val_accuracy: 0.7964\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 457.1689 - accuracy: 0.7650 - val_loss: 401.5397 - val_accuracy: 0.7944\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 449.1303 - accuracy: 0.7670 - val_loss: 400.9335 - val_accuracy: 0.7993\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 446.9582 - accuracy: 0.7683 - val_loss: 412.1651 - val_accuracy: 0.7947\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 453.7712 - accuracy: 0.7663 - val_loss: 397.7609 - val_accuracy: 0.7974\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 442.0646 - accuracy: 0.7711 - val_loss: 404.8003 - val_accuracy: 0.7949\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 452.6757 - accuracy: 0.7694 - val_loss: 412.5928 - val_accuracy: 0.7919\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 448.1973 - accuracy: 0.7692 - val_loss: 402.7140 - val_accuracy: 0.7949\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 442.4287 - accuracy: 0.7665 - val_loss: 395.7223 - val_accuracy: 0.7911\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 440.5802 - accuracy: 0.7692 - val_loss: 397.7893 - val_accuracy: 0.7938\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 441.5170 - accuracy: 0.7704 - val_loss: 398.4191 - val_accuracy: 0.7979\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 442.7690 - accuracy: 0.7687 - val_loss: 398.8805 - val_accuracy: 0.7938\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 441.8901 - accuracy: 0.7695 - val_loss: 396.2816 - val_accuracy: 0.7974\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 439.2459 - accuracy: 0.7700 - val_loss: 394.8369 - val_accuracy: 0.7942\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 438.2370 - accuracy: 0.7701 - val_loss: 394.4029 - val_accuracy: 0.7970\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 437.6587 - accuracy: 0.7710 - val_loss: 395.2684 - val_accuracy: 0.7937\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 438.1093 - accuracy: 0.7698 - val_loss: 399.1283 - val_accuracy: 0.7948\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 440.2997 - accuracy: 0.7705 - val_loss: 397.6458 - val_accuracy: 0.7982\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 441.0692 - accuracy: 0.7699 - val_loss: 398.3286 - val_accuracy: 0.7944\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 441.6415 - accuracy: 0.7695 - val_loss: 400.2915 - val_accuracy: 0.7966\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 440.0271 - accuracy: 0.7671 - val_loss: 396.5043 - val_accuracy: 0.7968\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 442.3351 - accuracy: 0.7712 - val_loss: 396.0046 - val_accuracy: 0.8004\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 442.9756 - accuracy: 0.7695 - val_loss: 405.9453 - val_accuracy: 0.7995\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 444.5395 - accuracy: 0.7682 - val_loss: 392.7151 - val_accuracy: 0.8010\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 438.3558 - accuracy: 0.7717 - val_loss: 393.9052 - val_accuracy: 0.7988\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 436.8316 - accuracy: 0.7700 - val_loss: 394.2798 - val_accuracy: 0.7987\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 440.2466 - accuracy: 0.7696 - val_loss: 406.3574 - val_accuracy: 0.7990\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 450.2249 - accuracy: 0.7715 - val_loss: 411.4354 - val_accuracy: 0.7928\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 458.2676 - accuracy: 0.7699 - val_loss: 407.2403 - val_accuracy: 0.7968\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 444.9052 - accuracy: 0.7718 - val_loss: 392.8308 - val_accuracy: 0.7990\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 442.6914 - accuracy: 0.7698 - val_loss: 394.8992 - val_accuracy: 0.7957\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 442.8259 - accuracy: 0.7710 - val_loss: 395.4140 - val_accuracy: 0.7950\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 442.5769 - accuracy: 0.7688 - val_loss: 402.6324 - val_accuracy: 0.7988\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 443.5965 - accuracy: 0.7697 - val_loss: 402.3412 - val_accuracy: 0.7939\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 439.7323 - accuracy: 0.7698 - val_loss: 392.6981 - val_accuracy: 0.7978\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 434.9276 - accuracy: 0.7707 - val_loss: 392.8178 - val_accuracy: 0.7988\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 437.4887 - accuracy: 0.7703 - val_loss: 393.8008 - val_accuracy: 0.8000\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 440.2311 - accuracy: 0.7704 - val_loss: 394.8628 - val_accuracy: 0.8023\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 439.4844 - accuracy: 0.7684 - val_loss: 393.8356 - val_accuracy: 0.7960\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 437.7647 - accuracy: 0.7701 - val_loss: 394.9996 - val_accuracy: 0.7961\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 437.5752 - accuracy: 0.7693 - val_loss: 394.7510 - val_accuracy: 0.7965\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 438.4542 - accuracy: 0.7701 - val_loss: 392.7596 - val_accuracy: 0.7984\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 435.7885 - accuracy: 0.7716 - val_loss: 392.4763 - val_accuracy: 0.8035\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 446.8750 - accuracy: 0.7660 - val_loss: 400.5749 - val_accuracy: 0.7932\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 446.0983 - accuracy: 0.7703 - val_loss: 396.2743 - val_accuracy: 0.8008\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 443.9077 - accuracy: 0.7693 - val_loss: 395.7215 - val_accuracy: 0.7950\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 441.2907 - accuracy: 0.7693 - val_loss: 397.1011 - val_accuracy: 0.7957\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 436.3201 - accuracy: 0.7719 - val_loss: 391.3061 - val_accuracy: 0.8004\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 434.5080 - accuracy: 0.7716 - val_loss: 392.4759 - val_accuracy: 0.7991\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 433.3973 - accuracy: 0.7704 - val_loss: 390.2645 - val_accuracy: 0.7980\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 433.6314 - accuracy: 0.7719 - val_loss: 391.4513 - val_accuracy: 0.7960\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 456.1481 - accuracy: 0.7723 - val_loss: 433.9082 - val_accuracy: 0.7953\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 475.3868 - accuracy: 0.7695 - val_loss: 431.8634 - val_accuracy: 0.7898\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 453.7080 - accuracy: 0.7710 - val_loss: 409.1856 - val_accuracy: 0.7959\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 449.6245 - accuracy: 0.7707 - val_loss: 395.3499 - val_accuracy: 0.8012\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 450.7258 - accuracy: 0.7720 - val_loss: 400.1611 - val_accuracy: 0.7930\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 441.8676 - accuracy: 0.7691 - val_loss: 395.5048 - val_accuracy: 0.7991\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 440.9915 - accuracy: 0.7696 - val_loss: 395.8972 - val_accuracy: 0.7916\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 437.8677 - accuracy: 0.7712 - val_loss: 392.5449 - val_accuracy: 0.7946\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 440.6966 - accuracy: 0.7718 - val_loss: 406.0299 - val_accuracy: 0.8002\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 443.0315 - accuracy: 0.7706 - val_loss: 393.3968 - val_accuracy: 0.7976\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 435.6801 - accuracy: 0.7714 - val_loss: 392.8676 - val_accuracy: 0.8003\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 435.1224 - accuracy: 0.7667 - val_loss: 395.7534 - val_accuracy: 0.7974\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 436.4341 - accuracy: 0.7714 - val_loss: 392.2442 - val_accuracy: 0.7986\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 434.2084 - accuracy: 0.7701 - val_loss: 390.4196 - val_accuracy: 0.7995\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 433.4033 - accuracy: 0.7713 - val_loss: 390.9410 - val_accuracy: 0.8023\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 440.1678 - accuracy: 0.7707 - val_loss: 415.0007 - val_accuracy: 0.7953\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 450.4532 - accuracy: 0.7704 - val_loss: 394.4984 - val_accuracy: 0.7932\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 447.2448 - accuracy: 0.7736 - val_loss: 392.2360 - val_accuracy: 0.7993\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 447.0252 - accuracy: 0.7677 - val_loss: 393.1201 - val_accuracy: 0.8008\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 436.0879 - accuracy: 0.7665 - val_loss: 389.6276 - val_accuracy: 0.7989\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 432.0567 - accuracy: 0.7740 - val_loss: 389.4189 - val_accuracy: 0.8003\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 430.5438 - accuracy: 0.7714 - val_loss: 389.0523 - val_accuracy: 0.7970\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 430.1319 - accuracy: 0.7732 - val_loss: 398.2067 - val_accuracy: 0.7968\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 439.6942 - accuracy: 0.7730 - val_loss: 395.4872 - val_accuracy: 0.7959\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 444.2176 - accuracy: 0.7728 - val_loss: 396.4324 - val_accuracy: 0.8003\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 443.8469 - accuracy: 0.7727 - val_loss: 411.7172 - val_accuracy: 0.7951\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 439.8376 - accuracy: 0.7736 - val_loss: 395.9560 - val_accuracy: 0.7994\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 435.4989 - accuracy: 0.7698 - val_loss: 396.2834 - val_accuracy: 0.7991\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 462.8076 - accuracy: 0.7727 - val_loss: 406.4226 - val_accuracy: 0.8022\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 444.7023 - accuracy: 0.7728 - val_loss: 412.5503 - val_accuracy: 0.7910\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 456.4731 - accuracy: 0.7714 - val_loss: 395.4275 - val_accuracy: 0.7981\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 450.9164 - accuracy: 0.7731 - val_loss: 391.8995 - val_accuracy: 0.8044\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 436.9719 - accuracy: 0.7714 - val_loss: 392.8167 - val_accuracy: 0.8045\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 433.8684 - accuracy: 0.7711 - val_loss: 392.3214 - val_accuracy: 0.7997\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 433.6635 - accuracy: 0.7713 - val_loss: 389.1769 - val_accuracy: 0.7969\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 431.5179 - accuracy: 0.7736 - val_loss: 387.8916 - val_accuracy: 0.7934\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 429.5616 - accuracy: 0.7714 - val_loss: 388.0399 - val_accuracy: 0.7940\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 430.8012 - accuracy: 0.7691 - val_loss: 389.0509 - val_accuracy: 0.7955\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 430.3393 - accuracy: 0.7739 - val_loss: 388.6205 - val_accuracy: 0.7958\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 428.3883 - accuracy: 0.7721 - val_loss: 389.5692 - val_accuracy: 0.7962\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 436.5145 - accuracy: 0.7732 - val_loss: 391.6107 - val_accuracy: 0.7980\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 446.7047 - accuracy: 0.7738 - val_loss: 420.1541 - val_accuracy: 0.7975\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 457.0819 - accuracy: 0.7743 - val_loss: 409.6870 - val_accuracy: 0.8022\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 444.4423 - accuracy: 0.7735 - val_loss: 391.3239 - val_accuracy: 0.7989\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 435.4561 - accuracy: 0.7709 - val_loss: 389.2249 - val_accuracy: 0.7998\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 434.0176 - accuracy: 0.7736 - val_loss: 387.3046 - val_accuracy: 0.7964\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 443.8248 - accuracy: 0.7729 - val_loss: 402.1794 - val_accuracy: 0.7978\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 446.5821 - accuracy: 0.7702 - val_loss: 395.9352 - val_accuracy: 0.7995\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 437.2408 - accuracy: 0.7731 - val_loss: 389.8648 - val_accuracy: 0.7981\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 432.9263 - accuracy: 0.7723 - val_loss: 389.7995 - val_accuracy: 0.7952\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 436.0969 - accuracy: 0.7709 - val_loss: 400.1169 - val_accuracy: 0.8038\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 436.7639 - accuracy: 0.7753 - val_loss: 389.1411 - val_accuracy: 0.7998\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 431.7711 - accuracy: 0.7716 - val_loss: 386.4110 - val_accuracy: 0.7975\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 428.2832 - accuracy: 0.7743 - val_loss: 388.5136 - val_accuracy: 0.7966\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 429.6817 - accuracy: 0.7738 - val_loss: 391.7329 - val_accuracy: 0.7999\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 432.4227 - accuracy: 0.7726 - val_loss: 395.5822 - val_accuracy: 0.8023\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 433.4582 - accuracy: 0.7706 - val_loss: 386.9863 - val_accuracy: 0.7962\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 432.3676 - accuracy: 0.7724 - val_loss: 388.1957 - val_accuracy: 0.8029\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 430.7004 - accuracy: 0.7746 - val_loss: 386.0734 - val_accuracy: 0.7988\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 426.3463 - accuracy: 0.7735 - val_loss: 384.1893 - val_accuracy: 0.7996\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 435.4107 - accuracy: 0.7742 - val_loss: 386.9713 - val_accuracy: 0.7991\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 447.5304 - accuracy: 0.7738 - val_loss: 445.2995 - val_accuracy: 0.7996\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 489.4048 - accuracy: 0.7713 - val_loss: 439.1533 - val_accuracy: 0.8004\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 469.4941 - accuracy: 0.7752 - val_loss: 398.2304 - val_accuracy: 0.7999\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 445.2041 - accuracy: 0.7711 - val_loss: 413.0854 - val_accuracy: 0.8022\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 442.8415 - accuracy: 0.7730 - val_loss: 397.7414 - val_accuracy: 0.8042\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 448.3277 - accuracy: 0.7728 - val_loss: 388.7170 - val_accuracy: 0.7955\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 438.1741 - accuracy: 0.7736 - val_loss: 388.2581 - val_accuracy: 0.8024\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 429.7455 - accuracy: 0.7730 - val_loss: 387.1836 - val_accuracy: 0.7972\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 428.5160 - accuracy: 0.7745 - val_loss: 386.1562 - val_accuracy: 0.8027\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 432.1556 - accuracy: 0.7715 - val_loss: 386.9865 - val_accuracy: 0.8010\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 438.7804 - accuracy: 0.7704 - val_loss: 393.8747 - val_accuracy: 0.7978\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 441.2364 - accuracy: 0.7739 - val_loss: 390.0552 - val_accuracy: 0.7966\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 431.7718 - accuracy: 0.7745 - val_loss: 388.1276 - val_accuracy: 0.7987\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 425.9358 - accuracy: 0.7731 - val_loss: 385.6086 - val_accuracy: 0.7956\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 425.0052 - accuracy: 0.7717 - val_loss: 386.2652 - val_accuracy: 0.7958\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 428.6474 - accuracy: 0.7716 - val_loss: 393.0211 - val_accuracy: 0.7940\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 435.6096 - accuracy: 0.7730 - val_loss: 393.4352 - val_accuracy: 0.7974\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 429.1862 - accuracy: 0.7740 - val_loss: 390.8061 - val_accuracy: 0.7973\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 438.5989 - accuracy: 0.7754 - val_loss: 428.7835 - val_accuracy: 0.8003\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 436.1546 - accuracy: 0.7724 - val_loss: 389.3113 - val_accuracy: 0.8010\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 437.0782 - accuracy: 0.7753 - val_loss: 390.6290 - val_accuracy: 0.7995\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 436.2495 - accuracy: 0.7752 - val_loss: 387.7148 - val_accuracy: 0.7945\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 433.6671 - accuracy: 0.7719 - val_loss: 390.8594 - val_accuracy: 0.8016\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 430.4068 - accuracy: 0.7736 - val_loss: 388.7212 - val_accuracy: 0.7943\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 430.2465 - accuracy: 0.7698 - val_loss: 388.2902 - val_accuracy: 0.7965\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 429.1795 - accuracy: 0.7741 - val_loss: 388.9017 - val_accuracy: 0.7972\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 432.7219 - accuracy: 0.7751 - val_loss: 388.0379 - val_accuracy: 0.7960\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 427.5423 - accuracy: 0.7683 - val_loss: 390.3162 - val_accuracy: 0.8010\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 428.9949 - accuracy: 0.7731 - val_loss: 384.8180 - val_accuracy: 0.8003\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 423.4411 - accuracy: 0.7744 - val_loss: 383.5569 - val_accuracy: 0.7984\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 422.2578 - accuracy: 0.7741 - val_loss: 384.4669 - val_accuracy: 0.8004\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 427.1896 - accuracy: 0.7722 - val_loss: 383.2967 - val_accuracy: 0.7989\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 423.5979 - accuracy: 0.7738 - val_loss: 382.6429 - val_accuracy: 0.7995\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 426.7942 - accuracy: 0.7740 - val_loss: 389.3749 - val_accuracy: 0.7987\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 428.8828 - accuracy: 0.7727 - val_loss: 382.2523 - val_accuracy: 0.8001\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 427.4416 - accuracy: 0.7762 - val_loss: 403.3436 - val_accuracy: 0.8041\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 434.0831 - accuracy: 0.7758 - val_loss: 393.8611 - val_accuracy: 0.8002\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 428.3719 - accuracy: 0.7758 - val_loss: 384.8761 - val_accuracy: 0.8015\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 422.1405 - accuracy: 0.7741 - val_loss: 381.0311 - val_accuracy: 0.7975\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 421.0233 - accuracy: 0.7764 - val_loss: 382.0400 - val_accuracy: 0.8005\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 420.5398 - accuracy: 0.7728 - val_loss: 380.4025 - val_accuracy: 0.7990\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 420.2772 - accuracy: 0.7774 - val_loss: 383.2868 - val_accuracy: 0.7999\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 424.2650 - accuracy: 0.7738 - val_loss: 393.2444 - val_accuracy: 0.7978\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 426.8036 - accuracy: 0.7741 - val_loss: 384.0513 - val_accuracy: 0.7983\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 427.2454 - accuracy: 0.7740 - val_loss: 382.8102 - val_accuracy: 0.8017\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 423.0999 - accuracy: 0.7728 - val_loss: 382.5417 - val_accuracy: 0.8011\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 422.3920 - accuracy: 0.7757 - val_loss: 386.6036 - val_accuracy: 0.7998\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 427.7101 - accuracy: 0.7746 - val_loss: 391.1231 - val_accuracy: 0.7983\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 427.8816 - accuracy: 0.7761 - val_loss: 381.2908 - val_accuracy: 0.8053\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 428.0103 - accuracy: 0.7745 - val_loss: 384.3687 - val_accuracy: 0.7947\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 425.7598 - accuracy: 0.7735 - val_loss: 383.1957 - val_accuracy: 0.7993\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 423.4381 - accuracy: 0.7724 - val_loss: 381.0174 - val_accuracy: 0.7986\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 424.4958 - accuracy: 0.7734 - val_loss: 385.1267 - val_accuracy: 0.7996\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 424.2286 - accuracy: 0.7750 - val_loss: 385.7622 - val_accuracy: 0.7998\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 424.0611 - accuracy: 0.7752 - val_loss: 381.7470 - val_accuracy: 0.7977\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 422.1118 - accuracy: 0.7747 - val_loss: 381.3934 - val_accuracy: 0.7982\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 419.0561 - accuracy: 0.7762 - val_loss: 385.8734 - val_accuracy: 0.7993\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 421.1060 - accuracy: 0.7739 - val_loss: 385.7605 - val_accuracy: 0.8017\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 423.5203 - accuracy: 0.7754 - val_loss: 380.6592 - val_accuracy: 0.7960\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 421.0744 - accuracy: 0.7750 - val_loss: 380.6671 - val_accuracy: 0.8012\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 423.5316 - accuracy: 0.7766 - val_loss: 381.3892 - val_accuracy: 0.8010\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 422.9880 - accuracy: 0.7734 - val_loss: 379.4579 - val_accuracy: 0.7989\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 418.4980 - accuracy: 0.7770 - val_loss: 377.9867 - val_accuracy: 0.7962\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 416.7313 - accuracy: 0.7756 - val_loss: 379.2552 - val_accuracy: 0.7979\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 419.0683 - accuracy: 0.7772 - val_loss: 380.7813 - val_accuracy: 0.8002\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 418.6422 - accuracy: 0.7724 - val_loss: 378.6392 - val_accuracy: 0.7987\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 418.7188 - accuracy: 0.7749 - val_loss: 379.4888 - val_accuracy: 0.8003\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 420.6965 - accuracy: 0.7756 - val_loss: 378.9497 - val_accuracy: 0.8023\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 423.5967 - accuracy: 0.7753 - val_loss: 387.5568 - val_accuracy: 0.7979\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 441.2798 - accuracy: 0.7731 - val_loss: 381.1606 - val_accuracy: 0.7937\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 434.9602 - accuracy: 0.7754 - val_loss: 387.4591 - val_accuracy: 0.8009\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 433.6706 - accuracy: 0.7750 - val_loss: 391.3871 - val_accuracy: 0.8026\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 436.6905 - accuracy: 0.7745 - val_loss: 389.3672 - val_accuracy: 0.8002\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 446.7430 - accuracy: 0.7739 - val_loss: 393.6888 - val_accuracy: 0.8045\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 456.8080 - accuracy: 0.7728 - val_loss: 399.8021 - val_accuracy: 0.7943\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 445.4021 - accuracy: 0.7729 - val_loss: 384.6764 - val_accuracy: 0.8045\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 429.6651 - accuracy: 0.7716 - val_loss: 386.5796 - val_accuracy: 0.7980\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 420.9183 - accuracy: 0.7715 - val_loss: 386.8811 - val_accuracy: 0.7963\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 423.3521 - accuracy: 0.7754 - val_loss: 383.0587 - val_accuracy: 0.7976\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 429.1350 - accuracy: 0.7756 - val_loss: 389.8991 - val_accuracy: 0.8002\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 426.8665 - accuracy: 0.7748 - val_loss: 382.8577 - val_accuracy: 0.7997\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 418.8054 - accuracy: 0.7751 - val_loss: 377.3747 - val_accuracy: 0.7995\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 416.9030 - accuracy: 0.7753 - val_loss: 377.4532 - val_accuracy: 0.7980\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 417.8783 - accuracy: 0.7759 - val_loss: 377.3309 - val_accuracy: 0.7997\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 416.4619 - accuracy: 0.7762 - val_loss: 377.4496 - val_accuracy: 0.7985\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 422.2502 - accuracy: 0.7749 - val_loss: 384.8269 - val_accuracy: 0.7970\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 418.8161 - accuracy: 0.7772 - val_loss: 380.7270 - val_accuracy: 0.7975\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 420.7949 - accuracy: 0.7764 - val_loss: 384.2415 - val_accuracy: 0.7983\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 418.3128 - accuracy: 0.7773 - val_loss: 377.2043 - val_accuracy: 0.7987\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 417.1028 - accuracy: 0.7764 - val_loss: 380.4163 - val_accuracy: 0.7990\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 425.1740 - accuracy: 0.7751 - val_loss: 379.5523 - val_accuracy: 0.8000\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 421.4995 - accuracy: 0.7767 - val_loss: 379.2733 - val_accuracy: 0.8018\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 419.8185 - accuracy: 0.7767 - val_loss: 377.3354 - val_accuracy: 0.8008\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 415.3596 - accuracy: 0.7756 - val_loss: 382.0598 - val_accuracy: 0.8017\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 425.1981 - accuracy: 0.7765 - val_loss: 384.4314 - val_accuracy: 0.8019\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 460.6911 - accuracy: 0.7760 - val_loss: 391.6512 - val_accuracy: 0.8011\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 462.1329 - accuracy: 0.7771 - val_loss: 405.1859 - val_accuracy: 0.8020\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 440.8036 - accuracy: 0.7726 - val_loss: 433.2825 - val_accuracy: 0.7953\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 465.7912 - accuracy: 0.7737 - val_loss: 384.8983 - val_accuracy: 0.8058\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 424.9894 - accuracy: 0.7755 - val_loss: 382.9427 - val_accuracy: 0.8026\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 420.0974 - accuracy: 0.7733 - val_loss: 380.8083 - val_accuracy: 0.8018\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 416.1405 - accuracy: 0.7768 - val_loss: 377.4071 - val_accuracy: 0.8019\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 416.2720 - accuracy: 0.7780 - val_loss: 384.9797 - val_accuracy: 0.7948\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 418.2816 - accuracy: 0.7748 - val_loss: 375.8062 - val_accuracy: 0.8022\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 416.2642 - accuracy: 0.7770 - val_loss: 375.5116 - val_accuracy: 0.8005\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 415.9427 - accuracy: 0.7758 - val_loss: 375.9688 - val_accuracy: 0.8018\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 416.4781 - accuracy: 0.7803 - val_loss: 375.9259 - val_accuracy: 0.8010\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 417.1170 - accuracy: 0.7762 - val_loss: 374.9772 - val_accuracy: 0.8031\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 415.9700 - accuracy: 0.7782 - val_loss: 377.2535 - val_accuracy: 0.8029\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 416.6922 - accuracy: 0.7756 - val_loss: 381.6139 - val_accuracy: 0.8008\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 419.7083 - accuracy: 0.7792 - val_loss: 377.1236 - val_accuracy: 0.8037\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 418.5692 - accuracy: 0.7752 - val_loss: 376.7923 - val_accuracy: 0.8006\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 419.5193 - accuracy: 0.7783 - val_loss: 378.2972 - val_accuracy: 0.8006\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 418.0396 - accuracy: 0.7729 - val_loss: 376.0693 - val_accuracy: 0.8011\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 414.2749 - accuracy: 0.7786 - val_loss: 374.9923 - val_accuracy: 0.7992\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 413.7850 - accuracy: 0.7765 - val_loss: 375.7655 - val_accuracy: 0.7984\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 415.4682 - accuracy: 0.7782 - val_loss: 378.0591 - val_accuracy: 0.7991\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 414.8906 - accuracy: 0.7793 - val_loss: 374.7656 - val_accuracy: 0.8007\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 415.7119 - accuracy: 0.7775 - val_loss: 376.1194 - val_accuracy: 0.7994\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 415.7629 - accuracy: 0.7772 - val_loss: 384.3275 - val_accuracy: 0.8003\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 417.0764 - accuracy: 0.7785 - val_loss: 377.6428 - val_accuracy: 0.8006\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 413.2455 - accuracy: 0.7754 - val_loss: 375.0797 - val_accuracy: 0.8017\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 412.6269 - accuracy: 0.7792 - val_loss: 374.4674 - val_accuracy: 0.8020\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 413.5124 - accuracy: 0.7763 - val_loss: 379.2301 - val_accuracy: 0.8008\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 416.2866 - accuracy: 0.7778 - val_loss: 376.3626 - val_accuracy: 0.8009\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 423.1183 - accuracy: 0.7784 - val_loss: 376.8892 - val_accuracy: 0.8001\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 422.0373 - accuracy: 0.7781 - val_loss: 394.8616 - val_accuracy: 0.8013\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 434.2282 - accuracy: 0.7745 - val_loss: 377.1325 - val_accuracy: 0.7977\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 417.5022 - accuracy: 0.7775 - val_loss: 374.7190 - val_accuracy: 0.8047\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.7430 - accuracy: 0.7777 - val_loss: 377.7916 - val_accuracy: 0.8036\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 416.7565 - accuracy: 0.7766 - val_loss: 375.6652 - val_accuracy: 0.8024\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 415.9105 - accuracy: 0.7776 - val_loss: 374.8418 - val_accuracy: 0.8046\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 414.1005 - accuracy: 0.7761 - val_loss: 375.1494 - val_accuracy: 0.8018\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 413.3495 - accuracy: 0.7782 - val_loss: 376.5820 - val_accuracy: 0.7999\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 413.3140 - accuracy: 0.7775 - val_loss: 376.4085 - val_accuracy: 0.7996\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 414.2526 - accuracy: 0.7749 - val_loss: 374.4797 - val_accuracy: 0.8002\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 412.9073 - accuracy: 0.7797 - val_loss: 379.1724 - val_accuracy: 0.8000\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 412.6980 - accuracy: 0.7774 - val_loss: 373.1032 - val_accuracy: 0.8006\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 412.3518 - accuracy: 0.7774 - val_loss: 375.9427 - val_accuracy: 0.8012\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 412.9066 - accuracy: 0.7777 - val_loss: 379.8304 - val_accuracy: 0.7996\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.3315 - accuracy: 0.7776 - val_loss: 373.2355 - val_accuracy: 0.8016\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 413.2233 - accuracy: 0.7765 - val_loss: 376.3220 - val_accuracy: 0.8007\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 414.1577 - accuracy: 0.7774 - val_loss: 374.5589 - val_accuracy: 0.8026\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 414.2119 - accuracy: 0.7764 - val_loss: 375.9019 - val_accuracy: 0.8052\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 420.3316 - accuracy: 0.7785 - val_loss: 375.7244 - val_accuracy: 0.8029\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 423.3431 - accuracy: 0.7784 - val_loss: 384.8985 - val_accuracy: 0.8015\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 426.2105 - accuracy: 0.7763 - val_loss: 385.5799 - val_accuracy: 0.8056\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 443.5189 - accuracy: 0.7777 - val_loss: 404.9010 - val_accuracy: 0.7982\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 431.7270 - accuracy: 0.7765 - val_loss: 379.8606 - val_accuracy: 0.8028\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 422.7485 - accuracy: 0.7767 - val_loss: 376.4843 - val_accuracy: 0.8042\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 415.9370 - accuracy: 0.7746 - val_loss: 375.8471 - val_accuracy: 0.7990\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 416.8781 - accuracy: 0.7769 - val_loss: 379.2539 - val_accuracy: 0.8026\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 421.4933 - accuracy: 0.7787 - val_loss: 384.1255 - val_accuracy: 0.7963\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 420.9728 - accuracy: 0.7787 - val_loss: 375.5238 - val_accuracy: 0.7972\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 416.0004 - accuracy: 0.7769 - val_loss: 377.7924 - val_accuracy: 0.8019\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 417.1531 - accuracy: 0.7783 - val_loss: 385.4671 - val_accuracy: 0.8009\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 422.6926 - accuracy: 0.7791 - val_loss: 382.5870 - val_accuracy: 0.8017\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 418.9894 - accuracy: 0.7722 - val_loss: 381.4086 - val_accuracy: 0.8030\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 417.3299 - accuracy: 0.7785 - val_loss: 377.3037 - val_accuracy: 0.7975\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 411.8127 - accuracy: 0.7793 - val_loss: 375.6577 - val_accuracy: 0.8023\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 413.3931 - accuracy: 0.7807 - val_loss: 377.3335 - val_accuracy: 0.8022\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 419.9147 - accuracy: 0.7778 - val_loss: 452.2202 - val_accuracy: 0.8014\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 449.2677 - accuracy: 0.7772 - val_loss: 441.0929 - val_accuracy: 0.7992\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 512.5426 - accuracy: 0.7729 - val_loss: 407.0730 - val_accuracy: 0.7986\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 511.4557 - accuracy: 0.7737 - val_loss: 406.5915 - val_accuracy: 0.8060\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 474.0681 - accuracy: 0.7747 - val_loss: 392.7910 - val_accuracy: 0.7975\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 429.1338 - accuracy: 0.7756 - val_loss: 385.5516 - val_accuracy: 0.7968\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 419.4780 - accuracy: 0.7763 - val_loss: 375.5130 - val_accuracy: 0.8011\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 413.8173 - accuracy: 0.7769 - val_loss: 376.5583 - val_accuracy: 0.8041\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.1388 - accuracy: 0.7759 - val_loss: 387.8377 - val_accuracy: 0.8012\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 425.7378 - accuracy: 0.7794 - val_loss: 380.5240 - val_accuracy: 0.8026\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.5540 - accuracy: 0.7786 - val_loss: 376.7390 - val_accuracy: 0.8026\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.7660 - accuracy: 0.7766 - val_loss: 387.7366 - val_accuracy: 0.8009\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 414.4969 - accuracy: 0.7785 - val_loss: 374.8268 - val_accuracy: 0.7989\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 419.1700 - accuracy: 0.7785 - val_loss: 387.1659 - val_accuracy: 0.7995\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 420.4920 - accuracy: 0.7794 - val_loss: 374.8750 - val_accuracy: 0.8068\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 420.1556 - accuracy: 0.7791 - val_loss: 400.6012 - val_accuracy: 0.8012\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 429.0341 - accuracy: 0.7783 - val_loss: 376.7735 - val_accuracy: 0.8018\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 418.8357 - accuracy: 0.7791 - val_loss: 381.6154 - val_accuracy: 0.8055\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 416.5268 - accuracy: 0.7790 - val_loss: 375.3810 - val_accuracy: 0.8081\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 411.4789 - accuracy: 0.7794 - val_loss: 377.0162 - val_accuracy: 0.8051\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 429.9519 - accuracy: 0.7784 - val_loss: 378.4002 - val_accuracy: 0.8009\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 414.7026 - accuracy: 0.7791 - val_loss: 373.5548 - val_accuracy: 0.8018\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 411.7910 - accuracy: 0.7778 - val_loss: 373.0603 - val_accuracy: 0.8040\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 410.7902 - accuracy: 0.7806 - val_loss: 371.2629 - val_accuracy: 0.8056\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 409.0732 - accuracy: 0.7788 - val_loss: 371.8003 - val_accuracy: 0.8002\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 408.0332 - accuracy: 0.7795 - val_loss: 371.5504 - val_accuracy: 0.8026\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 410.5555 - accuracy: 0.7777 - val_loss: 377.0491 - val_accuracy: 0.8029\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 412.2228 - accuracy: 0.7806 - val_loss: 377.7792 - val_accuracy: 0.7982\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 412.0548 - accuracy: 0.7775 - val_loss: 373.5526 - val_accuracy: 0.8020\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 410.6181 - accuracy: 0.7790 - val_loss: 371.3907 - val_accuracy: 0.8021\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 409.0593 - accuracy: 0.7805 - val_loss: 372.5880 - val_accuracy: 0.7988\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 410.8765 - accuracy: 0.7795 - val_loss: 372.2915 - val_accuracy: 0.8014\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 408.2714 - accuracy: 0.7802 - val_loss: 370.3304 - val_accuracy: 0.8043\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 409.4768 - accuracy: 0.7805 - val_loss: 377.2301 - val_accuracy: 0.8030\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 412.8916 - accuracy: 0.7792 - val_loss: 377.8614 - val_accuracy: 0.8017\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 415.9397 - accuracy: 0.7786 - val_loss: 372.7643 - val_accuracy: 0.7990\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 412.3229 - accuracy: 0.7798 - val_loss: 383.1818 - val_accuracy: 0.8029\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 411.7159 - accuracy: 0.7762 - val_loss: 371.9930 - val_accuracy: 0.7973\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 407.8408 - accuracy: 0.7782 - val_loss: 372.6705 - val_accuracy: 0.8012\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 410.8540 - accuracy: 0.7815 - val_loss: 373.4517 - val_accuracy: 0.8034\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.3402 - accuracy: 0.7790 - val_loss: 372.0807 - val_accuracy: 0.8038\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 417.4286 - accuracy: 0.7777 - val_loss: 374.9086 - val_accuracy: 0.8004\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 413.6298 - accuracy: 0.7778 - val_loss: 375.6917 - val_accuracy: 0.8037\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 411.3593 - accuracy: 0.7786 - val_loss: 374.6051 - val_accuracy: 0.8052\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 411.0447 - accuracy: 0.7792 - val_loss: 377.1054 - val_accuracy: 0.7979\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 415.6588 - accuracy: 0.7792 - val_loss: 372.5187 - val_accuracy: 0.8000\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 412.2957 - accuracy: 0.7801 - val_loss: 377.4590 - val_accuracy: 0.8001\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 409.2549 - accuracy: 0.7785 - val_loss: 373.2469 - val_accuracy: 0.8008\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 408.3994 - accuracy: 0.7810 - val_loss: 369.4055 - val_accuracy: 0.7998\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 405.6877 - accuracy: 0.7774 - val_loss: 370.5189 - val_accuracy: 0.7986\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 406.0853 - accuracy: 0.7802 - val_loss: 371.0156 - val_accuracy: 0.8035\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 408.9666 - accuracy: 0.7796 - val_loss: 373.6482 - val_accuracy: 0.7997\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 407.9982 - accuracy: 0.7817 - val_loss: 372.1582 - val_accuracy: 0.8021\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 409.7715 - accuracy: 0.7794 - val_loss: 369.6063 - val_accuracy: 0.8009\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 408.9298 - accuracy: 0.7812 - val_loss: 370.4323 - val_accuracy: 0.8040\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 407.3776 - accuracy: 0.7792 - val_loss: 374.9366 - val_accuracy: 0.8040\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 410.9290 - accuracy: 0.7801 - val_loss: 373.3019 - val_accuracy: 0.8057\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 407.9566 - accuracy: 0.7795 - val_loss: 371.3716 - val_accuracy: 0.8005\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 409.1225 - accuracy: 0.7788 - val_loss: 377.2437 - val_accuracy: 0.8038\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 421.2789 - accuracy: 0.7814 - val_loss: 377.7016 - val_accuracy: 0.8004\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 425.1755 - accuracy: 0.7801 - val_loss: 375.5434 - val_accuracy: 0.7989\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 415.5656 - accuracy: 0.7791 - val_loss: 372.0933 - val_accuracy: 0.7996\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 413.2624 - accuracy: 0.7785 - val_loss: 381.9499 - val_accuracy: 0.8038\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 414.1608 - accuracy: 0.7804 - val_loss: 372.6913 - val_accuracy: 0.8058\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 418.3404 - accuracy: 0.7798 - val_loss: 393.6697 - val_accuracy: 0.8027\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 426.6689 - accuracy: 0.7799 - val_loss: 384.9134 - val_accuracy: 0.8009\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 448.9704 - accuracy: 0.7785 - val_loss: 377.7686 - val_accuracy: 0.8048\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 441.9908 - accuracy: 0.7815 - val_loss: 381.0471 - val_accuracy: 0.8004\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 440.8724 - accuracy: 0.7798 - val_loss: 403.3316 - val_accuracy: 0.8071\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 468.9884 - accuracy: 0.7796 - val_loss: 469.4673 - val_accuracy: 0.8071\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 468.2006 - accuracy: 0.7756 - val_loss: 400.0061 - val_accuracy: 0.8027\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 422.6042 - accuracy: 0.7797 - val_loss: 377.5327 - val_accuracy: 0.8046\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.6170 - accuracy: 0.7789 - val_loss: 382.4338 - val_accuracy: 0.7997\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 412.5605 - accuracy: 0.7818 - val_loss: 372.1924 - val_accuracy: 0.8009\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 406.1269 - accuracy: 0.7811 - val_loss: 370.5620 - val_accuracy: 0.8002\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 407.0084 - accuracy: 0.7812 - val_loss: 373.3336 - val_accuracy: 0.8058\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 408.4137 - accuracy: 0.7802 - val_loss: 369.6470 - val_accuracy: 0.8038\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 405.3333 - accuracy: 0.7821 - val_loss: 373.7774 - val_accuracy: 0.7995\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 411.5160 - accuracy: 0.7789 - val_loss: 374.2756 - val_accuracy: 0.8000\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 410.4939 - accuracy: 0.7801 - val_loss: 373.2368 - val_accuracy: 0.8044\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 412.6971 - accuracy: 0.7794 - val_loss: 372.1330 - val_accuracy: 0.8009\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 410.6654 - accuracy: 0.7819 - val_loss: 380.7017 - val_accuracy: 0.8018\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 409.8283 - accuracy: 0.7790 - val_loss: 374.0184 - val_accuracy: 0.8014\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 412.2773 - accuracy: 0.7797 - val_loss: 370.7172 - val_accuracy: 0.8011\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 411.5869 - accuracy: 0.7790 - val_loss: 393.4806 - val_accuracy: 0.7993\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 419.2077 - accuracy: 0.7805 - val_loss: 371.4439 - val_accuracy: 0.8044\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 418.5056 - accuracy: 0.7819 - val_loss: 374.3691 - val_accuracy: 0.8048\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 418.8634 - accuracy: 0.7795 - val_loss: 371.0088 - val_accuracy: 0.8031\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 417.8669 - accuracy: 0.7806 - val_loss: 374.4780 - val_accuracy: 0.7986\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 417.0285 - accuracy: 0.7785 - val_loss: 375.3538 - val_accuracy: 0.8059\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 412.9441 - accuracy: 0.7816 - val_loss: 377.3178 - val_accuracy: 0.8024\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 409.4904 - accuracy: 0.7816 - val_loss: 376.7513 - val_accuracy: 0.8020\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 410.5066 - accuracy: 0.7809 - val_loss: 371.1481 - val_accuracy: 0.8001\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 406.7211 - accuracy: 0.7832 - val_loss: 374.2036 - val_accuracy: 0.8025\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 411.2639 - accuracy: 0.7816 - val_loss: 369.5720 - val_accuracy: 0.8023\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 403.9619 - accuracy: 0.7806 - val_loss: 367.3734 - val_accuracy: 0.8022\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 402.5494 - accuracy: 0.7825 - val_loss: 368.8877 - val_accuracy: 0.8040\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 405.6197 - accuracy: 0.7811 - val_loss: 368.0610 - val_accuracy: 0.8020\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 405.7322 - accuracy: 0.7810 - val_loss: 368.9888 - val_accuracy: 0.8039\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 406.5457 - accuracy: 0.7824 - val_loss: 373.0157 - val_accuracy: 0.8005\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 405.3716 - accuracy: 0.7817 - val_loss: 368.3257 - val_accuracy: 0.8031\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 404.1454 - accuracy: 0.7812 - val_loss: 369.5745 - val_accuracy: 0.8037\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 403.2285 - accuracy: 0.7833 - val_loss: 367.2718 - val_accuracy: 0.8020\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 402.8675 - accuracy: 0.7830 - val_loss: 367.2588 - val_accuracy: 0.8050\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 402.7816 - accuracy: 0.7829 - val_loss: 367.2607 - val_accuracy: 0.8039\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 403.5739 - accuracy: 0.7838 - val_loss: 368.4581 - val_accuracy: 0.8011\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 404.8499 - accuracy: 0.7820 - val_loss: 368.8152 - val_accuracy: 0.8049\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 404.2950 - accuracy: 0.7832 - val_loss: 370.2379 - val_accuracy: 0.8048\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 403.3557 - accuracy: 0.7820 - val_loss: 368.0782 - val_accuracy: 0.8072\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 403.3806 - accuracy: 0.7804 - val_loss: 368.3350 - val_accuracy: 0.8035\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 405.1455 - accuracy: 0.7837 - val_loss: 369.9421 - val_accuracy: 0.8014\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 404.1204 - accuracy: 0.7814 - val_loss: 373.2291 - val_accuracy: 0.8024\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 406.7184 - accuracy: 0.7824 - val_loss: 369.9203 - val_accuracy: 0.8056\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 409.9566 - accuracy: 0.7817 - val_loss: 368.4630 - val_accuracy: 0.8062\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 409.6204 - accuracy: 0.7807 - val_loss: 369.8382 - val_accuracy: 0.8046\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 407.4532 - accuracy: 0.7793 - val_loss: 369.7584 - val_accuracy: 0.8011\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 408.1118 - accuracy: 0.7806 - val_loss: 374.5452 - val_accuracy: 0.8032\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 414.9585 - accuracy: 0.7822 - val_loss: 374.1740 - val_accuracy: 0.8000\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 413.8312 - accuracy: 0.7822 - val_loss: 370.9942 - val_accuracy: 0.8044\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 411.3617 - accuracy: 0.7835 - val_loss: 367.3974 - val_accuracy: 0.8049\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 405.1713 - accuracy: 0.7808 - val_loss: 370.1655 - val_accuracy: 0.8042\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 408.7652 - accuracy: 0.7825 - val_loss: 368.3152 - val_accuracy: 0.8047\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 414.2095 - accuracy: 0.7802 - val_loss: 369.7319 - val_accuracy: 0.8071\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 405.6545 - accuracy: 0.7821 - val_loss: 368.7093 - val_accuracy: 0.8047\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 407.7087 - accuracy: 0.7837 - val_loss: 372.0980 - val_accuracy: 0.8075\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 406.1330 - accuracy: 0.7805 - val_loss: 367.1065 - val_accuracy: 0.8033\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 402.5988 - accuracy: 0.7834 - val_loss: 366.2389 - val_accuracy: 0.8070\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 401.5372 - accuracy: 0.7823 - val_loss: 366.1241 - val_accuracy: 0.8052\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 401.2283 - accuracy: 0.7832 - val_loss: 368.8198 - val_accuracy: 0.8037\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 403.3403 - accuracy: 0.7814 - val_loss: 371.5488 - val_accuracy: 0.8046\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 408.9908 - accuracy: 0.7834 - val_loss: 371.5450 - val_accuracy: 0.8099\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 409.1707 - accuracy: 0.7789 - val_loss: 371.7473 - val_accuracy: 0.8027\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 407.8000 - accuracy: 0.7818 - val_loss: 373.9001 - val_accuracy: 0.8063\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 410.7195 - accuracy: 0.7789 - val_loss: 373.2871 - val_accuracy: 0.7992\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 407.6707 - accuracy: 0.7788 - val_loss: 370.1752 - val_accuracy: 0.8085\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 407.3023 - accuracy: 0.7826 - val_loss: 368.1247 - val_accuracy: 0.8047\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 403.6917 - accuracy: 0.7827 - val_loss: 374.4680 - val_accuracy: 0.8017\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 412.9641 - accuracy: 0.7805 - val_loss: 382.8908 - val_accuracy: 0.8061\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 422.3184 - accuracy: 0.7838 - val_loss: 393.4765 - val_accuracy: 0.8074\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 419.5229 - accuracy: 0.7822 - val_loss: 371.1217 - val_accuracy: 0.8083\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 405.7556 - accuracy: 0.7803 - val_loss: 367.3340 - val_accuracy: 0.8075\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 401.2614 - accuracy: 0.7832 - val_loss: 365.9547 - val_accuracy: 0.8071\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 402.6082 - accuracy: 0.7803 - val_loss: 368.1227 - val_accuracy: 0.8025\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 402.9117 - accuracy: 0.7826 - val_loss: 367.2143 - val_accuracy: 0.8018\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 401.3958 - accuracy: 0.7820 - val_loss: 371.7281 - val_accuracy: 0.8021\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 402.5857 - accuracy: 0.7841 - val_loss: 380.1275 - val_accuracy: 0.8065\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 417.9358 - accuracy: 0.7830 - val_loss: 367.7012 - val_accuracy: 0.8028\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 412.4402 - accuracy: 0.7809 - val_loss: 372.5503 - val_accuracy: 0.8051\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 406.8968 - accuracy: 0.7808 - val_loss: 373.2185 - val_accuracy: 0.8062\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.5609 - accuracy: 0.7804 - val_loss: 370.0082 - val_accuracy: 0.7979\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 409.4989 - accuracy: 0.7804 - val_loss: 373.4064 - val_accuracy: 0.8092\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 410.0508 - accuracy: 0.7823 - val_loss: 368.4329 - val_accuracy: 0.8020\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 405.4375 - accuracy: 0.7817 - val_loss: 368.3174 - val_accuracy: 0.8062\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 403.9014 - accuracy: 0.7790 - val_loss: 369.1031 - val_accuracy: 0.8063\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 407.3555 - accuracy: 0.7820 - val_loss: 368.9122 - val_accuracy: 0.8004\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 403.5307 - accuracy: 0.7812 - val_loss: 368.8751 - val_accuracy: 0.8054\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 403.3608 - accuracy: 0.7821 - val_loss: 366.7091 - val_accuracy: 0.8050\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 401.1252 - accuracy: 0.7824 - val_loss: 374.7163 - val_accuracy: 0.8071\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 403.7592 - accuracy: 0.7829 - val_loss: 368.4507 - val_accuracy: 0.8038\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 401.3355 - accuracy: 0.7817 - val_loss: 365.8605 - val_accuracy: 0.8073\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 402.6048 - accuracy: 0.7824 - val_loss: 377.2831 - val_accuracy: 0.8024\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 410.5491 - accuracy: 0.7827 - val_loss: 372.9131 - val_accuracy: 0.8001\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 424.1670 - accuracy: 0.7816 - val_loss: 407.4217 - val_accuracy: 0.8087\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 414.3122 - accuracy: 0.7781 - val_loss: 375.7801 - val_accuracy: 0.8042\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 407.4360 - accuracy: 0.7791 - val_loss: 370.1084 - val_accuracy: 0.8042\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 407.0063 - accuracy: 0.7821 - val_loss: 369.3345 - val_accuracy: 0.8052\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 404.5247 - accuracy: 0.7836 - val_loss: 370.4748 - val_accuracy: 0.8037\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 405.0550 - accuracy: 0.7828 - val_loss: 367.1594 - val_accuracy: 0.8063\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 407.3994 - accuracy: 0.7818 - val_loss: 390.1676 - val_accuracy: 0.8025\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 432.2717 - accuracy: 0.7835 - val_loss: 385.0341 - val_accuracy: 0.8050\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 417.6717 - accuracy: 0.7772 - val_loss: 380.6810 - val_accuracy: 0.8052\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 441.5742 - accuracy: 0.7778 - val_loss: 380.1927 - val_accuracy: 0.8054\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 421.7883 - accuracy: 0.7832 - val_loss: 424.7909 - val_accuracy: 0.8087\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 444.5366 - accuracy: 0.7825 - val_loss: 401.2886 - val_accuracy: 0.8026\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 448.4997 - accuracy: 0.7829 - val_loss: 375.8251 - val_accuracy: 0.8016\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 433.1798 - accuracy: 0.7815 - val_loss: 402.6401 - val_accuracy: 0.8013\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 420.8162 - accuracy: 0.7816 - val_loss: 377.4236 - val_accuracy: 0.8089\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 408.4160 - accuracy: 0.7809 - val_loss: 370.5068 - val_accuracy: 0.7978\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 405.7749 - accuracy: 0.7825 - val_loss: 369.0928 - val_accuracy: 0.8045\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 400.8897 - accuracy: 0.7844 - val_loss: 365.6191 - val_accuracy: 0.8056\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 401.4264 - accuracy: 0.7829 - val_loss: 377.6978 - val_accuracy: 0.8034\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 407.8127 - accuracy: 0.7844 - val_loss: 369.0613 - val_accuracy: 0.8048\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 401.9565 - accuracy: 0.7820 - val_loss: 367.6614 - val_accuracy: 0.8044\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 401.6203 - accuracy: 0.7820 - val_loss: 364.7876 - val_accuracy: 0.8053\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 400.3697 - accuracy: 0.7852 - val_loss: 366.1575 - val_accuracy: 0.8036\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 401.2538 - accuracy: 0.7835 - val_loss: 366.5961 - val_accuracy: 0.8028\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 403.7077 - accuracy: 0.7833 - val_loss: 373.1375 - val_accuracy: 0.8072\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 401.9772 - accuracy: 0.7851 - val_loss: 369.0298 - val_accuracy: 0.8031\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 401.5533 - accuracy: 0.7851 - val_loss: 368.5085 - val_accuracy: 0.8061\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 401.1317 - accuracy: 0.7830 - val_loss: 363.8847 - val_accuracy: 0.8046\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 400.1844 - accuracy: 0.7828 - val_loss: 365.5741 - val_accuracy: 0.8079\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 398.9305 - accuracy: 0.7852 - val_loss: 366.1678 - val_accuracy: 0.8020\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 400.0882 - accuracy: 0.7830 - val_loss: 365.6802 - val_accuracy: 0.8041\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 397.8418 - accuracy: 0.7835 - val_loss: 362.9223 - val_accuracy: 0.8055\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 399.5588 - accuracy: 0.7845 - val_loss: 365.1401 - val_accuracy: 0.8051\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 398.2788 - accuracy: 0.7856 - val_loss: 371.2440 - val_accuracy: 0.8084\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 403.3482 - accuracy: 0.7852 - val_loss: 366.8914 - val_accuracy: 0.8047\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 399.6658 - accuracy: 0.7849 - val_loss: 366.1476 - val_accuracy: 0.8062\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 401.9919 - accuracy: 0.7812 - val_loss: 365.9026 - val_accuracy: 0.8049\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 400.8400 - accuracy: 0.7840 - val_loss: 366.6155 - val_accuracy: 0.8018\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 401.2491 - accuracy: 0.7849 - val_loss: 364.2530 - val_accuracy: 0.8053\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 400.2718 - accuracy: 0.7829 - val_loss: 366.2402 - val_accuracy: 0.8058\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 401.2067 - accuracy: 0.7829 - val_loss: 366.8132 - val_accuracy: 0.8064\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 402.2383 - accuracy: 0.7847 - val_loss: 372.0515 - val_accuracy: 0.8037\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 400.5205 - accuracy: 0.7830 - val_loss: 366.6357 - val_accuracy: 0.8039\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 400.1736 - accuracy: 0.7827 - val_loss: 366.1775 - val_accuracy: 0.8091\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 407.8464 - accuracy: 0.7832 - val_loss: 367.6145 - val_accuracy: 0.8060\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 404.9495 - accuracy: 0.7840 - val_loss: 367.9730 - val_accuracy: 0.8025\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 401.8045 - accuracy: 0.7839 - val_loss: 364.7297 - val_accuracy: 0.8076\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 405.1461 - accuracy: 0.7818 - val_loss: 366.1852 - val_accuracy: 0.8034\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 403.1573 - accuracy: 0.7843 - val_loss: 363.6573 - val_accuracy: 0.8043\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 398.9014 - accuracy: 0.7842 - val_loss: 363.3992 - val_accuracy: 0.8051\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 396.9830 - accuracy: 0.7838 - val_loss: 363.7254 - val_accuracy: 0.8042\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 396.1808 - accuracy: 0.7840 - val_loss: 362.6781 - val_accuracy: 0.8059\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 395.9361 - accuracy: 0.7852 - val_loss: 367.8019 - val_accuracy: 0.8058\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 405.1154 - accuracy: 0.7831 - val_loss: 364.7585 - val_accuracy: 0.8062\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 402.9940 - accuracy: 0.7835 - val_loss: 368.1375 - val_accuracy: 0.8043\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 402.5172 - accuracy: 0.7787 - val_loss: 372.4738 - val_accuracy: 0.8034\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 410.7856 - accuracy: 0.7794 - val_loss: 375.9339 - val_accuracy: 0.8098\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 409.6509 - accuracy: 0.7828 - val_loss: 373.1431 - val_accuracy: 0.8078\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 404.7224 - accuracy: 0.7831 - val_loss: 366.0724 - val_accuracy: 0.8056\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 400.6437 - accuracy: 0.7848 - val_loss: 364.8875 - val_accuracy: 0.8075\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 398.8871 - accuracy: 0.7834 - val_loss: 362.7048 - val_accuracy: 0.8087\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 398.5604 - accuracy: 0.7824 - val_loss: 363.8290 - val_accuracy: 0.8083\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 397.8075 - accuracy: 0.7861 - val_loss: 371.5098 - val_accuracy: 0.8065\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 402.7165 - accuracy: 0.7844 - val_loss: 365.2307 - val_accuracy: 0.8062\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 398.0271 - accuracy: 0.7832 - val_loss: 366.8754 - val_accuracy: 0.8026\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 397.9334 - accuracy: 0.7857 - val_loss: 363.8280 - val_accuracy: 0.8049\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 407.3207 - accuracy: 0.7856 - val_loss: 379.8229 - val_accuracy: 0.8071\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 406.1113 - accuracy: 0.7834 - val_loss: 366.9250 - val_accuracy: 0.8054\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 405.6725 - accuracy: 0.7812 - val_loss: 372.5213 - val_accuracy: 0.8063\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 399.9318 - accuracy: 0.7842 - val_loss: 368.3270 - val_accuracy: 0.8056\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 400.3982 - accuracy: 0.7855 - val_loss: 366.8156 - val_accuracy: 0.8057\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 397.4863 - accuracy: 0.7826 - val_loss: 363.6382 - val_accuracy: 0.8045\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 399.1313 - accuracy: 0.7866 - val_loss: 364.2516 - val_accuracy: 0.8050\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 399.1138 - accuracy: 0.7846 - val_loss: 367.3056 - val_accuracy: 0.8099\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 399.1957 - accuracy: 0.7852 - val_loss: 369.9098 - val_accuracy: 0.8081\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 398.3894 - accuracy: 0.7808 - val_loss: 364.2781 - val_accuracy: 0.8070\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 399.3521 - accuracy: 0.7841 - val_loss: 364.6507 - val_accuracy: 0.8028\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 396.7786 - accuracy: 0.7864 - val_loss: 367.7659 - val_accuracy: 0.8099\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 398.4693 - accuracy: 0.7831 - val_loss: 364.9002 - val_accuracy: 0.8099\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 401.3112 - accuracy: 0.7872 - val_loss: 365.4933 - val_accuracy: 0.8037\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 403.5412 - accuracy: 0.7857 - val_loss: 372.3880 - val_accuracy: 0.8062\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 405.4126 - accuracy: 0.7846 - val_loss: 364.9699 - val_accuracy: 0.8105\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 402.3455 - accuracy: 0.7843 - val_loss: 362.3976 - val_accuracy: 0.8065\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 396.2837 - accuracy: 0.7854 - val_loss: 363.1343 - val_accuracy: 0.8046\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 395.2216 - accuracy: 0.7856 - val_loss: 362.4622 - val_accuracy: 0.8095\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 397.6063 - accuracy: 0.7857 - val_loss: 365.3628 - val_accuracy: 0.8032\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 401.0028 - accuracy: 0.7835 - val_loss: 367.0562 - val_accuracy: 0.8056\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 406.9105 - accuracy: 0.7831 - val_loss: 372.9527 - val_accuracy: 0.8083\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 402.0938 - accuracy: 0.7853 - val_loss: 362.9880 - val_accuracy: 0.8106\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 397.8937 - accuracy: 0.7808 - val_loss: 364.6200 - val_accuracy: 0.8064\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 399.2596 - accuracy: 0.7848 - val_loss: 370.0498 - val_accuracy: 0.8108\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 401.4952 - accuracy: 0.7836 - val_loss: 363.6303 - val_accuracy: 0.8110\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 402.2801 - accuracy: 0.7839 - val_loss: 367.0244 - val_accuracy: 0.8037\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 399.6082 - accuracy: 0.7851 - val_loss: 364.5397 - val_accuracy: 0.8041\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 395.7583 - accuracy: 0.7851 - val_loss: 363.3164 - val_accuracy: 0.8098\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 396.5918 - accuracy: 0.7846 - val_loss: 366.9517 - val_accuracy: 0.8073\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 398.7321 - accuracy: 0.7864 - val_loss: 362.1869 - val_accuracy: 0.8061\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 398.4177 - accuracy: 0.7867 - val_loss: 364.4897 - val_accuracy: 0.8069\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 398.4763 - accuracy: 0.7841 - val_loss: 364.4975 - val_accuracy: 0.8053\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 396.5467 - accuracy: 0.7819 - val_loss: 362.1795 - val_accuracy: 0.8055\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 400.3907 - accuracy: 0.7863 - val_loss: 364.4665 - val_accuracy: 0.8070\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 408.9865 - accuracy: 0.7853 - val_loss: 388.5193 - val_accuracy: 0.8077\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 420.7769 - accuracy: 0.7836 - val_loss: 401.2217 - val_accuracy: 0.8063\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 416.1342 - accuracy: 0.7823 - val_loss: 369.0058 - val_accuracy: 0.8051\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 414.2793 - accuracy: 0.7802 - val_loss: 368.6239 - val_accuracy: 0.8053\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 405.8576 - accuracy: 0.7817 - val_loss: 378.2650 - val_accuracy: 0.8144\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 405.3520 - accuracy: 0.7826 - val_loss: 365.9707 - val_accuracy: 0.8058\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 400.5843 - accuracy: 0.7853 - val_loss: 366.1390 - val_accuracy: 0.8094\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 403.3629 - accuracy: 0.7863 - val_loss: 364.3332 - val_accuracy: 0.8062\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 401.5966 - accuracy: 0.7839 - val_loss: 365.5472 - val_accuracy: 0.8093\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 414.9648 - accuracy: 0.7855 - val_loss: 366.0011 - val_accuracy: 0.8122\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 399.7611 - accuracy: 0.7877 - val_loss: 365.9754 - val_accuracy: 0.8074\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 397.4535 - accuracy: 0.7861 - val_loss: 368.5813 - val_accuracy: 0.8093\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 409.3519 - accuracy: 0.7860 - val_loss: 363.1840 - val_accuracy: 0.8055\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 436.5290 - accuracy: 0.7853 - val_loss: 384.0780 - val_accuracy: 0.8063\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 423.8602 - accuracy: 0.7858 - val_loss: 393.4397 - val_accuracy: 0.8120\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 413.6504 - accuracy: 0.7824 - val_loss: 368.1616 - val_accuracy: 0.8067\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 403.1556 - accuracy: 0.7847 - val_loss: 365.8627 - val_accuracy: 0.8118\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 396.9430 - accuracy: 0.7863 - val_loss: 364.9594 - val_accuracy: 0.8077\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 400.6381 - accuracy: 0.7862 - val_loss: 386.9635 - val_accuracy: 0.8028\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 407.5707 - accuracy: 0.7848 - val_loss: 368.1161 - val_accuracy: 0.8098\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 400.5616 - accuracy: 0.7850 - val_loss: 366.6943 - val_accuracy: 0.8108\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 406.2297 - accuracy: 0.7872 - val_loss: 414.0660 - val_accuracy: 0.8035\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 468.4069 - accuracy: 0.7818 - val_loss: 387.9207 - val_accuracy: 0.8086\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 451.9919 - accuracy: 0.7801 - val_loss: 395.5369 - val_accuracy: 0.8072\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 428.8546 - accuracy: 0.7823 - val_loss: 375.8620 - val_accuracy: 0.8094\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 413.8656 - accuracy: 0.7814 - val_loss: 374.4626 - val_accuracy: 0.8057\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 407.9195 - accuracy: 0.7859 - val_loss: 373.3503 - val_accuracy: 0.8102\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 405.3138 - accuracy: 0.7824 - val_loss: 368.0345 - val_accuracy: 0.8100\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 400.8462 - accuracy: 0.7854 - val_loss: 363.1048 - val_accuracy: 0.8090\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 397.8129 - accuracy: 0.7844 - val_loss: 363.1073 - val_accuracy: 0.8096\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 394.1090 - accuracy: 0.7872 - val_loss: 359.6956 - val_accuracy: 0.8096\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 393.1643 - accuracy: 0.7863 - val_loss: 360.1461 - val_accuracy: 0.8086\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 395.3730 - accuracy: 0.7872 - val_loss: 362.0244 - val_accuracy: 0.8121\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 396.8929 - accuracy: 0.7844 - val_loss: 366.6987 - val_accuracy: 0.8084\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 398.1278 - accuracy: 0.7859 - val_loss: 365.7977 - val_accuracy: 0.8075\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 395.8912 - accuracy: 0.7847 - val_loss: 366.2211 - val_accuracy: 0.8059\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 396.1180 - accuracy: 0.7853 - val_loss: 360.9020 - val_accuracy: 0.8121\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 398.5293 - accuracy: 0.7864 - val_loss: 359.3928 - val_accuracy: 0.8084\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 396.2311 - accuracy: 0.7881 - val_loss: 364.0373 - val_accuracy: 0.8042\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 395.3408 - accuracy: 0.7865 - val_loss: 360.2574 - val_accuracy: 0.8121\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 395.3352 - accuracy: 0.7872 - val_loss: 360.2753 - val_accuracy: 0.8104\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 396.0245 - accuracy: 0.7876 - val_loss: 365.1652 - val_accuracy: 0.8068\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 400.4686 - accuracy: 0.7845 - val_loss: 368.7198 - val_accuracy: 0.8072\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 398.3076 - accuracy: 0.7831 - val_loss: 366.8602 - val_accuracy: 0.8120\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 400.3322 - accuracy: 0.7855 - val_loss: 372.4520 - val_accuracy: 0.8092\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 416.7927 - accuracy: 0.7870 - val_loss: 415.6350 - val_accuracy: 0.8043\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 463.5210 - accuracy: 0.7840 - val_loss: 410.5672 - val_accuracy: 0.8122\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 427.3823 - accuracy: 0.7819 - val_loss: 403.5131 - val_accuracy: 0.8110\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 435.0047 - accuracy: 0.7787 - val_loss: 368.9796 - val_accuracy: 0.8051\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 410.2674 - accuracy: 0.7817 - val_loss: 364.0296 - val_accuracy: 0.8106\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 400.7563 - accuracy: 0.7827 - val_loss: 369.9575 - val_accuracy: 0.8065\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 396.7740 - accuracy: 0.7858 - val_loss: 360.6006 - val_accuracy: 0.8064\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 392.8915 - accuracy: 0.7840 - val_loss: 360.3762 - val_accuracy: 0.8104\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 391.9963 - accuracy: 0.7870 - val_loss: 361.9791 - val_accuracy: 0.8060\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 392.8922 - accuracy: 0.7881 - val_loss: 360.6061 - val_accuracy: 0.8120\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 395.4082 - accuracy: 0.7876 - val_loss: 363.3609 - val_accuracy: 0.8087\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 396.7464 - accuracy: 0.7861 - val_loss: 360.1362 - val_accuracy: 0.8082\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 397.0035 - accuracy: 0.7866 - val_loss: 361.7556 - val_accuracy: 0.8098\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 396.7055 - accuracy: 0.7853 - val_loss: 364.4817 - val_accuracy: 0.8107\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 396.7501 - accuracy: 0.7862 - val_loss: 360.5716 - val_accuracy: 0.8066\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 393.6603 - accuracy: 0.7855 - val_loss: 364.3492 - val_accuracy: 0.8060\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 395.8419 - accuracy: 0.7872 - val_loss: 370.6594 - val_accuracy: 0.8071\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 400.7833 - accuracy: 0.7855 - val_loss: 363.4690 - val_accuracy: 0.8103\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 397.7744 - accuracy: 0.7846 - val_loss: 362.1874 - val_accuracy: 0.8098\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 400.2858 - accuracy: 0.7886 - val_loss: 378.4951 - val_accuracy: 0.8091\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 404.4673 - accuracy: 0.7847 - val_loss: 364.8981 - val_accuracy: 0.8116\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 398.9483 - accuracy: 0.7855 - val_loss: 362.3791 - val_accuracy: 0.8084\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 394.4265 - accuracy: 0.7874 - val_loss: 368.3049 - val_accuracy: 0.8057\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 398.1827 - accuracy: 0.7860 - val_loss: 360.5077 - val_accuracy: 0.8100\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 399.0101 - accuracy: 0.7844 - val_loss: 364.1476 - val_accuracy: 0.8047\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 399.2729 - accuracy: 0.7840 - val_loss: 363.9453 - val_accuracy: 0.8093\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 394.4799 - accuracy: 0.7848 - val_loss: 366.3113 - val_accuracy: 0.8054\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 398.1899 - accuracy: 0.7868 - val_loss: 360.9020 - val_accuracy: 0.8127\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 393.3334 - accuracy: 0.7869 - val_loss: 361.2746 - val_accuracy: 0.8067\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 398.2654 - accuracy: 0.7871 - val_loss: 359.7509 - val_accuracy: 0.8076\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 396.7137 - accuracy: 0.7861 - val_loss: 366.6679 - val_accuracy: 0.8112\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 396.6949 - accuracy: 0.7861 - val_loss: 364.5151 - val_accuracy: 0.8090\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 401.8498 - accuracy: 0.7861 - val_loss: 367.9856 - val_accuracy: 0.8083\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 403.0757 - accuracy: 0.7854 - val_loss: 363.8360 - val_accuracy: 0.8093\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 399.8328 - accuracy: 0.7859 - val_loss: 361.7318 - val_accuracy: 0.8049\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 402.6924 - accuracy: 0.7854 - val_loss: 369.9076 - val_accuracy: 0.8093\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 402.2823 - accuracy: 0.7854 - val_loss: 368.9440 - val_accuracy: 0.8101\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 400.4825 - accuracy: 0.7868 - val_loss: 362.0568 - val_accuracy: 0.8107\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 395.6897 - accuracy: 0.7877 - val_loss: 364.0037 - val_accuracy: 0.8081\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 393.5993 - accuracy: 0.7880 - val_loss: 359.9263 - val_accuracy: 0.8130\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 392.7514 - accuracy: 0.7876 - val_loss: 360.2527 - val_accuracy: 0.8101\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 391.1437 - accuracy: 0.7878 - val_loss: 360.3796 - val_accuracy: 0.8092\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 391.6856 - accuracy: 0.7865 - val_loss: 360.6594 - val_accuracy: 0.8091\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 392.7722 - accuracy: 0.7878 - val_loss: 359.0820 - val_accuracy: 0.8120\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 392.8318 - accuracy: 0.7884 - val_loss: 361.2826 - val_accuracy: 0.8112\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 391.6626 - accuracy: 0.7867 - val_loss: 357.9031 - val_accuracy: 0.8067\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 391.5002 - accuracy: 0.7871 - val_loss: 360.6179 - val_accuracy: 0.8106\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 393.6445 - accuracy: 0.7875 - val_loss: 361.3314 - val_accuracy: 0.8100\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 393.9921 - accuracy: 0.7892 - val_loss: 360.1151 - val_accuracy: 0.8094\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 393.3066 - accuracy: 0.7861 - val_loss: 359.9561 - val_accuracy: 0.8065\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 394.5251 - accuracy: 0.7869 - val_loss: 367.5014 - val_accuracy: 0.8115\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 408.3719 - accuracy: 0.7852 - val_loss: 373.1833 - val_accuracy: 0.8088\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 405.8461 - accuracy: 0.7841 - val_loss: 374.2671 - val_accuracy: 0.8096\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 400.9208 - accuracy: 0.7835 - val_loss: 366.3196 - val_accuracy: 0.8047\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 407.9455 - accuracy: 0.7881 - val_loss: 374.8854 - val_accuracy: 0.8069\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 396.4968 - accuracy: 0.7852 - val_loss: 360.0312 - val_accuracy: 0.8087\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 397.6937 - accuracy: 0.7881 - val_loss: 370.9333 - val_accuracy: 0.8067\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 396.6985 - accuracy: 0.7877 - val_loss: 381.7121 - val_accuracy: 0.8066\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 423.9395 - accuracy: 0.7856 - val_loss: 383.1033 - val_accuracy: 0.8100\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 404.3794 - accuracy: 0.7874 - val_loss: 366.2938 - val_accuracy: 0.8103\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 395.1024 - accuracy: 0.7879 - val_loss: 361.8672 - val_accuracy: 0.8127\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 394.1969 - accuracy: 0.7887 - val_loss: 357.9633 - val_accuracy: 0.8110\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 396.1948 - accuracy: 0.7883 - val_loss: 367.7246 - val_accuracy: 0.8074\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 395.1252 - accuracy: 0.7859 - val_loss: 358.8483 - val_accuracy: 0.8100\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 397.4845 - accuracy: 0.7867 - val_loss: 360.7343 - val_accuracy: 0.8105\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 394.2703 - accuracy: 0.7879 - val_loss: 358.6334 - val_accuracy: 0.8087\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 396.5376 - accuracy: 0.7872 - val_loss: 359.2664 - val_accuracy: 0.8116\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 393.4245 - accuracy: 0.7879 - val_loss: 361.2762 - val_accuracy: 0.8105\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 391.8918 - accuracy: 0.7859 - val_loss: 358.8239 - val_accuracy: 0.8136\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 390.2666 - accuracy: 0.7892 - val_loss: 359.0292 - val_accuracy: 0.8103\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 391.6885 - accuracy: 0.7889 - val_loss: 359.1274 - val_accuracy: 0.8098\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 389.5815 - accuracy: 0.7882 - val_loss: 357.0078 - val_accuracy: 0.8133\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 392.0363 - accuracy: 0.7895 - val_loss: 358.3093 - val_accuracy: 0.8124\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 397.5813 - accuracy: 0.7872 - val_loss: 363.9930 - val_accuracy: 0.8066\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 401.9220 - accuracy: 0.7888 - val_loss: 359.0242 - val_accuracy: 0.8129\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 390.9791 - accuracy: 0.7883 - val_loss: 358.9361 - val_accuracy: 0.8118\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 390.7673 - accuracy: 0.7868 - val_loss: 357.8315 - val_accuracy: 0.8095\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 390.2668 - accuracy: 0.7889 - val_loss: 358.7960 - val_accuracy: 0.8111\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 395.3322 - accuracy: 0.7867 - val_loss: 361.6672 - val_accuracy: 0.8125\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 392.8759 - accuracy: 0.7868 - val_loss: 358.2638 - val_accuracy: 0.8078\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 394.9756 - accuracy: 0.7888 - val_loss: 362.8671 - val_accuracy: 0.8085\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 395.5460 - accuracy: 0.7877 - val_loss: 360.4953 - val_accuracy: 0.8119\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 391.1023 - accuracy: 0.7869 - val_loss: 357.9779 - val_accuracy: 0.8100\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 392.3481 - accuracy: 0.7881 - val_loss: 358.9048 - val_accuracy: 0.8123\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 398.6726 - accuracy: 0.7855 - val_loss: 358.8133 - val_accuracy: 0.8084\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 394.5446 - accuracy: 0.7878 - val_loss: 367.5056 - val_accuracy: 0.8125\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 399.2569 - accuracy: 0.7868 - val_loss: 361.3479 - val_accuracy: 0.8106\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 401.2769 - accuracy: 0.7867 - val_loss: 361.1363 - val_accuracy: 0.8154\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 399.8854 - accuracy: 0.7859 - val_loss: 367.9058 - val_accuracy: 0.8143\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 396.4469 - accuracy: 0.7879 - val_loss: 359.3139 - val_accuracy: 0.8064\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 395.1323 - accuracy: 0.7854 - val_loss: 358.4629 - val_accuracy: 0.8081\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 391.2690 - accuracy: 0.7877 - val_loss: 361.2684 - val_accuracy: 0.8116\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 389.9121 - accuracy: 0.7896 - val_loss: 361.6154 - val_accuracy: 0.8110\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 393.8927 - accuracy: 0.7895 - val_loss: 359.3189 - val_accuracy: 0.8106\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 395.2278 - accuracy: 0.7870 - val_loss: 361.8940 - val_accuracy: 0.8106\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 392.9693 - accuracy: 0.7883 - val_loss: 365.6540 - val_accuracy: 0.8068\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the second input image\n",
        "upsampled = layers.UpSampling2D(size=8)(input_layer2)\n",
        "\n",
        "# Concatenate the two input images\n",
        "concatenated = layers.Concatenate()([input_layer1, upsampled])\n",
        "\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(concatenated)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "#conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "#pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer = layers.Conv2D(31, kernel_size=1, activation='relu')(pool2)\n",
        "\n",
        "# Define the model\n",
        "modelnew = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "modelnew.compile(optimizer='adam',\n",
        "loss='mean_absolute_error',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = modelnew.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbDywvk-vI4U",
        "outputId": "45ec32c9-6c0d-4d68-9f12-3324e4bf21be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 37ms/step - loss: 8343.4209 - accuracy: 0.0283 - val_loss: 6061.4609 - val_accuracy: 0.1079\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 7003.5488 - accuracy: 0.0296 - val_loss: 5137.4463 - val_accuracy: 0.1131\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 5521.0703 - accuracy: 0.0332 - val_loss: 4125.4634 - val_accuracy: 0.1174\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 4140.3828 - accuracy: 0.0488 - val_loss: 3077.7732 - val_accuracy: 0.1691\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3300.4302 - accuracy: 0.1599 - val_loss: 2599.3997 - val_accuracy: 0.2219\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 2745.5596 - accuracy: 0.2058 - val_loss: 2132.1753 - val_accuracy: 0.2344\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 2247.0471 - accuracy: 0.2179 - val_loss: 1745.5624 - val_accuracy: 0.2657\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1936.7585 - accuracy: 0.2187 - val_loss: 1455.2677 - val_accuracy: 0.2758\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1722.0901 - accuracy: 0.2161 - val_loss: 1282.6995 - val_accuracy: 0.2465\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1603.8932 - accuracy: 0.1960 - val_loss: 1212.0398 - val_accuracy: 0.2523\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1520.2340 - accuracy: 0.2089 - val_loss: 1150.7378 - val_accuracy: 0.4267\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1472.5892 - accuracy: 0.2088 - val_loss: 1116.3641 - val_accuracy: 0.5599\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1428.0845 - accuracy: 0.2913 - val_loss: 1097.5128 - val_accuracy: 0.5974\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1392.1503 - accuracy: 0.3175 - val_loss: 1064.9480 - val_accuracy: 0.5964\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1354.0958 - accuracy: 0.3267 - val_loss: 1031.3484 - val_accuracy: 0.5911\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1232.3298 - accuracy: 0.3367 - val_loss: 922.0043 - val_accuracy: 0.5923\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1049.2184 - accuracy: 0.4215 - val_loss: 826.3668 - val_accuracy: 0.5820\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 996.1106 - accuracy: 0.4171 - val_loss: 787.1462 - val_accuracy: 0.5011\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 949.1320 - accuracy: 0.3720 - val_loss: 770.9625 - val_accuracy: 0.5191\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 927.7724 - accuracy: 0.4092 - val_loss: 743.3691 - val_accuracy: 0.4870\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 903.2706 - accuracy: 0.4134 - val_loss: 725.3832 - val_accuracy: 0.4806\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 886.6757 - accuracy: 0.4192 - val_loss: 716.5291 - val_accuracy: 0.5070\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 874.0710 - accuracy: 0.4539 - val_loss: 691.8464 - val_accuracy: 0.5459\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 865.7722 - accuracy: 0.4674 - val_loss: 684.5558 - val_accuracy: 0.5749\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 857.4623 - accuracy: 0.4751 - val_loss: 682.1763 - val_accuracy: 0.6366\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 846.9329 - accuracy: 0.4978 - val_loss: 672.0845 - val_accuracy: 0.6193\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 840.4885 - accuracy: 0.5491 - val_loss: 663.5163 - val_accuracy: 0.6219\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 834.7679 - accuracy: 0.5865 - val_loss: 659.4026 - val_accuracy: 0.6542\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 829.6020 - accuracy: 0.6130 - val_loss: 664.9319 - val_accuracy: 0.7034\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 827.8429 - accuracy: 0.6357 - val_loss: 651.6044 - val_accuracy: 0.6863\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 822.7903 - accuracy: 0.6444 - val_loss: 649.4126 - val_accuracy: 0.7236\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 814.4127 - accuracy: 0.6306 - val_loss: 642.4922 - val_accuracy: 0.7293\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 809.1920 - accuracy: 0.6497 - val_loss: 640.0903 - val_accuracy: 0.7324\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 803.9449 - accuracy: 0.6613 - val_loss: 637.7848 - val_accuracy: 0.7392\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 799.5670 - accuracy: 0.6458 - val_loss: 638.7662 - val_accuracy: 0.7388\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 793.9473 - accuracy: 0.6655 - val_loss: 640.5981 - val_accuracy: 0.7434\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 787.8604 - accuracy: 0.6680 - val_loss: 636.8532 - val_accuracy: 0.7484\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 785.2095 - accuracy: 0.6749 - val_loss: 625.0527 - val_accuracy: 0.7472\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 781.4313 - accuracy: 0.6617 - val_loss: 627.4670 - val_accuracy: 0.7463\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 783.0115 - accuracy: 0.6774 - val_loss: 627.6147 - val_accuracy: 0.7423\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 788.0461 - accuracy: 0.6587 - val_loss: 626.4985 - val_accuracy: 0.7367\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 778.6909 - accuracy: 0.6717 - val_loss: 621.8558 - val_accuracy: 0.7381\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 773.9916 - accuracy: 0.6707 - val_loss: 615.1970 - val_accuracy: 0.7432\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 768.2343 - accuracy: 0.6823 - val_loss: 614.4802 - val_accuracy: 0.7428\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 763.2667 - accuracy: 0.6841 - val_loss: 609.2937 - val_accuracy: 0.7490\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 764.0216 - accuracy: 0.6835 - val_loss: 612.8904 - val_accuracy: 0.7556\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 771.3283 - accuracy: 0.6870 - val_loss: 606.3958 - val_accuracy: 0.7593\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 763.9108 - accuracy: 0.6834 - val_loss: 605.2643 - val_accuracy: 0.7559\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 757.8004 - accuracy: 0.6879 - val_loss: 606.5592 - val_accuracy: 0.7570\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 756.0855 - accuracy: 0.6834 - val_loss: 598.2512 - val_accuracy: 0.7572\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 749.1396 - accuracy: 0.6860 - val_loss: 596.3948 - val_accuracy: 0.7499\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 742.0800 - accuracy: 0.6902 - val_loss: 593.3043 - val_accuracy: 0.7546\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 736.8961 - accuracy: 0.6910 - val_loss: 589.9014 - val_accuracy: 0.7532\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 734.6617 - accuracy: 0.6890 - val_loss: 590.0341 - val_accuracy: 0.7575\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 731.4788 - accuracy: 0.6845 - val_loss: 586.6315 - val_accuracy: 0.7526\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 730.3034 - accuracy: 0.6774 - val_loss: 585.3180 - val_accuracy: 0.7623\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 727.6008 - accuracy: 0.6892 - val_loss: 585.7786 - val_accuracy: 0.7639\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 724.1092 - accuracy: 0.6893 - val_loss: 585.3813 - val_accuracy: 0.7637\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 725.1257 - accuracy: 0.6884 - val_loss: 586.7904 - val_accuracy: 0.7656\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 721.5162 - accuracy: 0.6798 - val_loss: 587.2942 - val_accuracy: 0.7678\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 717.2963 - accuracy: 0.6883 - val_loss: 579.5521 - val_accuracy: 0.7521\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 714.4299 - accuracy: 0.6869 - val_loss: 582.0680 - val_accuracy: 0.7553\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 713.3207 - accuracy: 0.6854 - val_loss: 576.5367 - val_accuracy: 0.7553\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 713.1613 - accuracy: 0.6911 - val_loss: 572.9343 - val_accuracy: 0.7506\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 708.8595 - accuracy: 0.6896 - val_loss: 571.7770 - val_accuracy: 0.7508\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 705.8145 - accuracy: 0.6939 - val_loss: 572.7179 - val_accuracy: 0.7540\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 703.2682 - accuracy: 0.6943 - val_loss: 583.0889 - val_accuracy: 0.7562\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 703.8265 - accuracy: 0.6950 - val_loss: 577.4403 - val_accuracy: 0.7556\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 700.7380 - accuracy: 0.6885 - val_loss: 569.2801 - val_accuracy: 0.7529\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 698.0726 - accuracy: 0.6955 - val_loss: 569.9335 - val_accuracy: 0.7522\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 698.0966 - accuracy: 0.6946 - val_loss: 573.5064 - val_accuracy: 0.7579\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 706.8157 - accuracy: 0.6936 - val_loss: 570.3082 - val_accuracy: 0.7519\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 702.4720 - accuracy: 0.6896 - val_loss: 572.0302 - val_accuracy: 0.7555\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 708.1588 - accuracy: 0.6922 - val_loss: 574.6633 - val_accuracy: 0.7564\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 699.8441 - accuracy: 0.6906 - val_loss: 565.7399 - val_accuracy: 0.7521\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 693.4923 - accuracy: 0.6928 - val_loss: 566.0809 - val_accuracy: 0.7570\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 692.2695 - accuracy: 0.6928 - val_loss: 564.3282 - val_accuracy: 0.7550\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 696.4642 - accuracy: 0.6941 - val_loss: 561.2741 - val_accuracy: 0.7466\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 693.3576 - accuracy: 0.6926 - val_loss: 560.5088 - val_accuracy: 0.7488\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 695.8350 - accuracy: 0.6933 - val_loss: 564.6086 - val_accuracy: 0.7543\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 686.1404 - accuracy: 0.6941 - val_loss: 560.2601 - val_accuracy: 0.7441\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 683.6356 - accuracy: 0.6958 - val_loss: 558.2057 - val_accuracy: 0.7480\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 682.3890 - accuracy: 0.6928 - val_loss: 558.5785 - val_accuracy: 0.7432\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 684.0023 - accuracy: 0.6970 - val_loss: 561.5876 - val_accuracy: 0.7507\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 685.5888 - accuracy: 0.6976 - val_loss: 558.0109 - val_accuracy: 0.7525\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 682.7604 - accuracy: 0.6932 - val_loss: 554.5693 - val_accuracy: 0.7517\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 681.5897 - accuracy: 0.6857 - val_loss: 558.5070 - val_accuracy: 0.7483\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 678.2844 - accuracy: 0.6930 - val_loss: 555.1684 - val_accuracy: 0.7485\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 678.2535 - accuracy: 0.6956 - val_loss: 559.4583 - val_accuracy: 0.7539\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 675.9581 - accuracy: 0.6962 - val_loss: 549.2659 - val_accuracy: 0.7428\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 674.8058 - accuracy: 0.6998 - val_loss: 550.6812 - val_accuracy: 0.7404\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 672.8842 - accuracy: 0.6973 - val_loss: 548.3336 - val_accuracy: 0.7488\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 672.3264 - accuracy: 0.6953 - val_loss: 550.5867 - val_accuracy: 0.7547\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 672.1378 - accuracy: 0.7012 - val_loss: 549.8528 - val_accuracy: 0.7463\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 673.8369 - accuracy: 0.6939 - val_loss: 554.5629 - val_accuracy: 0.7521\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 671.8915 - accuracy: 0.7011 - val_loss: 555.4167 - val_accuracy: 0.7544\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 679.6855 - accuracy: 0.6988 - val_loss: 558.5453 - val_accuracy: 0.7571\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 675.9433 - accuracy: 0.6949 - val_loss: 557.4434 - val_accuracy: 0.7483\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 674.1471 - accuracy: 0.6980 - val_loss: 558.7821 - val_accuracy: 0.7504\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 679.6859 - accuracy: 0.6999 - val_loss: 560.1400 - val_accuracy: 0.7434\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 676.4138 - accuracy: 0.6980 - val_loss: 555.7150 - val_accuracy: 0.7500\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 682.0240 - accuracy: 0.6924 - val_loss: 543.5669 - val_accuracy: 0.7418\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 670.3139 - accuracy: 0.6961 - val_loss: 553.3851 - val_accuracy: 0.7267\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 669.1341 - accuracy: 0.7002 - val_loss: 545.2699 - val_accuracy: 0.7407\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 663.4395 - accuracy: 0.7020 - val_loss: 551.0848 - val_accuracy: 0.7385\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 666.9350 - accuracy: 0.7005 - val_loss: 545.9965 - val_accuracy: 0.7619\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 666.6999 - accuracy: 0.7027 - val_loss: 551.5742 - val_accuracy: 0.7604\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 666.5659 - accuracy: 0.6998 - val_loss: 540.1089 - val_accuracy: 0.7412\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 659.5904 - accuracy: 0.6985 - val_loss: 544.3277 - val_accuracy: 0.7379\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 659.6376 - accuracy: 0.7026 - val_loss: 539.8222 - val_accuracy: 0.7478\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 658.1291 - accuracy: 0.7005 - val_loss: 542.3720 - val_accuracy: 0.7467\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 656.9820 - accuracy: 0.7007 - val_loss: 536.4583 - val_accuracy: 0.7480\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 656.4474 - accuracy: 0.7026 - val_loss: 543.9600 - val_accuracy: 0.7438\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 660.9222 - accuracy: 0.7020 - val_loss: 541.5547 - val_accuracy: 0.7606\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 657.5022 - accuracy: 0.7008 - val_loss: 538.7542 - val_accuracy: 0.7312\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 654.9299 - accuracy: 0.7032 - val_loss: 538.9192 - val_accuracy: 0.7319\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 655.5803 - accuracy: 0.7036 - val_loss: 533.9811 - val_accuracy: 0.7289\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 652.9308 - accuracy: 0.7003 - val_loss: 535.4618 - val_accuracy: 0.7467\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 651.9792 - accuracy: 0.7024 - val_loss: 542.7194 - val_accuracy: 0.7375\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 661.8961 - accuracy: 0.6999 - val_loss: 533.0158 - val_accuracy: 0.7324\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 652.4224 - accuracy: 0.7008 - val_loss: 533.0405 - val_accuracy: 0.7456\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 650.8447 - accuracy: 0.7031 - val_loss: 540.2202 - val_accuracy: 0.7359\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 655.2553 - accuracy: 0.7063 - val_loss: 543.2818 - val_accuracy: 0.7435\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 656.5443 - accuracy: 0.7040 - val_loss: 533.8271 - val_accuracy: 0.7361\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 655.1652 - accuracy: 0.7013 - val_loss: 535.7145 - val_accuracy: 0.7288\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 650.4812 - accuracy: 0.7019 - val_loss: 530.3911 - val_accuracy: 0.7367\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 647.4911 - accuracy: 0.7072 - val_loss: 526.0876 - val_accuracy: 0.7397\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 644.7621 - accuracy: 0.7036 - val_loss: 529.0917 - val_accuracy: 0.7438\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 644.7523 - accuracy: 0.7077 - val_loss: 526.5731 - val_accuracy: 0.7335\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 643.9221 - accuracy: 0.7042 - val_loss: 524.8826 - val_accuracy: 0.7351\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 642.1131 - accuracy: 0.7052 - val_loss: 527.6591 - val_accuracy: 0.7425\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 643.7100 - accuracy: 0.7051 - val_loss: 526.5630 - val_accuracy: 0.7401\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 643.3895 - accuracy: 0.7014 - val_loss: 524.9123 - val_accuracy: 0.7276\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 645.8146 - accuracy: 0.7048 - val_loss: 529.3019 - val_accuracy: 0.7403\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 650.3177 - accuracy: 0.7038 - val_loss: 529.4237 - val_accuracy: 0.7414\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 647.6235 - accuracy: 0.7057 - val_loss: 533.4390 - val_accuracy: 0.7336\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 655.5604 - accuracy: 0.7070 - val_loss: 548.1377 - val_accuracy: 0.7461\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 647.1534 - accuracy: 0.7060 - val_loss: 531.6237 - val_accuracy: 0.7407\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 641.5171 - accuracy: 0.7066 - val_loss: 527.0426 - val_accuracy: 0.7339\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 638.9594 - accuracy: 0.7041 - val_loss: 520.3036 - val_accuracy: 0.7304\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 636.8602 - accuracy: 0.7025 - val_loss: 521.8071 - val_accuracy: 0.7377\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 636.6476 - accuracy: 0.7096 - val_loss: 519.6533 - val_accuracy: 0.7329\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 636.7854 - accuracy: 0.7055 - val_loss: 522.9465 - val_accuracy: 0.7442\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 635.1633 - accuracy: 0.7101 - val_loss: 520.1431 - val_accuracy: 0.7286\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 633.2790 - accuracy: 0.7064 - val_loss: 518.3049 - val_accuracy: 0.7374\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 632.4003 - accuracy: 0.7047 - val_loss: 518.7477 - val_accuracy: 0.7371\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 632.8492 - accuracy: 0.7107 - val_loss: 518.3571 - val_accuracy: 0.7402\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 632.3623 - accuracy: 0.7054 - val_loss: 515.6676 - val_accuracy: 0.7373\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 630.7678 - accuracy: 0.7094 - val_loss: 517.5834 - val_accuracy: 0.7435\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 630.4214 - accuracy: 0.7084 - val_loss: 515.9564 - val_accuracy: 0.7333\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 629.9108 - accuracy: 0.7090 - val_loss: 518.6627 - val_accuracy: 0.7426\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 630.0667 - accuracy: 0.7088 - val_loss: 520.9272 - val_accuracy: 0.7484\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 631.8585 - accuracy: 0.7085 - val_loss: 514.6338 - val_accuracy: 0.7394\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 631.3574 - accuracy: 0.7090 - val_loss: 517.7814 - val_accuracy: 0.7488\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 628.4729 - accuracy: 0.7060 - val_loss: 516.6022 - val_accuracy: 0.7363\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 628.6132 - accuracy: 0.7083 - val_loss: 522.0154 - val_accuracy: 0.7391\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 629.4314 - accuracy: 0.7094 - val_loss: 517.1470 - val_accuracy: 0.7429\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 628.5426 - accuracy: 0.7084 - val_loss: 516.1243 - val_accuracy: 0.7304\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 628.9252 - accuracy: 0.7064 - val_loss: 514.0182 - val_accuracy: 0.7433\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 625.4382 - accuracy: 0.7066 - val_loss: 516.1406 - val_accuracy: 0.7326\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 629.0099 - accuracy: 0.7053 - val_loss: 513.8414 - val_accuracy: 0.7305\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 630.5793 - accuracy: 0.7085 - val_loss: 518.7076 - val_accuracy: 0.7379\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 632.5270 - accuracy: 0.7057 - val_loss: 517.8310 - val_accuracy: 0.7405\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 628.0284 - accuracy: 0.7121 - val_loss: 513.0594 - val_accuracy: 0.7475\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 628.9214 - accuracy: 0.7039 - val_loss: 511.8465 - val_accuracy: 0.7329\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 622.3967 - accuracy: 0.7125 - val_loss: 510.1103 - val_accuracy: 0.7400\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 621.4294 - accuracy: 0.7127 - val_loss: 511.2708 - val_accuracy: 0.7414\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 622.8102 - accuracy: 0.7130 - val_loss: 517.2418 - val_accuracy: 0.7392\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 628.9054 - accuracy: 0.7073 - val_loss: 513.4642 - val_accuracy: 0.7353\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 625.9742 - accuracy: 0.7133 - val_loss: 513.1359 - val_accuracy: 0.7417\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 624.9995 - accuracy: 0.6908 - val_loss: 508.5101 - val_accuracy: 0.7368\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 623.2883 - accuracy: 0.7135 - val_loss: 518.4027 - val_accuracy: 0.7461\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 625.7231 - accuracy: 0.7087 - val_loss: 510.1490 - val_accuracy: 0.7380\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 621.4963 - accuracy: 0.7133 - val_loss: 515.0630 - val_accuracy: 0.7405\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 621.8619 - accuracy: 0.7107 - val_loss: 510.4475 - val_accuracy: 0.7380\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 620.4119 - accuracy: 0.7113 - val_loss: 509.8708 - val_accuracy: 0.7471\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 619.4781 - accuracy: 0.7093 - val_loss: 512.4191 - val_accuracy: 0.7266\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 621.1200 - accuracy: 0.7093 - val_loss: 508.2247 - val_accuracy: 0.7304\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 618.8251 - accuracy: 0.7089 - val_loss: 520.2095 - val_accuracy: 0.7452\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 623.2741 - accuracy: 0.7104 - val_loss: 515.4206 - val_accuracy: 0.7263\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 620.6165 - accuracy: 0.7154 - val_loss: 507.4480 - val_accuracy: 0.7390\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 617.5234 - accuracy: 0.7114 - val_loss: 505.7377 - val_accuracy: 0.7434\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 618.2233 - accuracy: 0.7094 - val_loss: 506.4172 - val_accuracy: 0.7363\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 616.1194 - accuracy: 0.7142 - val_loss: 504.6297 - val_accuracy: 0.7399\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 614.6125 - accuracy: 0.7131 - val_loss: 505.1838 - val_accuracy: 0.7413\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 615.4395 - accuracy: 0.7154 - val_loss: 506.0466 - val_accuracy: 0.7420\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 616.3315 - accuracy: 0.7134 - val_loss: 505.7100 - val_accuracy: 0.7376\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 616.8715 - accuracy: 0.7135 - val_loss: 510.0915 - val_accuracy: 0.7434\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 615.5590 - accuracy: 0.7148 - val_loss: 505.9711 - val_accuracy: 0.7281\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 617.2547 - accuracy: 0.7109 - val_loss: 505.3937 - val_accuracy: 0.7362\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 617.7314 - accuracy: 0.7134 - val_loss: 505.8261 - val_accuracy: 0.7527\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 618.7999 - accuracy: 0.7134 - val_loss: 507.5334 - val_accuracy: 0.7416\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 614.1111 - accuracy: 0.7153 - val_loss: 506.9896 - val_accuracy: 0.7480\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 614.7944 - accuracy: 0.7114 - val_loss: 503.8923 - val_accuracy: 0.7352\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 612.0699 - accuracy: 0.7143 - val_loss: 501.7061 - val_accuracy: 0.7484\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 613.3339 - accuracy: 0.7148 - val_loss: 508.4868 - val_accuracy: 0.7467\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 613.6399 - accuracy: 0.7190 - val_loss: 502.1254 - val_accuracy: 0.7462\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 611.2728 - accuracy: 0.7114 - val_loss: 502.6406 - val_accuracy: 0.7474\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 611.5826 - accuracy: 0.7173 - val_loss: 502.0538 - val_accuracy: 0.7471\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 609.4036 - accuracy: 0.7168 - val_loss: 500.5948 - val_accuracy: 0.7424\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 608.2642 - accuracy: 0.7143 - val_loss: 500.6320 - val_accuracy: 0.7435\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 607.3843 - accuracy: 0.7157 - val_loss: 500.5840 - val_accuracy: 0.7382\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 607.7344 - accuracy: 0.7160 - val_loss: 499.2131 - val_accuracy: 0.7464\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 611.1723 - accuracy: 0.7161 - val_loss: 503.5734 - val_accuracy: 0.7489\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 614.2739 - accuracy: 0.7127 - val_loss: 504.7206 - val_accuracy: 0.7373\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 612.9808 - accuracy: 0.7151 - val_loss: 503.2361 - val_accuracy: 0.7558\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 608.6782 - accuracy: 0.7095 - val_loss: 499.4356 - val_accuracy: 0.7397\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 607.5472 - accuracy: 0.7151 - val_loss: 500.5086 - val_accuracy: 0.7389\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 607.0748 - accuracy: 0.7157 - val_loss: 500.6970 - val_accuracy: 0.7454\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 606.6967 - accuracy: 0.7128 - val_loss: 500.2575 - val_accuracy: 0.7473\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 605.8678 - accuracy: 0.7166 - val_loss: 499.5485 - val_accuracy: 0.7439\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 605.6689 - accuracy: 0.7188 - val_loss: 499.7299 - val_accuracy: 0.7445\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 605.7087 - accuracy: 0.7174 - val_loss: 499.4080 - val_accuracy: 0.7404\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 612.5593 - accuracy: 0.7193 - val_loss: 497.9128 - val_accuracy: 0.7483\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 608.9697 - accuracy: 0.7176 - val_loss: 501.2088 - val_accuracy: 0.7480\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 608.4041 - accuracy: 0.7142 - val_loss: 498.2956 - val_accuracy: 0.7470\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 608.2800 - accuracy: 0.7206 - val_loss: 501.2184 - val_accuracy: 0.7477\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 606.7509 - accuracy: 0.7168 - val_loss: 500.0182 - val_accuracy: 0.7497\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 603.8730 - accuracy: 0.7171 - val_loss: 497.9034 - val_accuracy: 0.7334\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 604.4128 - accuracy: 0.7145 - val_loss: 503.9457 - val_accuracy: 0.7504\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 607.5698 - accuracy: 0.7160 - val_loss: 502.4363 - val_accuracy: 0.7447\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 611.2079 - accuracy: 0.7141 - val_loss: 499.0477 - val_accuracy: 0.7426\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 606.8390 - accuracy: 0.7205 - val_loss: 498.9395 - val_accuracy: 0.7462\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 604.1853 - accuracy: 0.7203 - val_loss: 495.7245 - val_accuracy: 0.7448\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 606.9626 - accuracy: 0.7187 - val_loss: 497.5248 - val_accuracy: 0.7508\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 601.2980 - accuracy: 0.7186 - val_loss: 496.2855 - val_accuracy: 0.7496\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 602.9818 - accuracy: 0.7199 - val_loss: 501.0160 - val_accuracy: 0.7443\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 603.8245 - accuracy: 0.7182 - val_loss: 495.8613 - val_accuracy: 0.7434\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 602.5399 - accuracy: 0.7180 - val_loss: 496.0328 - val_accuracy: 0.7522\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 602.1503 - accuracy: 0.7160 - val_loss: 497.5915 - val_accuracy: 0.7376\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 603.4014 - accuracy: 0.7157 - val_loss: 494.7069 - val_accuracy: 0.7418\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 601.3790 - accuracy: 0.7213 - val_loss: 495.2109 - val_accuracy: 0.7471\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 599.5571 - accuracy: 0.7194 - val_loss: 493.1694 - val_accuracy: 0.7495\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 599.0619 - accuracy: 0.7192 - val_loss: 494.5957 - val_accuracy: 0.7445\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 599.7621 - accuracy: 0.7192 - val_loss: 494.9529 - val_accuracy: 0.7497\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 599.2869 - accuracy: 0.7178 - val_loss: 496.5427 - val_accuracy: 0.7504\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 600.1856 - accuracy: 0.7212 - val_loss: 494.6000 - val_accuracy: 0.7522\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 599.2822 - accuracy: 0.7204 - val_loss: 494.1812 - val_accuracy: 0.7486\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 598.5489 - accuracy: 0.7210 - val_loss: 494.0981 - val_accuracy: 0.7490\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 598.8657 - accuracy: 0.7188 - val_loss: 498.8264 - val_accuracy: 0.7372\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 600.3166 - accuracy: 0.7192 - val_loss: 498.8386 - val_accuracy: 0.7518\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 606.7208 - accuracy: 0.7162 - val_loss: 498.2934 - val_accuracy: 0.7452\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 604.9259 - accuracy: 0.7208 - val_loss: 506.5715 - val_accuracy: 0.7479\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 603.1322 - accuracy: 0.7188 - val_loss: 493.5282 - val_accuracy: 0.7463\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 599.7809 - accuracy: 0.7168 - val_loss: 497.4975 - val_accuracy: 0.7564\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 600.3857 - accuracy: 0.7217 - val_loss: 498.4617 - val_accuracy: 0.7488\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 617.6950 - accuracy: 0.7189 - val_loss: 521.6151 - val_accuracy: 0.7474\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 607.3165 - accuracy: 0.7205 - val_loss: 494.6127 - val_accuracy: 0.7453\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 601.6816 - accuracy: 0.7187 - val_loss: 491.9882 - val_accuracy: 0.7466\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 597.2495 - accuracy: 0.7171 - val_loss: 493.7947 - val_accuracy: 0.7553\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 597.4047 - accuracy: 0.7226 - val_loss: 492.1606 - val_accuracy: 0.7471\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 594.7538 - accuracy: 0.7235 - val_loss: 492.0968 - val_accuracy: 0.7515\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 594.5002 - accuracy: 0.7210 - val_loss: 491.1151 - val_accuracy: 0.7518\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 594.2670 - accuracy: 0.7217 - val_loss: 492.6997 - val_accuracy: 0.7508\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 593.3312 - accuracy: 0.7230 - val_loss: 490.8122 - val_accuracy: 0.7522\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 594.0463 - accuracy: 0.7224 - val_loss: 492.0633 - val_accuracy: 0.7544\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 596.8691 - accuracy: 0.7222 - val_loss: 491.0138 - val_accuracy: 0.7532\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 598.4036 - accuracy: 0.7231 - val_loss: 495.0732 - val_accuracy: 0.7527\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 597.2441 - accuracy: 0.7234 - val_loss: 490.0251 - val_accuracy: 0.7513\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 594.3013 - accuracy: 0.7225 - val_loss: 497.4030 - val_accuracy: 0.7479\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 597.6583 - accuracy: 0.7226 - val_loss: 490.4338 - val_accuracy: 0.7513\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 596.6802 - accuracy: 0.7213 - val_loss: 490.7614 - val_accuracy: 0.7563\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 596.4106 - accuracy: 0.7253 - val_loss: 492.1105 - val_accuracy: 0.7458\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 596.0893 - accuracy: 0.7230 - val_loss: 494.6311 - val_accuracy: 0.7526\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 596.0166 - accuracy: 0.7220 - val_loss: 494.8267 - val_accuracy: 0.7526\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 594.7294 - accuracy: 0.7211 - val_loss: 492.8163 - val_accuracy: 0.7569\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 593.2598 - accuracy: 0.7254 - val_loss: 489.5613 - val_accuracy: 0.7522\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 594.2224 - accuracy: 0.7234 - val_loss: 489.8011 - val_accuracy: 0.7524\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 593.5131 - accuracy: 0.7206 - val_loss: 490.2825 - val_accuracy: 0.7483\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 592.1675 - accuracy: 0.7218 - val_loss: 489.2702 - val_accuracy: 0.7469\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 591.9183 - accuracy: 0.7206 - val_loss: 493.2054 - val_accuracy: 0.7520\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 591.4479 - accuracy: 0.7234 - val_loss: 488.8545 - val_accuracy: 0.7491\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 590.3650 - accuracy: 0.7226 - val_loss: 487.7887 - val_accuracy: 0.7528\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 590.4301 - accuracy: 0.7247 - val_loss: 489.3122 - val_accuracy: 0.7551\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 592.8125 - accuracy: 0.7245 - val_loss: 490.3083 - val_accuracy: 0.7546\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 589.7236 - accuracy: 0.7253 - val_loss: 488.3825 - val_accuracy: 0.7470\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 589.3409 - accuracy: 0.7235 - val_loss: 489.5905 - val_accuracy: 0.7569\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 588.8641 - accuracy: 0.7255 - val_loss: 492.4910 - val_accuracy: 0.7489\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 594.2236 - accuracy: 0.7246 - val_loss: 488.3919 - val_accuracy: 0.7562\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 593.6790 - accuracy: 0.7268 - val_loss: 487.0813 - val_accuracy: 0.7524\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 592.4648 - accuracy: 0.7263 - val_loss: 488.5745 - val_accuracy: 0.7548\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 591.9084 - accuracy: 0.7242 - val_loss: 492.3293 - val_accuracy: 0.7462\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 594.2623 - accuracy: 0.7259 - val_loss: 488.7176 - val_accuracy: 0.7511\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 589.4572 - accuracy: 0.7251 - val_loss: 486.9564 - val_accuracy: 0.7570\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 589.6505 - accuracy: 0.7241 - val_loss: 487.2509 - val_accuracy: 0.7523\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 589.2258 - accuracy: 0.7259 - val_loss: 487.4793 - val_accuracy: 0.7551\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 590.1782 - accuracy: 0.7234 - val_loss: 489.6249 - val_accuracy: 0.7530\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 589.1342 - accuracy: 0.7248 - val_loss: 487.3531 - val_accuracy: 0.7489\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 588.7579 - accuracy: 0.7271 - val_loss: 488.2114 - val_accuracy: 0.7520\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 587.8181 - accuracy: 0.7235 - val_loss: 486.4822 - val_accuracy: 0.7548\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 588.8692 - accuracy: 0.7271 - val_loss: 489.3978 - val_accuracy: 0.7536\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 589.0659 - accuracy: 0.7266 - val_loss: 485.7853 - val_accuracy: 0.7570\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 591.0302 - accuracy: 0.7235 - val_loss: 485.7152 - val_accuracy: 0.7538\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 591.2051 - accuracy: 0.7262 - val_loss: 489.8167 - val_accuracy: 0.7554\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 587.4130 - accuracy: 0.7262 - val_loss: 486.8776 - val_accuracy: 0.7556\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 588.3732 - accuracy: 0.7245 - val_loss: 486.3513 - val_accuracy: 0.7558\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 592.1898 - accuracy: 0.7275 - val_loss: 497.1174 - val_accuracy: 0.7529\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 591.3468 - accuracy: 0.7282 - val_loss: 487.7050 - val_accuracy: 0.7501\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 587.7709 - accuracy: 0.7266 - val_loss: 487.7917 - val_accuracy: 0.7598\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 586.9333 - accuracy: 0.7253 - val_loss: 486.1180 - val_accuracy: 0.7496\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 586.0044 - accuracy: 0.7263 - val_loss: 485.5894 - val_accuracy: 0.7588\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 584.8301 - accuracy: 0.7257 - val_loss: 486.7740 - val_accuracy: 0.7557\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 586.0711 - accuracy: 0.7273 - val_loss: 488.4200 - val_accuracy: 0.7511\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 587.6431 - accuracy: 0.7247 - val_loss: 489.8813 - val_accuracy: 0.7517\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 591.1185 - accuracy: 0.7255 - val_loss: 486.0648 - val_accuracy: 0.7537\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 586.0825 - accuracy: 0.7265 - val_loss: 487.1294 - val_accuracy: 0.7472\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 584.7525 - accuracy: 0.7252 - val_loss: 484.5727 - val_accuracy: 0.7583\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 584.9077 - accuracy: 0.7271 - val_loss: 490.5043 - val_accuracy: 0.7560\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 587.0462 - accuracy: 0.7253 - val_loss: 489.0402 - val_accuracy: 0.7569\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 591.3427 - accuracy: 0.7256 - val_loss: 487.0502 - val_accuracy: 0.7576\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 587.4370 - accuracy: 0.7291 - val_loss: 484.6180 - val_accuracy: 0.7536\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 588.5888 - accuracy: 0.7285 - val_loss: 484.9274 - val_accuracy: 0.7528\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 586.1562 - accuracy: 0.7268 - val_loss: 485.7819 - val_accuracy: 0.7583\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 585.6869 - accuracy: 0.7282 - val_loss: 486.8421 - val_accuracy: 0.7481\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 585.3931 - accuracy: 0.7286 - val_loss: 490.1747 - val_accuracy: 0.7540\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 588.0014 - accuracy: 0.7251 - val_loss: 486.2947 - val_accuracy: 0.7539\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 583.7806 - accuracy: 0.7301 - val_loss: 488.1639 - val_accuracy: 0.7568\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 584.3065 - accuracy: 0.7256 - val_loss: 484.6770 - val_accuracy: 0.7586\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 585.5025 - accuracy: 0.7303 - val_loss: 484.8599 - val_accuracy: 0.7496\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 585.9172 - accuracy: 0.7273 - val_loss: 486.3694 - val_accuracy: 0.7572\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 585.6458 - accuracy: 0.7318 - val_loss: 489.6230 - val_accuracy: 0.7582\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 586.9411 - accuracy: 0.7277 - val_loss: 486.9052 - val_accuracy: 0.7530\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 585.0333 - accuracy: 0.7320 - val_loss: 485.7216 - val_accuracy: 0.7597\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 583.4084 - accuracy: 0.7249 - val_loss: 484.8156 - val_accuracy: 0.7564\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 583.1965 - accuracy: 0.7277 - val_loss: 487.1271 - val_accuracy: 0.7600\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 584.7866 - accuracy: 0.7295 - val_loss: 483.6466 - val_accuracy: 0.7562\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 581.7083 - accuracy: 0.7289 - val_loss: 486.1584 - val_accuracy: 0.7602\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 581.9608 - accuracy: 0.7286 - val_loss: 482.6689 - val_accuracy: 0.7544\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 582.1571 - accuracy: 0.7301 - val_loss: 483.0764 - val_accuracy: 0.7600\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 583.4565 - accuracy: 0.7295 - val_loss: 488.5965 - val_accuracy: 0.7507\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 588.4484 - accuracy: 0.7301 - val_loss: 485.5804 - val_accuracy: 0.7588\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 582.5510 - accuracy: 0.7289 - val_loss: 483.9105 - val_accuracy: 0.7556\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 581.5684 - accuracy: 0.7307 - val_loss: 484.3543 - val_accuracy: 0.7592\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 582.5977 - accuracy: 0.7305 - val_loss: 485.1212 - val_accuracy: 0.7530\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 583.4216 - accuracy: 0.7287 - val_loss: 482.5406 - val_accuracy: 0.7568\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 581.8676 - accuracy: 0.7314 - val_loss: 486.0511 - val_accuracy: 0.7560\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 582.6544 - accuracy: 0.7300 - val_loss: 483.6376 - val_accuracy: 0.7589\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 582.0529 - accuracy: 0.7311 - val_loss: 483.7795 - val_accuracy: 0.7594\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 580.3189 - accuracy: 0.7326 - val_loss: 483.2559 - val_accuracy: 0.7621\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 580.7213 - accuracy: 0.7307 - val_loss: 485.1827 - val_accuracy: 0.7553\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 581.7527 - accuracy: 0.7315 - val_loss: 491.0291 - val_accuracy: 0.7491\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 587.2838 - accuracy: 0.7295 - val_loss: 493.6468 - val_accuracy: 0.7598\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 583.2641 - accuracy: 0.7296 - val_loss: 481.7159 - val_accuracy: 0.7580\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 581.0693 - accuracy: 0.7297 - val_loss: 481.0298 - val_accuracy: 0.7606\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 579.0459 - accuracy: 0.7331 - val_loss: 482.4226 - val_accuracy: 0.7548\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 579.2844 - accuracy: 0.7345 - val_loss: 481.5160 - val_accuracy: 0.7600\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 579.2886 - accuracy: 0.7284 - val_loss: 482.4442 - val_accuracy: 0.7608\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 579.2548 - accuracy: 0.7331 - val_loss: 486.9292 - val_accuracy: 0.7554\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 581.5920 - accuracy: 0.7310 - val_loss: 485.8669 - val_accuracy: 0.7649\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 581.3185 - accuracy: 0.7326 - val_loss: 483.1249 - val_accuracy: 0.7571\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 580.6370 - accuracy: 0.7306 - val_loss: 483.0432 - val_accuracy: 0.7558\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 580.5179 - accuracy: 0.7327 - val_loss: 483.7244 - val_accuracy: 0.7613\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 580.6009 - accuracy: 0.7342 - val_loss: 486.8761 - val_accuracy: 0.7641\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 582.2096 - accuracy: 0.7336 - val_loss: 482.6886 - val_accuracy: 0.7601\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 579.7744 - accuracy: 0.7321 - val_loss: 482.2621 - val_accuracy: 0.7581\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 578.8721 - accuracy: 0.7318 - val_loss: 481.5124 - val_accuracy: 0.7606\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 579.7213 - accuracy: 0.7334 - val_loss: 483.5287 - val_accuracy: 0.7567\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 583.7710 - accuracy: 0.7332 - val_loss: 486.0932 - val_accuracy: 0.7633\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 581.4335 - accuracy: 0.7336 - val_loss: 481.9791 - val_accuracy: 0.7579\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 580.3083 - accuracy: 0.7330 - val_loss: 480.3769 - val_accuracy: 0.7589\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 580.1169 - accuracy: 0.7353 - val_loss: 482.9543 - val_accuracy: 0.7672\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 578.4437 - accuracy: 0.7322 - val_loss: 480.3777 - val_accuracy: 0.7595\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 577.6420 - accuracy: 0.7345 - val_loss: 481.8448 - val_accuracy: 0.7619\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 578.5857 - accuracy: 0.7339 - val_loss: 480.6017 - val_accuracy: 0.7570\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 578.3060 - accuracy: 0.7341 - val_loss: 485.1633 - val_accuracy: 0.7576\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 580.4613 - accuracy: 0.7356 - val_loss: 481.4664 - val_accuracy: 0.7607\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 578.3851 - accuracy: 0.7327 - val_loss: 481.3457 - val_accuracy: 0.7600\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 577.6476 - accuracy: 0.7334 - val_loss: 483.2192 - val_accuracy: 0.7634\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 579.5742 - accuracy: 0.7340 - val_loss: 479.7453 - val_accuracy: 0.7599\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 579.6493 - accuracy: 0.7336 - val_loss: 483.8126 - val_accuracy: 0.7570\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 577.3802 - accuracy: 0.7331 - val_loss: 481.1368 - val_accuracy: 0.7593\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 575.6227 - accuracy: 0.7345 - val_loss: 478.7603 - val_accuracy: 0.7592\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 575.5541 - accuracy: 0.7346 - val_loss: 479.9741 - val_accuracy: 0.7588\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 575.6522 - accuracy: 0.7372 - val_loss: 481.3430 - val_accuracy: 0.7652\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 577.0309 - accuracy: 0.7344 - val_loss: 483.7796 - val_accuracy: 0.7576\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 582.1700 - accuracy: 0.7351 - val_loss: 484.3885 - val_accuracy: 0.7652\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 594.2884 - accuracy: 0.7341 - val_loss: 479.9509 - val_accuracy: 0.7588\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 591.2792 - accuracy: 0.7355 - val_loss: 490.8146 - val_accuracy: 0.7607\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 581.9493 - accuracy: 0.7335 - val_loss: 481.1155 - val_accuracy: 0.7632\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 576.0743 - accuracy: 0.7353 - val_loss: 483.6607 - val_accuracy: 0.7582\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 576.7820 - accuracy: 0.7343 - val_loss: 479.5401 - val_accuracy: 0.7617\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 574.5549 - accuracy: 0.7367 - val_loss: 480.4683 - val_accuracy: 0.7615\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 575.7888 - accuracy: 0.7361 - val_loss: 478.7507 - val_accuracy: 0.7609\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 575.1495 - accuracy: 0.7363 - val_loss: 478.3086 - val_accuracy: 0.7602\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 574.6113 - accuracy: 0.7371 - val_loss: 479.9771 - val_accuracy: 0.7606\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 573.5925 - accuracy: 0.7351 - val_loss: 478.7641 - val_accuracy: 0.7634\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 574.8903 - accuracy: 0.7365 - val_loss: 480.5394 - val_accuracy: 0.7598\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 574.0719 - accuracy: 0.7373 - val_loss: 478.4145 - val_accuracy: 0.7624\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 573.6882 - accuracy: 0.7374 - val_loss: 479.3212 - val_accuracy: 0.7592\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 574.6554 - accuracy: 0.7330 - val_loss: 477.6486 - val_accuracy: 0.7605\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 575.0804 - accuracy: 0.7369 - val_loss: 479.1115 - val_accuracy: 0.7709\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 577.9091 - accuracy: 0.7352 - val_loss: 477.9367 - val_accuracy: 0.7632\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 573.0748 - accuracy: 0.7375 - val_loss: 478.2068 - val_accuracy: 0.7597\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 573.3692 - accuracy: 0.7364 - val_loss: 479.0088 - val_accuracy: 0.7675\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 572.6768 - accuracy: 0.7364 - val_loss: 477.5778 - val_accuracy: 0.7614\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 572.1581 - accuracy: 0.7382 - val_loss: 479.4017 - val_accuracy: 0.7641\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 573.6570 - accuracy: 0.7375 - val_loss: 477.9175 - val_accuracy: 0.7614\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 573.8821 - accuracy: 0.7370 - val_loss: 480.3210 - val_accuracy: 0.7619\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 572.7014 - accuracy: 0.7367 - val_loss: 480.8625 - val_accuracy: 0.7562\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 575.3321 - accuracy: 0.7357 - val_loss: 478.9733 - val_accuracy: 0.7664\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 579.0831 - accuracy: 0.7344 - val_loss: 490.1492 - val_accuracy: 0.7601\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 583.2918 - accuracy: 0.7372 - val_loss: 480.5945 - val_accuracy: 0.7635\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 576.4086 - accuracy: 0.7387 - val_loss: 479.2456 - val_accuracy: 0.7617\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 577.4158 - accuracy: 0.7375 - val_loss: 477.2232 - val_accuracy: 0.7612\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 575.1505 - accuracy: 0.7375 - val_loss: 489.0463 - val_accuracy: 0.7598\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 577.0043 - accuracy: 0.7378 - val_loss: 478.9488 - val_accuracy: 0.7630\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 572.4988 - accuracy: 0.7380 - val_loss: 477.3126 - val_accuracy: 0.7696\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 572.4011 - accuracy: 0.7389 - val_loss: 480.9284 - val_accuracy: 0.7606\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 573.7618 - accuracy: 0.7366 - val_loss: 478.5259 - val_accuracy: 0.7598\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 573.3152 - accuracy: 0.7371 - val_loss: 477.7408 - val_accuracy: 0.7661\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 572.7237 - accuracy: 0.7384 - val_loss: 479.5665 - val_accuracy: 0.7621\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 573.4161 - accuracy: 0.7396 - val_loss: 477.1388 - val_accuracy: 0.7643\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 570.9793 - accuracy: 0.7391 - val_loss: 477.2142 - val_accuracy: 0.7673\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 570.9379 - accuracy: 0.7386 - val_loss: 479.9402 - val_accuracy: 0.7656\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 571.2829 - accuracy: 0.7379 - val_loss: 477.0309 - val_accuracy: 0.7654\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 570.6059 - accuracy: 0.7392 - val_loss: 476.9009 - val_accuracy: 0.7640\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 571.8612 - accuracy: 0.7382 - val_loss: 483.9541 - val_accuracy: 0.7688\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 577.2725 - accuracy: 0.7398 - val_loss: 492.0191 - val_accuracy: 0.7648\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 584.5942 - accuracy: 0.7403 - val_loss: 481.8493 - val_accuracy: 0.7681\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 575.7250 - accuracy: 0.7372 - val_loss: 483.8708 - val_accuracy: 0.7593\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 576.3697 - accuracy: 0.7404 - val_loss: 479.1328 - val_accuracy: 0.7679\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 572.4525 - accuracy: 0.7412 - val_loss: 476.7292 - val_accuracy: 0.7678\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 570.1228 - accuracy: 0.7392 - val_loss: 478.2402 - val_accuracy: 0.7584\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 571.9425 - accuracy: 0.7387 - val_loss: 484.7935 - val_accuracy: 0.7762\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 577.1721 - accuracy: 0.7381 - val_loss: 476.4668 - val_accuracy: 0.7739\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 572.0587 - accuracy: 0.7386 - val_loss: 475.3707 - val_accuracy: 0.7626\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 572.6126 - accuracy: 0.7390 - val_loss: 479.5419 - val_accuracy: 0.7665\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 572.1216 - accuracy: 0.7408 - val_loss: 476.0940 - val_accuracy: 0.7681\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 570.9903 - accuracy: 0.7402 - val_loss: 477.3019 - val_accuracy: 0.7699\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 569.6377 - accuracy: 0.7390 - val_loss: 476.5319 - val_accuracy: 0.7703\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 569.4225 - accuracy: 0.7398 - val_loss: 474.5588 - val_accuracy: 0.7694\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 569.2576 - accuracy: 0.7405 - val_loss: 477.6130 - val_accuracy: 0.7686\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 572.0351 - accuracy: 0.7410 - val_loss: 477.9911 - val_accuracy: 0.7665\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 571.4428 - accuracy: 0.7396 - val_loss: 474.6603 - val_accuracy: 0.7646\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 569.1587 - accuracy: 0.7396 - val_loss: 474.7929 - val_accuracy: 0.7665\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 569.0543 - accuracy: 0.7405 - val_loss: 476.7627 - val_accuracy: 0.7739\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 570.4521 - accuracy: 0.7410 - val_loss: 484.0885 - val_accuracy: 0.7659\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 573.9382 - accuracy: 0.7413 - val_loss: 476.1251 - val_accuracy: 0.7657\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 572.3770 - accuracy: 0.7394 - val_loss: 475.6015 - val_accuracy: 0.7697\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 569.8785 - accuracy: 0.7413 - val_loss: 475.5010 - val_accuracy: 0.7705\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 569.0775 - accuracy: 0.7406 - val_loss: 475.1747 - val_accuracy: 0.7658\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 569.0572 - accuracy: 0.7412 - val_loss: 475.0003 - val_accuracy: 0.7714\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 570.2680 - accuracy: 0.7419 - val_loss: 476.9944 - val_accuracy: 0.7690\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 568.2154 - accuracy: 0.7408 - val_loss: 474.7263 - val_accuracy: 0.7678\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 568.5027 - accuracy: 0.7418 - val_loss: 475.3522 - val_accuracy: 0.7698\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 568.0179 - accuracy: 0.7403 - val_loss: 476.2534 - val_accuracy: 0.7704\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 568.5172 - accuracy: 0.7410 - val_loss: 473.8065 - val_accuracy: 0.7689\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 570.6628 - accuracy: 0.7411 - val_loss: 476.3308 - val_accuracy: 0.7669\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 569.1453 - accuracy: 0.7407 - val_loss: 474.7220 - val_accuracy: 0.7669\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 567.9338 - accuracy: 0.7408 - val_loss: 474.3326 - val_accuracy: 0.7704\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 568.4092 - accuracy: 0.7423 - val_loss: 476.5523 - val_accuracy: 0.7692\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 569.5826 - accuracy: 0.7412 - val_loss: 475.0974 - val_accuracy: 0.7694\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 570.3956 - accuracy: 0.7414 - val_loss: 476.6688 - val_accuracy: 0.7784\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 570.1922 - accuracy: 0.7425 - val_loss: 478.3621 - val_accuracy: 0.7643\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 568.4374 - accuracy: 0.7402 - val_loss: 475.7298 - val_accuracy: 0.7682\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 568.6350 - accuracy: 0.7415 - val_loss: 475.3233 - val_accuracy: 0.7672\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 568.5897 - accuracy: 0.7387 - val_loss: 476.3661 - val_accuracy: 0.7752\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 569.0438 - accuracy: 0.7431 - val_loss: 476.2369 - val_accuracy: 0.7671\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 567.8409 - accuracy: 0.7413 - val_loss: 476.8119 - val_accuracy: 0.7688\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 568.8563 - accuracy: 0.7407 - val_loss: 475.0860 - val_accuracy: 0.7682\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 567.3624 - accuracy: 0.7448 - val_loss: 474.9316 - val_accuracy: 0.7734\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 566.1704 - accuracy: 0.7413 - val_loss: 479.7754 - val_accuracy: 0.7647\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 568.7684 - accuracy: 0.7433 - val_loss: 476.5952 - val_accuracy: 0.7705\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 567.7380 - accuracy: 0.7417 - val_loss: 474.5661 - val_accuracy: 0.7750\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 565.9939 - accuracy: 0.7432 - val_loss: 475.5568 - val_accuracy: 0.7715\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 568.4876 - accuracy: 0.7432 - val_loss: 473.4142 - val_accuracy: 0.7744\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 569.1669 - accuracy: 0.7435 - val_loss: 474.4563 - val_accuracy: 0.7783\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 569.9268 - accuracy: 0.7441 - val_loss: 480.5319 - val_accuracy: 0.7682\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 573.2327 - accuracy: 0.7421 - val_loss: 479.1679 - val_accuracy: 0.7749\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 569.8121 - accuracy: 0.7442 - val_loss: 474.3730 - val_accuracy: 0.7725\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 568.3424 - accuracy: 0.7431 - val_loss: 472.8506 - val_accuracy: 0.7722\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 567.1585 - accuracy: 0.7430 - val_loss: 474.2681 - val_accuracy: 0.7732\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 567.5847 - accuracy: 0.7442 - val_loss: 476.0363 - val_accuracy: 0.7698\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 569.9698 - accuracy: 0.7451 - val_loss: 473.3454 - val_accuracy: 0.7731\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 568.2985 - accuracy: 0.7420 - val_loss: 473.0885 - val_accuracy: 0.7743\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 566.7955 - accuracy: 0.7418 - val_loss: 473.6632 - val_accuracy: 0.7764\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 566.3324 - accuracy: 0.7450 - val_loss: 473.0594 - val_accuracy: 0.7684\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 566.3307 - accuracy: 0.7451 - val_loss: 473.6907 - val_accuracy: 0.7807\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 568.0217 - accuracy: 0.7439 - val_loss: 473.7207 - val_accuracy: 0.7746\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 567.1738 - accuracy: 0.7424 - val_loss: 471.8029 - val_accuracy: 0.7751\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 565.5992 - accuracy: 0.7447 - val_loss: 473.9041 - val_accuracy: 0.7730\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 564.5220 - accuracy: 0.7429 - val_loss: 471.7083 - val_accuracy: 0.7699\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 565.1417 - accuracy: 0.7439 - val_loss: 472.3325 - val_accuracy: 0.7764\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 564.5519 - accuracy: 0.7449 - val_loss: 472.3918 - val_accuracy: 0.7721\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 564.4988 - accuracy: 0.7448 - val_loss: 472.2437 - val_accuracy: 0.7710\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 565.5020 - accuracy: 0.7439 - val_loss: 477.0263 - val_accuracy: 0.7732\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 567.8955 - accuracy: 0.7431 - val_loss: 472.2247 - val_accuracy: 0.7736\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 572.3268 - accuracy: 0.7440 - val_loss: 482.8560 - val_accuracy: 0.7757\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 577.9745 - accuracy: 0.7434 - val_loss: 489.4175 - val_accuracy: 0.7745\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 576.9158 - accuracy: 0.7464 - val_loss: 474.1890 - val_accuracy: 0.7717\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 567.1536 - accuracy: 0.7426 - val_loss: 472.1766 - val_accuracy: 0.7815\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 564.2535 - accuracy: 0.7451 - val_loss: 474.9917 - val_accuracy: 0.7705\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 565.1903 - accuracy: 0.7446 - val_loss: 471.8195 - val_accuracy: 0.7766\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 564.8386 - accuracy: 0.7435 - val_loss: 470.7296 - val_accuracy: 0.7728\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 563.2278 - accuracy: 0.7443 - val_loss: 474.9767 - val_accuracy: 0.7710\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 566.1587 - accuracy: 0.7439 - val_loss: 474.5724 - val_accuracy: 0.7860\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 566.8328 - accuracy: 0.7452 - val_loss: 470.0311 - val_accuracy: 0.7712\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 564.4557 - accuracy: 0.7431 - val_loss: 471.9034 - val_accuracy: 0.7819\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 563.5082 - accuracy: 0.7445 - val_loss: 471.4052 - val_accuracy: 0.7773\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 561.2206 - accuracy: 0.7434 - val_loss: 470.0942 - val_accuracy: 0.7710\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 563.6429 - accuracy: 0.7429 - val_loss: 477.4673 - val_accuracy: 0.7809\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 564.7859 - accuracy: 0.7441 - val_loss: 468.6127 - val_accuracy: 0.7762\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 561.2055 - accuracy: 0.7437 - val_loss: 469.6159 - val_accuracy: 0.7745\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 561.7814 - accuracy: 0.7405 - val_loss: 473.2107 - val_accuracy: 0.7788\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 563.5486 - accuracy: 0.7426 - val_loss: 473.2472 - val_accuracy: 0.7768\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 561.1425 - accuracy: 0.7443 - val_loss: 465.8486 - val_accuracy: 0.7836\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 558.3818 - accuracy: 0.7398 - val_loss: 465.2383 - val_accuracy: 0.7735\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 556.9074 - accuracy: 0.7431 - val_loss: 465.1168 - val_accuracy: 0.7818\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 556.4891 - accuracy: 0.7427 - val_loss: 463.8545 - val_accuracy: 0.7786\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 556.6608 - accuracy: 0.7437 - val_loss: 464.1413 - val_accuracy: 0.7702\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 555.9301 - accuracy: 0.7441 - val_loss: 464.4749 - val_accuracy: 0.7832\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 555.5687 - accuracy: 0.7433 - val_loss: 464.2552 - val_accuracy: 0.7745\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 554.8864 - accuracy: 0.7421 - val_loss: 464.6068 - val_accuracy: 0.7823\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 555.2332 - accuracy: 0.7432 - val_loss: 465.1945 - val_accuracy: 0.7796\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 554.5374 - accuracy: 0.7454 - val_loss: 466.6439 - val_accuracy: 0.7743\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 555.5460 - accuracy: 0.7439 - val_loss: 471.6486 - val_accuracy: 0.7810\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 561.8080 - accuracy: 0.7456 - val_loss: 466.7361 - val_accuracy: 0.7811\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 556.8018 - accuracy: 0.7460 - val_loss: 462.3008 - val_accuracy: 0.7800\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 557.6243 - accuracy: 0.7447 - val_loss: 474.2818 - val_accuracy: 0.7766\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 555.9224 - accuracy: 0.7442 - val_loss: 462.8755 - val_accuracy: 0.7799\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 553.3808 - accuracy: 0.7456 - val_loss: 463.3810 - val_accuracy: 0.7813\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 552.8585 - accuracy: 0.7462 - val_loss: 464.6382 - val_accuracy: 0.7819\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 554.6040 - accuracy: 0.7478 - val_loss: 469.8540 - val_accuracy: 0.7798\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 554.4385 - accuracy: 0.7458 - val_loss: 465.5482 - val_accuracy: 0.7726\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 553.5494 - accuracy: 0.7454 - val_loss: 463.8463 - val_accuracy: 0.7830\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 554.3175 - accuracy: 0.7464 - val_loss: 460.4152 - val_accuracy: 0.7792\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 550.6052 - accuracy: 0.7464 - val_loss: 464.6456 - val_accuracy: 0.7822\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 551.0840 - accuracy: 0.7469 - val_loss: 464.4505 - val_accuracy: 0.7809\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 550.7094 - accuracy: 0.7468 - val_loss: 460.7994 - val_accuracy: 0.7813\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 549.2131 - accuracy: 0.7471 - val_loss: 460.0144 - val_accuracy: 0.7771\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 549.2168 - accuracy: 0.7460 - val_loss: 462.9329 - val_accuracy: 0.7743\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 548.4909 - accuracy: 0.7458 - val_loss: 466.5970 - val_accuracy: 0.7857\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 551.5642 - accuracy: 0.7474 - val_loss: 463.8714 - val_accuracy: 0.7785\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 552.2269 - accuracy: 0.7467 - val_loss: 467.5383 - val_accuracy: 0.7845\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 551.6905 - accuracy: 0.7461 - val_loss: 462.2488 - val_accuracy: 0.7770\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 548.3026 - accuracy: 0.7467 - val_loss: 462.5142 - val_accuracy: 0.7782\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 547.2739 - accuracy: 0.7453 - val_loss: 459.4286 - val_accuracy: 0.7838\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 548.5456 - accuracy: 0.7470 - val_loss: 459.0428 - val_accuracy: 0.7789\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 548.4648 - accuracy: 0.7488 - val_loss: 460.4685 - val_accuracy: 0.7791\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 548.1415 - accuracy: 0.7475 - val_loss: 460.9678 - val_accuracy: 0.7807\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 551.6638 - accuracy: 0.7467 - val_loss: 462.9813 - val_accuracy: 0.7773\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 557.3948 - accuracy: 0.7468 - val_loss: 460.1023 - val_accuracy: 0.7838\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 548.1059 - accuracy: 0.7478 - val_loss: 462.5759 - val_accuracy: 0.7773\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 548.1078 - accuracy: 0.7481 - val_loss: 459.6330 - val_accuracy: 0.7829\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 546.7523 - accuracy: 0.7475 - val_loss: 462.0375 - val_accuracy: 0.7784\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 547.8437 - accuracy: 0.7487 - val_loss: 467.0062 - val_accuracy: 0.7799\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 547.1363 - accuracy: 0.7457 - val_loss: 460.8306 - val_accuracy: 0.7807\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 545.4557 - accuracy: 0.7475 - val_loss: 457.9261 - val_accuracy: 0.7823\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 545.1299 - accuracy: 0.7486 - val_loss: 462.1956 - val_accuracy: 0.7793\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 547.9642 - accuracy: 0.7460 - val_loss: 459.6640 - val_accuracy: 0.7754\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 549.2682 - accuracy: 0.7469 - val_loss: 460.6829 - val_accuracy: 0.7816\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 545.7419 - accuracy: 0.7463 - val_loss: 460.1844 - val_accuracy: 0.7859\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 545.0399 - accuracy: 0.7485 - val_loss: 458.6129 - val_accuracy: 0.7815\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 544.8777 - accuracy: 0.7480 - val_loss: 461.7361 - val_accuracy: 0.7814\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 554.5930 - accuracy: 0.7472 - val_loss: 485.1889 - val_accuracy: 0.7835\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 561.9959 - accuracy: 0.7463 - val_loss: 462.0030 - val_accuracy: 0.7891\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 552.6608 - accuracy: 0.7488 - val_loss: 458.5845 - val_accuracy: 0.7740\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 549.7089 - accuracy: 0.7480 - val_loss: 460.4878 - val_accuracy: 0.7894\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 548.4661 - accuracy: 0.7479 - val_loss: 457.2249 - val_accuracy: 0.7774\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 543.2155 - accuracy: 0.7476 - val_loss: 459.2744 - val_accuracy: 0.7835\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 544.2712 - accuracy: 0.7490 - val_loss: 456.8040 - val_accuracy: 0.7849\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 542.8662 - accuracy: 0.7479 - val_loss: 456.9657 - val_accuracy: 0.7866\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 542.0628 - accuracy: 0.7485 - val_loss: 457.2529 - val_accuracy: 0.7801\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 541.6353 - accuracy: 0.7492 - val_loss: 457.0285 - val_accuracy: 0.7846\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 543.6512 - accuracy: 0.7476 - val_loss: 458.6181 - val_accuracy: 0.7751\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 544.5336 - accuracy: 0.7470 - val_loss: 458.0759 - val_accuracy: 0.7836\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 542.2018 - accuracy: 0.7475 - val_loss: 457.0685 - val_accuracy: 0.7818\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 542.0689 - accuracy: 0.7482 - val_loss: 458.4039 - val_accuracy: 0.7778\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 542.2786 - accuracy: 0.7471 - val_loss: 455.8261 - val_accuracy: 0.7850\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 542.1000 - accuracy: 0.7479 - val_loss: 462.0895 - val_accuracy: 0.7841\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 544.0093 - accuracy: 0.7469 - val_loss: 456.4195 - val_accuracy: 0.7773\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 545.2898 - accuracy: 0.7467 - val_loss: 459.1030 - val_accuracy: 0.7907\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 547.3159 - accuracy: 0.7470 - val_loss: 457.5423 - val_accuracy: 0.7825\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 542.4268 - accuracy: 0.7484 - val_loss: 457.4541 - val_accuracy: 0.7800\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 542.6061 - accuracy: 0.7478 - val_loss: 459.7333 - val_accuracy: 0.7875\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 542.3960 - accuracy: 0.7473 - val_loss: 466.2241 - val_accuracy: 0.7831\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 551.0187 - accuracy: 0.7460 - val_loss: 459.0450 - val_accuracy: 0.7749\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 543.5623 - accuracy: 0.7468 - val_loss: 456.5695 - val_accuracy: 0.7824\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 541.9406 - accuracy: 0.7493 - val_loss: 457.2112 - val_accuracy: 0.7873\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 544.4202 - accuracy: 0.7497 - val_loss: 466.9539 - val_accuracy: 0.7827\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 546.5847 - accuracy: 0.7464 - val_loss: 457.2731 - val_accuracy: 0.7859\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 542.5829 - accuracy: 0.7488 - val_loss: 457.8083 - val_accuracy: 0.7847\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 541.3235 - accuracy: 0.7478 - val_loss: 456.1396 - val_accuracy: 0.7840\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 540.7330 - accuracy: 0.7490 - val_loss: 456.4436 - val_accuracy: 0.7851\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 538.8798 - accuracy: 0.7497 - val_loss: 455.3519 - val_accuracy: 0.7836\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 539.4321 - accuracy: 0.7491 - val_loss: 454.8562 - val_accuracy: 0.7857\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 541.0971 - accuracy: 0.7495 - val_loss: 457.4907 - val_accuracy: 0.7867\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 547.0056 - accuracy: 0.7481 - val_loss: 464.9671 - val_accuracy: 0.7830\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 542.8948 - accuracy: 0.7494 - val_loss: 455.1958 - val_accuracy: 0.7803\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 538.8259 - accuracy: 0.7491 - val_loss: 458.0954 - val_accuracy: 0.7840\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 541.3505 - accuracy: 0.7491 - val_loss: 455.8423 - val_accuracy: 0.7880\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 541.9643 - accuracy: 0.7480 - val_loss: 455.3605 - val_accuracy: 0.7831\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 540.4752 - accuracy: 0.7494 - val_loss: 454.7115 - val_accuracy: 0.7882\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 540.3697 - accuracy: 0.7490 - val_loss: 455.4645 - val_accuracy: 0.7751\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 538.2102 - accuracy: 0.7499 - val_loss: 456.4911 - val_accuracy: 0.7859\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 541.2318 - accuracy: 0.7497 - val_loss: 462.3268 - val_accuracy: 0.7917\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 540.1613 - accuracy: 0.7499 - val_loss: 456.7906 - val_accuracy: 0.7815\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 538.5763 - accuracy: 0.7493 - val_loss: 454.2852 - val_accuracy: 0.7861\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 538.1599 - accuracy: 0.7500 - val_loss: 454.6766 - val_accuracy: 0.7909\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 544.9102 - accuracy: 0.7497 - val_loss: 458.0671 - val_accuracy: 0.7798\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 542.3618 - accuracy: 0.7502 - val_loss: 458.0455 - val_accuracy: 0.7816\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 538.4933 - accuracy: 0.7471 - val_loss: 455.7190 - val_accuracy: 0.7860\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 538.8920 - accuracy: 0.7487 - val_loss: 454.5327 - val_accuracy: 0.7842\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 538.2339 - accuracy: 0.7498 - val_loss: 454.1266 - val_accuracy: 0.7899\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 538.9125 - accuracy: 0.7500 - val_loss: 456.5397 - val_accuracy: 0.7815\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 536.4243 - accuracy: 0.7506 - val_loss: 454.6309 - val_accuracy: 0.7860\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 536.9401 - accuracy: 0.7503 - val_loss: 455.0767 - val_accuracy: 0.7924\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 540.5595 - accuracy: 0.7507 - val_loss: 455.9538 - val_accuracy: 0.7832\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 537.8509 - accuracy: 0.7496 - val_loss: 453.8050 - val_accuracy: 0.7864\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 540.1201 - accuracy: 0.7479 - val_loss: 453.5055 - val_accuracy: 0.7855\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 537.6362 - accuracy: 0.7500 - val_loss: 454.4555 - val_accuracy: 0.7883\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 536.3204 - accuracy: 0.7498 - val_loss: 453.5204 - val_accuracy: 0.7822\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 536.2803 - accuracy: 0.7508 - val_loss: 453.7701 - val_accuracy: 0.7838\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 535.7325 - accuracy: 0.7493 - val_loss: 456.7116 - val_accuracy: 0.7879\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 538.3073 - accuracy: 0.7501 - val_loss: 453.5772 - val_accuracy: 0.7871\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 539.1700 - accuracy: 0.7498 - val_loss: 454.6053 - val_accuracy: 0.7891\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 540.4969 - accuracy: 0.7504 - val_loss: 454.6451 - val_accuracy: 0.7860\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 538.2419 - accuracy: 0.7498 - val_loss: 454.1177 - val_accuracy: 0.7852\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 535.6085 - accuracy: 0.7505 - val_loss: 453.9033 - val_accuracy: 0.7882\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 535.9991 - accuracy: 0.7511 - val_loss: 455.3357 - val_accuracy: 0.7846\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 537.3701 - accuracy: 0.7500 - val_loss: 452.8233 - val_accuracy: 0.7855\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 536.2275 - accuracy: 0.7477 - val_loss: 454.8315 - val_accuracy: 0.7918\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 536.8417 - accuracy: 0.7520 - val_loss: 454.7270 - val_accuracy: 0.7847\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 536.7504 - accuracy: 0.7502 - val_loss: 452.8602 - val_accuracy: 0.7920\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 534.9851 - accuracy: 0.7505 - val_loss: 454.2123 - val_accuracy: 0.7887\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 535.8659 - accuracy: 0.7503 - val_loss: 452.5122 - val_accuracy: 0.7845\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 536.7166 - accuracy: 0.7503 - val_loss: 453.0513 - val_accuracy: 0.7898\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 535.5243 - accuracy: 0.7503 - val_loss: 459.4576 - val_accuracy: 0.7839\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 539.6860 - accuracy: 0.7508 - val_loss: 452.9207 - val_accuracy: 0.7881\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 538.1739 - accuracy: 0.7491 - val_loss: 456.2484 - val_accuracy: 0.7819\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 539.3264 - accuracy: 0.7490 - val_loss: 451.9075 - val_accuracy: 0.7920\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 535.2413 - accuracy: 0.7522 - val_loss: 456.2639 - val_accuracy: 0.7855\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 537.9056 - accuracy: 0.7501 - val_loss: 454.7642 - val_accuracy: 0.7807\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 536.4463 - accuracy: 0.7496 - val_loss: 453.8287 - val_accuracy: 0.7937\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 536.2278 - accuracy: 0.7512 - val_loss: 452.5392 - val_accuracy: 0.7800\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 535.9446 - accuracy: 0.7520 - val_loss: 452.2124 - val_accuracy: 0.7904\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 534.1575 - accuracy: 0.7485 - val_loss: 456.5956 - val_accuracy: 0.7878\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 550.1340 - accuracy: 0.7513 - val_loss: 466.4427 - val_accuracy: 0.7853\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 555.2269 - accuracy: 0.7496 - val_loss: 456.8029 - val_accuracy: 0.7919\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 555.7001 - accuracy: 0.7474 - val_loss: 456.7759 - val_accuracy: 0.7890\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 555.8613 - accuracy: 0.7480 - val_loss: 454.4915 - val_accuracy: 0.7934\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 543.2753 - accuracy: 0.7516 - val_loss: 461.0300 - val_accuracy: 0.7902\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 540.7052 - accuracy: 0.7500 - val_loss: 457.8895 - val_accuracy: 0.7921\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 546.6589 - accuracy: 0.7518 - val_loss: 452.7736 - val_accuracy: 0.7903\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 539.8215 - accuracy: 0.7492 - val_loss: 461.5888 - val_accuracy: 0.7906\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 536.6215 - accuracy: 0.7510 - val_loss: 452.0535 - val_accuracy: 0.7903\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 536.8127 - accuracy: 0.7507 - val_loss: 454.2788 - val_accuracy: 0.7898\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 536.6318 - accuracy: 0.7505 - val_loss: 452.9824 - val_accuracy: 0.7883\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 533.2106 - accuracy: 0.7510 - val_loss: 450.5922 - val_accuracy: 0.7896\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 532.5238 - accuracy: 0.7507 - val_loss: 451.0251 - val_accuracy: 0.7895\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 533.0134 - accuracy: 0.7517 - val_loss: 450.1969 - val_accuracy: 0.7822\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 533.3212 - accuracy: 0.7507 - val_loss: 450.8091 - val_accuracy: 0.7901\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 532.4337 - accuracy: 0.7515 - val_loss: 452.2461 - val_accuracy: 0.7917\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 531.2525 - accuracy: 0.7509 - val_loss: 451.9433 - val_accuracy: 0.7930\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 533.2933 - accuracy: 0.7517 - val_loss: 451.3450 - val_accuracy: 0.7839\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 534.5611 - accuracy: 0.7522 - val_loss: 459.0863 - val_accuracy: 0.7906\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 541.4796 - accuracy: 0.7514 - val_loss: 455.4452 - val_accuracy: 0.7887\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 534.7617 - accuracy: 0.7514 - val_loss: 449.8465 - val_accuracy: 0.7914\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 531.7886 - accuracy: 0.7524 - val_loss: 450.8122 - val_accuracy: 0.7916\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 532.5908 - accuracy: 0.7505 - val_loss: 452.1587 - val_accuracy: 0.7906\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 532.1262 - accuracy: 0.7507 - val_loss: 450.4430 - val_accuracy: 0.7850\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 531.3426 - accuracy: 0.7494 - val_loss: 452.3829 - val_accuracy: 0.7954\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 532.1406 - accuracy: 0.7513 - val_loss: 451.0408 - val_accuracy: 0.7904\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 531.6328 - accuracy: 0.7514 - val_loss: 451.4326 - val_accuracy: 0.7938\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 531.4338 - accuracy: 0.7511 - val_loss: 452.1329 - val_accuracy: 0.7888\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 533.6359 - accuracy: 0.7514 - val_loss: 460.3126 - val_accuracy: 0.7963\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 533.5134 - accuracy: 0.7506 - val_loss: 452.1578 - val_accuracy: 0.7865\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 532.5576 - accuracy: 0.7505 - val_loss: 450.4334 - val_accuracy: 0.7928\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 530.7802 - accuracy: 0.7519 - val_loss: 450.7507 - val_accuracy: 0.7952\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 530.8528 - accuracy: 0.7520 - val_loss: 450.7543 - val_accuracy: 0.7844\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 530.8908 - accuracy: 0.7518 - val_loss: 453.8646 - val_accuracy: 0.7892\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 533.2654 - accuracy: 0.7499 - val_loss: 449.7603 - val_accuracy: 0.7932\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 531.3277 - accuracy: 0.7526 - val_loss: 450.0243 - val_accuracy: 0.7930\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 530.2086 - accuracy: 0.7519 - val_loss: 449.8616 - val_accuracy: 0.7887\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 531.9787 - accuracy: 0.7505 - val_loss: 449.6366 - val_accuracy: 0.7939\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 532.1176 - accuracy: 0.7531 - val_loss: 451.9677 - val_accuracy: 0.7873\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 535.4938 - accuracy: 0.7511 - val_loss: 459.5229 - val_accuracy: 0.7891\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 537.1575 - accuracy: 0.7518 - val_loss: 459.4194 - val_accuracy: 0.7943\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 540.3192 - accuracy: 0.7530 - val_loss: 462.8082 - val_accuracy: 0.7912\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 535.3371 - accuracy: 0.7531 - val_loss: 453.2954 - val_accuracy: 0.7914\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 532.7854 - accuracy: 0.7526 - val_loss: 450.7998 - val_accuracy: 0.7907\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 530.4467 - accuracy: 0.7514 - val_loss: 453.0114 - val_accuracy: 0.7937\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 536.6823 - accuracy: 0.7540 - val_loss: 455.0719 - val_accuracy: 0.7928\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 536.3864 - accuracy: 0.7521 - val_loss: 449.0879 - val_accuracy: 0.7916\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 534.5222 - accuracy: 0.7518 - val_loss: 460.1971 - val_accuracy: 0.7944\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 533.3655 - accuracy: 0.7521 - val_loss: 460.7616 - val_accuracy: 0.7883\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 533.0322 - accuracy: 0.7520 - val_loss: 450.9855 - val_accuracy: 0.7942\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 529.6016 - accuracy: 0.7536 - val_loss: 448.6427 - val_accuracy: 0.7930\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 528.7935 - accuracy: 0.7527 - val_loss: 450.7829 - val_accuracy: 0.7967\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 528.6537 - accuracy: 0.7534 - val_loss: 448.4011 - val_accuracy: 0.7957\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 530.3747 - accuracy: 0.7524 - val_loss: 448.8116 - val_accuracy: 0.7914\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 528.0983 - accuracy: 0.7524 - val_loss: 448.7599 - val_accuracy: 0.7924\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 528.7448 - accuracy: 0.7516 - val_loss: 448.6796 - val_accuracy: 0.7933\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 528.6780 - accuracy: 0.7532 - val_loss: 449.6438 - val_accuracy: 0.7885\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 527.5528 - accuracy: 0.7512 - val_loss: 449.1368 - val_accuracy: 0.7959\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.3621 - accuracy: 0.7522 - val_loss: 447.8761 - val_accuracy: 0.7967\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 527.4170 - accuracy: 0.7536 - val_loss: 449.9884 - val_accuracy: 0.7923\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 528.4166 - accuracy: 0.7509 - val_loss: 449.6718 - val_accuracy: 0.7936\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 527.0812 - accuracy: 0.7532 - val_loss: 451.9746 - val_accuracy: 0.7958\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 529.0899 - accuracy: 0.7536 - val_loss: 452.5284 - val_accuracy: 0.7869\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 531.0616 - accuracy: 0.7512 - val_loss: 457.3310 - val_accuracy: 0.7936\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 535.9128 - accuracy: 0.7513 - val_loss: 448.8309 - val_accuracy: 0.7915\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 532.6978 - accuracy: 0.7502 - val_loss: 451.7274 - val_accuracy: 0.7933\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 532.5757 - accuracy: 0.7532 - val_loss: 448.1276 - val_accuracy: 0.7910\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.0854 - accuracy: 0.7517 - val_loss: 450.2350 - val_accuracy: 0.7891\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.9481 - accuracy: 0.7530 - val_loss: 447.7918 - val_accuracy: 0.7955\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 528.6434 - accuracy: 0.7515 - val_loss: 448.9849 - val_accuracy: 0.7927\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 529.0760 - accuracy: 0.7516 - val_loss: 449.4207 - val_accuracy: 0.7918\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 530.0615 - accuracy: 0.7531 - val_loss: 451.0505 - val_accuracy: 0.7924\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 529.8658 - accuracy: 0.7527 - val_loss: 448.8215 - val_accuracy: 0.7945\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 530.3685 - accuracy: 0.7518 - val_loss: 449.1335 - val_accuracy: 0.7954\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 527.8645 - accuracy: 0.7533 - val_loss: 447.9862 - val_accuracy: 0.7933\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.4521 - accuracy: 0.7540 - val_loss: 448.5421 - val_accuracy: 0.7878\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.2657 - accuracy: 0.7515 - val_loss: 448.2416 - val_accuracy: 0.7947\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 526.0599 - accuracy: 0.7532 - val_loss: 447.4338 - val_accuracy: 0.7961\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 526.3822 - accuracy: 0.7532 - val_loss: 447.5882 - val_accuracy: 0.7928\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 530.8686 - accuracy: 0.7504 - val_loss: 455.7884 - val_accuracy: 0.7965\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 532.9545 - accuracy: 0.7497 - val_loss: 450.1502 - val_accuracy: 0.7947\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 532.4501 - accuracy: 0.7520 - val_loss: 452.0872 - val_accuracy: 0.7918\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 529.0789 - accuracy: 0.7503 - val_loss: 447.7088 - val_accuracy: 0.7909\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 525.7838 - accuracy: 0.7513 - val_loss: 447.3854 - val_accuracy: 0.7951\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 531.0114 - accuracy: 0.7513 - val_loss: 448.0666 - val_accuracy: 0.7971\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 527.2804 - accuracy: 0.7559 - val_loss: 449.2972 - val_accuracy: 0.7924\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 525.6593 - accuracy: 0.7523 - val_loss: 447.3227 - val_accuracy: 0.7946\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 525.7615 - accuracy: 0.7533 - val_loss: 449.9655 - val_accuracy: 0.7954\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 526.6572 - accuracy: 0.7519 - val_loss: 449.7904 - val_accuracy: 0.7945\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 525.0806 - accuracy: 0.7551 - val_loss: 446.0204 - val_accuracy: 0.7964\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 524.2310 - accuracy: 0.7539 - val_loss: 448.3348 - val_accuracy: 0.7940\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 526.4465 - accuracy: 0.7530 - val_loss: 448.6881 - val_accuracy: 0.7925\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.3068 - accuracy: 0.7527 - val_loss: 449.5585 - val_accuracy: 0.7922\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.5858 - accuracy: 0.7529 - val_loss: 447.6968 - val_accuracy: 0.7897\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 528.4505 - accuracy: 0.7535 - val_loss: 450.2518 - val_accuracy: 0.7988\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 529.2512 - accuracy: 0.7531 - val_loss: 446.7208 - val_accuracy: 0.7935\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.0153 - accuracy: 0.7512 - val_loss: 446.8773 - val_accuracy: 0.7953\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.7457 - accuracy: 0.7542 - val_loss: 449.1158 - val_accuracy: 0.7915\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 525.7855 - accuracy: 0.7516 - val_loss: 450.7366 - val_accuracy: 0.7950\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 528.1366 - accuracy: 0.7532 - val_loss: 447.2091 - val_accuracy: 0.7947\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 525.0318 - accuracy: 0.7521 - val_loss: 447.1707 - val_accuracy: 0.7951\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 525.5952 - accuracy: 0.7526 - val_loss: 449.9950 - val_accuracy: 0.7962\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.9085 - accuracy: 0.7532 - val_loss: 451.4877 - val_accuracy: 0.7930\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 530.5242 - accuracy: 0.7537 - val_loss: 459.0971 - val_accuracy: 0.7977\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 528.4290 - accuracy: 0.7534 - val_loss: 449.0396 - val_accuracy: 0.7973\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 528.0398 - accuracy: 0.7533 - val_loss: 446.5978 - val_accuracy: 0.7927\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 525.0762 - accuracy: 0.7522 - val_loss: 448.4510 - val_accuracy: 0.7960\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 524.7380 - accuracy: 0.7529 - val_loss: 450.9910 - val_accuracy: 0.7964\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 526.4990 - accuracy: 0.7554 - val_loss: 446.7314 - val_accuracy: 0.7898\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 529.2216 - accuracy: 0.7548 - val_loss: 446.1712 - val_accuracy: 0.7963\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 524.3963 - accuracy: 0.7523 - val_loss: 447.0264 - val_accuracy: 0.7992\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 523.7669 - accuracy: 0.7563 - val_loss: 452.0430 - val_accuracy: 0.7937\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 533.1264 - accuracy: 0.7515 - val_loss: 447.5295 - val_accuracy: 0.7996\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.0350 - accuracy: 0.7555 - val_loss: 447.5627 - val_accuracy: 0.7963\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 523.3888 - accuracy: 0.7537 - val_loss: 447.4790 - val_accuracy: 0.7995\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.6897 - accuracy: 0.7542 - val_loss: 455.0062 - val_accuracy: 0.7976\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 524.3925 - accuracy: 0.7545 - val_loss: 445.0671 - val_accuracy: 0.7974\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 523.3114 - accuracy: 0.7539 - val_loss: 446.8099 - val_accuracy: 0.7935\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.7089 - accuracy: 0.7547 - val_loss: 446.9294 - val_accuracy: 0.8006\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.2920 - accuracy: 0.7537 - val_loss: 446.7284 - val_accuracy: 0.7939\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 523.7762 - accuracy: 0.7554 - val_loss: 450.7553 - val_accuracy: 0.7942\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.5528 - accuracy: 0.7544 - val_loss: 447.1898 - val_accuracy: 0.7979\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 528.2960 - accuracy: 0.7554 - val_loss: 446.7968 - val_accuracy: 0.7961\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 529.5162 - accuracy: 0.7538 - val_loss: 448.5337 - val_accuracy: 0.7957\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 526.2468 - accuracy: 0.7561 - val_loss: 456.8716 - val_accuracy: 0.7969\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 526.0328 - accuracy: 0.7552 - val_loss: 445.4273 - val_accuracy: 0.7982\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 522.6865 - accuracy: 0.7562 - val_loss: 447.4932 - val_accuracy: 0.7945\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 522.8739 - accuracy: 0.7533 - val_loss: 453.1622 - val_accuracy: 0.7970\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 526.1452 - accuracy: 0.7563 - val_loss: 457.6489 - val_accuracy: 0.7989\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.8583 - accuracy: 0.7559 - val_loss: 448.2126 - val_accuracy: 0.7945\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 522.6643 - accuracy: 0.7546 - val_loss: 445.9684 - val_accuracy: 0.8005\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 522.2905 - accuracy: 0.7554 - val_loss: 445.0906 - val_accuracy: 0.7987\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 523.0726 - accuracy: 0.7550 - val_loss: 446.3646 - val_accuracy: 0.7977\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 521.5107 - accuracy: 0.7553 - val_loss: 445.1803 - val_accuracy: 0.7924\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 520.2363 - accuracy: 0.7545 - val_loss: 445.8220 - val_accuracy: 0.8001\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 521.0128 - accuracy: 0.7559 - val_loss: 445.8702 - val_accuracy: 0.7913\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 523.3862 - accuracy: 0.7548 - val_loss: 448.0191 - val_accuracy: 0.7994\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 523.2966 - accuracy: 0.7548 - val_loss: 445.3584 - val_accuracy: 0.7935\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 521.3495 - accuracy: 0.7556 - val_loss: 445.9933 - val_accuracy: 0.7986\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 522.7420 - accuracy: 0.7554 - val_loss: 447.7068 - val_accuracy: 0.7982\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 530.1268 - accuracy: 0.7564 - val_loss: 449.4262 - val_accuracy: 0.8000\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.1025 - accuracy: 0.7558 - val_loss: 449.5757 - val_accuracy: 0.8005\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.8864 - accuracy: 0.7549 - val_loss: 445.8221 - val_accuracy: 0.8003\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 526.9188 - accuracy: 0.7559 - val_loss: 456.3701 - val_accuracy: 0.7987\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 530.2915 - accuracy: 0.7554 - val_loss: 451.6867 - val_accuracy: 0.7973\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 524.3582 - accuracy: 0.7559 - val_loss: 457.0912 - val_accuracy: 0.7980\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 525.3874 - accuracy: 0.7554 - val_loss: 447.3439 - val_accuracy: 0.7943\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 525.5410 - accuracy: 0.7544 - val_loss: 446.3854 - val_accuracy: 0.7977\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 526.3653 - accuracy: 0.7551 - val_loss: 447.8956 - val_accuracy: 0.7932\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 523.1172 - accuracy: 0.7556 - val_loss: 449.6881 - val_accuracy: 0.7960\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 522.1038 - accuracy: 0.7548 - val_loss: 444.9853 - val_accuracy: 0.7978\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 521.4768 - accuracy: 0.7571 - val_loss: 447.5030 - val_accuracy: 0.8001\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 520.0910 - accuracy: 0.7543 - val_loss: 444.5664 - val_accuracy: 0.7990\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 519.7701 - accuracy: 0.7555 - val_loss: 444.3646 - val_accuracy: 0.7912\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 520.9805 - accuracy: 0.7525 - val_loss: 445.2162 - val_accuracy: 0.8017\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 521.5139 - accuracy: 0.7538 - val_loss: 451.9452 - val_accuracy: 0.7913\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 521.6013 - accuracy: 0.7552 - val_loss: 444.9920 - val_accuracy: 0.7986\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 524.7084 - accuracy: 0.7562 - val_loss: 452.4746 - val_accuracy: 0.7989\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 525.8556 - accuracy: 0.7575 - val_loss: 462.0601 - val_accuracy: 0.7985\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 526.2958 - accuracy: 0.7556 - val_loss: 448.6093 - val_accuracy: 0.7993\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 523.8549 - accuracy: 0.7560 - val_loss: 456.0744 - val_accuracy: 0.7997\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 523.9561 - accuracy: 0.7563 - val_loss: 444.8652 - val_accuracy: 0.7988\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 521.7303 - accuracy: 0.7546 - val_loss: 449.0891 - val_accuracy: 0.7934\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 521.1437 - accuracy: 0.7560 - val_loss: 443.9807 - val_accuracy: 0.8020\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 519.0305 - accuracy: 0.7578 - val_loss: 446.2033 - val_accuracy: 0.7983\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 519.5922 - accuracy: 0.7561 - val_loss: 445.5345 - val_accuracy: 0.7993\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 518.2611 - accuracy: 0.7562 - val_loss: 446.3506 - val_accuracy: 0.8010\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 521.9919 - accuracy: 0.7574 - val_loss: 447.5203 - val_accuracy: 0.7948\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 522.6462 - accuracy: 0.7568 - val_loss: 444.7370 - val_accuracy: 0.7993\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 521.1599 - accuracy: 0.7558 - val_loss: 446.3430 - val_accuracy: 0.7972\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 520.4067 - accuracy: 0.7561 - val_loss: 444.6304 - val_accuracy: 0.7970\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 518.6909 - accuracy: 0.7579 - val_loss: 444.5777 - val_accuracy: 0.8013\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 519.0087 - accuracy: 0.7561 - val_loss: 444.6695 - val_accuracy: 0.8014\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 519.9341 - accuracy: 0.7559 - val_loss: 450.6870 - val_accuracy: 0.7976\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 523.2219 - accuracy: 0.7567 - val_loss: 445.6415 - val_accuracy: 0.7966\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 524.2158 - accuracy: 0.7571 - val_loss: 444.4909 - val_accuracy: 0.8006\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 520.6856 - accuracy: 0.7571 - val_loss: 445.7730 - val_accuracy: 0.7974\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.9592 - accuracy: 0.7571 - val_loss: 443.8407 - val_accuracy: 0.7986\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 518.3438 - accuracy: 0.7577 - val_loss: 444.3004 - val_accuracy: 0.8032\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 522.8846 - accuracy: 0.7569 - val_loss: 444.6603 - val_accuracy: 0.7968\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 519.6317 - accuracy: 0.7561 - val_loss: 451.2115 - val_accuracy: 0.7995\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 522.7923 - accuracy: 0.7565 - val_loss: 443.8201 - val_accuracy: 0.7971\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 518.3690 - accuracy: 0.7560 - val_loss: 444.6014 - val_accuracy: 0.7978\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 519.9166 - accuracy: 0.7577 - val_loss: 446.1454 - val_accuracy: 0.8008\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 521.4643 - accuracy: 0.7554 - val_loss: 445.0248 - val_accuracy: 0.7992\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 518.9147 - accuracy: 0.7562 - val_loss: 444.3405 - val_accuracy: 0.7986\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 517.1840 - accuracy: 0.7564 - val_loss: 444.1676 - val_accuracy: 0.8025\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.5648 - accuracy: 0.7574 - val_loss: 443.3985 - val_accuracy: 0.8006\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 516.7349 - accuracy: 0.7560 - val_loss: 444.3047 - val_accuracy: 0.7974\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 518.5059 - accuracy: 0.7554 - val_loss: 447.9835 - val_accuracy: 0.7966\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 521.7286 - accuracy: 0.7575 - val_loss: 444.4131 - val_accuracy: 0.8008\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 522.4034 - accuracy: 0.7556 - val_loss: 451.7665 - val_accuracy: 0.7996\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 520.4329 - accuracy: 0.7575 - val_loss: 448.4687 - val_accuracy: 0.8014\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 518.4807 - accuracy: 0.7561 - val_loss: 442.7539 - val_accuracy: 0.7977\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 518.2044 - accuracy: 0.7591 - val_loss: 445.5208 - val_accuracy: 0.8018\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 524.3851 - accuracy: 0.7573 - val_loss: 450.9222 - val_accuracy: 0.7996\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 523.9658 - accuracy: 0.7562 - val_loss: 445.7400 - val_accuracy: 0.8002\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 528.4095 - accuracy: 0.7567 - val_loss: 443.0028 - val_accuracy: 0.7988\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 516.6544 - accuracy: 0.7580 - val_loss: 443.5246 - val_accuracy: 0.7994\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 517.5247 - accuracy: 0.7569 - val_loss: 443.1656 - val_accuracy: 0.8002\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 518.8244 - accuracy: 0.7543 - val_loss: 444.0168 - val_accuracy: 0.8006\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.4020 - accuracy: 0.7579 - val_loss: 443.6667 - val_accuracy: 0.8016\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 516.4020 - accuracy: 0.7572 - val_loss: 444.0269 - val_accuracy: 0.7970\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.5526 - accuracy: 0.7566 - val_loss: 443.2675 - val_accuracy: 0.8005\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 516.0992 - accuracy: 0.7588 - val_loss: 443.5687 - val_accuracy: 0.8041\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 517.1569 - accuracy: 0.7579 - val_loss: 444.2448 - val_accuracy: 0.7990\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 515.9232 - accuracy: 0.7577 - val_loss: 443.8791 - val_accuracy: 0.8004\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 517.2537 - accuracy: 0.7571 - val_loss: 443.6029 - val_accuracy: 0.7987\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 518.0315 - accuracy: 0.7572 - val_loss: 446.0304 - val_accuracy: 0.8011\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.1595 - accuracy: 0.7576 - val_loss: 441.6796 - val_accuracy: 0.7998\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 516.2263 - accuracy: 0.7558 - val_loss: 442.2348 - val_accuracy: 0.7995\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 515.4427 - accuracy: 0.7568 - val_loss: 442.9344 - val_accuracy: 0.8020\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 516.6861 - accuracy: 0.7572 - val_loss: 443.3558 - val_accuracy: 0.8011\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 518.0436 - accuracy: 0.7588 - val_loss: 441.8080 - val_accuracy: 0.7982\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 516.2036 - accuracy: 0.7582 - val_loss: 442.3842 - val_accuracy: 0.7995\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 518.8104 - accuracy: 0.7578 - val_loss: 445.4008 - val_accuracy: 0.8014\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 527.8175 - accuracy: 0.7556 - val_loss: 443.1516 - val_accuracy: 0.8017\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 522.5830 - accuracy: 0.7594 - val_loss: 444.9943 - val_accuracy: 0.7967\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 519.7695 - accuracy: 0.7573 - val_loss: 443.5186 - val_accuracy: 0.8012\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 516.7083 - accuracy: 0.7583 - val_loss: 445.1718 - val_accuracy: 0.8022\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 518.2874 - accuracy: 0.7580 - val_loss: 444.5493 - val_accuracy: 0.7941\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 519.2172 - accuracy: 0.7576 - val_loss: 442.6651 - val_accuracy: 0.7984\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.9672 - accuracy: 0.7574 - val_loss: 441.8419 - val_accuracy: 0.8027\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.3203 - accuracy: 0.7584 - val_loss: 443.0934 - val_accuracy: 0.7996\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 516.6108 - accuracy: 0.7578 - val_loss: 444.9879 - val_accuracy: 0.8012\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 516.7269 - accuracy: 0.7586 - val_loss: 459.4567 - val_accuracy: 0.8012\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 523.9866 - accuracy: 0.7606 - val_loss: 444.2450 - val_accuracy: 0.7994\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 516.9161 - accuracy: 0.7587 - val_loss: 442.1644 - val_accuracy: 0.8014\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 515.9106 - accuracy: 0.7587 - val_loss: 441.7745 - val_accuracy: 0.8000\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 516.2273 - accuracy: 0.7572 - val_loss: 442.6592 - val_accuracy: 0.8037\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 515.5064 - accuracy: 0.7578 - val_loss: 441.4997 - val_accuracy: 0.8004\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 517.7147 - accuracy: 0.7592 - val_loss: 443.0890 - val_accuracy: 0.7989\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 514.9156 - accuracy: 0.7579 - val_loss: 444.9229 - val_accuracy: 0.7991\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 515.3384 - accuracy: 0.7589 - val_loss: 444.2423 - val_accuracy: 0.8005\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 518.1428 - accuracy: 0.7584 - val_loss: 441.7651 - val_accuracy: 0.8009\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 528.7709 - accuracy: 0.7584 - val_loss: 443.0640 - val_accuracy: 0.8016\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 522.9432 - accuracy: 0.7584 - val_loss: 447.2397 - val_accuracy: 0.8019\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 522.3820 - accuracy: 0.7571 - val_loss: 462.1618 - val_accuracy: 0.8028\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 533.5289 - accuracy: 0.7596 - val_loss: 455.6037 - val_accuracy: 0.7982\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 539.3842 - accuracy: 0.7581 - val_loss: 449.7220 - val_accuracy: 0.8012\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 526.2216 - accuracy: 0.7581 - val_loss: 443.1841 - val_accuracy: 0.8021\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 522.2426 - accuracy: 0.7585 - val_loss: 443.0257 - val_accuracy: 0.8019\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 516.4430 - accuracy: 0.7581 - val_loss: 445.7455 - val_accuracy: 0.8024\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 514.8232 - accuracy: 0.7590 - val_loss: 441.6405 - val_accuracy: 0.8009\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.7230 - accuracy: 0.7592 - val_loss: 441.5782 - val_accuracy: 0.8005\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 514.2882 - accuracy: 0.7576 - val_loss: 443.7980 - val_accuracy: 0.8000\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 515.2403 - accuracy: 0.7582 - val_loss: 443.4799 - val_accuracy: 0.8007\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 515.2573 - accuracy: 0.7608 - val_loss: 441.6739 - val_accuracy: 0.8007\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 514.5729 - accuracy: 0.7585 - val_loss: 441.5612 - val_accuracy: 0.8005\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 519.6832 - accuracy: 0.7585 - val_loss: 457.9396 - val_accuracy: 0.7982\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 522.1438 - accuracy: 0.7580 - val_loss: 445.1007 - val_accuracy: 0.8012\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 515.1860 - accuracy: 0.7583 - val_loss: 441.8212 - val_accuracy: 0.8004\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 514.6622 - accuracy: 0.7586 - val_loss: 440.9554 - val_accuracy: 0.7977\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 513.3417 - accuracy: 0.7591 - val_loss: 440.5336 - val_accuracy: 0.8021\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 513.9423 - accuracy: 0.7603 - val_loss: 441.3976 - val_accuracy: 0.8018\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 515.4724 - accuracy: 0.7561 - val_loss: 440.3880 - val_accuracy: 0.8028\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 513.8948 - accuracy: 0.7568 - val_loss: 440.5114 - val_accuracy: 0.7970\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 513.2902 - accuracy: 0.7581 - val_loss: 442.5871 - val_accuracy: 0.8009\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 514.8693 - accuracy: 0.7582 - val_loss: 440.2691 - val_accuracy: 0.8020\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 515.3626 - accuracy: 0.7595 - val_loss: 441.5089 - val_accuracy: 0.8001\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 514.4839 - accuracy: 0.7565 - val_loss: 440.1638 - val_accuracy: 0.8012\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 513.0363 - accuracy: 0.7581 - val_loss: 445.1505 - val_accuracy: 0.7980\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.6995 - accuracy: 0.7591 - val_loss: 448.5293 - val_accuracy: 0.7990\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 516.8901 - accuracy: 0.7593 - val_loss: 441.2671 - val_accuracy: 0.8043\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.0477 - accuracy: 0.7591 - val_loss: 439.6868 - val_accuracy: 0.7980\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 514.1590 - accuracy: 0.7609 - val_loss: 439.3191 - val_accuracy: 0.8013\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 513.2583 - accuracy: 0.7597 - val_loss: 440.5117 - val_accuracy: 0.8021\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 514.5586 - accuracy: 0.7568 - val_loss: 440.9014 - val_accuracy: 0.8022\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.3909 - accuracy: 0.7593 - val_loss: 441.0078 - val_accuracy: 0.8011\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 513.3321 - accuracy: 0.7580 - val_loss: 442.4312 - val_accuracy: 0.8010\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 513.6921 - accuracy: 0.7584 - val_loss: 442.1978 - val_accuracy: 0.7996\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.8623 - accuracy: 0.7589 - val_loss: 440.8068 - val_accuracy: 0.8013\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 514.1853 - accuracy: 0.7596 - val_loss: 442.2795 - val_accuracy: 0.8024\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 513.9863 - accuracy: 0.7592 - val_loss: 440.3131 - val_accuracy: 0.8025\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 516.4777 - accuracy: 0.7595 - val_loss: 439.9278 - val_accuracy: 0.8020\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.3204 - accuracy: 0.7585 - val_loss: 442.7450 - val_accuracy: 0.7998\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.9750 - accuracy: 0.7581 - val_loss: 441.5145 - val_accuracy: 0.8010\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 511.9734 - accuracy: 0.7590 - val_loss: 441.8596 - val_accuracy: 0.8015\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 513.0002 - accuracy: 0.7583 - val_loss: 440.8383 - val_accuracy: 0.8031\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 512.9320 - accuracy: 0.7604 - val_loss: 439.7270 - val_accuracy: 0.7992\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.3938 - accuracy: 0.7607 - val_loss: 440.3406 - val_accuracy: 0.7998\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.9460 - accuracy: 0.7586 - val_loss: 441.4105 - val_accuracy: 0.8005\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.3440 - accuracy: 0.7598 - val_loss: 446.5957 - val_accuracy: 0.8001\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 514.2327 - accuracy: 0.7596 - val_loss: 444.0157 - val_accuracy: 0.8015\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 517.4222 - accuracy: 0.7595 - val_loss: 441.6543 - val_accuracy: 0.8022\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 515.7834 - accuracy: 0.7592 - val_loss: 440.0514 - val_accuracy: 0.8016\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.5717 - accuracy: 0.7597 - val_loss: 440.3305 - val_accuracy: 0.8026\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 511.7978 - accuracy: 0.7585 - val_loss: 439.8383 - val_accuracy: 0.8001\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.1095 - accuracy: 0.7597 - val_loss: 440.9556 - val_accuracy: 0.8005\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.1071 - accuracy: 0.7605 - val_loss: 440.3608 - val_accuracy: 0.8024\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 513.6949 - accuracy: 0.7589 - val_loss: 439.9325 - val_accuracy: 0.7987\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.9748 - accuracy: 0.7601 - val_loss: 439.6922 - val_accuracy: 0.8000\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.5746 - accuracy: 0.7581 - val_loss: 441.3348 - val_accuracy: 0.8024\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.5867 - accuracy: 0.7593 - val_loss: 440.3770 - val_accuracy: 0.8023\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 511.4185 - accuracy: 0.7599 - val_loss: 440.3098 - val_accuracy: 0.8002\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.0076 - accuracy: 0.7585 - val_loss: 446.1002 - val_accuracy: 0.8028\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 515.6588 - accuracy: 0.7595 - val_loss: 440.8285 - val_accuracy: 0.8020\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 512.0944 - accuracy: 0.7596 - val_loss: 440.4465 - val_accuracy: 0.8005\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 511.8022 - accuracy: 0.7583 - val_loss: 438.4753 - val_accuracy: 0.8021\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 511.8854 - accuracy: 0.7609 - val_loss: 441.4716 - val_accuracy: 0.7994\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 511.2064 - accuracy: 0.7596 - val_loss: 441.2096 - val_accuracy: 0.8032\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 514.1461 - accuracy: 0.7595 - val_loss: 440.1577 - val_accuracy: 0.7996\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.2655 - accuracy: 0.7600 - val_loss: 439.7025 - val_accuracy: 0.8014\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 510.7639 - accuracy: 0.7594 - val_loss: 439.5387 - val_accuracy: 0.8020\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 510.9845 - accuracy: 0.7603 - val_loss: 438.8723 - val_accuracy: 0.8001\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 511.1322 - accuracy: 0.7603 - val_loss: 439.6939 - val_accuracy: 0.8024\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 511.2942 - accuracy: 0.7615 - val_loss: 440.5267 - val_accuracy: 0.8008\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 512.5856 - accuracy: 0.7595 - val_loss: 438.7914 - val_accuracy: 0.8015\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.0389 - accuracy: 0.7605 - val_loss: 444.1621 - val_accuracy: 0.8014\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 513.5761 - accuracy: 0.7586 - val_loss: 442.1748 - val_accuracy: 0.8029\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.6013 - accuracy: 0.7587 - val_loss: 440.8841 - val_accuracy: 0.8025\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 513.3596 - accuracy: 0.7597 - val_loss: 439.8335 - val_accuracy: 0.8010\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 512.6948 - accuracy: 0.7598 - val_loss: 439.9896 - val_accuracy: 0.8030\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 512.1681 - accuracy: 0.7606 - val_loss: 442.7257 - val_accuracy: 0.7952\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.6165 - accuracy: 0.7585 - val_loss: 455.1881 - val_accuracy: 0.8040\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 515.8326 - accuracy: 0.7588 - val_loss: 441.9476 - val_accuracy: 0.7985\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.2901 - accuracy: 0.7601 - val_loss: 440.5725 - val_accuracy: 0.8018\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 511.7272 - accuracy: 0.7581 - val_loss: 439.8675 - val_accuracy: 0.8022\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 511.7720 - accuracy: 0.7605 - val_loss: 439.8166 - val_accuracy: 0.8010\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.9276 - accuracy: 0.7600 - val_loss: 438.7691 - val_accuracy: 0.8036\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 515.1219 - accuracy: 0.7595 - val_loss: 439.4154 - val_accuracy: 0.7993\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.8451 - accuracy: 0.7592 - val_loss: 439.6069 - val_accuracy: 0.8008\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 511.3750 - accuracy: 0.7613 - val_loss: 440.8141 - val_accuracy: 0.7997\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 510.4268 - accuracy: 0.7608 - val_loss: 438.4739 - val_accuracy: 0.8033\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 510.2370 - accuracy: 0.7599 - val_loss: 442.4232 - val_accuracy: 0.8026\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.4094 - accuracy: 0.7604 - val_loss: 441.9089 - val_accuracy: 0.8008\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 510.5521 - accuracy: 0.7604 - val_loss: 441.7570 - val_accuracy: 0.7992\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.1231 - accuracy: 0.7607 - val_loss: 441.0382 - val_accuracy: 0.8022\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 512.5080 - accuracy: 0.7579 - val_loss: 440.3156 - val_accuracy: 0.8023\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 511.6699 - accuracy: 0.7612 - val_loss: 439.5589 - val_accuracy: 0.8012\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 511.0017 - accuracy: 0.7585 - val_loss: 437.4786 - val_accuracy: 0.7990\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 510.1577 - accuracy: 0.7608 - val_loss: 448.1628 - val_accuracy: 0.8034\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.5974 - accuracy: 0.7593 - val_loss: 438.6421 - val_accuracy: 0.8036\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 511.3965 - accuracy: 0.7596 - val_loss: 440.8302 - val_accuracy: 0.8023\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 510.8494 - accuracy: 0.7607 - val_loss: 439.2039 - val_accuracy: 0.8013\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 511.5150 - accuracy: 0.7598 - val_loss: 438.8372 - val_accuracy: 0.8010\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 510.1287 - accuracy: 0.7584 - val_loss: 438.0356 - val_accuracy: 0.8035\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 511.3771 - accuracy: 0.7606 - val_loss: 440.2277 - val_accuracy: 0.8019\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 512.8416 - accuracy: 0.7590 - val_loss: 443.2955 - val_accuracy: 0.8011\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 514.4490 - accuracy: 0.7602 - val_loss: 439.7683 - val_accuracy: 0.8050\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 511.8798 - accuracy: 0.7603 - val_loss: 444.3069 - val_accuracy: 0.8011\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 512.3995 - accuracy: 0.7581 - val_loss: 438.4124 - val_accuracy: 0.8040\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 510.0615 - accuracy: 0.7596 - val_loss: 439.8291 - val_accuracy: 0.8016\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 509.8261 - accuracy: 0.7600 - val_loss: 439.0402 - val_accuracy: 0.8018\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 512.6572 - accuracy: 0.7598 - val_loss: 438.7687 - val_accuracy: 0.8035\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 509.8981 - accuracy: 0.7604 - val_loss: 442.0204 - val_accuracy: 0.7949\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 512.8907 - accuracy: 0.7594 - val_loss: 441.4757 - val_accuracy: 0.8054\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.4304 - accuracy: 0.7600 - val_loss: 441.6264 - val_accuracy: 0.7993\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.8938 - accuracy: 0.7602 - val_loss: 439.6671 - val_accuracy: 0.8018\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 512.3734 - accuracy: 0.7579 - val_loss: 443.0154 - val_accuracy: 0.8040\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 518.6588 - accuracy: 0.7618 - val_loss: 449.4179 - val_accuracy: 0.8002\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 520.8090 - accuracy: 0.7587 - val_loss: 439.7599 - val_accuracy: 0.8013\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 518.5040 - accuracy: 0.7596 - val_loss: 438.8252 - val_accuracy: 0.8019\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 510.5688 - accuracy: 0.7596 - val_loss: 439.7393 - val_accuracy: 0.8021\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 509.7788 - accuracy: 0.7591 - val_loss: 437.8661 - val_accuracy: 0.8023\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 509.2806 - accuracy: 0.7586 - val_loss: 437.8190 - val_accuracy: 0.8021\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 508.8092 - accuracy: 0.7604 - val_loss: 439.4937 - val_accuracy: 0.8024\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 517.4281 - accuracy: 0.7603 - val_loss: 439.2208 - val_accuracy: 0.8026\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 513.4825 - accuracy: 0.7591 - val_loss: 438.8939 - val_accuracy: 0.8028\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.4978 - accuracy: 0.7603 - val_loss: 439.0838 - val_accuracy: 0.8019\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 511.9911 - accuracy: 0.7592 - val_loss: 436.5450 - val_accuracy: 0.8039\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 510.4584 - accuracy: 0.7596 - val_loss: 436.9278 - val_accuracy: 0.8025\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 509.3802 - accuracy: 0.7583 - val_loss: 436.9295 - val_accuracy: 0.8056\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the second input image\n",
        "upsampled = layers.UpSampling2D(size=8)(input_layer2)\n",
        "\n",
        "# Concatenate the two input images\n",
        "concatenated = layers.Concatenate()([input_layer1, upsampled])\n",
        "\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(concatenated)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "#conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "#pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "#conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "#pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer = layers.Conv2D(31, kernel_size=1, activation='relu')(pool1)\n",
        "\n",
        "# Define the model\n",
        "modelnew = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "modelnew.compile(optimizer='adam',\n",
        "loss='mean_absolute_error',\n",
        "metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = modelnew.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0A_CkcBx9O5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGPIhQkyx9u7",
        "outputId": "c6ad95ea-49fa-4e2e-8f34-bfd31ea310e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 2s 76ms/step - loss: 8334.9824 - accuracy: 0.0150 - val_loss: 5622.1113 - val_accuracy: 0.0098\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 5744.4404 - accuracy: 0.0183 - val_loss: 4263.4238 - val_accuracy: 0.0112\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 4099.4106 - accuracy: 0.0360 - val_loss: 3163.2632 - val_accuracy: 0.0210\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 3380.2534 - accuracy: 0.0889 - val_loss: 2787.1758 - val_accuracy: 0.2930\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 2838.4998 - accuracy: 0.1042 - val_loss: 2179.8188 - val_accuracy: 0.3763\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 2336.9189 - accuracy: 0.1301 - val_loss: 1838.3257 - val_accuracy: 0.2991\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1986.3640 - accuracy: 0.1796 - val_loss: 1671.2394 - val_accuracy: 0.3636\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1775.3663 - accuracy: 0.2433 - val_loss: 1557.3313 - val_accuracy: 0.3233\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1648.4806 - accuracy: 0.2376 - val_loss: 1485.0052 - val_accuracy: 0.3696\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1565.8400 - accuracy: 0.2965 - val_loss: 1390.7936 - val_accuracy: 0.3657\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1499.9413 - accuracy: 0.3038 - val_loss: 1326.1234 - val_accuracy: 0.3107\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1464.1964 - accuracy: 0.3272 - val_loss: 1274.5044 - val_accuracy: 0.2740\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1436.8359 - accuracy: 0.3926 - val_loss: 1232.6611 - val_accuracy: 0.3966\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1402.8188 - accuracy: 0.4526 - val_loss: 1218.2148 - val_accuracy: 0.3711\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1373.9547 - accuracy: 0.4926 - val_loss: 1172.2651 - val_accuracy: 0.3429\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1357.9884 - accuracy: 0.4705 - val_loss: 1154.0734 - val_accuracy: 0.4160\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1346.5237 - accuracy: 0.5232 - val_loss: 1132.3628 - val_accuracy: 0.4160\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 1336.1144 - accuracy: 0.5164 - val_loss: 1125.9708 - val_accuracy: 0.4292\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1333.9310 - accuracy: 0.5164 - val_loss: 1119.8420 - val_accuracy: 0.4254\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1307.2891 - accuracy: 0.5541 - val_loss: 1102.1517 - val_accuracy: 0.4159\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1309.1685 - accuracy: 0.5535 - val_loss: 1110.2413 - val_accuracy: 0.4615\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1298.7435 - accuracy: 0.5766 - val_loss: 1085.8157 - val_accuracy: 0.4899\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1283.5455 - accuracy: 0.5644 - val_loss: 1081.6027 - val_accuracy: 0.4297\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1275.7598 - accuracy: 0.5851 - val_loss: 1080.3794 - val_accuracy: 0.5092\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1277.2327 - accuracy: 0.5849 - val_loss: 1069.8605 - val_accuracy: 0.5206\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1267.6400 - accuracy: 0.5989 - val_loss: 1063.0587 - val_accuracy: 0.4741\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1263.1879 - accuracy: 0.6068 - val_loss: 1061.3920 - val_accuracy: 0.4812\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1251.3094 - accuracy: 0.5976 - val_loss: 1057.2039 - val_accuracy: 0.5015\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1248.9181 - accuracy: 0.6165 - val_loss: 1077.5050 - val_accuracy: 0.5026\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1250.5636 - accuracy: 0.5982 - val_loss: 1061.0869 - val_accuracy: 0.4881\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1245.0410 - accuracy: 0.5966 - val_loss: 1077.7252 - val_accuracy: 0.4892\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1254.1355 - accuracy: 0.5832 - val_loss: 1088.3527 - val_accuracy: 0.5522\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1253.7263 - accuracy: 0.6121 - val_loss: 1118.1434 - val_accuracy: 0.5044\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1265.1991 - accuracy: 0.6174 - val_loss: 1075.4606 - val_accuracy: 0.5065\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1237.2454 - accuracy: 0.5910 - val_loss: 1053.7675 - val_accuracy: 0.5159\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1224.5640 - accuracy: 0.6281 - val_loss: 1042.3418 - val_accuracy: 0.4984\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1216.6288 - accuracy: 0.6293 - val_loss: 1057.1184 - val_accuracy: 0.4572\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1223.1292 - accuracy: 0.5763 - val_loss: 1057.3544 - val_accuracy: 0.5186\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1211.6342 - accuracy: 0.6178 - val_loss: 1044.0946 - val_accuracy: 0.5083\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1204.2394 - accuracy: 0.6167 - val_loss: 1036.9355 - val_accuracy: 0.5035\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1201.1278 - accuracy: 0.6233 - val_loss: 1039.0167 - val_accuracy: 0.5061\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1199.5336 - accuracy: 0.6117 - val_loss: 1041.9479 - val_accuracy: 0.5211\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1197.4675 - accuracy: 0.6213 - val_loss: 1040.0029 - val_accuracy: 0.5150\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1192.4119 - accuracy: 0.6244 - val_loss: 1051.6718 - val_accuracy: 0.4811\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1191.2417 - accuracy: 0.6199 - val_loss: 1037.8809 - val_accuracy: 0.4816\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1188.7150 - accuracy: 0.6118 - val_loss: 1058.0425 - val_accuracy: 0.5115\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1199.0277 - accuracy: 0.6154 - val_loss: 1046.5762 - val_accuracy: 0.5147\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1202.5137 - accuracy: 0.6178 - val_loss: 1076.8119 - val_accuracy: 0.4827\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1202.2372 - accuracy: 0.6165 - val_loss: 1042.6835 - val_accuracy: 0.5103\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1178.1230 - accuracy: 0.6200 - val_loss: 1050.7272 - val_accuracy: 0.5182\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1174.2491 - accuracy: 0.6317 - val_loss: 1066.6826 - val_accuracy: 0.5015\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1184.6074 - accuracy: 0.6245 - val_loss: 1062.2559 - val_accuracy: 0.4801\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1180.1495 - accuracy: 0.6067 - val_loss: 1068.4944 - val_accuracy: 0.4441\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1187.4392 - accuracy: 0.5742 - val_loss: 1081.2844 - val_accuracy: 0.5617\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1205.8571 - accuracy: 0.6380 - val_loss: 1053.4318 - val_accuracy: 0.4562\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1178.3718 - accuracy: 0.5915 - val_loss: 1054.0721 - val_accuracy: 0.5326\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1179.9968 - accuracy: 0.6125 - val_loss: 1049.1012 - val_accuracy: 0.4442\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1168.5994 - accuracy: 0.6152 - val_loss: 1050.3652 - val_accuracy: 0.4803\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1164.3945 - accuracy: 0.6041 - val_loss: 1042.2607 - val_accuracy: 0.4634\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1156.8184 - accuracy: 0.6126 - val_loss: 1041.2853 - val_accuracy: 0.5321\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1154.4050 - accuracy: 0.6244 - val_loss: 1031.2330 - val_accuracy: 0.5115\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 1148.5356 - accuracy: 0.6186 - val_loss: 1035.6678 - val_accuracy: 0.4895\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 1159.0197 - accuracy: 0.5960 - val_loss: 1053.5654 - val_accuracy: 0.5267\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1160.3792 - accuracy: 0.6293 - val_loss: 1049.7592 - val_accuracy: 0.4861\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1161.2322 - accuracy: 0.6046 - val_loss: 1043.0571 - val_accuracy: 0.5201\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1159.4747 - accuracy: 0.6441 - val_loss: 1037.0569 - val_accuracy: 0.4810\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1151.9905 - accuracy: 0.6142 - val_loss: 1049.2517 - val_accuracy: 0.4725\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1146.5253 - accuracy: 0.6064 - val_loss: 1045.2687 - val_accuracy: 0.5201\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1140.0338 - accuracy: 0.6175 - val_loss: 1040.8844 - val_accuracy: 0.4670\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1141.6366 - accuracy: 0.6196 - val_loss: 1038.0326 - val_accuracy: 0.4750\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1139.2198 - accuracy: 0.6128 - val_loss: 1042.5968 - val_accuracy: 0.4753\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1143.4039 - accuracy: 0.6164 - val_loss: 1041.0330 - val_accuracy: 0.5108\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1141.4413 - accuracy: 0.6188 - val_loss: 1047.2939 - val_accuracy: 0.4978\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1135.4659 - accuracy: 0.6237 - val_loss: 1038.1212 - val_accuracy: 0.4604\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1134.1245 - accuracy: 0.6268 - val_loss: 1045.9102 - val_accuracy: 0.4806\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1136.0988 - accuracy: 0.6261 - val_loss: 1045.6469 - val_accuracy: 0.4844\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1130.6044 - accuracy: 0.6135 - val_loss: 1039.8252 - val_accuracy: 0.4811\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1133.6238 - accuracy: 0.6321 - val_loss: 1051.0798 - val_accuracy: 0.4927\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1158.4404 - accuracy: 0.6024 - val_loss: 1077.4978 - val_accuracy: 0.4599\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1151.2281 - accuracy: 0.6189 - val_loss: 1042.5492 - val_accuracy: 0.5057\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1147.2585 - accuracy: 0.6000 - val_loss: 1055.4950 - val_accuracy: 0.4609\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1136.4095 - accuracy: 0.6129 - val_loss: 1047.5596 - val_accuracy: 0.4847\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1135.3322 - accuracy: 0.6065 - val_loss: 1060.2773 - val_accuracy: 0.5330\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1145.8636 - accuracy: 0.6198 - val_loss: 1050.4294 - val_accuracy: 0.4478\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1139.4258 - accuracy: 0.6032 - val_loss: 1065.4746 - val_accuracy: 0.5397\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1133.2991 - accuracy: 0.6244 - val_loss: 1041.9060 - val_accuracy: 0.5321\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1133.6350 - accuracy: 0.6267 - val_loss: 1031.8921 - val_accuracy: 0.4851\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1136.1788 - accuracy: 0.6196 - val_loss: 1045.4896 - val_accuracy: 0.4720\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1134.0128 - accuracy: 0.6197 - val_loss: 1053.6555 - val_accuracy: 0.4857\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1130.6686 - accuracy: 0.6141 - val_loss: 1047.0251 - val_accuracy: 0.4836\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1124.0287 - accuracy: 0.6288 - val_loss: 1035.2264 - val_accuracy: 0.4797\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1123.1309 - accuracy: 0.6236 - val_loss: 1041.5165 - val_accuracy: 0.4658\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1119.6576 - accuracy: 0.6245 - val_loss: 1040.4790 - val_accuracy: 0.4691\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1127.0300 - accuracy: 0.6148 - val_loss: 1046.2594 - val_accuracy: 0.5037\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1120.5525 - accuracy: 0.6193 - val_loss: 1039.6586 - val_accuracy: 0.4794\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1131.4918 - accuracy: 0.5985 - val_loss: 1050.0967 - val_accuracy: 0.5095\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1136.5044 - accuracy: 0.6349 - val_loss: 1046.2734 - val_accuracy: 0.4916\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1138.7594 - accuracy: 0.6190 - val_loss: 1061.0537 - val_accuracy: 0.4999\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1142.2784 - accuracy: 0.6075 - val_loss: 1058.0314 - val_accuracy: 0.5644\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 1133.2716 - accuracy: 0.6318 - val_loss: 1049.0118 - val_accuracy: 0.5154\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 1135.3994 - accuracy: 0.6132 - val_loss: 1051.1890 - val_accuracy: 0.4736\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1153.5203 - accuracy: 0.6265 - val_loss: 1058.4832 - val_accuracy: 0.4616\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1124.7810 - accuracy: 0.6104 - val_loss: 1053.8557 - val_accuracy: 0.5089\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1118.5826 - accuracy: 0.6284 - val_loss: 1039.6987 - val_accuracy: 0.4777\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1124.2264 - accuracy: 0.6117 - val_loss: 1041.1975 - val_accuracy: 0.4829\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1126.1056 - accuracy: 0.6095 - val_loss: 1030.2773 - val_accuracy: 0.5174\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1118.1804 - accuracy: 0.6442 - val_loss: 1028.3453 - val_accuracy: 0.5334\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 1111.1853 - accuracy: 0.6210 - val_loss: 1034.1172 - val_accuracy: 0.5000\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 1118.2612 - accuracy: 0.6262 - val_loss: 1033.9712 - val_accuracy: 0.4878\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 1s 73ms/step - loss: 1113.1034 - accuracy: 0.6295 - val_loss: 1039.9584 - val_accuracy: 0.4649\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 1111.1758 - accuracy: 0.6187 - val_loss: 1043.1855 - val_accuracy: 0.4737\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 1110.8083 - accuracy: 0.6256 - val_loss: 1037.6892 - val_accuracy: 0.5479\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 1123.6354 - accuracy: 0.6272 - val_loss: 1030.2590 - val_accuracy: 0.5083\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 1s 70ms/step - loss: 1111.8301 - accuracy: 0.6113 - val_loss: 1015.2958 - val_accuracy: 0.4510\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 1093.6595 - accuracy: 0.6117 - val_loss: 988.5966 - val_accuracy: 0.5177\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1093.4791 - accuracy: 0.6091 - val_loss: 1005.2159 - val_accuracy: 0.5141\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 1086.2809 - accuracy: 0.5858 - val_loss: 971.8646 - val_accuracy: 0.4611\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 1044.3403 - accuracy: 0.5639 - val_loss: 916.5842 - val_accuracy: 0.5847\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 997.8381 - accuracy: 0.5916 - val_loss: 870.1211 - val_accuracy: 0.5701\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 964.7620 - accuracy: 0.5946 - val_loss: 815.5118 - val_accuracy: 0.5807\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 958.0735 - accuracy: 0.6089 - val_loss: 808.4706 - val_accuracy: 0.5613\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 930.1136 - accuracy: 0.5985 - val_loss: 815.6520 - val_accuracy: 0.6208\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 916.0056 - accuracy: 0.6411 - val_loss: 791.2015 - val_accuracy: 0.5707\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 911.5492 - accuracy: 0.6278 - val_loss: 785.5647 - val_accuracy: 0.5854\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 903.3376 - accuracy: 0.6487 - val_loss: 774.4658 - val_accuracy: 0.5654\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 901.1694 - accuracy: 0.6509 - val_loss: 776.0430 - val_accuracy: 0.5921\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 897.0837 - accuracy: 0.6642 - val_loss: 771.9418 - val_accuracy: 0.6055\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 888.1332 - accuracy: 0.6678 - val_loss: 768.1686 - val_accuracy: 0.6425\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 893.4064 - accuracy: 0.6711 - val_loss: 778.9194 - val_accuracy: 0.5701\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 888.6373 - accuracy: 0.6465 - val_loss: 767.6458 - val_accuracy: 0.6496\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 882.6458 - accuracy: 0.6672 - val_loss: 764.8935 - val_accuracy: 0.6135\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 880.6536 - accuracy: 0.6720 - val_loss: 770.0997 - val_accuracy: 0.6523\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 877.9832 - accuracy: 0.6724 - val_loss: 766.7594 - val_accuracy: 0.6436\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 886.6108 - accuracy: 0.6783 - val_loss: 761.2838 - val_accuracy: 0.6527\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 896.9576 - accuracy: 0.6788 - val_loss: 773.9720 - val_accuracy: 0.6456\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 887.8246 - accuracy: 0.6773 - val_loss: 762.9092 - val_accuracy: 0.6406\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 881.4515 - accuracy: 0.6704 - val_loss: 753.9177 - val_accuracy: 0.6568\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 878.4389 - accuracy: 0.6853 - val_loss: 760.1964 - val_accuracy: 0.6534\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 880.0671 - accuracy: 0.6822 - val_loss: 761.0448 - val_accuracy: 0.6572\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 876.7263 - accuracy: 0.6822 - val_loss: 770.7662 - val_accuracy: 0.6589\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 895.7404 - accuracy: 0.6786 - val_loss: 776.5601 - val_accuracy: 0.6520\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 884.9436 - accuracy: 0.6758 - val_loss: 772.1135 - val_accuracy: 0.6592\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 876.4559 - accuracy: 0.6805 - val_loss: 762.9665 - val_accuracy: 0.6470\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 873.2100 - accuracy: 0.6824 - val_loss: 761.4839 - val_accuracy: 0.6462\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 873.7667 - accuracy: 0.6865 - val_loss: 758.4313 - val_accuracy: 0.6329\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 869.3482 - accuracy: 0.6739 - val_loss: 764.4392 - val_accuracy: 0.6495\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 871.4242 - accuracy: 0.6803 - val_loss: 768.0621 - val_accuracy: 0.6550\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 876.7507 - accuracy: 0.6816 - val_loss: 758.7408 - val_accuracy: 0.6452\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 876.1169 - accuracy: 0.6807 - val_loss: 781.7597 - val_accuracy: 0.6588\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 877.6752 - accuracy: 0.6825 - val_loss: 766.7474 - val_accuracy: 0.6502\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 869.7947 - accuracy: 0.6860 - val_loss: 761.1281 - val_accuracy: 0.6519\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 867.5041 - accuracy: 0.6775 - val_loss: 769.7705 - val_accuracy: 0.6454\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 871.3013 - accuracy: 0.6829 - val_loss: 756.4014 - val_accuracy: 0.6516\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 865.9135 - accuracy: 0.6850 - val_loss: 758.7048 - val_accuracy: 0.6485\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 863.9805 - accuracy: 0.6858 - val_loss: 758.6156 - val_accuracy: 0.6526\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 871.7033 - accuracy: 0.6787 - val_loss: 781.3273 - val_accuracy: 0.6388\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 924.9784 - accuracy: 0.6781 - val_loss: 767.1887 - val_accuracy: 0.6522\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 884.9366 - accuracy: 0.6803 - val_loss: 761.0222 - val_accuracy: 0.6506\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 872.1501 - accuracy: 0.6748 - val_loss: 770.0811 - val_accuracy: 0.6451\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 871.3380 - accuracy: 0.6769 - val_loss: 759.4464 - val_accuracy: 0.6498\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 864.8222 - accuracy: 0.6788 - val_loss: 764.6998 - val_accuracy: 0.6269\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 870.0865 - accuracy: 0.6674 - val_loss: 761.8419 - val_accuracy: 0.6490\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 871.9418 - accuracy: 0.6837 - val_loss: 754.4041 - val_accuracy: 0.6349\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 865.5781 - accuracy: 0.6715 - val_loss: 763.8396 - val_accuracy: 0.6335\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 862.4478 - accuracy: 0.6760 - val_loss: 762.9288 - val_accuracy: 0.6385\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 872.5690 - accuracy: 0.6814 - val_loss: 792.2181 - val_accuracy: 0.6420\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 886.8339 - accuracy: 0.6858 - val_loss: 763.3969 - val_accuracy: 0.6453\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 870.5940 - accuracy: 0.6814 - val_loss: 758.3705 - val_accuracy: 0.6569\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 867.8215 - accuracy: 0.6848 - val_loss: 774.0851 - val_accuracy: 0.6325\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 887.2104 - accuracy: 0.6781 - val_loss: 772.7050 - val_accuracy: 0.6269\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 872.0008 - accuracy: 0.6731 - val_loss: 765.7123 - val_accuracy: 0.6499\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 870.0090 - accuracy: 0.6768 - val_loss: 759.7732 - val_accuracy: 0.6435\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 867.1702 - accuracy: 0.6819 - val_loss: 758.1264 - val_accuracy: 0.6390\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 860.7642 - accuracy: 0.6798 - val_loss: 764.0092 - val_accuracy: 0.6419\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 861.6250 - accuracy: 0.6864 - val_loss: 758.3123 - val_accuracy: 0.6356\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 863.5465 - accuracy: 0.6830 - val_loss: 752.5540 - val_accuracy: 0.6538\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 863.2239 - accuracy: 0.6887 - val_loss: 752.5349 - val_accuracy: 0.6530\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 877.6992 - accuracy: 0.6838 - val_loss: 764.9490 - val_accuracy: 0.6523\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 870.6851 - accuracy: 0.6824 - val_loss: 769.3201 - val_accuracy: 0.6285\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 865.7108 - accuracy: 0.6840 - val_loss: 774.9354 - val_accuracy: 0.6449\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 870.3414 - accuracy: 0.6787 - val_loss: 759.5687 - val_accuracy: 0.6392\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 868.5250 - accuracy: 0.6814 - val_loss: 758.5585 - val_accuracy: 0.6470\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 871.2432 - accuracy: 0.6836 - val_loss: 787.3065 - val_accuracy: 0.6161\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 876.5010 - accuracy: 0.6806 - val_loss: 767.2659 - val_accuracy: 0.6476\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 867.8383 - accuracy: 0.6866 - val_loss: 769.5828 - val_accuracy: 0.6498\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 862.6735 - accuracy: 0.6863 - val_loss: 757.8939 - val_accuracy: 0.6245\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 861.3406 - accuracy: 0.6805 - val_loss: 748.5115 - val_accuracy: 0.6449\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 857.4822 - accuracy: 0.6864 - val_loss: 760.2906 - val_accuracy: 0.6385\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 858.3859 - accuracy: 0.6813 - val_loss: 748.5043 - val_accuracy: 0.6563\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 854.3902 - accuracy: 0.6883 - val_loss: 768.5463 - val_accuracy: 0.6257\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 871.3190 - accuracy: 0.6764 - val_loss: 760.2854 - val_accuracy: 0.6324\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 865.1005 - accuracy: 0.6782 - val_loss: 746.9332 - val_accuracy: 0.6389\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 859.2687 - accuracy: 0.6759 - val_loss: 752.5160 - val_accuracy: 0.6424\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 855.9343 - accuracy: 0.6866 - val_loss: 750.6055 - val_accuracy: 0.6376\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 858.7767 - accuracy: 0.6799 - val_loss: 756.2882 - val_accuracy: 0.6364\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 870.3325 - accuracy: 0.6853 - val_loss: 765.4932 - val_accuracy: 0.6421\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 887.7028 - accuracy: 0.6825 - val_loss: 772.1614 - val_accuracy: 0.6379\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 874.9374 - accuracy: 0.6717 - val_loss: 762.3935 - val_accuracy: 0.6367\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 864.3524 - accuracy: 0.6841 - val_loss: 757.3057 - val_accuracy: 0.6307\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 858.3799 - accuracy: 0.6886 - val_loss: 750.1669 - val_accuracy: 0.6450\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 860.8571 - accuracy: 0.6846 - val_loss: 771.2465 - val_accuracy: 0.6523\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 873.3372 - accuracy: 0.6688 - val_loss: 763.3881 - val_accuracy: 0.6339\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 862.1674 - accuracy: 0.6811 - val_loss: 751.8980 - val_accuracy: 0.6331\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 854.1521 - accuracy: 0.6822 - val_loss: 750.5306 - val_accuracy: 0.6451\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 853.5042 - accuracy: 0.6865 - val_loss: 750.9698 - val_accuracy: 0.6376\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 854.5991 - accuracy: 0.6929 - val_loss: 756.2070 - val_accuracy: 0.6339\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 865.7702 - accuracy: 0.6789 - val_loss: 760.2724 - val_accuracy: 0.6472\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 856.4518 - accuracy: 0.6846 - val_loss: 751.5201 - val_accuracy: 0.6382\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 854.0883 - accuracy: 0.6846 - val_loss: 756.8566 - val_accuracy: 0.6200\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 860.0698 - accuracy: 0.6854 - val_loss: 762.9202 - val_accuracy: 0.6410\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 861.0397 - accuracy: 0.6826 - val_loss: 765.5430 - val_accuracy: 0.6315\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 864.8482 - accuracy: 0.6844 - val_loss: 777.3137 - val_accuracy: 0.6427\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 871.5284 - accuracy: 0.6817 - val_loss: 766.0419 - val_accuracy: 0.6530\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 877.8926 - accuracy: 0.6847 - val_loss: 754.2304 - val_accuracy: 0.6159\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 869.0444 - accuracy: 0.6771 - val_loss: 767.6166 - val_accuracy: 0.6459\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 861.1630 - accuracy: 0.6876 - val_loss: 749.0899 - val_accuracy: 0.6352\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 856.7284 - accuracy: 0.6728 - val_loss: 760.6290 - val_accuracy: 0.6154\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 850.6635 - accuracy: 0.6854 - val_loss: 752.1118 - val_accuracy: 0.6376\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 851.4879 - accuracy: 0.6863 - val_loss: 758.9455 - val_accuracy: 0.6370\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 861.5796 - accuracy: 0.6842 - val_loss: 754.9792 - val_accuracy: 0.6380\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 855.2798 - accuracy: 0.6850 - val_loss: 749.2426 - val_accuracy: 0.6401\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 851.9939 - accuracy: 0.6877 - val_loss: 751.7591 - val_accuracy: 0.6525\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 852.8148 - accuracy: 0.6899 - val_loss: 743.5033 - val_accuracy: 0.6522\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 851.2944 - accuracy: 0.6885 - val_loss: 751.3174 - val_accuracy: 0.6385\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 856.6998 - accuracy: 0.6881 - val_loss: 755.6647 - val_accuracy: 0.6371\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 864.2404 - accuracy: 0.6735 - val_loss: 759.0580 - val_accuracy: 0.6410\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 866.3599 - accuracy: 0.6809 - val_loss: 753.3497 - val_accuracy: 0.6397\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 856.6676 - accuracy: 0.6855 - val_loss: 752.9708 - val_accuracy: 0.6369\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 857.8375 - accuracy: 0.6822 - val_loss: 761.4027 - val_accuracy: 0.6373\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 859.5704 - accuracy: 0.6851 - val_loss: 751.1854 - val_accuracy: 0.6436\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 858.6113 - accuracy: 0.6868 - val_loss: 751.6706 - val_accuracy: 0.6364\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 852.0956 - accuracy: 0.6905 - val_loss: 745.6221 - val_accuracy: 0.6339\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 856.0349 - accuracy: 0.6827 - val_loss: 757.6332 - val_accuracy: 0.6349\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 855.8487 - accuracy: 0.6928 - val_loss: 755.3624 - val_accuracy: 0.6306\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 862.4001 - accuracy: 0.6834 - val_loss: 829.3830 - val_accuracy: 0.6448\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 884.7910 - accuracy: 0.6796 - val_loss: 756.1568 - val_accuracy: 0.6398\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 860.1660 - accuracy: 0.6871 - val_loss: 750.4661 - val_accuracy: 0.6430\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 858.6683 - accuracy: 0.6860 - val_loss: 748.9955 - val_accuracy: 0.6404\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 855.1658 - accuracy: 0.6916 - val_loss: 744.9324 - val_accuracy: 0.6483\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 849.5298 - accuracy: 0.6864 - val_loss: 744.5710 - val_accuracy: 0.6468\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 848.6538 - accuracy: 0.6918 - val_loss: 748.8386 - val_accuracy: 0.6346\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 848.6057 - accuracy: 0.6902 - val_loss: 758.5516 - val_accuracy: 0.6238\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 856.7294 - accuracy: 0.6795 - val_loss: 757.7892 - val_accuracy: 0.6450\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 853.1741 - accuracy: 0.6874 - val_loss: 748.0755 - val_accuracy: 0.6381\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 853.3779 - accuracy: 0.6854 - val_loss: 751.1953 - val_accuracy: 0.6373\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 847.5909 - accuracy: 0.6906 - val_loss: 745.8278 - val_accuracy: 0.6502\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 849.6972 - accuracy: 0.6886 - val_loss: 750.0318 - val_accuracy: 0.6417\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 853.0849 - accuracy: 0.6829 - val_loss: 751.9708 - val_accuracy: 0.6453\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 851.6468 - accuracy: 0.6901 - val_loss: 748.4020 - val_accuracy: 0.6412\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 850.2555 - accuracy: 0.6867 - val_loss: 747.7782 - val_accuracy: 0.6564\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 849.7968 - accuracy: 0.6898 - val_loss: 752.1888 - val_accuracy: 0.6492\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 859.6232 - accuracy: 0.6859 - val_loss: 757.0993 - val_accuracy: 0.6441\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 856.5211 - accuracy: 0.6950 - val_loss: 741.7045 - val_accuracy: 0.6435\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 845.2438 - accuracy: 0.6875 - val_loss: 755.9381 - val_accuracy: 0.6266\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 851.8558 - accuracy: 0.6808 - val_loss: 752.6904 - val_accuracy: 0.6481\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 857.5452 - accuracy: 0.6801 - val_loss: 773.1107 - val_accuracy: 0.6479\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 862.4801 - accuracy: 0.6857 - val_loss: 753.4150 - val_accuracy: 0.6442\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 858.3507 - accuracy: 0.6896 - val_loss: 754.8629 - val_accuracy: 0.6358\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 859.4097 - accuracy: 0.6807 - val_loss: 762.1149 - val_accuracy: 0.6623\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 864.7692 - accuracy: 0.6939 - val_loss: 742.2773 - val_accuracy: 0.6446\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 858.9424 - accuracy: 0.6860 - val_loss: 757.6553 - val_accuracy: 0.6450\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 852.1913 - accuracy: 0.6856 - val_loss: 745.0329 - val_accuracy: 0.6486\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 859.1953 - accuracy: 0.6854 - val_loss: 758.2568 - val_accuracy: 0.6556\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 855.9597 - accuracy: 0.6923 - val_loss: 744.2944 - val_accuracy: 0.6290\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 853.1191 - accuracy: 0.6905 - val_loss: 756.1426 - val_accuracy: 0.6351\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 848.2354 - accuracy: 0.6857 - val_loss: 746.7056 - val_accuracy: 0.6425\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 850.0494 - accuracy: 0.6862 - val_loss: 753.0690 - val_accuracy: 0.6537\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 847.5226 - accuracy: 0.6861 - val_loss: 744.9005 - val_accuracy: 0.6432\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 849.0238 - accuracy: 0.6824 - val_loss: 753.7179 - val_accuracy: 0.6401\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 850.0720 - accuracy: 0.6894 - val_loss: 740.6748 - val_accuracy: 0.6375\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 848.5089 - accuracy: 0.6873 - val_loss: 749.1965 - val_accuracy: 0.6425\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 851.9871 - accuracy: 0.6898 - val_loss: 756.4489 - val_accuracy: 0.6511\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 850.1569 - accuracy: 0.6906 - val_loss: 752.6514 - val_accuracy: 0.6353\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 848.6402 - accuracy: 0.6808 - val_loss: 751.3979 - val_accuracy: 0.6287\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 843.4854 - accuracy: 0.6869 - val_loss: 745.3201 - val_accuracy: 0.6378\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 843.7581 - accuracy: 0.6854 - val_loss: 753.6505 - val_accuracy: 0.6459\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 848.3452 - accuracy: 0.6869 - val_loss: 760.6927 - val_accuracy: 0.6123\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 868.2828 - accuracy: 0.6760 - val_loss: 773.5242 - val_accuracy: 0.6501\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 874.8519 - accuracy: 0.6866 - val_loss: 749.5898 - val_accuracy: 0.6436\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 895.8705 - accuracy: 0.6871 - val_loss: 809.5152 - val_accuracy: 0.6515\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 891.6513 - accuracy: 0.6834 - val_loss: 767.1740 - val_accuracy: 0.6359\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 871.1446 - accuracy: 0.6838 - val_loss: 750.7829 - val_accuracy: 0.6549\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 873.2651 - accuracy: 0.6856 - val_loss: 751.4958 - val_accuracy: 0.6559\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 860.2486 - accuracy: 0.6876 - val_loss: 756.3320 - val_accuracy: 0.6542\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 858.6321 - accuracy: 0.6909 - val_loss: 749.4068 - val_accuracy: 0.6461\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 852.8049 - accuracy: 0.6896 - val_loss: 755.1345 - val_accuracy: 0.6628\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 849.2329 - accuracy: 0.6914 - val_loss: 747.2101 - val_accuracy: 0.6548\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 850.0289 - accuracy: 0.6923 - val_loss: 756.5850 - val_accuracy: 0.6532\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 856.1016 - accuracy: 0.6896 - val_loss: 753.5757 - val_accuracy: 0.6635\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 852.6946 - accuracy: 0.6954 - val_loss: 753.6159 - val_accuracy: 0.6382\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 851.3453 - accuracy: 0.6876 - val_loss: 755.4000 - val_accuracy: 0.6324\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 854.0042 - accuracy: 0.6840 - val_loss: 743.7177 - val_accuracy: 0.6410\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 844.5579 - accuracy: 0.6899 - val_loss: 740.1664 - val_accuracy: 0.6528\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 847.1975 - accuracy: 0.6930 - val_loss: 746.9883 - val_accuracy: 0.6522\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 848.5977 - accuracy: 0.6910 - val_loss: 749.6226 - val_accuracy: 0.6457\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 853.2450 - accuracy: 0.6939 - val_loss: 749.1816 - val_accuracy: 0.6456\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 848.9249 - accuracy: 0.6849 - val_loss: 746.7938 - val_accuracy: 0.6420\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 845.5438 - accuracy: 0.6955 - val_loss: 737.6544 - val_accuracy: 0.6367\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 844.2800 - accuracy: 0.6811 - val_loss: 758.5121 - val_accuracy: 0.6411\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 842.6660 - accuracy: 0.6857 - val_loss: 744.2444 - val_accuracy: 0.6480\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 842.3512 - accuracy: 0.6916 - val_loss: 754.0140 - val_accuracy: 0.6326\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 848.6639 - accuracy: 0.6924 - val_loss: 767.9285 - val_accuracy: 0.6416\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 849.9072 - accuracy: 0.6910 - val_loss: 742.7309 - val_accuracy: 0.6369\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 843.3565 - accuracy: 0.6907 - val_loss: 747.6683 - val_accuracy: 0.6358\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 846.8929 - accuracy: 0.6853 - val_loss: 760.1100 - val_accuracy: 0.6328\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 864.5020 - accuracy: 0.6923 - val_loss: 747.5719 - val_accuracy: 0.6372\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 856.3109 - accuracy: 0.6784 - val_loss: 754.1758 - val_accuracy: 0.6500\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 848.0396 - accuracy: 0.6894 - val_loss: 747.0351 - val_accuracy: 0.6581\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 851.9281 - accuracy: 0.6906 - val_loss: 760.6049 - val_accuracy: 0.6327\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 853.7200 - accuracy: 0.6860 - val_loss: 757.8355 - val_accuracy: 0.6485\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 855.0587 - accuracy: 0.6745 - val_loss: 749.9809 - val_accuracy: 0.6503\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 845.5161 - accuracy: 0.6898 - val_loss: 738.9866 - val_accuracy: 0.6473\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 841.6168 - accuracy: 0.6933 - val_loss: 743.1058 - val_accuracy: 0.6373\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 845.3444 - accuracy: 0.6876 - val_loss: 796.7595 - val_accuracy: 0.6229\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 879.4698 - accuracy: 0.6667 - val_loss: 768.7735 - val_accuracy: 0.6548\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 857.1885 - accuracy: 0.6871 - val_loss: 742.8735 - val_accuracy: 0.6400\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 845.4757 - accuracy: 0.6865 - val_loss: 746.0582 - val_accuracy: 0.6395\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 841.7696 - accuracy: 0.6929 - val_loss: 745.6677 - val_accuracy: 0.6361\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 842.8913 - accuracy: 0.6881 - val_loss: 746.5236 - val_accuracy: 0.6414\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 845.2546 - accuracy: 0.6823 - val_loss: 745.9559 - val_accuracy: 0.6528\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 848.8503 - accuracy: 0.6916 - val_loss: 743.9079 - val_accuracy: 0.6276\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 844.2451 - accuracy: 0.6787 - val_loss: 754.2311 - val_accuracy: 0.6428\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 846.0863 - accuracy: 0.6778 - val_loss: 748.0936 - val_accuracy: 0.6459\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 843.9915 - accuracy: 0.6930 - val_loss: 749.9120 - val_accuracy: 0.6365\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 843.5925 - accuracy: 0.6917 - val_loss: 749.9124 - val_accuracy: 0.6491\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 843.3416 - accuracy: 0.6908 - val_loss: 739.7178 - val_accuracy: 0.6473\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 839.9883 - accuracy: 0.6943 - val_loss: 736.2630 - val_accuracy: 0.6572\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 840.9153 - accuracy: 0.6962 - val_loss: 747.4880 - val_accuracy: 0.6372\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 845.4147 - accuracy: 0.6891 - val_loss: 749.9990 - val_accuracy: 0.6472\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 847.7066 - accuracy: 0.6890 - val_loss: 742.2311 - val_accuracy: 0.6595\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 847.4150 - accuracy: 0.6957 - val_loss: 739.8915 - val_accuracy: 0.6484\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 859.5689 - accuracy: 0.6887 - val_loss: 763.2522 - val_accuracy: 0.6454\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 846.9332 - accuracy: 0.6902 - val_loss: 749.8946 - val_accuracy: 0.6328\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 852.9398 - accuracy: 0.6897 - val_loss: 752.8790 - val_accuracy: 0.6499\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 879.4603 - accuracy: 0.6841 - val_loss: 784.8920 - val_accuracy: 0.6393\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 871.1852 - accuracy: 0.6903 - val_loss: 747.4377 - val_accuracy: 0.6415\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 854.1667 - accuracy: 0.6814 - val_loss: 743.9509 - val_accuracy: 0.6470\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 849.0850 - accuracy: 0.6805 - val_loss: 751.9412 - val_accuracy: 0.6440\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 845.0016 - accuracy: 0.6907 - val_loss: 747.3148 - val_accuracy: 0.6362\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 844.7523 - accuracy: 0.6829 - val_loss: 750.9052 - val_accuracy: 0.6487\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 840.9577 - accuracy: 0.6953 - val_loss: 741.8096 - val_accuracy: 0.6477\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 837.5954 - accuracy: 0.6943 - val_loss: 747.6215 - val_accuracy: 0.6345\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 840.6858 - accuracy: 0.6930 - val_loss: 752.8845 - val_accuracy: 0.6216\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 840.2073 - accuracy: 0.6915 - val_loss: 743.7316 - val_accuracy: 0.6437\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 842.6667 - accuracy: 0.6889 - val_loss: 748.8141 - val_accuracy: 0.6426\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 860.3075 - accuracy: 0.6933 - val_loss: 779.2325 - val_accuracy: 0.6318\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 876.9337 - accuracy: 0.6805 - val_loss: 763.3337 - val_accuracy: 0.6450\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 864.2679 - accuracy: 0.6901 - val_loss: 751.9920 - val_accuracy: 0.6291\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 854.5908 - accuracy: 0.6888 - val_loss: 751.1061 - val_accuracy: 0.6498\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 848.6055 - accuracy: 0.6896 - val_loss: 749.3859 - val_accuracy: 0.6482\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 845.1990 - accuracy: 0.6850 - val_loss: 746.4807 - val_accuracy: 0.6175\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 847.0974 - accuracy: 0.6788 - val_loss: 745.2377 - val_accuracy: 0.6513\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 839.6585 - accuracy: 0.6943 - val_loss: 734.6052 - val_accuracy: 0.6471\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 840.3185 - accuracy: 0.6928 - val_loss: 739.8244 - val_accuracy: 0.6393\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 840.2059 - accuracy: 0.6848 - val_loss: 755.6267 - val_accuracy: 0.6530\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 847.5302 - accuracy: 0.6884 - val_loss: 737.8741 - val_accuracy: 0.6501\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 852.3355 - accuracy: 0.6985 - val_loss: 744.3580 - val_accuracy: 0.6314\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 843.6404 - accuracy: 0.6875 - val_loss: 735.5113 - val_accuracy: 0.6569\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 841.1941 - accuracy: 0.6870 - val_loss: 737.6635 - val_accuracy: 0.6632\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 839.2281 - accuracy: 0.6919 - val_loss: 729.5709 - val_accuracy: 0.6460\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 838.0640 - accuracy: 0.6896 - val_loss: 737.7803 - val_accuracy: 0.6489\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 837.2815 - accuracy: 0.6956 - val_loss: 737.9013 - val_accuracy: 0.6328\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 836.7672 - accuracy: 0.6856 - val_loss: 736.7866 - val_accuracy: 0.6439\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 840.8604 - accuracy: 0.6889 - val_loss: 744.8561 - val_accuracy: 0.6196\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 838.8179 - accuracy: 0.6874 - val_loss: 742.4218 - val_accuracy: 0.6391\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 841.3035 - accuracy: 0.6875 - val_loss: 737.4369 - val_accuracy: 0.6417\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 845.5516 - accuracy: 0.6949 - val_loss: 736.0851 - val_accuracy: 0.6435\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 859.8141 - accuracy: 0.6934 - val_loss: 788.1377 - val_accuracy: 0.6280\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 863.8989 - accuracy: 0.6907 - val_loss: 757.8984 - val_accuracy: 0.6287\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 853.7251 - accuracy: 0.6883 - val_loss: 740.9706 - val_accuracy: 0.6565\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 841.5576 - accuracy: 0.6889 - val_loss: 742.6431 - val_accuracy: 0.6262\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 843.0657 - accuracy: 0.6875 - val_loss: 747.7787 - val_accuracy: 0.6431\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 867.3147 - accuracy: 0.6877 - val_loss: 780.2998 - val_accuracy: 0.6459\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 944.0856 - accuracy: 0.6857 - val_loss: 788.2419 - val_accuracy: 0.6444\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 959.8335 - accuracy: 0.6738 - val_loss: 766.5352 - val_accuracy: 0.6304\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 916.0391 - accuracy: 0.6900 - val_loss: 792.0992 - val_accuracy: 0.6495\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 880.5775 - accuracy: 0.6764 - val_loss: 783.0479 - val_accuracy: 0.6409\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 865.6556 - accuracy: 0.6848 - val_loss: 744.4503 - val_accuracy: 0.6305\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 859.3039 - accuracy: 0.6829 - val_loss: 750.7977 - val_accuracy: 0.6436\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 858.0039 - accuracy: 0.6810 - val_loss: 738.3495 - val_accuracy: 0.6371\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 845.3115 - accuracy: 0.6902 - val_loss: 738.6637 - val_accuracy: 0.6435\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 842.6096 - accuracy: 0.6903 - val_loss: 755.8719 - val_accuracy: 0.6264\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 844.1733 - accuracy: 0.6793 - val_loss: 751.6330 - val_accuracy: 0.6178\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 842.7763 - accuracy: 0.6720 - val_loss: 740.4813 - val_accuracy: 0.6434\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 838.5181 - accuracy: 0.6910 - val_loss: 737.9852 - val_accuracy: 0.6478\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 841.2249 - accuracy: 0.6933 - val_loss: 733.6139 - val_accuracy: 0.6456\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 838.8107 - accuracy: 0.6951 - val_loss: 738.1527 - val_accuracy: 0.6442\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 835.9755 - accuracy: 0.6816 - val_loss: 743.2474 - val_accuracy: 0.6465\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 838.1932 - accuracy: 0.6916 - val_loss: 747.7354 - val_accuracy: 0.6414\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 841.7972 - accuracy: 0.6937 - val_loss: 751.4297 - val_accuracy: 0.6191\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 846.4883 - accuracy: 0.6823 - val_loss: 756.3402 - val_accuracy: 0.6405\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 843.3078 - accuracy: 0.6939 - val_loss: 734.8782 - val_accuracy: 0.6543\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 841.2745 - accuracy: 0.6965 - val_loss: 741.0434 - val_accuracy: 0.6553\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 837.6854 - accuracy: 0.6941 - val_loss: 744.0905 - val_accuracy: 0.6387\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 839.7324 - accuracy: 0.6932 - val_loss: 750.3281 - val_accuracy: 0.6330\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 844.6749 - accuracy: 0.6823 - val_loss: 742.0641 - val_accuracy: 0.6458\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 838.8828 - accuracy: 0.6943 - val_loss: 737.4311 - val_accuracy: 0.6519\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 845.0331 - accuracy: 0.6909 - val_loss: 750.9544 - val_accuracy: 0.6470\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 847.1453 - accuracy: 0.6886 - val_loss: 740.4824 - val_accuracy: 0.6431\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 840.4276 - accuracy: 0.6900 - val_loss: 742.7771 - val_accuracy: 0.6366\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 837.8785 - accuracy: 0.6872 - val_loss: 737.6116 - val_accuracy: 0.6440\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 841.8953 - accuracy: 0.6917 - val_loss: 751.0585 - val_accuracy: 0.6522\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 846.4795 - accuracy: 0.6927 - val_loss: 746.1493 - val_accuracy: 0.6420\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 842.9092 - accuracy: 0.6954 - val_loss: 741.2570 - val_accuracy: 0.6515\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 843.0366 - accuracy: 0.6894 - val_loss: 750.4130 - val_accuracy: 0.6625\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 839.4670 - accuracy: 0.6978 - val_loss: 730.8845 - val_accuracy: 0.6481\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 835.9847 - accuracy: 0.6946 - val_loss: 738.1170 - val_accuracy: 0.6525\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 834.3509 - accuracy: 0.6963 - val_loss: 732.7568 - val_accuracy: 0.6503\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 838.2052 - accuracy: 0.6979 - val_loss: 739.2928 - val_accuracy: 0.6484\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 835.2938 - accuracy: 0.6973 - val_loss: 733.2373 - val_accuracy: 0.6489\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 832.5336 - accuracy: 0.6939 - val_loss: 739.2620 - val_accuracy: 0.6364\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 834.2973 - accuracy: 0.6889 - val_loss: 732.1870 - val_accuracy: 0.6398\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 835.6274 - accuracy: 0.6912 - val_loss: 731.1362 - val_accuracy: 0.6562\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 840.7512 - accuracy: 0.6937 - val_loss: 736.0656 - val_accuracy: 0.6325\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 838.2966 - accuracy: 0.6843 - val_loss: 740.3526 - val_accuracy: 0.6462\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 835.7722 - accuracy: 0.6939 - val_loss: 732.2434 - val_accuracy: 0.6467\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 835.8549 - accuracy: 0.6987 - val_loss: 728.3180 - val_accuracy: 0.6408\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 834.9353 - accuracy: 0.6889 - val_loss: 738.9957 - val_accuracy: 0.6600\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 844.2675 - accuracy: 0.6802 - val_loss: 742.2564 - val_accuracy: 0.6516\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 842.3296 - accuracy: 0.6953 - val_loss: 736.3801 - val_accuracy: 0.6260\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 839.5280 - accuracy: 0.6880 - val_loss: 741.6840 - val_accuracy: 0.6517\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 836.3980 - accuracy: 0.6874 - val_loss: 742.1641 - val_accuracy: 0.6353\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 832.9702 - accuracy: 0.6954 - val_loss: 735.0956 - val_accuracy: 0.6420\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 836.4196 - accuracy: 0.6869 - val_loss: 739.1735 - val_accuracy: 0.6566\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 833.7021 - accuracy: 0.6958 - val_loss: 737.7950 - val_accuracy: 0.6274\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 840.4965 - accuracy: 0.6840 - val_loss: 739.5966 - val_accuracy: 0.6524\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 835.1087 - accuracy: 0.6889 - val_loss: 731.9077 - val_accuracy: 0.6445\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 834.2553 - accuracy: 0.6964 - val_loss: 734.6001 - val_accuracy: 0.6451\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 838.7795 - accuracy: 0.6919 - val_loss: 738.7745 - val_accuracy: 0.6396\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.3658 - accuracy: 0.6873 - val_loss: 736.1820 - val_accuracy: 0.6402\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.0665 - accuracy: 0.6933 - val_loss: 729.4406 - val_accuracy: 0.6441\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 833.9322 - accuracy: 0.6935 - val_loss: 738.9186 - val_accuracy: 0.6462\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 834.5333 - accuracy: 0.6913 - val_loss: 738.0253 - val_accuracy: 0.6517\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 836.2479 - accuracy: 0.6954 - val_loss: 736.7332 - val_accuracy: 0.6511\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 834.4610 - accuracy: 0.6947 - val_loss: 739.8828 - val_accuracy: 0.6472\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 837.8265 - accuracy: 0.6920 - val_loss: 738.7444 - val_accuracy: 0.6493\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 840.3525 - accuracy: 0.6908 - val_loss: 739.1836 - val_accuracy: 0.6446\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 840.4437 - accuracy: 0.6917 - val_loss: 748.7562 - val_accuracy: 0.6217\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 838.4417 - accuracy: 0.6887 - val_loss: 750.4007 - val_accuracy: 0.6401\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 840.2787 - accuracy: 0.6910 - val_loss: 740.6262 - val_accuracy: 0.6291\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 840.5753 - accuracy: 0.6873 - val_loss: 741.1816 - val_accuracy: 0.6300\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 834.5721 - accuracy: 0.6794 - val_loss: 743.0081 - val_accuracy: 0.6529\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 835.4510 - accuracy: 0.6883 - val_loss: 731.9061 - val_accuracy: 0.6398\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.2700 - accuracy: 0.6938 - val_loss: 740.7769 - val_accuracy: 0.6480\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 840.5980 - accuracy: 0.6954 - val_loss: 735.8915 - val_accuracy: 0.6493\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 848.4268 - accuracy: 0.6920 - val_loss: 748.3663 - val_accuracy: 0.6390\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 837.5667 - accuracy: 0.6908 - val_loss: 732.5127 - val_accuracy: 0.6425\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 832.2496 - accuracy: 0.6965 - val_loss: 737.8879 - val_accuracy: 0.6517\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 832.6858 - accuracy: 0.6920 - val_loss: 737.2090 - val_accuracy: 0.6289\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 831.8240 - accuracy: 0.6865 - val_loss: 747.6624 - val_accuracy: 0.6427\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 834.0803 - accuracy: 0.6936 - val_loss: 740.0121 - val_accuracy: 0.6355\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 835.3921 - accuracy: 0.6936 - val_loss: 736.1745 - val_accuracy: 0.6555\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.3057 - accuracy: 0.6995 - val_loss: 744.9638 - val_accuracy: 0.6143\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 839.7620 - accuracy: 0.6862 - val_loss: 751.9900 - val_accuracy: 0.6393\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 856.1075 - accuracy: 0.6899 - val_loss: 746.5247 - val_accuracy: 0.6241\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 846.1674 - accuracy: 0.6889 - val_loss: 746.8035 - val_accuracy: 0.6140\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 838.8075 - accuracy: 0.6829 - val_loss: 745.1166 - val_accuracy: 0.6238\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 840.6077 - accuracy: 0.6865 - val_loss: 740.3376 - val_accuracy: 0.6369\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 838.6912 - accuracy: 0.6886 - val_loss: 741.4866 - val_accuracy: 0.6289\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 844.4910 - accuracy: 0.6862 - val_loss: 758.2060 - val_accuracy: 0.6269\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 855.3402 - accuracy: 0.6953 - val_loss: 745.2402 - val_accuracy: 0.6439\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 847.3787 - accuracy: 0.6925 - val_loss: 747.9909 - val_accuracy: 0.6553\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 841.3072 - accuracy: 0.6943 - val_loss: 738.9496 - val_accuracy: 0.6344\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 844.0921 - accuracy: 0.6898 - val_loss: 755.2046 - val_accuracy: 0.6388\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 845.8117 - accuracy: 0.6917 - val_loss: 766.3225 - val_accuracy: 0.6467\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 856.0387 - accuracy: 0.6920 - val_loss: 742.2531 - val_accuracy: 0.6320\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 839.3129 - accuracy: 0.6909 - val_loss: 741.5156 - val_accuracy: 0.6310\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 837.3896 - accuracy: 0.6948 - val_loss: 743.7115 - val_accuracy: 0.6291\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 834.3500 - accuracy: 0.6901 - val_loss: 747.0952 - val_accuracy: 0.6444\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 833.5193 - accuracy: 0.6897 - val_loss: 732.7545 - val_accuracy: 0.6449\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 832.2222 - accuracy: 0.6934 - val_loss: 741.5156 - val_accuracy: 0.6379\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 830.8064 - accuracy: 0.6864 - val_loss: 741.2986 - val_accuracy: 0.6451\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 837.7812 - accuracy: 0.6967 - val_loss: 727.2303 - val_accuracy: 0.6367\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 831.1517 - accuracy: 0.6917 - val_loss: 738.2845 - val_accuracy: 0.6422\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 835.6494 - accuracy: 0.6962 - val_loss: 732.7458 - val_accuracy: 0.6523\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 838.2559 - accuracy: 0.6920 - val_loss: 733.6951 - val_accuracy: 0.6418\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 833.9895 - accuracy: 0.6943 - val_loss: 735.2983 - val_accuracy: 0.6270\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 834.1127 - accuracy: 0.6843 - val_loss: 742.3788 - val_accuracy: 0.6547\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 833.8205 - accuracy: 0.6942 - val_loss: 742.7486 - val_accuracy: 0.6257\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 840.6475 - accuracy: 0.6878 - val_loss: 740.1283 - val_accuracy: 0.6373\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 842.4089 - accuracy: 0.6892 - val_loss: 744.9747 - val_accuracy: 0.6540\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 837.5901 - accuracy: 0.6938 - val_loss: 739.2830 - val_accuracy: 0.6355\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 833.8569 - accuracy: 0.6921 - val_loss: 739.1926 - val_accuracy: 0.6428\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 841.9548 - accuracy: 0.6946 - val_loss: 762.7852 - val_accuracy: 0.6627\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 847.7159 - accuracy: 0.6955 - val_loss: 744.0196 - val_accuracy: 0.6222\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 840.0262 - accuracy: 0.6840 - val_loss: 746.3397 - val_accuracy: 0.6549\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 836.3486 - accuracy: 0.6913 - val_loss: 732.5590 - val_accuracy: 0.6351\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 836.8530 - accuracy: 0.6908 - val_loss: 740.4346 - val_accuracy: 0.6468\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 839.6314 - accuracy: 0.6919 - val_loss: 736.3658 - val_accuracy: 0.6396\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 837.7634 - accuracy: 0.6882 - val_loss: 737.9286 - val_accuracy: 0.6428\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 837.9771 - accuracy: 0.7000 - val_loss: 731.7910 - val_accuracy: 0.6494\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 834.7560 - accuracy: 0.6944 - val_loss: 736.6706 - val_accuracy: 0.6501\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 833.9384 - accuracy: 0.6955 - val_loss: 734.1620 - val_accuracy: 0.6547\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.8948 - accuracy: 0.6922 - val_loss: 727.0765 - val_accuracy: 0.6475\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 829.0203 - accuracy: 0.6921 - val_loss: 733.8540 - val_accuracy: 0.6440\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 830.4367 - accuracy: 0.6985 - val_loss: 736.7953 - val_accuracy: 0.6390\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 834.5788 - accuracy: 0.6968 - val_loss: 738.2816 - val_accuracy: 0.6408\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 835.0890 - accuracy: 0.6921 - val_loss: 750.7319 - val_accuracy: 0.6182\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 833.1490 - accuracy: 0.6810 - val_loss: 735.9675 - val_accuracy: 0.6434\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 831.2737 - accuracy: 0.6943 - val_loss: 736.1028 - val_accuracy: 0.6459\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 842.7029 - accuracy: 0.6928 - val_loss: 763.9642 - val_accuracy: 0.6275\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 890.7047 - accuracy: 0.6918 - val_loss: 750.3142 - val_accuracy: 0.6483\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 874.4383 - accuracy: 0.6894 - val_loss: 738.7615 - val_accuracy: 0.6410\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 847.5469 - accuracy: 0.6883 - val_loss: 737.9294 - val_accuracy: 0.6516\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 846.0495 - accuracy: 0.6885 - val_loss: 755.0746 - val_accuracy: 0.6176\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 838.9346 - accuracy: 0.6899 - val_loss: 734.9379 - val_accuracy: 0.6573\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 841.9686 - accuracy: 0.7023 - val_loss: 747.5483 - val_accuracy: 0.6470\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 839.4089 - accuracy: 0.6991 - val_loss: 743.8101 - val_accuracy: 0.6441\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 837.6158 - accuracy: 0.6912 - val_loss: 743.3071 - val_accuracy: 0.6515\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 842.4838 - accuracy: 0.6969 - val_loss: 736.2226 - val_accuracy: 0.6348\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 835.8934 - accuracy: 0.6954 - val_loss: 742.9248 - val_accuracy: 0.6503\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 833.8458 - accuracy: 0.6915 - val_loss: 746.2708 - val_accuracy: 0.6405\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 841.8789 - accuracy: 0.6908 - val_loss: 743.8384 - val_accuracy: 0.6446\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 842.2706 - accuracy: 0.6927 - val_loss: 739.1330 - val_accuracy: 0.6339\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 832.4545 - accuracy: 0.6899 - val_loss: 732.3378 - val_accuracy: 0.6409\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 831.2851 - accuracy: 0.6968 - val_loss: 727.4758 - val_accuracy: 0.6552\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 836.2455 - accuracy: 0.6963 - val_loss: 729.4642 - val_accuracy: 0.6559\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 849.2521 - accuracy: 0.6991 - val_loss: 727.3756 - val_accuracy: 0.6464\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 841.4309 - accuracy: 0.6966 - val_loss: 734.5840 - val_accuracy: 0.6631\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 840.1061 - accuracy: 0.6995 - val_loss: 735.5847 - val_accuracy: 0.6399\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 838.2972 - accuracy: 0.6954 - val_loss: 738.9337 - val_accuracy: 0.6493\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 836.9926 - accuracy: 0.6971 - val_loss: 733.8857 - val_accuracy: 0.6452\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 836.6094 - accuracy: 0.6905 - val_loss: 737.1071 - val_accuracy: 0.6534\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 832.7549 - accuracy: 0.6971 - val_loss: 737.6932 - val_accuracy: 0.6511\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 831.1617 - accuracy: 0.7001 - val_loss: 739.3191 - val_accuracy: 0.6468\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 832.2765 - accuracy: 0.6961 - val_loss: 738.3923 - val_accuracy: 0.6427\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 835.4176 - accuracy: 0.6944 - val_loss: 738.6636 - val_accuracy: 0.6343\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 831.9921 - accuracy: 0.6952 - val_loss: 734.7891 - val_accuracy: 0.6541\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 831.3219 - accuracy: 0.7017 - val_loss: 734.7315 - val_accuracy: 0.6516\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 834.4576 - accuracy: 0.6991 - val_loss: 770.1736 - val_accuracy: 0.6437\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 868.7317 - accuracy: 0.6918 - val_loss: 733.2365 - val_accuracy: 0.6502\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 842.6935 - accuracy: 0.6914 - val_loss: 742.9364 - val_accuracy: 0.6459\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 834.7393 - accuracy: 0.6952 - val_loss: 729.9392 - val_accuracy: 0.6543\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 829.9416 - accuracy: 0.6943 - val_loss: 736.4517 - val_accuracy: 0.6515\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 830.2936 - accuracy: 0.7011 - val_loss: 726.3053 - val_accuracy: 0.6429\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 832.4791 - accuracy: 0.6950 - val_loss: 733.1635 - val_accuracy: 0.6462\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 830.1078 - accuracy: 0.7015 - val_loss: 730.9003 - val_accuracy: 0.6476\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 832.8187 - accuracy: 0.6997 - val_loss: 737.8661 - val_accuracy: 0.6364\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 844.4886 - accuracy: 0.7010 - val_loss: 736.7299 - val_accuracy: 0.6425\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 836.6218 - accuracy: 0.6903 - val_loss: 739.1557 - val_accuracy: 0.6453\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 832.0547 - accuracy: 0.6956 - val_loss: 731.8661 - val_accuracy: 0.6461\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 830.3326 - accuracy: 0.6984 - val_loss: 729.9108 - val_accuracy: 0.6491\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 828.9420 - accuracy: 0.6928 - val_loss: 739.3600 - val_accuracy: 0.6416\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 827.7414 - accuracy: 0.6941 - val_loss: 731.8069 - val_accuracy: 0.6501\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 827.2902 - accuracy: 0.6984 - val_loss: 726.6329 - val_accuracy: 0.6424\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 827.7233 - accuracy: 0.6912 - val_loss: 742.9706 - val_accuracy: 0.6457\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 828.3602 - accuracy: 0.6984 - val_loss: 730.3380 - val_accuracy: 0.6391\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 825.3315 - accuracy: 0.6991 - val_loss: 733.8962 - val_accuracy: 0.6512\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 826.1242 - accuracy: 0.6960 - val_loss: 732.1334 - val_accuracy: 0.6385\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 829.0129 - accuracy: 0.6919 - val_loss: 732.4171 - val_accuracy: 0.6443\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 828.0357 - accuracy: 0.6968 - val_loss: 727.0641 - val_accuracy: 0.6401\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 835.5555 - accuracy: 0.6945 - val_loss: 776.5763 - val_accuracy: 0.6524\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 873.1032 - accuracy: 0.6932 - val_loss: 742.3785 - val_accuracy: 0.6511\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 843.7550 - accuracy: 0.6947 - val_loss: 737.5353 - val_accuracy: 0.6471\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 836.0725 - accuracy: 0.6948 - val_loss: 740.0684 - val_accuracy: 0.6286\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 840.3025 - accuracy: 0.6836 - val_loss: 733.2272 - val_accuracy: 0.6400\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 834.0274 - accuracy: 0.6886 - val_loss: 727.3528 - val_accuracy: 0.6532\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 829.9858 - accuracy: 0.6955 - val_loss: 724.5601 - val_accuracy: 0.6420\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 835.2764 - accuracy: 0.6895 - val_loss: 731.7806 - val_accuracy: 0.6508\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 830.5380 - accuracy: 0.6952 - val_loss: 727.9977 - val_accuracy: 0.6460\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 828.9402 - accuracy: 0.6981 - val_loss: 724.4977 - val_accuracy: 0.6528\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 832.1133 - accuracy: 0.7007 - val_loss: 733.4592 - val_accuracy: 0.6336\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 830.1458 - accuracy: 0.6980 - val_loss: 729.3800 - val_accuracy: 0.6497\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 825.8268 - accuracy: 0.6972 - val_loss: 727.1667 - val_accuracy: 0.6428\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 829.8554 - accuracy: 0.6925 - val_loss: 728.5995 - val_accuracy: 0.6570\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 842.1450 - accuracy: 0.7007 - val_loss: 726.9787 - val_accuracy: 0.6355\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 841.6624 - accuracy: 0.6919 - val_loss: 726.4308 - val_accuracy: 0.6524\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 831.8528 - accuracy: 0.6942 - val_loss: 730.1523 - val_accuracy: 0.6357\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 833.7533 - accuracy: 0.6922 - val_loss: 738.0714 - val_accuracy: 0.6532\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 848.9291 - accuracy: 0.6965 - val_loss: 761.9077 - val_accuracy: 0.6402\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 854.5510 - accuracy: 0.6944 - val_loss: 744.7740 - val_accuracy: 0.6265\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 851.0792 - accuracy: 0.6915 - val_loss: 754.2136 - val_accuracy: 0.6537\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 848.9137 - accuracy: 0.6910 - val_loss: 743.7868 - val_accuracy: 0.6411\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 837.9852 - accuracy: 0.6935 - val_loss: 741.7200 - val_accuracy: 0.6397\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 830.7677 - accuracy: 0.6964 - val_loss: 732.2434 - val_accuracy: 0.6519\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 836.8536 - accuracy: 0.7007 - val_loss: 730.6968 - val_accuracy: 0.6436\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 831.4713 - accuracy: 0.6964 - val_loss: 733.8134 - val_accuracy: 0.6481\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 831.7281 - accuracy: 0.7019 - val_loss: 734.4357 - val_accuracy: 0.6487\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.5009 - accuracy: 0.6985 - val_loss: 748.5264 - val_accuracy: 0.6262\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 837.8939 - accuracy: 0.6918 - val_loss: 733.8979 - val_accuracy: 0.6527\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 831.8590 - accuracy: 0.6996 - val_loss: 727.7151 - val_accuracy: 0.6436\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 826.0259 - accuracy: 0.6963 - val_loss: 730.4130 - val_accuracy: 0.6433\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 828.5123 - accuracy: 0.6896 - val_loss: 732.7272 - val_accuracy: 0.6615\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 827.8163 - accuracy: 0.6910 - val_loss: 734.3495 - val_accuracy: 0.6475\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 830.4547 - accuracy: 0.7026 - val_loss: 729.2810 - val_accuracy: 0.6254\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 830.0308 - accuracy: 0.6864 - val_loss: 742.7338 - val_accuracy: 0.6470\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 839.4403 - accuracy: 0.6830 - val_loss: 738.4056 - val_accuracy: 0.6358\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 851.9984 - accuracy: 0.6853 - val_loss: 744.2272 - val_accuracy: 0.6477\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 836.8315 - accuracy: 0.6951 - val_loss: 738.0361 - val_accuracy: 0.6477\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 830.6347 - accuracy: 0.6910 - val_loss: 732.1233 - val_accuracy: 0.6551\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 828.8336 - accuracy: 0.6951 - val_loss: 733.5784 - val_accuracy: 0.6373\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 827.2949 - accuracy: 0.6949 - val_loss: 728.8513 - val_accuracy: 0.6537\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 825.3985 - accuracy: 0.7010 - val_loss: 724.7657 - val_accuracy: 0.6474\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 827.0079 - accuracy: 0.6997 - val_loss: 731.2682 - val_accuracy: 0.6306\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 828.4709 - accuracy: 0.6967 - val_loss: 729.6852 - val_accuracy: 0.6451\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 826.1221 - accuracy: 0.6991 - val_loss: 729.1097 - val_accuracy: 0.6463\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 824.0714 - accuracy: 0.7011 - val_loss: 728.0026 - val_accuracy: 0.6517\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 825.8470 - accuracy: 0.7026 - val_loss: 723.4944 - val_accuracy: 0.6516\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 823.4747 - accuracy: 0.6987 - val_loss: 726.5224 - val_accuracy: 0.6383\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 824.6863 - accuracy: 0.6983 - val_loss: 729.4912 - val_accuracy: 0.6582\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 824.5728 - accuracy: 0.6961 - val_loss: 728.0598 - val_accuracy: 0.6474\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 830.0169 - accuracy: 0.6966 - val_loss: 733.6700 - val_accuracy: 0.6369\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 826.0997 - accuracy: 0.6995 - val_loss: 730.8513 - val_accuracy: 0.6430\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 824.6141 - accuracy: 0.6972 - val_loss: 725.4543 - val_accuracy: 0.6572\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 824.9796 - accuracy: 0.7058 - val_loss: 726.7053 - val_accuracy: 0.6369\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 823.9743 - accuracy: 0.6948 - val_loss: 734.3617 - val_accuracy: 0.6363\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 824.1690 - accuracy: 0.7042 - val_loss: 723.6572 - val_accuracy: 0.6425\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 826.4867 - accuracy: 0.7002 - val_loss: 728.8554 - val_accuracy: 0.6565\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 831.5005 - accuracy: 0.7040 - val_loss: 732.6323 - val_accuracy: 0.6250\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 828.2645 - accuracy: 0.6982 - val_loss: 728.9493 - val_accuracy: 0.6584\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 825.0286 - accuracy: 0.7005 - val_loss: 735.3153 - val_accuracy: 0.6459\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 831.4512 - accuracy: 0.6947 - val_loss: 722.7991 - val_accuracy: 0.6527\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 832.4887 - accuracy: 0.6939 - val_loss: 724.3131 - val_accuracy: 0.6403\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 833.4600 - accuracy: 0.7020 - val_loss: 725.5128 - val_accuracy: 0.6261\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 828.3101 - accuracy: 0.6867 - val_loss: 737.1346 - val_accuracy: 0.6578\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 831.4120 - accuracy: 0.6934 - val_loss: 727.1332 - val_accuracy: 0.6393\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 838.3715 - accuracy: 0.6952 - val_loss: 741.2074 - val_accuracy: 0.6467\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 873.7868 - accuracy: 0.7032 - val_loss: 809.8057 - val_accuracy: 0.6448\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 882.8890 - accuracy: 0.6962 - val_loss: 845.4490 - val_accuracy: 0.6333\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 898.2155 - accuracy: 0.6835 - val_loss: 782.8719 - val_accuracy: 0.6643\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 864.1945 - accuracy: 0.6920 - val_loss: 769.8719 - val_accuracy: 0.6170\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 853.8112 - accuracy: 0.6827 - val_loss: 735.2031 - val_accuracy: 0.6227\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 837.4093 - accuracy: 0.6918 - val_loss: 732.6826 - val_accuracy: 0.6621\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 833.8083 - accuracy: 0.6983 - val_loss: 727.9675 - val_accuracy: 0.6460\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 828.6989 - accuracy: 0.6937 - val_loss: 741.8940 - val_accuracy: 0.6314\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 827.8016 - accuracy: 0.7003 - val_loss: 728.0362 - val_accuracy: 0.6358\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 824.9643 - accuracy: 0.6942 - val_loss: 735.6266 - val_accuracy: 0.6624\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 825.8662 - accuracy: 0.6905 - val_loss: 729.0020 - val_accuracy: 0.6544\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 823.8746 - accuracy: 0.7049 - val_loss: 728.8873 - val_accuracy: 0.6372\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 824.8427 - accuracy: 0.6989 - val_loss: 731.4446 - val_accuracy: 0.6412\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 825.8920 - accuracy: 0.6977 - val_loss: 734.6790 - val_accuracy: 0.6447\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 825.7800 - accuracy: 0.6931 - val_loss: 732.3321 - val_accuracy: 0.6455\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 828.9176 - accuracy: 0.7023 - val_loss: 730.9481 - val_accuracy: 0.6400\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 827.8558 - accuracy: 0.6914 - val_loss: 731.2260 - val_accuracy: 0.6396\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 826.2802 - accuracy: 0.6932 - val_loss: 726.0656 - val_accuracy: 0.6398\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 826.1248 - accuracy: 0.6992 - val_loss: 734.8433 - val_accuracy: 0.6453\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 828.6852 - accuracy: 0.7009 - val_loss: 725.3641 - val_accuracy: 0.6457\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 827.7422 - accuracy: 0.7011 - val_loss: 727.8458 - val_accuracy: 0.6502\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 829.7652 - accuracy: 0.6893 - val_loss: 736.7509 - val_accuracy: 0.6526\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 829.3364 - accuracy: 0.7045 - val_loss: 722.0249 - val_accuracy: 0.6564\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 830.1786 - accuracy: 0.6878 - val_loss: 734.3218 - val_accuracy: 0.6507\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 824.4077 - accuracy: 0.7044 - val_loss: 720.2806 - val_accuracy: 0.6574\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 825.9886 - accuracy: 0.7024 - val_loss: 730.1396 - val_accuracy: 0.6507\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 826.7274 - accuracy: 0.7040 - val_loss: 726.5898 - val_accuracy: 0.6431\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 828.9025 - accuracy: 0.6963 - val_loss: 738.2510 - val_accuracy: 0.6375\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 831.7483 - accuracy: 0.7007 - val_loss: 725.9990 - val_accuracy: 0.6435\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 831.2054 - accuracy: 0.6957 - val_loss: 739.5768 - val_accuracy: 0.6521\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 824.5539 - accuracy: 0.6979 - val_loss: 732.3946 - val_accuracy: 0.6461\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 826.3234 - accuracy: 0.6929 - val_loss: 736.9712 - val_accuracy: 0.6390\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 826.0502 - accuracy: 0.6972 - val_loss: 729.4529 - val_accuracy: 0.6447\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 831.4517 - accuracy: 0.6931 - val_loss: 734.8358 - val_accuracy: 0.6418\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 828.9073 - accuracy: 0.7006 - val_loss: 730.0391 - val_accuracy: 0.6407\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 827.4122 - accuracy: 0.6957 - val_loss: 733.7358 - val_accuracy: 0.6415\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 823.3038 - accuracy: 0.6959 - val_loss: 727.9577 - val_accuracy: 0.6463\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 824.2706 - accuracy: 0.7032 - val_loss: 723.9586 - val_accuracy: 0.6427\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 826.6031 - accuracy: 0.6915 - val_loss: 731.3992 - val_accuracy: 0.6517\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 823.9926 - accuracy: 0.7009 - val_loss: 721.8215 - val_accuracy: 0.6591\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 825.2202 - accuracy: 0.7055 - val_loss: 730.6826 - val_accuracy: 0.6509\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 832.0892 - accuracy: 0.7022 - val_loss: 752.8586 - val_accuracy: 0.6388\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 839.1184 - accuracy: 0.7006 - val_loss: 730.5972 - val_accuracy: 0.6501\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 829.8279 - accuracy: 0.6902 - val_loss: 736.7362 - val_accuracy: 0.6264\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 825.5074 - accuracy: 0.6872 - val_loss: 737.0972 - val_accuracy: 0.6524\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 827.4488 - accuracy: 0.7029 - val_loss: 722.9963 - val_accuracy: 0.6489\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 824.7177 - accuracy: 0.6988 - val_loss: 734.4437 - val_accuracy: 0.6429\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 823.7855 - accuracy: 0.7057 - val_loss: 724.5152 - val_accuracy: 0.6482\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 829.2916 - accuracy: 0.6887 - val_loss: 749.9399 - val_accuracy: 0.6433\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 845.7864 - accuracy: 0.6880 - val_loss: 725.9422 - val_accuracy: 0.6557\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 841.6693 - accuracy: 0.7053 - val_loss: 722.6659 - val_accuracy: 0.6591\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 831.3229 - accuracy: 0.6953 - val_loss: 731.8627 - val_accuracy: 0.6453\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 823.7159 - accuracy: 0.6997 - val_loss: 723.1172 - val_accuracy: 0.6422\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 822.0657 - accuracy: 0.7008 - val_loss: 722.1189 - val_accuracy: 0.6466\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 824.4903 - accuracy: 0.6988 - val_loss: 732.3328 - val_accuracy: 0.6322\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 823.1940 - accuracy: 0.6962 - val_loss: 728.0394 - val_accuracy: 0.6536\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 833.7386 - accuracy: 0.7019 - val_loss: 725.9140 - val_accuracy: 0.6473\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 825.2599 - accuracy: 0.6999 - val_loss: 724.7275 - val_accuracy: 0.6511\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 824.9704 - accuracy: 0.6960 - val_loss: 727.1985 - val_accuracy: 0.6431\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 823.6437 - accuracy: 0.7005 - val_loss: 726.6659 - val_accuracy: 0.6462\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 824.0022 - accuracy: 0.7016 - val_loss: 723.4021 - val_accuracy: 0.6502\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 825.8824 - accuracy: 0.6899 - val_loss: 732.9606 - val_accuracy: 0.6366\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 831.6655 - accuracy: 0.6855 - val_loss: 729.7969 - val_accuracy: 0.6460\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 828.3839 - accuracy: 0.7023 - val_loss: 723.8779 - val_accuracy: 0.6433\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 826.1865 - accuracy: 0.6896 - val_loss: 726.0997 - val_accuracy: 0.6447\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 824.8911 - accuracy: 0.7028 - val_loss: 724.3348 - val_accuracy: 0.6417\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 824.1480 - accuracy: 0.6994 - val_loss: 732.2715 - val_accuracy: 0.6513\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 825.7821 - accuracy: 0.7037 - val_loss: 728.0498 - val_accuracy: 0.6441\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 835.3965 - accuracy: 0.6969 - val_loss: 746.8549 - val_accuracy: 0.6323\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 840.4244 - accuracy: 0.6970 - val_loss: 728.5995 - val_accuracy: 0.6472\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 834.7067 - accuracy: 0.6909 - val_loss: 730.3359 - val_accuracy: 0.6386\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 826.0825 - accuracy: 0.6977 - val_loss: 734.4297 - val_accuracy: 0.6342\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 834.3688 - accuracy: 0.6847 - val_loss: 731.3350 - val_accuracy: 0.6563\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 832.5394 - accuracy: 0.7000 - val_loss: 724.7378 - val_accuracy: 0.6390\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 831.5477 - accuracy: 0.7005 - val_loss: 730.0535 - val_accuracy: 0.6386\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 830.5854 - accuracy: 0.6884 - val_loss: 730.6392 - val_accuracy: 0.6529\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 831.2995 - accuracy: 0.7003 - val_loss: 727.8469 - val_accuracy: 0.6433\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 825.0153 - accuracy: 0.6960 - val_loss: 738.0863 - val_accuracy: 0.6537\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 829.4626 - accuracy: 0.7032 - val_loss: 722.8945 - val_accuracy: 0.6537\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 825.8986 - accuracy: 0.7025 - val_loss: 731.9263 - val_accuracy: 0.6342\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 831.0783 - accuracy: 0.6831 - val_loss: 744.8460 - val_accuracy: 0.6652\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 848.4731 - accuracy: 0.7018 - val_loss: 731.8406 - val_accuracy: 0.6566\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 843.6161 - accuracy: 0.6989 - val_loss: 747.5275 - val_accuracy: 0.6445\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 847.9922 - accuracy: 0.7043 - val_loss: 719.6431 - val_accuracy: 0.6612\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 839.4772 - accuracy: 0.6924 - val_loss: 728.8039 - val_accuracy: 0.6561\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 829.7358 - accuracy: 0.7024 - val_loss: 712.6029 - val_accuracy: 0.6555\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 825.9312 - accuracy: 0.7061 - val_loss: 721.6700 - val_accuracy: 0.6677\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 824.5864 - accuracy: 0.7036 - val_loss: 722.8765 - val_accuracy: 0.6349\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 822.8680 - accuracy: 0.7032 - val_loss: 720.2650 - val_accuracy: 0.6552\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 821.7549 - accuracy: 0.7040 - val_loss: 727.2522 - val_accuracy: 0.6482\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.2414 - accuracy: 0.6956 - val_loss: 730.5604 - val_accuracy: 0.6387\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 835.4466 - accuracy: 0.6919 - val_loss: 734.0954 - val_accuracy: 0.6288\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 826.9978 - accuracy: 0.6928 - val_loss: 732.6923 - val_accuracy: 0.6415\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 827.2142 - accuracy: 0.6946 - val_loss: 730.1354 - val_accuracy: 0.6401\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 830.8339 - accuracy: 0.7060 - val_loss: 723.3669 - val_accuracy: 0.6397\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 830.1980 - accuracy: 0.6966 - val_loss: 738.1335 - val_accuracy: 0.6239\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 827.7700 - accuracy: 0.7000 - val_loss: 715.8929 - val_accuracy: 0.6606\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 836.4893 - accuracy: 0.7036 - val_loss: 724.1914 - val_accuracy: 0.6558\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 838.2596 - accuracy: 0.6937 - val_loss: 738.0510 - val_accuracy: 0.6246\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 840.0757 - accuracy: 0.6961 - val_loss: 740.3578 - val_accuracy: 0.6517\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 832.9505 - accuracy: 0.7048 - val_loss: 722.4096 - val_accuracy: 0.6475\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 826.6166 - accuracy: 0.6960 - val_loss: 733.8063 - val_accuracy: 0.6394\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 826.1949 - accuracy: 0.6955 - val_loss: 722.7719 - val_accuracy: 0.6494\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 824.9583 - accuracy: 0.7014 - val_loss: 721.6709 - val_accuracy: 0.6540\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 824.7523 - accuracy: 0.7055 - val_loss: 723.0807 - val_accuracy: 0.6454\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 827.5165 - accuracy: 0.6983 - val_loss: 728.8641 - val_accuracy: 0.6403\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 823.8390 - accuracy: 0.6937 - val_loss: 729.5230 - val_accuracy: 0.6415\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 820.9440 - accuracy: 0.7015 - val_loss: 723.8356 - val_accuracy: 0.6584\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 822.0463 - accuracy: 0.7019 - val_loss: 728.1129 - val_accuracy: 0.6526\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 821.4017 - accuracy: 0.7074 - val_loss: 729.0292 - val_accuracy: 0.6349\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 826.8953 - accuracy: 0.6904 - val_loss: 727.2423 - val_accuracy: 0.6496\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 826.4590 - accuracy: 0.7075 - val_loss: 715.3175 - val_accuracy: 0.6558\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 829.5956 - accuracy: 0.6916 - val_loss: 736.5931 - val_accuracy: 0.6413\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 835.7906 - accuracy: 0.6891 - val_loss: 732.2606 - val_accuracy: 0.6585\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 828.5289 - accuracy: 0.7050 - val_loss: 719.3170 - val_accuracy: 0.6474\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 822.5450 - accuracy: 0.6989 - val_loss: 722.2308 - val_accuracy: 0.6559\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 823.4816 - accuracy: 0.7012 - val_loss: 727.5626 - val_accuracy: 0.6492\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 823.7678 - accuracy: 0.7038 - val_loss: 720.5232 - val_accuracy: 0.6476\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 820.3653 - accuracy: 0.6973 - val_loss: 728.5510 - val_accuracy: 0.6387\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.6757 - accuracy: 0.7011 - val_loss: 732.0674 - val_accuracy: 0.6458\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 830.9969 - accuracy: 0.6996 - val_loss: 736.6602 - val_accuracy: 0.6358\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 850.2177 - accuracy: 0.6945 - val_loss: 730.6818 - val_accuracy: 0.6660\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 831.4083 - accuracy: 0.6994 - val_loss: 725.4122 - val_accuracy: 0.6262\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 824.2502 - accuracy: 0.6967 - val_loss: 732.3189 - val_accuracy: 0.6509\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 826.2477 - accuracy: 0.6994 - val_loss: 721.8655 - val_accuracy: 0.6562\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 820.4454 - accuracy: 0.7023 - val_loss: 723.9262 - val_accuracy: 0.6313\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 821.7294 - accuracy: 0.6906 - val_loss: 734.8814 - val_accuracy: 0.6586\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 822.6554 - accuracy: 0.7034 - val_loss: 718.7097 - val_accuracy: 0.6469\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.4017 - accuracy: 0.7033 - val_loss: 725.8801 - val_accuracy: 0.6412\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 825.3917 - accuracy: 0.6947 - val_loss: 729.3391 - val_accuracy: 0.6439\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 828.7642 - accuracy: 0.6978 - val_loss: 733.0974 - val_accuracy: 0.6410\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 835.9071 - accuracy: 0.7026 - val_loss: 755.2634 - val_accuracy: 0.6574\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 842.3356 - accuracy: 0.6979 - val_loss: 740.2023 - val_accuracy: 0.6451\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 858.0861 - accuracy: 0.7000 - val_loss: 735.2876 - val_accuracy: 0.6448\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 839.2932 - accuracy: 0.6985 - val_loss: 727.5278 - val_accuracy: 0.6493\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 825.5056 - accuracy: 0.7030 - val_loss: 721.0692 - val_accuracy: 0.6467\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 821.4556 - accuracy: 0.7030 - val_loss: 732.6814 - val_accuracy: 0.6273\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 820.3817 - accuracy: 0.6969 - val_loss: 722.6415 - val_accuracy: 0.6515\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 821.7667 - accuracy: 0.6999 - val_loss: 731.2346 - val_accuracy: 0.6511\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 821.7106 - accuracy: 0.7040 - val_loss: 716.8684 - val_accuracy: 0.6525\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 819.2475 - accuracy: 0.6992 - val_loss: 727.6369 - val_accuracy: 0.6346\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 820.6273 - accuracy: 0.6943 - val_loss: 730.8129 - val_accuracy: 0.6329\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 820.4733 - accuracy: 0.7042 - val_loss: 720.1015 - val_accuracy: 0.6432\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 818.5937 - accuracy: 0.7028 - val_loss: 725.7008 - val_accuracy: 0.6397\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 819.6047 - accuracy: 0.6984 - val_loss: 725.0102 - val_accuracy: 0.6479\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 824.3727 - accuracy: 0.7039 - val_loss: 726.9515 - val_accuracy: 0.6265\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 819.3448 - accuracy: 0.6961 - val_loss: 726.7991 - val_accuracy: 0.6336\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.4540 - accuracy: 0.7016 - val_loss: 723.8617 - val_accuracy: 0.6484\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 823.5654 - accuracy: 0.7034 - val_loss: 723.4094 - val_accuracy: 0.6305\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 822.2447 - accuracy: 0.6923 - val_loss: 733.2972 - val_accuracy: 0.6523\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 824.4534 - accuracy: 0.7069 - val_loss: 714.1984 - val_accuracy: 0.6424\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 823.7463 - accuracy: 0.6987 - val_loss: 716.1088 - val_accuracy: 0.6517\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 823.6949 - accuracy: 0.6940 - val_loss: 720.5983 - val_accuracy: 0.6400\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 820.7812 - accuracy: 0.7025 - val_loss: 713.4714 - val_accuracy: 0.6549\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 819.0135 - accuracy: 0.7049 - val_loss: 723.6025 - val_accuracy: 0.6451\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 818.7698 - accuracy: 0.7045 - val_loss: 722.3963 - val_accuracy: 0.6373\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 819.1215 - accuracy: 0.6994 - val_loss: 723.8859 - val_accuracy: 0.6412\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 817.1361 - accuracy: 0.6984 - val_loss: 719.9872 - val_accuracy: 0.6462\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 818.0861 - accuracy: 0.7024 - val_loss: 728.7087 - val_accuracy: 0.6389\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 818.9062 - accuracy: 0.6955 - val_loss: 731.2280 - val_accuracy: 0.6365\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 830.9271 - accuracy: 0.6933 - val_loss: 731.3470 - val_accuracy: 0.6519\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.6316 - accuracy: 0.7041 - val_loss: 733.5551 - val_accuracy: 0.6451\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 829.2172 - accuracy: 0.6994 - val_loss: 729.3896 - val_accuracy: 0.6479\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 827.8035 - accuracy: 0.7043 - val_loss: 712.5449 - val_accuracy: 0.6577\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 820.1163 - accuracy: 0.6986 - val_loss: 725.6585 - val_accuracy: 0.6421\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 819.3781 - accuracy: 0.7058 - val_loss: 729.1586 - val_accuracy: 0.6269\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 820.1259 - accuracy: 0.7009 - val_loss: 719.0341 - val_accuracy: 0.6509\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 823.2802 - accuracy: 0.7057 - val_loss: 720.7559 - val_accuracy: 0.6500\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 827.7319 - accuracy: 0.7008 - val_loss: 720.6984 - val_accuracy: 0.6549\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 833.0693 - accuracy: 0.7025 - val_loss: 729.2635 - val_accuracy: 0.6387\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 828.2768 - accuracy: 0.6963 - val_loss: 726.9370 - val_accuracy: 0.6369\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 819.7747 - accuracy: 0.6971 - val_loss: 721.1949 - val_accuracy: 0.6461\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 818.8850 - accuracy: 0.7015 - val_loss: 722.3807 - val_accuracy: 0.6443\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 819.2144 - accuracy: 0.7008 - val_loss: 721.3664 - val_accuracy: 0.6389\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.8234 - accuracy: 0.6961 - val_loss: 723.9617 - val_accuracy: 0.6566\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 830.7007 - accuracy: 0.7044 - val_loss: 735.9080 - val_accuracy: 0.6234\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 831.7731 - accuracy: 0.6994 - val_loss: 727.4227 - val_accuracy: 0.6452\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 836.8284 - accuracy: 0.6949 - val_loss: 748.7637 - val_accuracy: 0.6536\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 835.7870 - accuracy: 0.6993 - val_loss: 731.7796 - val_accuracy: 0.6400\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 830.9276 - accuracy: 0.6982 - val_loss: 733.6046 - val_accuracy: 0.6446\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 829.1643 - accuracy: 0.6962 - val_loss: 735.0743 - val_accuracy: 0.6605\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 844.6268 - accuracy: 0.6934 - val_loss: 736.3766 - val_accuracy: 0.6388\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 834.9167 - accuracy: 0.7014 - val_loss: 729.8028 - val_accuracy: 0.6206\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 831.2374 - accuracy: 0.6896 - val_loss: 730.4218 - val_accuracy: 0.6440\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 829.9615 - accuracy: 0.6903 - val_loss: 726.2051 - val_accuracy: 0.6328\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 828.3774 - accuracy: 0.7036 - val_loss: 715.6038 - val_accuracy: 0.6498\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 825.5377 - accuracy: 0.6996 - val_loss: 719.2686 - val_accuracy: 0.6426\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 823.7051 - accuracy: 0.6980 - val_loss: 728.6177 - val_accuracy: 0.6519\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 827.8281 - accuracy: 0.7032 - val_loss: 731.5507 - val_accuracy: 0.6234\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 829.4899 - accuracy: 0.6984 - val_loss: 735.4656 - val_accuracy: 0.6377\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 825.3132 - accuracy: 0.6937 - val_loss: 722.8518 - val_accuracy: 0.6305\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 823.7827 - accuracy: 0.7015 - val_loss: 724.9431 - val_accuracy: 0.6417\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 832.0537 - accuracy: 0.6939 - val_loss: 777.0046 - val_accuracy: 0.6409\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 853.0606 - accuracy: 0.6974 - val_loss: 732.7455 - val_accuracy: 0.6355\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 841.9307 - accuracy: 0.6963 - val_loss: 732.4816 - val_accuracy: 0.6233\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 826.8895 - accuracy: 0.6950 - val_loss: 727.0723 - val_accuracy: 0.6347\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 819.9166 - accuracy: 0.7015 - val_loss: 729.4989 - val_accuracy: 0.6305\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 821.3643 - accuracy: 0.6952 - val_loss: 727.1403 - val_accuracy: 0.6404\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 818.5775 - accuracy: 0.6934 - val_loss: 725.4629 - val_accuracy: 0.6359\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 820.0752 - accuracy: 0.6997 - val_loss: 729.9646 - val_accuracy: 0.6230\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 823.3038 - accuracy: 0.6893 - val_loss: 731.5728 - val_accuracy: 0.6541\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 819.0883 - accuracy: 0.7013 - val_loss: 725.0228 - val_accuracy: 0.6417\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 825.9784 - accuracy: 0.6982 - val_loss: 732.3822 - val_accuracy: 0.6270\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 830.9065 - accuracy: 0.6972 - val_loss: 729.5446 - val_accuracy: 0.6523\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 861.5417 - accuracy: 0.6998 - val_loss: 787.0233 - val_accuracy: 0.6632\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 886.9087 - accuracy: 0.7017 - val_loss: 743.6694 - val_accuracy: 0.6417\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 858.0253 - accuracy: 0.6969 - val_loss: 740.8256 - val_accuracy: 0.6534\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 850.0913 - accuracy: 0.6857 - val_loss: 737.3793 - val_accuracy: 0.6587\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 833.2379 - accuracy: 0.7022 - val_loss: 720.5216 - val_accuracy: 0.6458\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 824.2722 - accuracy: 0.6983 - val_loss: 722.4030 - val_accuracy: 0.6553\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.8608 - accuracy: 0.7058 - val_loss: 717.8679 - val_accuracy: 0.6541\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 820.2890 - accuracy: 0.7036 - val_loss: 717.4073 - val_accuracy: 0.6680\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 818.1189 - accuracy: 0.7059 - val_loss: 716.3812 - val_accuracy: 0.6425\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 817.5594 - accuracy: 0.7030 - val_loss: 725.7273 - val_accuracy: 0.6321\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 819.9416 - accuracy: 0.7043 - val_loss: 720.6567 - val_accuracy: 0.6373\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 815.8976 - accuracy: 0.6987 - val_loss: 723.9503 - val_accuracy: 0.6237\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 819.4241 - accuracy: 0.6962 - val_loss: 730.8125 - val_accuracy: 0.6344\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 822.1778 - accuracy: 0.7005 - val_loss: 738.8283 - val_accuracy: 0.6346\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 834.3561 - accuracy: 0.6972 - val_loss: 724.5503 - val_accuracy: 0.6378\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 821.1624 - accuracy: 0.6996 - val_loss: 726.8970 - val_accuracy: 0.6329\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 820.8587 - accuracy: 0.6993 - val_loss: 727.8553 - val_accuracy: 0.6303\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 817.2284 - accuracy: 0.6951 - val_loss: 724.8456 - val_accuracy: 0.6402\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 815.8785 - accuracy: 0.6958 - val_loss: 722.0221 - val_accuracy: 0.6485\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 820.5436 - accuracy: 0.7021 - val_loss: 726.8841 - val_accuracy: 0.6314\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 817.5948 - accuracy: 0.7061 - val_loss: 715.7284 - val_accuracy: 0.6556\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 817.6727 - accuracy: 0.6965 - val_loss: 728.9833 - val_accuracy: 0.6501\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 823.2922 - accuracy: 0.7012 - val_loss: 724.3752 - val_accuracy: 0.6262\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 829.1336 - accuracy: 0.7022 - val_loss: 730.6807 - val_accuracy: 0.6517\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 818.9995 - accuracy: 0.6993 - val_loss: 718.0345 - val_accuracy: 0.6423\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 819.7465 - accuracy: 0.7104 - val_loss: 712.0670 - val_accuracy: 0.6492\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 819.3186 - accuracy: 0.6969 - val_loss: 725.4634 - val_accuracy: 0.6404\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 822.1104 - accuracy: 0.7050 - val_loss: 712.3815 - val_accuracy: 0.6509\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 821.4464 - accuracy: 0.6998 - val_loss: 733.7083 - val_accuracy: 0.6379\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 826.2672 - accuracy: 0.6919 - val_loss: 726.3101 - val_accuracy: 0.6542\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 832.8335 - accuracy: 0.7079 - val_loss: 733.6254 - val_accuracy: 0.6628\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 1s 66ms/step - loss: 837.6786 - accuracy: 0.7057 - val_loss: 718.6423 - val_accuracy: 0.6551\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 834.6879 - accuracy: 0.7032 - val_loss: 723.0150 - val_accuracy: 0.6355\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 824.6693 - accuracy: 0.6962 - val_loss: 725.2255 - val_accuracy: 0.6411\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 821.0720 - accuracy: 0.7019 - val_loss: 721.7253 - val_accuracy: 0.6362\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 1s 63ms/step - loss: 823.2252 - accuracy: 0.6941 - val_loss: 726.3711 - val_accuracy: 0.6561\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 824.3112 - accuracy: 0.7015 - val_loss: 726.1940 - val_accuracy: 0.6623\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 830.7495 - accuracy: 0.7085 - val_loss: 717.3804 - val_accuracy: 0.6449\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 822.3820 - accuracy: 0.7046 - val_loss: 718.6464 - val_accuracy: 0.6412\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 826.7237 - accuracy: 0.6893 - val_loss: 740.7857 - val_accuracy: 0.6616\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 837.5905 - accuracy: 0.6951 - val_loss: 716.9828 - val_accuracy: 0.6372\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 825.0430 - accuracy: 0.7039 - val_loss: 720.3766 - val_accuracy: 0.6416\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 818.1523 - accuracy: 0.6949 - val_loss: 725.4629 - val_accuracy: 0.6424\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 815.9681 - accuracy: 0.7013 - val_loss: 720.5729 - val_accuracy: 0.6446\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 816.4526 - accuracy: 0.7045 - val_loss: 718.5170 - val_accuracy: 0.6512\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 818.3018 - accuracy: 0.6994 - val_loss: 724.6796 - val_accuracy: 0.6493\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 815.5603 - accuracy: 0.7052 - val_loss: 724.3843 - val_accuracy: 0.6205\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 814.5345 - accuracy: 0.6981 - val_loss: 718.2032 - val_accuracy: 0.6406\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.6470 - accuracy: 0.6985 - val_loss: 731.0839 - val_accuracy: 0.6356\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 821.0168 - accuracy: 0.6995 - val_loss: 725.6800 - val_accuracy: 0.6355\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 819.3431 - accuracy: 0.7021 - val_loss: 723.4443 - val_accuracy: 0.6332\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 817.2656 - accuracy: 0.7029 - val_loss: 716.8121 - val_accuracy: 0.6336\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 815.9871 - accuracy: 0.6928 - val_loss: 715.1783 - val_accuracy: 0.6591\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 816.7138 - accuracy: 0.7056 - val_loss: 710.9934 - val_accuracy: 0.6248\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 819.2451 - accuracy: 0.6891 - val_loss: 726.0441 - val_accuracy: 0.6550\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 820.2719 - accuracy: 0.7049 - val_loss: 714.5021 - val_accuracy: 0.6466\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 815.8331 - accuracy: 0.7070 - val_loss: 723.9048 - val_accuracy: 0.6290\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 824.2751 - accuracy: 0.6882 - val_loss: 722.7167 - val_accuracy: 0.6656\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 819.5651 - accuracy: 0.6998 - val_loss: 720.5932 - val_accuracy: 0.6378\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 814.8768 - accuracy: 0.6991 - val_loss: 726.7313 - val_accuracy: 0.6348\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 814.2796 - accuracy: 0.7036 - val_loss: 723.7559 - val_accuracy: 0.6500\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 815.1805 - accuracy: 0.7051 - val_loss: 715.4278 - val_accuracy: 0.6534\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 812.8181 - accuracy: 0.7014 - val_loss: 721.7751 - val_accuracy: 0.6405\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 813.7247 - accuracy: 0.6997 - val_loss: 720.4554 - val_accuracy: 0.6481\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 816.4275 - accuracy: 0.7008 - val_loss: 718.0640 - val_accuracy: 0.6596\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 816.1781 - accuracy: 0.7030 - val_loss: 724.9831 - val_accuracy: 0.6188\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 828.0287 - accuracy: 0.6915 - val_loss: 726.2227 - val_accuracy: 0.6532\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 830.8881 - accuracy: 0.6963 - val_loss: 719.2629 - val_accuracy: 0.6430\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 822.4965 - accuracy: 0.6926 - val_loss: 719.2386 - val_accuracy: 0.6364\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 819.1190 - accuracy: 0.6901 - val_loss: 721.6504 - val_accuracy: 0.6620\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 817.4808 - accuracy: 0.7080 - val_loss: 712.9608 - val_accuracy: 0.6398\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 816.8287 - accuracy: 0.6977 - val_loss: 727.1778 - val_accuracy: 0.6401\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 815.2449 - accuracy: 0.7031 - val_loss: 718.8551 - val_accuracy: 0.6525\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 822.3845 - accuracy: 0.7086 - val_loss: 716.1913 - val_accuracy: 0.6443\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 821.8384 - accuracy: 0.6937 - val_loss: 743.8469 - val_accuracy: 0.6426\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 833.0891 - accuracy: 0.6980 - val_loss: 727.0602 - val_accuracy: 0.6532\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 827.5099 - accuracy: 0.7016 - val_loss: 739.3604 - val_accuracy: 0.6368\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 825.2379 - accuracy: 0.6922 - val_loss: 726.8728 - val_accuracy: 0.6295\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 814.9258 - accuracy: 0.7080 - val_loss: 722.7668 - val_accuracy: 0.6558\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 817.6985 - accuracy: 0.7054 - val_loss: 739.5807 - val_accuracy: 0.6232\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 817.2597 - accuracy: 0.6993 - val_loss: 717.8965 - val_accuracy: 0.6533\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 816.2465 - accuracy: 0.7046 - val_loss: 722.8181 - val_accuracy: 0.6422\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 818.7880 - accuracy: 0.6944 - val_loss: 723.3674 - val_accuracy: 0.6614\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 818.8909 - accuracy: 0.7058 - val_loss: 719.0054 - val_accuracy: 0.6290\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.0211 - accuracy: 0.6935 - val_loss: 735.6791 - val_accuracy: 0.6411\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 835.0240 - accuracy: 0.7000 - val_loss: 724.0767 - val_accuracy: 0.6622\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 842.7092 - accuracy: 0.7042 - val_loss: 730.7021 - val_accuracy: 0.6490\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 839.5984 - accuracy: 0.7020 - val_loss: 730.9496 - val_accuracy: 0.6272\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 820.9644 - accuracy: 0.6956 - val_loss: 722.1807 - val_accuracy: 0.6279\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 817.7787 - accuracy: 0.6962 - val_loss: 717.9732 - val_accuracy: 0.6477\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 814.7177 - accuracy: 0.7007 - val_loss: 714.6176 - val_accuracy: 0.6362\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 815.2488 - accuracy: 0.6956 - val_loss: 726.0812 - val_accuracy: 0.6346\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 816.3695 - accuracy: 0.6956 - val_loss: 724.3056 - val_accuracy: 0.6498\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 818.5304 - accuracy: 0.7018 - val_loss: 709.4276 - val_accuracy: 0.6508\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 814.0101 - accuracy: 0.7056 - val_loss: 719.3382 - val_accuracy: 0.6311\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.2586 - accuracy: 0.6986 - val_loss: 725.9211 - val_accuracy: 0.6499\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 820.2624 - accuracy: 0.7048 - val_loss: 728.2298 - val_accuracy: 0.6403\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 834.5312 - accuracy: 0.7005 - val_loss: 737.9110 - val_accuracy: 0.6446\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 819.3958 - accuracy: 0.6994 - val_loss: 717.5425 - val_accuracy: 0.6462\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 823.6635 - accuracy: 0.6985 - val_loss: 729.9551 - val_accuracy: 0.6418\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 817.9147 - accuracy: 0.6989 - val_loss: 725.9664 - val_accuracy: 0.6340\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 816.7338 - accuracy: 0.7018 - val_loss: 719.2108 - val_accuracy: 0.6423\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 817.1476 - accuracy: 0.6957 - val_loss: 725.0697 - val_accuracy: 0.6410\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 812.9675 - accuracy: 0.7046 - val_loss: 711.4360 - val_accuracy: 0.6456\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 818.9650 - accuracy: 0.7060 - val_loss: 713.7944 - val_accuracy: 0.6480\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 821.3959 - accuracy: 0.6969 - val_loss: 721.4467 - val_accuracy: 0.6313\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 813.0446 - accuracy: 0.6929 - val_loss: 718.5854 - val_accuracy: 0.6324\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 812.6931 - accuracy: 0.7044 - val_loss: 710.8519 - val_accuracy: 0.6530\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 813.1329 - accuracy: 0.7009 - val_loss: 714.2994 - val_accuracy: 0.6533\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 814.8544 - accuracy: 0.7013 - val_loss: 715.9653 - val_accuracy: 0.6437\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 815.2266 - accuracy: 0.7008 - val_loss: 721.5527 - val_accuracy: 0.6577\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 815.3793 - accuracy: 0.7068 - val_loss: 711.8940 - val_accuracy: 0.6460\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 811.3317 - accuracy: 0.7064 - val_loss: 710.2833 - val_accuracy: 0.6438\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 1s 68ms/step - loss: 813.8639 - accuracy: 0.7019 - val_loss: 713.2767 - val_accuracy: 0.6463\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 813.6110 - accuracy: 0.7004 - val_loss: 723.2383 - val_accuracy: 0.6296\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 1s 76ms/step - loss: 843.0441 - accuracy: 0.6907 - val_loss: 757.8528 - val_accuracy: 0.6387\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 1s 72ms/step - loss: 848.6272 - accuracy: 0.6940 - val_loss: 737.3989 - val_accuracy: 0.6364\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 1s 65ms/step - loss: 834.8597 - accuracy: 0.6948 - val_loss: 742.1760 - val_accuracy: 0.6249\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 831.7927 - accuracy: 0.6835 - val_loss: 734.6313 - val_accuracy: 0.6635\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 832.2029 - accuracy: 0.6943 - val_loss: 708.7673 - val_accuracy: 0.6679\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 827.7442 - accuracy: 0.7031 - val_loss: 730.7271 - val_accuracy: 0.6419\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 1s 69ms/step - loss: 836.7711 - accuracy: 0.6925 - val_loss: 746.3935 - val_accuracy: 0.6526\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 879.5261 - accuracy: 0.7009 - val_loss: 758.4059 - val_accuracy: 0.6507\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 859.1914 - accuracy: 0.7027 - val_loss: 731.2224 - val_accuracy: 0.6408\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 829.6822 - accuracy: 0.6902 - val_loss: 733.1578 - val_accuracy: 0.6487\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.8040 - accuracy: 0.7057 - val_loss: 727.1926 - val_accuracy: 0.6428\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 818.2042 - accuracy: 0.6990 - val_loss: 717.1938 - val_accuracy: 0.6421\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 816.7457 - accuracy: 0.7022 - val_loss: 715.7548 - val_accuracy: 0.6468\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 814.3312 - accuracy: 0.7086 - val_loss: 719.2803 - val_accuracy: 0.6380\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 812.2089 - accuracy: 0.6983 - val_loss: 713.7369 - val_accuracy: 0.6467\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 811.4712 - accuracy: 0.7046 - val_loss: 714.8529 - val_accuracy: 0.6646\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 811.6528 - accuracy: 0.7048 - val_loss: 717.2231 - val_accuracy: 0.6509\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 813.7285 - accuracy: 0.7095 - val_loss: 716.9105 - val_accuracy: 0.6381\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 813.8533 - accuracy: 0.7074 - val_loss: 715.1685 - val_accuracy: 0.6345\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 811.8873 - accuracy: 0.7000 - val_loss: 724.3515 - val_accuracy: 0.6450\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 812.8979 - accuracy: 0.7071 - val_loss: 725.1303 - val_accuracy: 0.6218\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 816.8222 - accuracy: 0.7026 - val_loss: 716.8007 - val_accuracy: 0.6459\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 814.2860 - accuracy: 0.6991 - val_loss: 723.7588 - val_accuracy: 0.6437\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 813.0234 - accuracy: 0.6983 - val_loss: 716.6599 - val_accuracy: 0.6579\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 813.6341 - accuracy: 0.6978 - val_loss: 721.1541 - val_accuracy: 0.6420\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 812.3088 - accuracy: 0.7119 - val_loss: 709.6090 - val_accuracy: 0.6442\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 814.9772 - accuracy: 0.6981 - val_loss: 715.8612 - val_accuracy: 0.6503\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 816.7011 - accuracy: 0.7078 - val_loss: 712.4219 - val_accuracy: 0.6508\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 818.2657 - accuracy: 0.7069 - val_loss: 722.1003 - val_accuracy: 0.6544\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 815.0298 - accuracy: 0.7057 - val_loss: 720.5214 - val_accuracy: 0.6461\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 812.9268 - accuracy: 0.7013 - val_loss: 715.7808 - val_accuracy: 0.6556\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 826.5545 - accuracy: 0.7041 - val_loss: 735.2673 - val_accuracy: 0.6442\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 840.8349 - accuracy: 0.7007 - val_loss: 722.9193 - val_accuracy: 0.6538\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 819.9700 - accuracy: 0.6988 - val_loss: 721.7578 - val_accuracy: 0.6585\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 817.5439 - accuracy: 0.7089 - val_loss: 708.0343 - val_accuracy: 0.6367\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 813.2277 - accuracy: 0.7041 - val_loss: 717.7934 - val_accuracy: 0.6506\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 813.5314 - accuracy: 0.7012 - val_loss: 719.5550 - val_accuracy: 0.6575\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 811.7538 - accuracy: 0.7057 - val_loss: 710.6819 - val_accuracy: 0.6557\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 809.9768 - accuracy: 0.7024 - val_loss: 716.2872 - val_accuracy: 0.6492\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 808.5746 - accuracy: 0.7022 - val_loss: 714.5791 - val_accuracy: 0.6508\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 808.3139 - accuracy: 0.7076 - val_loss: 713.8870 - val_accuracy: 0.6385\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 811.4009 - accuracy: 0.6947 - val_loss: 725.3771 - val_accuracy: 0.6567\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 812.9184 - accuracy: 0.7027 - val_loss: 715.1451 - val_accuracy: 0.6356\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 819.7433 - accuracy: 0.7025 - val_loss: 727.8419 - val_accuracy: 0.6507\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 833.4848 - accuracy: 0.6944 - val_loss: 734.9984 - val_accuracy: 0.6495\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 825.2116 - accuracy: 0.7021 - val_loss: 720.6640 - val_accuracy: 0.6258\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 839.3817 - accuracy: 0.6947 - val_loss: 800.3945 - val_accuracy: 0.6657\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 863.3088 - accuracy: 0.6986 - val_loss: 751.8234 - val_accuracy: 0.6105\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 839.6500 - accuracy: 0.6910 - val_loss: 728.7479 - val_accuracy: 0.6553\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 829.8661 - accuracy: 0.6880 - val_loss: 733.6594 - val_accuracy: 0.6219\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 817.6188 - accuracy: 0.6981 - val_loss: 713.1697 - val_accuracy: 0.6511\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 816.9433 - accuracy: 0.7081 - val_loss: 717.5897 - val_accuracy: 0.6482\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 820.5154 - accuracy: 0.6940 - val_loss: 724.3925 - val_accuracy: 0.6530\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 824.0826 - accuracy: 0.7064 - val_loss: 712.5978 - val_accuracy: 0.6530\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 821.2702 - accuracy: 0.6977 - val_loss: 720.3423 - val_accuracy: 0.6528\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 818.0751 - accuracy: 0.7031 - val_loss: 720.1918 - val_accuracy: 0.6490\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 812.2092 - accuracy: 0.7002 - val_loss: 716.7075 - val_accuracy: 0.6495\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 809.1879 - accuracy: 0.6992 - val_loss: 720.6192 - val_accuracy: 0.6352\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 810.0455 - accuracy: 0.7022 - val_loss: 715.9410 - val_accuracy: 0.6375\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 808.2255 - accuracy: 0.6971 - val_loss: 723.8345 - val_accuracy: 0.6377\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 809.8739 - accuracy: 0.7021 - val_loss: 706.8788 - val_accuracy: 0.6541\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 810.2437 - accuracy: 0.7019 - val_loss: 716.3703 - val_accuracy: 0.6498\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 813.0980 - accuracy: 0.7041 - val_loss: 717.5834 - val_accuracy: 0.6212\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 811.5035 - accuracy: 0.6974 - val_loss: 718.2490 - val_accuracy: 0.6409\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample1)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer1)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "conv3 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool2)\n",
        "pool3 = layers.MaxPooling2D(pool_size=(1, 1))(conv3)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool3)\n",
        "\n",
        "# Define the convolutional layer\n",
        "#conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(input_layer1)\n",
        "upsample = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv4 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer2)\n",
        "pool4 = layers.MaxPooling2D(pool_size=(1, 1))(conv4)\n",
        "conv5 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool4)\n",
        "pool5 = layers.MaxPooling2D(pool_size=(1, 1))(conv5)\n",
        "conv6 = layers.Conv2D(64, kernel_size=1, activation='relu')(pool5)\n",
        "pool6 = layers.MaxPooling2D(pool_size=(1, 1))(conv6)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool6)\n",
        "# Define the output layer\n",
        "output_layer = layers.Add()([output_layer1, output_layer2 ])\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=32, validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOBNehcc0vaK",
        "outputId": "b8c4425f-b58e-4052-f98f-361a8efe75a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 7336.6611 - accuracy: 0.0053 - val_loss: 4332.5396 - val_accuracy: 0.0018\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 4839.1943 - accuracy: 0.0661 - val_loss: 3089.6382 - val_accuracy: 0.3085\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 3614.6421 - accuracy: 0.1013 - val_loss: 2495.3254 - val_accuracy: 0.0570\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 2755.1128 - accuracy: 0.0600 - val_loss: 2200.3069 - val_accuracy: 0.2202\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 2218.6594 - accuracy: 0.2936 - val_loss: 1649.9731 - val_accuracy: 0.5607\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1819.8262 - accuracy: 0.3101 - val_loss: 1326.4569 - val_accuracy: 0.4967\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1583.9790 - accuracy: 0.3482 - val_loss: 1154.9421 - val_accuracy: 0.6260\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1455.9591 - accuracy: 0.3519 - val_loss: 1058.3245 - val_accuracy: 0.5624\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1379.4745 - accuracy: 0.4832 - val_loss: 1011.4911 - val_accuracy: 0.6194\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1339.5292 - accuracy: 0.4578 - val_loss: 962.3203 - val_accuracy: 0.5286\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1300.6685 - accuracy: 0.4335 - val_loss: 932.3483 - val_accuracy: 0.5794\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1267.1438 - accuracy: 0.5003 - val_loss: 912.9393 - val_accuracy: 0.6265\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1242.7744 - accuracy: 0.5903 - val_loss: 901.0231 - val_accuracy: 0.6455\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1231.3936 - accuracy: 0.5886 - val_loss: 871.9756 - val_accuracy: 0.6986\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1215.1110 - accuracy: 0.6087 - val_loss: 872.8179 - val_accuracy: 0.6633\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1200.3972 - accuracy: 0.6026 - val_loss: 854.7363 - val_accuracy: 0.6882\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1189.6404 - accuracy: 0.6105 - val_loss: 850.9885 - val_accuracy: 0.6734\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1176.3401 - accuracy: 0.6267 - val_loss: 835.3865 - val_accuracy: 0.6939\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1162.1458 - accuracy: 0.6263 - val_loss: 835.4296 - val_accuracy: 0.7061\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1154.2761 - accuracy: 0.6193 - val_loss: 829.9818 - val_accuracy: 0.6871\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1146.3850 - accuracy: 0.6415 - val_loss: 823.0699 - val_accuracy: 0.7383\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1136.9286 - accuracy: 0.6417 - val_loss: 810.4344 - val_accuracy: 0.6841\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1072.8496 - accuracy: 0.6350 - val_loss: 715.1731 - val_accuracy: 0.6942\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 955.4528 - accuracy: 0.6311 - val_loss: 713.1261 - val_accuracy: 0.6953\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 930.8138 - accuracy: 0.6379 - val_loss: 715.6399 - val_accuracy: 0.7495\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 906.5753 - accuracy: 0.6555 - val_loss: 685.6793 - val_accuracy: 0.7255\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 896.4001 - accuracy: 0.6600 - val_loss: 682.7455 - val_accuracy: 0.7116\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 886.7818 - accuracy: 0.6512 - val_loss: 676.4517 - val_accuracy: 0.7523\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 884.2916 - accuracy: 0.6467 - val_loss: 669.8082 - val_accuracy: 0.7434\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 880.9673 - accuracy: 0.6665 - val_loss: 669.5823 - val_accuracy: 0.7201\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 878.3478 - accuracy: 0.6621 - val_loss: 663.3005 - val_accuracy: 0.7378\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 873.1605 - accuracy: 0.6695 - val_loss: 661.7711 - val_accuracy: 0.7362\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 868.1644 - accuracy: 0.6620 - val_loss: 667.2637 - val_accuracy: 0.7377\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 869.7253 - accuracy: 0.6786 - val_loss: 659.8064 - val_accuracy: 0.7602\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 869.8826 - accuracy: 0.6743 - val_loss: 665.5216 - val_accuracy: 0.7554\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 868.8119 - accuracy: 0.6749 - val_loss: 658.5914 - val_accuracy: 0.7566\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 868.7247 - accuracy: 0.6751 - val_loss: 656.9101 - val_accuracy: 0.7449\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 866.0313 - accuracy: 0.6799 - val_loss: 657.7001 - val_accuracy: 0.7386\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 858.6218 - accuracy: 0.6757 - val_loss: 653.8873 - val_accuracy: 0.7623\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 858.5078 - accuracy: 0.6872 - val_loss: 649.0789 - val_accuracy: 0.7509\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 854.6597 - accuracy: 0.6887 - val_loss: 649.5557 - val_accuracy: 0.7570\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 853.2235 - accuracy: 0.6811 - val_loss: 651.6300 - val_accuracy: 0.7678\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 851.1511 - accuracy: 0.6957 - val_loss: 646.2562 - val_accuracy: 0.7666\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 845.2141 - accuracy: 0.6867 - val_loss: 653.4384 - val_accuracy: 0.7260\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 854.8887 - accuracy: 0.6916 - val_loss: 643.6324 - val_accuracy: 0.7667\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 855.6556 - accuracy: 0.6886 - val_loss: 652.4670 - val_accuracy: 0.7627\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 845.7726 - accuracy: 0.6873 - val_loss: 648.5645 - val_accuracy: 0.7750\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 848.1904 - accuracy: 0.6898 - val_loss: 641.4864 - val_accuracy: 0.7609\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 844.5337 - accuracy: 0.6941 - val_loss: 645.9662 - val_accuracy: 0.7736\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 843.9765 - accuracy: 0.7000 - val_loss: 645.5758 - val_accuracy: 0.7639\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 844.8088 - accuracy: 0.6954 - val_loss: 652.0380 - val_accuracy: 0.7722\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 850.8645 - accuracy: 0.6990 - val_loss: 637.7510 - val_accuracy: 0.7532\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 834.7514 - accuracy: 0.6961 - val_loss: 638.1055 - val_accuracy: 0.7669\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 839.2666 - accuracy: 0.6985 - val_loss: 640.1609 - val_accuracy: 0.7785\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 832.9566 - accuracy: 0.6961 - val_loss: 638.6479 - val_accuracy: 0.7627\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 830.2789 - accuracy: 0.6933 - val_loss: 636.2034 - val_accuracy: 0.7622\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 830.4073 - accuracy: 0.7008 - val_loss: 634.8431 - val_accuracy: 0.7590\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 829.4028 - accuracy: 0.6996 - val_loss: 640.9568 - val_accuracy: 0.7738\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 830.5865 - accuracy: 0.7038 - val_loss: 632.9991 - val_accuracy: 0.7717\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 830.2638 - accuracy: 0.6959 - val_loss: 643.1487 - val_accuracy: 0.7662\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 840.2741 - accuracy: 0.7001 - val_loss: 639.0904 - val_accuracy: 0.7742\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 826.6633 - accuracy: 0.6961 - val_loss: 631.3680 - val_accuracy: 0.7697\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 820.3450 - accuracy: 0.7067 - val_loss: 628.6063 - val_accuracy: 0.7765\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 820.7812 - accuracy: 0.7071 - val_loss: 628.5493 - val_accuracy: 0.7735\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 822.4359 - accuracy: 0.6954 - val_loss: 627.3981 - val_accuracy: 0.7671\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 817.9105 - accuracy: 0.7064 - val_loss: 628.9894 - val_accuracy: 0.7719\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 816.7953 - accuracy: 0.7081 - val_loss: 627.5656 - val_accuracy: 0.7727\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 817.2360 - accuracy: 0.7020 - val_loss: 633.9729 - val_accuracy: 0.7764\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 816.7393 - accuracy: 0.6963 - val_loss: 627.2117 - val_accuracy: 0.7772\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 817.2344 - accuracy: 0.6937 - val_loss: 626.6565 - val_accuracy: 0.7740\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 817.0575 - accuracy: 0.7024 - val_loss: 630.3168 - val_accuracy: 0.7748\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 812.7037 - accuracy: 0.6978 - val_loss: 624.3542 - val_accuracy: 0.7753\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 812.5330 - accuracy: 0.7057 - val_loss: 623.8089 - val_accuracy: 0.7669\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 811.1805 - accuracy: 0.7013 - val_loss: 623.7471 - val_accuracy: 0.7759\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 812.0405 - accuracy: 0.7066 - val_loss: 625.9616 - val_accuracy: 0.7750\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 808.8250 - accuracy: 0.6946 - val_loss: 631.5583 - val_accuracy: 0.7754\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 815.1232 - accuracy: 0.7030 - val_loss: 625.6441 - val_accuracy: 0.7695\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 813.8822 - accuracy: 0.7014 - val_loss: 629.4546 - val_accuracy: 0.7741\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 810.9130 - accuracy: 0.6988 - val_loss: 623.0997 - val_accuracy: 0.7791\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 805.1957 - accuracy: 0.7025 - val_loss: 619.4507 - val_accuracy: 0.7727\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 805.5582 - accuracy: 0.6996 - val_loss: 624.9317 - val_accuracy: 0.7745\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 808.8925 - accuracy: 0.7013 - val_loss: 628.7018 - val_accuracy: 0.7759\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 813.8159 - accuracy: 0.6971 - val_loss: 655.7989 - val_accuracy: 0.7543\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 847.2484 - accuracy: 0.7010 - val_loss: 645.9800 - val_accuracy: 0.7746\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 822.8503 - accuracy: 0.7008 - val_loss: 642.6124 - val_accuracy: 0.7741\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 829.5835 - accuracy: 0.6948 - val_loss: 637.2485 - val_accuracy: 0.7702\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 816.8330 - accuracy: 0.7032 - val_loss: 622.3654 - val_accuracy: 0.7834\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 809.7488 - accuracy: 0.7070 - val_loss: 624.5925 - val_accuracy: 0.7745\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 801.9007 - accuracy: 0.7037 - val_loss: 619.6021 - val_accuracy: 0.7788\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 802.3853 - accuracy: 0.7034 - val_loss: 634.5381 - val_accuracy: 0.7758\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 815.3762 - accuracy: 0.6980 - val_loss: 647.1010 - val_accuracy: 0.7753\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 814.4662 - accuracy: 0.6964 - val_loss: 620.3121 - val_accuracy: 0.7798\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 803.0641 - accuracy: 0.7072 - val_loss: 621.3284 - val_accuracy: 0.7738\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 799.3411 - accuracy: 0.6985 - val_loss: 617.4600 - val_accuracy: 0.7794\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 794.0935 - accuracy: 0.7033 - val_loss: 613.8646 - val_accuracy: 0.7799\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 792.6816 - accuracy: 0.7083 - val_loss: 614.3226 - val_accuracy: 0.7795\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 795.9239 - accuracy: 0.7097 - val_loss: 617.9239 - val_accuracy: 0.7759\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 799.7372 - accuracy: 0.7002 - val_loss: 616.3234 - val_accuracy: 0.7834\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 796.6179 - accuracy: 0.7038 - val_loss: 615.5413 - val_accuracy: 0.7757\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 792.7412 - accuracy: 0.7129 - val_loss: 619.0170 - val_accuracy: 0.7687\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 794.9649 - accuracy: 0.7055 - val_loss: 628.7276 - val_accuracy: 0.7847\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 797.6970 - accuracy: 0.6972 - val_loss: 624.3438 - val_accuracy: 0.7746\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 801.0884 - accuracy: 0.7029 - val_loss: 640.0830 - val_accuracy: 0.7775\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 801.4425 - accuracy: 0.7061 - val_loss: 621.7859 - val_accuracy: 0.7804\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 795.7352 - accuracy: 0.7101 - val_loss: 619.9554 - val_accuracy: 0.7807\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 792.8516 - accuracy: 0.6982 - val_loss: 624.1569 - val_accuracy: 0.7745\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 793.7137 - accuracy: 0.7082 - val_loss: 625.6140 - val_accuracy: 0.7774\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 791.2048 - accuracy: 0.7109 - val_loss: 614.1644 - val_accuracy: 0.7842\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 788.9933 - accuracy: 0.7052 - val_loss: 617.1204 - val_accuracy: 0.7859\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 787.7031 - accuracy: 0.7071 - val_loss: 614.0408 - val_accuracy: 0.7891\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 788.2395 - accuracy: 0.7051 - val_loss: 624.8346 - val_accuracy: 0.7807\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 791.6370 - accuracy: 0.7130 - val_loss: 616.8886 - val_accuracy: 0.7797\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 787.5172 - accuracy: 0.7044 - val_loss: 609.6172 - val_accuracy: 0.7817\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.6763 - accuracy: 0.7115 - val_loss: 610.1865 - val_accuracy: 0.7826\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.1416 - accuracy: 0.7122 - val_loss: 613.1690 - val_accuracy: 0.7859\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 783.5479 - accuracy: 0.7063 - val_loss: 610.5742 - val_accuracy: 0.7815\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.4937 - accuracy: 0.7131 - val_loss: 613.9370 - val_accuracy: 0.7817\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.6882 - accuracy: 0.7096 - val_loss: 621.4644 - val_accuracy: 0.7846\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 790.7582 - accuracy: 0.7045 - val_loss: 616.6903 - val_accuracy: 0.7875\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 790.4615 - accuracy: 0.7025 - val_loss: 612.4248 - val_accuracy: 0.7849\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 788.0886 - accuracy: 0.7139 - val_loss: 616.0051 - val_accuracy: 0.7877\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 783.4451 - accuracy: 0.7088 - val_loss: 606.7318 - val_accuracy: 0.7806\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 781.4249 - accuracy: 0.7039 - val_loss: 613.5528 - val_accuracy: 0.7818\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.9156 - accuracy: 0.7096 - val_loss: 612.3341 - val_accuracy: 0.7832\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 782.2513 - accuracy: 0.7093 - val_loss: 614.8493 - val_accuracy: 0.7852\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 787.2880 - accuracy: 0.7125 - val_loss: 631.8917 - val_accuracy: 0.7861\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 796.8243 - accuracy: 0.7091 - val_loss: 626.3199 - val_accuracy: 0.7836\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 787.7389 - accuracy: 0.7085 - val_loss: 611.2215 - val_accuracy: 0.7917\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 784.0984 - accuracy: 0.7109 - val_loss: 610.3962 - val_accuracy: 0.7862\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 781.3130 - accuracy: 0.7072 - val_loss: 613.7426 - val_accuracy: 0.7884\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 779.1825 - accuracy: 0.7135 - val_loss: 612.1404 - val_accuracy: 0.7777\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 781.1467 - accuracy: 0.7145 - val_loss: 615.5839 - val_accuracy: 0.7829\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 780.3788 - accuracy: 0.7066 - val_loss: 609.3055 - val_accuracy: 0.7852\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.1476 - accuracy: 0.7049 - val_loss: 609.2396 - val_accuracy: 0.7831\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 778.8258 - accuracy: 0.7143 - val_loss: 609.3392 - val_accuracy: 0.7866\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 779.1371 - accuracy: 0.7109 - val_loss: 606.9515 - val_accuracy: 0.7883\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.4344 - accuracy: 0.7106 - val_loss: 610.5246 - val_accuracy: 0.7848\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 783.4610 - accuracy: 0.7116 - val_loss: 613.2731 - val_accuracy: 0.7816\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.9861 - accuracy: 0.7130 - val_loss: 611.5538 - val_accuracy: 0.7821\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 777.8078 - accuracy: 0.7109 - val_loss: 611.7448 - val_accuracy: 0.7856\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 777.7276 - accuracy: 0.7054 - val_loss: 610.1165 - val_accuracy: 0.7909\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 780.5423 - accuracy: 0.7158 - val_loss: 607.3476 - val_accuracy: 0.7840\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.5064 - accuracy: 0.7119 - val_loss: 608.9230 - val_accuracy: 0.7838\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.1885 - accuracy: 0.7107 - val_loss: 607.1050 - val_accuracy: 0.7930\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 777.8411 - accuracy: 0.7076 - val_loss: 614.1915 - val_accuracy: 0.7884\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.7015 - accuracy: 0.7141 - val_loss: 610.6466 - val_accuracy: 0.7876\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 775.7001 - accuracy: 0.7097 - val_loss: 610.5693 - val_accuracy: 0.7851\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 785.2664 - accuracy: 0.7107 - val_loss: 619.3143 - val_accuracy: 0.7881\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 779.8135 - accuracy: 0.7124 - val_loss: 606.9646 - val_accuracy: 0.7841\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 785.4128 - accuracy: 0.7087 - val_loss: 612.8180 - val_accuracy: 0.7822\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 793.6748 - accuracy: 0.7135 - val_loss: 611.8961 - val_accuracy: 0.7877\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 782.6896 - accuracy: 0.7022 - val_loss: 612.4358 - val_accuracy: 0.7834\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 780.7979 - accuracy: 0.7119 - val_loss: 609.3115 - val_accuracy: 0.7904\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 782.7037 - accuracy: 0.7054 - val_loss: 605.1890 - val_accuracy: 0.7873\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 776.3108 - accuracy: 0.7107 - val_loss: 611.6718 - val_accuracy: 0.7892\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 777.5228 - accuracy: 0.7150 - val_loss: 606.5988 - val_accuracy: 0.7882\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 775.4258 - accuracy: 0.7108 - val_loss: 605.8895 - val_accuracy: 0.7868\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 773.2932 - accuracy: 0.7141 - val_loss: 603.6119 - val_accuracy: 0.7867\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 773.2498 - accuracy: 0.7133 - val_loss: 604.9341 - val_accuracy: 0.7835\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 772.4924 - accuracy: 0.7131 - val_loss: 606.1241 - val_accuracy: 0.7895\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 776.2316 - accuracy: 0.7133 - val_loss: 606.7751 - val_accuracy: 0.7861\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.9813 - accuracy: 0.7120 - val_loss: 614.7408 - val_accuracy: 0.7906\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 793.1439 - accuracy: 0.7140 - val_loss: 614.4819 - val_accuracy: 0.7877\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 781.2100 - accuracy: 0.7109 - val_loss: 607.2311 - val_accuracy: 0.7825\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 772.8921 - accuracy: 0.7062 - val_loss: 606.7676 - val_accuracy: 0.7882\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.3712 - accuracy: 0.7111 - val_loss: 605.6438 - val_accuracy: 0.7880\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 773.1761 - accuracy: 0.7147 - val_loss: 608.2795 - val_accuracy: 0.7883\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 787.7841 - accuracy: 0.7144 - val_loss: 618.2181 - val_accuracy: 0.7893\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.2504 - accuracy: 0.7128 - val_loss: 605.8321 - val_accuracy: 0.7904\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 771.8524 - accuracy: 0.7116 - val_loss: 609.6668 - val_accuracy: 0.7897\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 774.3676 - accuracy: 0.7071 - val_loss: 608.7003 - val_accuracy: 0.7915\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 775.6149 - accuracy: 0.7095 - val_loss: 608.0010 - val_accuracy: 0.7906\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 773.4535 - accuracy: 0.7175 - val_loss: 603.8613 - val_accuracy: 0.7923\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 770.8984 - accuracy: 0.7114 - val_loss: 610.2507 - val_accuracy: 0.7835\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 772.8308 - accuracy: 0.7153 - val_loss: 606.2241 - val_accuracy: 0.7860\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 776.1362 - accuracy: 0.7130 - val_loss: 624.3528 - val_accuracy: 0.7902\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 778.2620 - accuracy: 0.7078 - val_loss: 622.3900 - val_accuracy: 0.7893\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 808.5162 - accuracy: 0.7054 - val_loss: 609.0413 - val_accuracy: 0.7906\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 821.8545 - accuracy: 0.7032 - val_loss: 660.7719 - val_accuracy: 0.7893\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 812.3291 - accuracy: 0.7084 - val_loss: 647.1493 - val_accuracy: 0.7626\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 796.4650 - accuracy: 0.7095 - val_loss: 611.5411 - val_accuracy: 0.7899\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.2831 - accuracy: 0.7139 - val_loss: 606.8818 - val_accuracy: 0.7821\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.3022 - accuracy: 0.7126 - val_loss: 603.8246 - val_accuracy: 0.7909\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.4446 - accuracy: 0.7094 - val_loss: 606.0974 - val_accuracy: 0.7867\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 768.4597 - accuracy: 0.7129 - val_loss: 604.6157 - val_accuracy: 0.7888\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.2621 - accuracy: 0.7122 - val_loss: 609.3931 - val_accuracy: 0.7832\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 769.6982 - accuracy: 0.7129 - val_loss: 601.9487 - val_accuracy: 0.7881\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.1331 - accuracy: 0.7163 - val_loss: 603.0488 - val_accuracy: 0.7944\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 770.9862 - accuracy: 0.7123 - val_loss: 602.5391 - val_accuracy: 0.7882\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 768.5754 - accuracy: 0.7099 - val_loss: 605.1321 - val_accuracy: 0.7912\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 772.8818 - accuracy: 0.7062 - val_loss: 610.8985 - val_accuracy: 0.7866\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.4361 - accuracy: 0.7112 - val_loss: 608.6915 - val_accuracy: 0.7908\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.3711 - accuracy: 0.7127 - val_loss: 600.7103 - val_accuracy: 0.7898\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 768.8508 - accuracy: 0.7083 - val_loss: 606.8193 - val_accuracy: 0.7919\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 768.4783 - accuracy: 0.7112 - val_loss: 602.7538 - val_accuracy: 0.7913\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.2961 - accuracy: 0.7124 - val_loss: 602.9520 - val_accuracy: 0.7911\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.7856 - accuracy: 0.7103 - val_loss: 602.2167 - val_accuracy: 0.7908\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.2681 - accuracy: 0.7129 - val_loss: 609.7702 - val_accuracy: 0.7874\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 769.4694 - accuracy: 0.7089 - val_loss: 605.5800 - val_accuracy: 0.7961\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 767.8860 - accuracy: 0.7161 - val_loss: 602.9102 - val_accuracy: 0.7897\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.1898 - accuracy: 0.7088 - val_loss: 602.3512 - val_accuracy: 0.7870\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.1861 - accuracy: 0.7133 - val_loss: 603.7815 - val_accuracy: 0.7958\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.8851 - accuracy: 0.7124 - val_loss: 601.0924 - val_accuracy: 0.7925\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 765.1970 - accuracy: 0.7179 - val_loss: 599.5165 - val_accuracy: 0.7923\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.5802 - accuracy: 0.7128 - val_loss: 603.2688 - val_accuracy: 0.7869\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 766.9159 - accuracy: 0.7171 - val_loss: 606.0126 - val_accuracy: 0.7873\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.2272 - accuracy: 0.7088 - val_loss: 607.5536 - val_accuracy: 0.7906\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.9307 - accuracy: 0.7146 - val_loss: 601.6894 - val_accuracy: 0.7927\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.7748 - accuracy: 0.7141 - val_loss: 598.5889 - val_accuracy: 0.7908\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 767.9453 - accuracy: 0.7183 - val_loss: 610.2570 - val_accuracy: 0.7951\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 765.4990 - accuracy: 0.7117 - val_loss: 601.7464 - val_accuracy: 0.7931\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 764.2138 - accuracy: 0.7192 - val_loss: 607.9275 - val_accuracy: 0.7902\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.5886 - accuracy: 0.7121 - val_loss: 600.8854 - val_accuracy: 0.7937\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.7002 - accuracy: 0.7120 - val_loss: 601.4585 - val_accuracy: 0.7960\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.3759 - accuracy: 0.7168 - val_loss: 604.7665 - val_accuracy: 0.7924\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.8533 - accuracy: 0.7127 - val_loss: 600.2318 - val_accuracy: 0.7943\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.5983 - accuracy: 0.7064 - val_loss: 607.3923 - val_accuracy: 0.7922\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.5989 - accuracy: 0.7123 - val_loss: 603.7327 - val_accuracy: 0.7962\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.2673 - accuracy: 0.7147 - val_loss: 601.1793 - val_accuracy: 0.7957\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.9765 - accuracy: 0.7175 - val_loss: 603.8730 - val_accuracy: 0.7889\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.8571 - accuracy: 0.7039 - val_loss: 600.5570 - val_accuracy: 0.7953\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.9850 - accuracy: 0.7218 - val_loss: 608.1826 - val_accuracy: 0.7949\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.2502 - accuracy: 0.7144 - val_loss: 599.1991 - val_accuracy: 0.7925\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 761.3793 - accuracy: 0.7106 - val_loss: 609.6865 - val_accuracy: 0.7941\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 773.0405 - accuracy: 0.7138 - val_loss: 604.0661 - val_accuracy: 0.7882\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.2220 - accuracy: 0.7116 - val_loss: 611.4084 - val_accuracy: 0.7890\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 776.4041 - accuracy: 0.7180 - val_loss: 612.2658 - val_accuracy: 0.7938\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 765.7700 - accuracy: 0.7099 - val_loss: 602.7609 - val_accuracy: 0.7928\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.7229 - accuracy: 0.7098 - val_loss: 611.8022 - val_accuracy: 0.7916\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.0325 - accuracy: 0.7165 - val_loss: 599.4490 - val_accuracy: 0.7907\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 760.2885 - accuracy: 0.7117 - val_loss: 598.3254 - val_accuracy: 0.7936\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 762.1725 - accuracy: 0.7178 - val_loss: 609.5915 - val_accuracy: 0.7867\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.5516 - accuracy: 0.7156 - val_loss: 605.0855 - val_accuracy: 0.7962\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.8408 - accuracy: 0.7154 - val_loss: 602.8911 - val_accuracy: 0.7894\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.2756 - accuracy: 0.7095 - val_loss: 601.2917 - val_accuracy: 0.7939\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 760.8867 - accuracy: 0.7179 - val_loss: 600.3270 - val_accuracy: 0.7915\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.9663 - accuracy: 0.7155 - val_loss: 608.1293 - val_accuracy: 0.7917\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.2550 - accuracy: 0.7170 - val_loss: 598.0945 - val_accuracy: 0.7925\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 759.0997 - accuracy: 0.7148 - val_loss: 602.1059 - val_accuracy: 0.7893\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 759.2233 - accuracy: 0.7167 - val_loss: 607.3973 - val_accuracy: 0.7908\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.3104 - accuracy: 0.7137 - val_loss: 611.7337 - val_accuracy: 0.7903\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.6670 - accuracy: 0.7156 - val_loss: 602.9273 - val_accuracy: 0.7888\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.0084 - accuracy: 0.7115 - val_loss: 599.4420 - val_accuracy: 0.7947\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 759.7159 - accuracy: 0.7130 - val_loss: 599.1657 - val_accuracy: 0.7926\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 761.1339 - accuracy: 0.7180 - val_loss: 602.1899 - val_accuracy: 0.7887\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.6464 - accuracy: 0.7163 - val_loss: 599.8200 - val_accuracy: 0.7935\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.9368 - accuracy: 0.7154 - val_loss: 597.5754 - val_accuracy: 0.7940\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.6874 - accuracy: 0.7152 - val_loss: 613.7218 - val_accuracy: 0.7993\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 766.8917 - accuracy: 0.7155 - val_loss: 600.8354 - val_accuracy: 0.7906\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 758.2447 - accuracy: 0.7131 - val_loss: 599.3133 - val_accuracy: 0.7942\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.7081 - accuracy: 0.7126 - val_loss: 598.3583 - val_accuracy: 0.7920\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 758.0328 - accuracy: 0.7199 - val_loss: 598.9963 - val_accuracy: 0.7955\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 760.8931 - accuracy: 0.7150 - val_loss: 604.2396 - val_accuracy: 0.7934\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 760.2418 - accuracy: 0.7176 - val_loss: 603.7464 - val_accuracy: 0.7966\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.5468 - accuracy: 0.7079 - val_loss: 611.8318 - val_accuracy: 0.7923\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.5273 - accuracy: 0.7186 - val_loss: 626.8109 - val_accuracy: 0.7969\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.2543 - accuracy: 0.7149 - val_loss: 603.7549 - val_accuracy: 0.7922\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 777.0620 - accuracy: 0.7141 - val_loss: 609.7293 - val_accuracy: 0.7984\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.1367 - accuracy: 0.7150 - val_loss: 601.8787 - val_accuracy: 0.7981\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 764.5670 - accuracy: 0.7163 - val_loss: 604.7549 - val_accuracy: 0.7940\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.1788 - accuracy: 0.7152 - val_loss: 612.2413 - val_accuracy: 0.7964\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.4838 - accuracy: 0.7162 - val_loss: 600.2377 - val_accuracy: 0.7993\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 759.2311 - accuracy: 0.7160 - val_loss: 600.9607 - val_accuracy: 0.7975\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 759.6077 - accuracy: 0.7163 - val_loss: 599.0631 - val_accuracy: 0.7940\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.6090 - accuracy: 0.7225 - val_loss: 598.9506 - val_accuracy: 0.7946\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 758.3651 - accuracy: 0.7115 - val_loss: 600.0190 - val_accuracy: 0.7949\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.5576 - accuracy: 0.7155 - val_loss: 597.7112 - val_accuracy: 0.7952\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 755.1780 - accuracy: 0.7166 - val_loss: 597.5495 - val_accuracy: 0.7940\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.2696 - accuracy: 0.7194 - val_loss: 606.9776 - val_accuracy: 0.7956\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 764.8450 - accuracy: 0.7112 - val_loss: 601.0277 - val_accuracy: 0.7909\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.6517 - accuracy: 0.7150 - val_loss: 601.6557 - val_accuracy: 0.7924\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 759.6199 - accuracy: 0.7151 - val_loss: 598.2562 - val_accuracy: 0.7982\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.3249 - accuracy: 0.7205 - val_loss: 603.4832 - val_accuracy: 0.7951\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.5865 - accuracy: 0.7113 - val_loss: 596.1963 - val_accuracy: 0.8001\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 758.3982 - accuracy: 0.7156 - val_loss: 597.2220 - val_accuracy: 0.7959\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 755.7841 - accuracy: 0.7157 - val_loss: 599.4487 - val_accuracy: 0.7962\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 756.6608 - accuracy: 0.7162 - val_loss: 595.9728 - val_accuracy: 0.7987\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 759.6293 - accuracy: 0.7159 - val_loss: 597.6465 - val_accuracy: 0.7992\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.8331 - accuracy: 0.7153 - val_loss: 597.5347 - val_accuracy: 0.7965\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 755.8257 - accuracy: 0.7217 - val_loss: 596.6973 - val_accuracy: 0.7954\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 755.7453 - accuracy: 0.7129 - val_loss: 602.2862 - val_accuracy: 0.7845\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 755.2165 - accuracy: 0.7126 - val_loss: 594.5020 - val_accuracy: 0.7974\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 753.2232 - accuracy: 0.7235 - val_loss: 600.2637 - val_accuracy: 0.7948\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 756.2818 - accuracy: 0.7095 - val_loss: 596.9673 - val_accuracy: 0.7943\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.1350 - accuracy: 0.7167 - val_loss: 602.8073 - val_accuracy: 0.8000\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 764.9749 - accuracy: 0.7142 - val_loss: 605.8890 - val_accuracy: 0.7927\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 759.7807 - accuracy: 0.7149 - val_loss: 600.4433 - val_accuracy: 0.7980\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 759.0152 - accuracy: 0.7137 - val_loss: 598.8244 - val_accuracy: 0.7966\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 756.1660 - accuracy: 0.7175 - val_loss: 599.4405 - val_accuracy: 0.7923\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 759.0146 - accuracy: 0.7135 - val_loss: 596.4532 - val_accuracy: 0.7968\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 756.5633 - accuracy: 0.7177 - val_loss: 597.3964 - val_accuracy: 0.7941\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 754.8030 - accuracy: 0.7129 - val_loss: 594.8223 - val_accuracy: 0.8044\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 754.4999 - accuracy: 0.7135 - val_loss: 597.7377 - val_accuracy: 0.7986\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.0554 - accuracy: 0.7200 - val_loss: 601.3217 - val_accuracy: 0.8013\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 754.4899 - accuracy: 0.7121 - val_loss: 595.4906 - val_accuracy: 0.8016\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.8396 - accuracy: 0.7224 - val_loss: 594.5812 - val_accuracy: 0.8001\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 753.9986 - accuracy: 0.7111 - val_loss: 599.2681 - val_accuracy: 0.7996\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 756.0831 - accuracy: 0.7218 - val_loss: 599.5880 - val_accuracy: 0.7940\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 758.7938 - accuracy: 0.7163 - val_loss: 597.5427 - val_accuracy: 0.7983\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 757.3630 - accuracy: 0.7157 - val_loss: 597.2179 - val_accuracy: 0.7946\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.3144 - accuracy: 0.7147 - val_loss: 593.8226 - val_accuracy: 0.8008\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 754.2159 - accuracy: 0.7180 - val_loss: 599.4840 - val_accuracy: 0.7982\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 757.5604 - accuracy: 0.7195 - val_loss: 595.3701 - val_accuracy: 0.7977\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 755.1243 - accuracy: 0.7143 - val_loss: 596.4437 - val_accuracy: 0.7995\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 755.1073 - accuracy: 0.7190 - val_loss: 599.4912 - val_accuracy: 0.7977\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 754.6594 - accuracy: 0.7181 - val_loss: 595.1686 - val_accuracy: 0.8029\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 752.2509 - accuracy: 0.7167 - val_loss: 594.0300 - val_accuracy: 0.8038\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 752.8448 - accuracy: 0.7115 - val_loss: 594.7524 - val_accuracy: 0.8034\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 753.7061 - accuracy: 0.7247 - val_loss: 599.5759 - val_accuracy: 0.8034\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 754.7845 - accuracy: 0.7117 - val_loss: 597.1529 - val_accuracy: 0.7965\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.6786 - accuracy: 0.7167 - val_loss: 601.8848 - val_accuracy: 0.8026\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.5647 - accuracy: 0.7207 - val_loss: 593.9333 - val_accuracy: 0.8017\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.7520 - accuracy: 0.7131 - val_loss: 600.6059 - val_accuracy: 0.8001\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 768.1859 - accuracy: 0.7084 - val_loss: 597.8394 - val_accuracy: 0.7947\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 758.1941 - accuracy: 0.7183 - val_loss: 597.5581 - val_accuracy: 0.7929\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.3758 - accuracy: 0.7121 - val_loss: 595.7642 - val_accuracy: 0.7977\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 753.9359 - accuracy: 0.7188 - val_loss: 597.1443 - val_accuracy: 0.7911\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 754.0626 - accuracy: 0.7160 - val_loss: 594.1254 - val_accuracy: 0.8028\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.2087 - accuracy: 0.7192 - val_loss: 600.8767 - val_accuracy: 0.7979\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 757.4309 - accuracy: 0.7121 - val_loss: 601.4476 - val_accuracy: 0.7935\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 756.5307 - accuracy: 0.7138 - val_loss: 596.7605 - val_accuracy: 0.8028\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 755.0836 - accuracy: 0.7202 - val_loss: 593.3604 - val_accuracy: 0.8019\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 752.1437 - accuracy: 0.7189 - val_loss: 592.7349 - val_accuracy: 0.8029\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 751.0893 - accuracy: 0.7151 - val_loss: 594.0960 - val_accuracy: 0.8007\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 750.7901 - accuracy: 0.7203 - val_loss: 595.7464 - val_accuracy: 0.7967\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 751.9163 - accuracy: 0.7190 - val_loss: 593.5717 - val_accuracy: 0.8001\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 750.8627 - accuracy: 0.7205 - val_loss: 596.1275 - val_accuracy: 0.8028\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 751.3240 - accuracy: 0.7147 - val_loss: 594.7432 - val_accuracy: 0.8031\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 750.3078 - accuracy: 0.7166 - val_loss: 593.3135 - val_accuracy: 0.8063\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 753.3209 - accuracy: 0.7183 - val_loss: 601.4373 - val_accuracy: 0.8026\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 757.6703 - accuracy: 0.7215 - val_loss: 594.8927 - val_accuracy: 0.8023\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 761.5228 - accuracy: 0.7115 - val_loss: 620.8029 - val_accuracy: 0.8031\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 778.9153 - accuracy: 0.7172 - val_loss: 600.4152 - val_accuracy: 0.8058\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.3983 - accuracy: 0.7169 - val_loss: 596.3784 - val_accuracy: 0.7984\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 761.3323 - accuracy: 0.7156 - val_loss: 594.0695 - val_accuracy: 0.7970\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 756.8631 - accuracy: 0.7183 - val_loss: 596.3940 - val_accuracy: 0.8009\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.2682 - accuracy: 0.7167 - val_loss: 595.5909 - val_accuracy: 0.7981\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 752.0284 - accuracy: 0.7167 - val_loss: 594.4718 - val_accuracy: 0.8048\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 751.4207 - accuracy: 0.7233 - val_loss: 596.4388 - val_accuracy: 0.8026\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 752.6300 - accuracy: 0.7209 - val_loss: 595.2078 - val_accuracy: 0.8041\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 751.4344 - accuracy: 0.7179 - val_loss: 591.4456 - val_accuracy: 0.8079\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 753.1755 - accuracy: 0.7186 - val_loss: 601.9673 - val_accuracy: 0.7998\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 764.9382 - accuracy: 0.7165 - val_loss: 598.6270 - val_accuracy: 0.7965\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 761.2737 - accuracy: 0.7112 - val_loss: 599.3787 - val_accuracy: 0.7927\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 756.7551 - accuracy: 0.7017 - val_loss: 596.0099 - val_accuracy: 0.8028\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 754.4092 - accuracy: 0.7128 - val_loss: 596.0419 - val_accuracy: 0.7994\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.1936 - accuracy: 0.7156 - val_loss: 605.7980 - val_accuracy: 0.8027\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 760.3148 - accuracy: 0.7169 - val_loss: 608.2231 - val_accuracy: 0.8039\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 758.6351 - accuracy: 0.7200 - val_loss: 601.4343 - val_accuracy: 0.8014\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.4610 - accuracy: 0.7159 - val_loss: 593.2822 - val_accuracy: 0.8050\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 751.5995 - accuracy: 0.7252 - val_loss: 596.3947 - val_accuracy: 0.7968\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 750.7987 - accuracy: 0.7165 - val_loss: 595.1214 - val_accuracy: 0.8045\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 752.1678 - accuracy: 0.7200 - val_loss: 594.9734 - val_accuracy: 0.8009\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.2131 - accuracy: 0.7144 - val_loss: 597.8785 - val_accuracy: 0.8022\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.2010 - accuracy: 0.7214 - val_loss: 599.3769 - val_accuracy: 0.8022\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 756.2818 - accuracy: 0.7153 - val_loss: 593.5121 - val_accuracy: 0.8001\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.2376 - accuracy: 0.7199 - val_loss: 594.7475 - val_accuracy: 0.8053\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 757.4435 - accuracy: 0.7179 - val_loss: 602.9971 - val_accuracy: 0.8048\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 776.4132 - accuracy: 0.7172 - val_loss: 636.4978 - val_accuracy: 0.7993\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 791.5090 - accuracy: 0.7131 - val_loss: 614.1808 - val_accuracy: 0.8047\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 776.4437 - accuracy: 0.7191 - val_loss: 627.0017 - val_accuracy: 0.7935\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.3439 - accuracy: 0.7116 - val_loss: 599.4041 - val_accuracy: 0.8022\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 756.5518 - accuracy: 0.7108 - val_loss: 592.7463 - val_accuracy: 0.8033\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 752.5759 - accuracy: 0.7152 - val_loss: 594.8968 - val_accuracy: 0.8079\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 755.7858 - accuracy: 0.7192 - val_loss: 597.9177 - val_accuracy: 0.8042\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 754.8403 - accuracy: 0.7150 - val_loss: 606.6153 - val_accuracy: 0.8013\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 758.1844 - accuracy: 0.7153 - val_loss: 598.9302 - val_accuracy: 0.8018\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.8658 - accuracy: 0.7170 - val_loss: 598.1548 - val_accuracy: 0.8044\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 754.5164 - accuracy: 0.7168 - val_loss: 599.9085 - val_accuracy: 0.8085\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 749.5091 - accuracy: 0.7213 - val_loss: 592.4205 - val_accuracy: 0.8045\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 748.6657 - accuracy: 0.7210 - val_loss: 591.7543 - val_accuracy: 0.8046\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 747.9736 - accuracy: 0.7174 - val_loss: 591.2043 - val_accuracy: 0.8051\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 747.7588 - accuracy: 0.7158 - val_loss: 589.1016 - val_accuracy: 0.8051\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 748.9240 - accuracy: 0.7256 - val_loss: 596.3602 - val_accuracy: 0.8033\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 750.0317 - accuracy: 0.7214 - val_loss: 592.4329 - val_accuracy: 0.8056\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 749.2472 - accuracy: 0.7188 - val_loss: 590.9668 - val_accuracy: 0.8064\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 748.4762 - accuracy: 0.7212 - val_loss: 588.6906 - val_accuracy: 0.8064\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 747.0911 - accuracy: 0.7196 - val_loss: 589.8853 - val_accuracy: 0.8063\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 746.3028 - accuracy: 0.7173 - val_loss: 590.4734 - val_accuracy: 0.8062\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 746.4537 - accuracy: 0.7220 - val_loss: 592.6353 - val_accuracy: 0.8061\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 746.8010 - accuracy: 0.7202 - val_loss: 594.8300 - val_accuracy: 0.8069\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 750.2532 - accuracy: 0.7160 - val_loss: 596.7543 - val_accuracy: 0.8049\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 751.8566 - accuracy: 0.7177 - val_loss: 597.9971 - val_accuracy: 0.8074\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 752.4626 - accuracy: 0.7243 - val_loss: 593.7223 - val_accuracy: 0.8053\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 761.1476 - accuracy: 0.7128 - val_loss: 591.0000 - val_accuracy: 0.8075\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 760.6014 - accuracy: 0.7205 - val_loss: 597.3749 - val_accuracy: 0.8056\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 750.2880 - accuracy: 0.7159 - val_loss: 591.4333 - val_accuracy: 0.8058\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 747.2822 - accuracy: 0.7191 - val_loss: 589.9030 - val_accuracy: 0.8088\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 748.6951 - accuracy: 0.7246 - val_loss: 588.4238 - val_accuracy: 0.8097\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 745.7917 - accuracy: 0.7183 - val_loss: 588.2532 - val_accuracy: 0.8070\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 746.6413 - accuracy: 0.7235 - val_loss: 593.9091 - val_accuracy: 0.8069\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 749.2561 - accuracy: 0.7250 - val_loss: 592.4015 - val_accuracy: 0.8018\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 749.0845 - accuracy: 0.7158 - val_loss: 595.4279 - val_accuracy: 0.8021\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 748.3656 - accuracy: 0.7214 - val_loss: 591.8538 - val_accuracy: 0.8054\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 745.4398 - accuracy: 0.7217 - val_loss: 589.1638 - val_accuracy: 0.8062\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 744.7982 - accuracy: 0.7189 - val_loss: 586.6527 - val_accuracy: 0.8089\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 745.6605 - accuracy: 0.7266 - val_loss: 590.6526 - val_accuracy: 0.8048\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 748.3745 - accuracy: 0.7173 - val_loss: 591.4489 - val_accuracy: 0.8041\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 750.5070 - accuracy: 0.7250 - val_loss: 593.8715 - val_accuracy: 0.8092\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 762.9709 - accuracy: 0.7194 - val_loss: 600.1664 - val_accuracy: 0.7971\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 755.9661 - accuracy: 0.7244 - val_loss: 591.7670 - val_accuracy: 0.8095\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 748.9008 - accuracy: 0.7164 - val_loss: 593.8541 - val_accuracy: 0.8043\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 747.2731 - accuracy: 0.7230 - val_loss: 596.3318 - val_accuracy: 0.8019\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 748.5153 - accuracy: 0.7180 - val_loss: 592.2884 - val_accuracy: 0.8021\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 746.5244 - accuracy: 0.7252 - val_loss: 591.1680 - val_accuracy: 0.8063\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 746.7722 - accuracy: 0.7177 - val_loss: 591.6983 - val_accuracy: 0.8051\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 745.9824 - accuracy: 0.7223 - val_loss: 591.5231 - val_accuracy: 0.8058\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 746.0787 - accuracy: 0.7232 - val_loss: 588.6856 - val_accuracy: 0.8082\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 746.9406 - accuracy: 0.7193 - val_loss: 591.0244 - val_accuracy: 0.8084\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 748.1658 - accuracy: 0.7205 - val_loss: 589.2994 - val_accuracy: 0.7979\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 745.9489 - accuracy: 0.7166 - val_loss: 588.7365 - val_accuracy: 0.8065\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 749.2599 - accuracy: 0.7190 - val_loss: 591.5062 - val_accuracy: 0.8089\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 752.4163 - accuracy: 0.7169 - val_loss: 590.3802 - val_accuracy: 0.8067\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 752.6089 - accuracy: 0.7222 - val_loss: 599.2827 - val_accuracy: 0.8054\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 747.4866 - accuracy: 0.7255 - val_loss: 590.6306 - val_accuracy: 0.8067\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 748.6577 - accuracy: 0.7125 - val_loss: 591.3698 - val_accuracy: 0.8022\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 749.6246 - accuracy: 0.7235 - val_loss: 592.8652 - val_accuracy: 0.8039\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 753.4896 - accuracy: 0.7202 - val_loss: 592.8627 - val_accuracy: 0.8029\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 752.5541 - accuracy: 0.7219 - val_loss: 596.2899 - val_accuracy: 0.8090\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 748.5275 - accuracy: 0.7195 - val_loss: 593.8430 - val_accuracy: 0.8070\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 751.0381 - accuracy: 0.7214 - val_loss: 597.6357 - val_accuracy: 0.8042\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.0826 - accuracy: 0.7166 - val_loss: 601.9763 - val_accuracy: 0.8084\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 760.0411 - accuracy: 0.7239 - val_loss: 606.0110 - val_accuracy: 0.8062\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.3555 - accuracy: 0.7182 - val_loss: 629.9328 - val_accuracy: 0.8057\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 756.3856 - accuracy: 0.7198 - val_loss: 592.7672 - val_accuracy: 0.8059\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 751.2881 - accuracy: 0.7245 - val_loss: 593.5074 - val_accuracy: 0.8007\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 745.3030 - accuracy: 0.7202 - val_loss: 589.0703 - val_accuracy: 0.8014\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 745.3851 - accuracy: 0.7206 - val_loss: 589.2303 - val_accuracy: 0.8067\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.4449 - accuracy: 0.7201 - val_loss: 589.1752 - val_accuracy: 0.8071\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.5634 - accuracy: 0.7243 - val_loss: 589.1552 - val_accuracy: 0.8069\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 744.1378 - accuracy: 0.7203 - val_loss: 592.7651 - val_accuracy: 0.8089\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 749.5624 - accuracy: 0.7271 - val_loss: 588.1339 - val_accuracy: 0.7962\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 745.0391 - accuracy: 0.7178 - val_loss: 590.9136 - val_accuracy: 0.8070\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 744.3211 - accuracy: 0.7234 - val_loss: 590.1144 - val_accuracy: 0.8075\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 745.4729 - accuracy: 0.7205 - val_loss: 591.2987 - val_accuracy: 0.8055\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 744.3079 - accuracy: 0.7218 - val_loss: 595.3338 - val_accuracy: 0.8041\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 745.1244 - accuracy: 0.7235 - val_loss: 589.2213 - val_accuracy: 0.8051\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 747.7302 - accuracy: 0.7255 - val_loss: 590.4541 - val_accuracy: 0.8074\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 745.1735 - accuracy: 0.7234 - val_loss: 593.9665 - val_accuracy: 0.8013\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.6180 - accuracy: 0.7179 - val_loss: 593.6704 - val_accuracy: 0.8016\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.2696 - accuracy: 0.7194 - val_loss: 616.3340 - val_accuracy: 0.8083\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.6882 - accuracy: 0.7193 - val_loss: 594.7194 - val_accuracy: 0.8078\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 754.8549 - accuracy: 0.7188 - val_loss: 591.6262 - val_accuracy: 0.8058\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 754.5634 - accuracy: 0.7205 - val_loss: 594.1923 - val_accuracy: 0.7974\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 756.4901 - accuracy: 0.7201 - val_loss: 601.8452 - val_accuracy: 0.7971\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 751.7025 - accuracy: 0.7182 - val_loss: 599.4257 - val_accuracy: 0.8070\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 750.8277 - accuracy: 0.7214 - val_loss: 592.1075 - val_accuracy: 0.8050\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 746.5866 - accuracy: 0.7219 - val_loss: 588.0641 - val_accuracy: 0.8004\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 750.7083 - accuracy: 0.7200 - val_loss: 596.8180 - val_accuracy: 0.8074\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 746.5465 - accuracy: 0.7172 - val_loss: 587.6979 - val_accuracy: 0.8053\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 743.4057 - accuracy: 0.7242 - val_loss: 588.9846 - val_accuracy: 0.8055\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.9515 - accuracy: 0.7211 - val_loss: 590.3564 - val_accuracy: 0.8075\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.8387 - accuracy: 0.7226 - val_loss: 593.8788 - val_accuracy: 0.8038\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 751.6221 - accuracy: 0.7233 - val_loss: 594.2985 - val_accuracy: 0.8044\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 773.4778 - accuracy: 0.7191 - val_loss: 610.3344 - val_accuracy: 0.8068\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 803.3004 - accuracy: 0.7077 - val_loss: 622.4763 - val_accuracy: 0.8023\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 773.6306 - accuracy: 0.7146 - val_loss: 600.7007 - val_accuracy: 0.7996\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 760.0483 - accuracy: 0.7060 - val_loss: 597.2910 - val_accuracy: 0.7929\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 748.3011 - accuracy: 0.7191 - val_loss: 593.2391 - val_accuracy: 0.8031\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 747.5162 - accuracy: 0.7164 - val_loss: 590.6541 - val_accuracy: 0.8073\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 743.2991 - accuracy: 0.7225 - val_loss: 590.1230 - val_accuracy: 0.8058\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.5394 - accuracy: 0.7227 - val_loss: 586.6356 - val_accuracy: 0.8059\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.5600 - accuracy: 0.7269 - val_loss: 588.6536 - val_accuracy: 0.8059\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 743.6102 - accuracy: 0.7173 - val_loss: 590.2301 - val_accuracy: 0.7980\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 751.6129 - accuracy: 0.7255 - val_loss: 592.4603 - val_accuracy: 0.7999\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 746.6205 - accuracy: 0.7161 - val_loss: 592.0573 - val_accuracy: 0.8062\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 748.1251 - accuracy: 0.7237 - val_loss: 595.4733 - val_accuracy: 0.8095\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 750.8166 - accuracy: 0.7246 - val_loss: 594.7380 - val_accuracy: 0.7974\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 747.1761 - accuracy: 0.7191 - val_loss: 589.0330 - val_accuracy: 0.8052\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 749.1743 - accuracy: 0.7224 - val_loss: 602.6044 - val_accuracy: 0.8110\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 748.7491 - accuracy: 0.7182 - val_loss: 589.6708 - val_accuracy: 0.8071\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 744.9352 - accuracy: 0.7229 - val_loss: 593.0220 - val_accuracy: 0.8069\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 744.3972 - accuracy: 0.7219 - val_loss: 589.7416 - val_accuracy: 0.8075\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 744.3542 - accuracy: 0.7180 - val_loss: 589.7509 - val_accuracy: 0.8065\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 744.9385 - accuracy: 0.7196 - val_loss: 586.5245 - val_accuracy: 0.8061\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 744.3610 - accuracy: 0.7250 - val_loss: 588.6390 - val_accuracy: 0.8104\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 742.6288 - accuracy: 0.7219 - val_loss: 585.8067 - val_accuracy: 0.8040\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 740.9103 - accuracy: 0.7239 - val_loss: 586.6975 - val_accuracy: 0.8077\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 740.9788 - accuracy: 0.7199 - val_loss: 585.2485 - val_accuracy: 0.8085\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.6362 - accuracy: 0.7265 - val_loss: 586.2980 - val_accuracy: 0.8091\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.2706 - accuracy: 0.7257 - val_loss: 587.7627 - val_accuracy: 0.8069\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 740.4369 - accuracy: 0.7223 - val_loss: 586.2476 - val_accuracy: 0.8075\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 740.9027 - accuracy: 0.7240 - val_loss: 586.8495 - val_accuracy: 0.8079\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 740.7183 - accuracy: 0.7239 - val_loss: 584.6610 - val_accuracy: 0.8092\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 740.8475 - accuracy: 0.7188 - val_loss: 590.5286 - val_accuracy: 0.8039\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.8375 - accuracy: 0.7218 - val_loss: 588.0208 - val_accuracy: 0.8055\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 741.1647 - accuracy: 0.7260 - val_loss: 586.0165 - val_accuracy: 0.8089\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.3604 - accuracy: 0.7178 - val_loss: 584.8879 - val_accuracy: 0.8065\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.8405 - accuracy: 0.7252 - val_loss: 588.5936 - val_accuracy: 0.8083\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 744.1757 - accuracy: 0.7221 - val_loss: 587.8404 - val_accuracy: 0.8023\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 745.7555 - accuracy: 0.7225 - val_loss: 590.1390 - val_accuracy: 0.8038\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.6943 - accuracy: 0.7164 - val_loss: 585.9218 - val_accuracy: 0.8073\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 742.9050 - accuracy: 0.7250 - val_loss: 589.7788 - val_accuracy: 0.8037\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 741.0601 - accuracy: 0.7188 - val_loss: 586.4628 - val_accuracy: 0.8064\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 739.6652 - accuracy: 0.7249 - val_loss: 587.3848 - val_accuracy: 0.8071\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 739.5681 - accuracy: 0.7213 - val_loss: 588.7779 - val_accuracy: 0.8105\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 741.0853 - accuracy: 0.7261 - val_loss: 586.1752 - val_accuracy: 0.8024\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 741.0295 - accuracy: 0.7153 - val_loss: 588.0059 - val_accuracy: 0.8036\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 744.9529 - accuracy: 0.7217 - val_loss: 599.5402 - val_accuracy: 0.8064\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 754.0347 - accuracy: 0.7236 - val_loss: 590.7589 - val_accuracy: 0.8036\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 751.5240 - accuracy: 0.7168 - val_loss: 593.2751 - val_accuracy: 0.8049\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 750.9913 - accuracy: 0.7222 - val_loss: 600.0928 - val_accuracy: 0.8049\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 749.3900 - accuracy: 0.7225 - val_loss: 608.7705 - val_accuracy: 0.7991\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 767.9537 - accuracy: 0.7119 - val_loss: 605.2646 - val_accuracy: 0.7756\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.8472 - accuracy: 0.7111 - val_loss: 596.7753 - val_accuracy: 0.7989\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 746.8850 - accuracy: 0.7193 - val_loss: 592.3033 - val_accuracy: 0.7971\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 745.6622 - accuracy: 0.7181 - val_loss: 589.0856 - val_accuracy: 0.8008\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 744.3446 - accuracy: 0.7227 - val_loss: 586.9922 - val_accuracy: 0.8020\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 741.0892 - accuracy: 0.7231 - val_loss: 584.8023 - val_accuracy: 0.8074\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 739.9459 - accuracy: 0.7204 - val_loss: 585.0240 - val_accuracy: 0.8055\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 742.8942 - accuracy: 0.7208 - val_loss: 586.6877 - val_accuracy: 0.8053\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 741.1738 - accuracy: 0.7231 - val_loss: 586.8285 - val_accuracy: 0.8068\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.8855 - accuracy: 0.7193 - val_loss: 591.2985 - val_accuracy: 0.8080\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 752.4020 - accuracy: 0.7208 - val_loss: 585.9374 - val_accuracy: 0.8020\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 753.0880 - accuracy: 0.7260 - val_loss: 586.7935 - val_accuracy: 0.8071\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 763.5876 - accuracy: 0.7210 - val_loss: 669.7089 - val_accuracy: 0.7990\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 805.2571 - accuracy: 0.7186 - val_loss: 613.1299 - val_accuracy: 0.8038\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 753.9671 - accuracy: 0.7214 - val_loss: 592.7140 - val_accuracy: 0.7990\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 752.9733 - accuracy: 0.7127 - val_loss: 592.3584 - val_accuracy: 0.8055\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 756.6987 - accuracy: 0.7212 - val_loss: 588.5921 - val_accuracy: 0.8070\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 750.1655 - accuracy: 0.7138 - val_loss: 594.6519 - val_accuracy: 0.8042\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 747.1802 - accuracy: 0.7230 - val_loss: 590.5900 - val_accuracy: 0.8057\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 743.3646 - accuracy: 0.7185 - val_loss: 586.2138 - val_accuracy: 0.8018\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 742.3754 - accuracy: 0.7238 - val_loss: 588.1215 - val_accuracy: 0.8097\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.4649 - accuracy: 0.7216 - val_loss: 593.2954 - val_accuracy: 0.8082\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 742.9739 - accuracy: 0.7255 - val_loss: 587.7845 - val_accuracy: 0.8066\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 741.3801 - accuracy: 0.7209 - val_loss: 587.8577 - val_accuracy: 0.8069\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 740.4653 - accuracy: 0.7210 - val_loss: 586.5248 - val_accuracy: 0.8047\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.1309 - accuracy: 0.7201 - val_loss: 585.6147 - val_accuracy: 0.8074\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 741.6244 - accuracy: 0.7266 - val_loss: 583.2338 - val_accuracy: 0.8081\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 739.7399 - accuracy: 0.7174 - val_loss: 592.6625 - val_accuracy: 0.8047\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.2615 - accuracy: 0.7230 - val_loss: 584.5173 - val_accuracy: 0.8076\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 739.3368 - accuracy: 0.7247 - val_loss: 588.4535 - val_accuracy: 0.8071\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 741.2227 - accuracy: 0.7232 - val_loss: 589.4608 - val_accuracy: 0.8080\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 744.0208 - accuracy: 0.7202 - val_loss: 585.8452 - val_accuracy: 0.8018\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 746.4545 - accuracy: 0.7212 - val_loss: 591.7596 - val_accuracy: 0.8057\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 740.5317 - accuracy: 0.7203 - val_loss: 588.4907 - val_accuracy: 0.8083\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 739.6439 - accuracy: 0.7250 - val_loss: 584.2918 - val_accuracy: 0.8066\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.8925 - accuracy: 0.7239 - val_loss: 588.7947 - val_accuracy: 0.8067\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 739.4681 - accuracy: 0.7240 - val_loss: 590.6499 - val_accuracy: 0.8090\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 743.0916 - accuracy: 0.7183 - val_loss: 586.7966 - val_accuracy: 0.8093\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 739.7213 - accuracy: 0.7279 - val_loss: 594.4414 - val_accuracy: 0.8070\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.2614 - accuracy: 0.7140 - val_loss: 604.5964 - val_accuracy: 0.8000\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 749.0834 - accuracy: 0.7257 - val_loss: 598.7962 - val_accuracy: 0.8020\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 744.3689 - accuracy: 0.7222 - val_loss: 587.0603 - val_accuracy: 0.8022\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 742.5475 - accuracy: 0.7186 - val_loss: 585.6226 - val_accuracy: 0.8073\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 738.6305 - accuracy: 0.7259 - val_loss: 589.6865 - val_accuracy: 0.8049\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 739.4737 - accuracy: 0.7189 - val_loss: 585.6328 - val_accuracy: 0.8059\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 736.9571 - accuracy: 0.7238 - val_loss: 587.3495 - val_accuracy: 0.8039\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 741.3488 - accuracy: 0.7211 - val_loss: 585.5945 - val_accuracy: 0.8031\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 738.7724 - accuracy: 0.7219 - val_loss: 586.4065 - val_accuracy: 0.8094\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 737.9863 - accuracy: 0.7226 - val_loss: 586.5660 - val_accuracy: 0.8005\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 738.6797 - accuracy: 0.7257 - val_loss: 587.1188 - val_accuracy: 0.8110\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 736.6505 - accuracy: 0.7222 - val_loss: 581.7864 - val_accuracy: 0.8061\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 735.7892 - accuracy: 0.7253 - val_loss: 583.6827 - val_accuracy: 0.8030\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.9467 - accuracy: 0.7276 - val_loss: 584.3622 - val_accuracy: 0.8103\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 740.7934 - accuracy: 0.7192 - val_loss: 586.1711 - val_accuracy: 0.8077\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 742.0110 - accuracy: 0.7240 - val_loss: 588.0020 - val_accuracy: 0.8032\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.5906 - accuracy: 0.7205 - val_loss: 596.1121 - val_accuracy: 0.8078\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.2330 - accuracy: 0.7185 - val_loss: 588.2684 - val_accuracy: 0.8056\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 745.7796 - accuracy: 0.7239 - val_loss: 586.2887 - val_accuracy: 0.8026\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 740.7158 - accuracy: 0.7215 - val_loss: 585.4359 - val_accuracy: 0.8071\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 739.8196 - accuracy: 0.7234 - val_loss: 585.7782 - val_accuracy: 0.8073\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 737.0010 - accuracy: 0.7214 - val_loss: 580.0248 - val_accuracy: 0.8064\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 737.2885 - accuracy: 0.7259 - val_loss: 584.4592 - val_accuracy: 0.8039\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 738.2605 - accuracy: 0.7214 - val_loss: 586.6163 - val_accuracy: 0.7992\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 741.7218 - accuracy: 0.7185 - val_loss: 588.2119 - val_accuracy: 0.8066\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.2942 - accuracy: 0.7236 - val_loss: 586.3127 - val_accuracy: 0.8069\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 739.8910 - accuracy: 0.7215 - val_loss: 585.7399 - val_accuracy: 0.8049\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 737.9266 - accuracy: 0.7215 - val_loss: 585.2413 - val_accuracy: 0.8041\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 735.8043 - accuracy: 0.7278 - val_loss: 584.2887 - val_accuracy: 0.8080\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 738.2509 - accuracy: 0.7157 - val_loss: 582.3231 - val_accuracy: 0.8017\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.1769 - accuracy: 0.7273 - val_loss: 589.9205 - val_accuracy: 0.8071\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.8340 - accuracy: 0.7200 - val_loss: 588.6238 - val_accuracy: 0.8068\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 740.3098 - accuracy: 0.7196 - val_loss: 593.9118 - val_accuracy: 0.8049\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 742.1418 - accuracy: 0.7225 - val_loss: 589.9097 - val_accuracy: 0.8065\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 738.2648 - accuracy: 0.7215 - val_loss: 586.9493 - val_accuracy: 0.8080\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.5977 - accuracy: 0.7250 - val_loss: 589.6244 - val_accuracy: 0.8075\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.1722 - accuracy: 0.7159 - val_loss: 586.0571 - val_accuracy: 0.8100\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.0989 - accuracy: 0.7216 - val_loss: 593.0259 - val_accuracy: 0.8040\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.3180 - accuracy: 0.7120 - val_loss: 597.4711 - val_accuracy: 0.7937\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 746.2399 - accuracy: 0.7173 - val_loss: 589.5933 - val_accuracy: 0.8056\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 745.5941 - accuracy: 0.7269 - val_loss: 590.5997 - val_accuracy: 0.8028\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 774.2701 - accuracy: 0.7158 - val_loss: 594.2903 - val_accuracy: 0.8054\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 761.3157 - accuracy: 0.7189 - val_loss: 598.1341 - val_accuracy: 0.8022\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 750.1694 - accuracy: 0.7186 - val_loss: 589.5923 - val_accuracy: 0.8062\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 745.0958 - accuracy: 0.7181 - val_loss: 594.6954 - val_accuracy: 0.8013\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.1094 - accuracy: 0.7230 - val_loss: 583.6945 - val_accuracy: 0.8073\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 734.6378 - accuracy: 0.7236 - val_loss: 582.7942 - val_accuracy: 0.8045\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 735.1248 - accuracy: 0.7291 - val_loss: 587.5897 - val_accuracy: 0.8092\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.1740 - accuracy: 0.7176 - val_loss: 590.4781 - val_accuracy: 0.7985\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 738.8349 - accuracy: 0.7276 - val_loss: 590.0088 - val_accuracy: 0.8084\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 739.5434 - accuracy: 0.7211 - val_loss: 585.2653 - val_accuracy: 0.8067\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 737.5253 - accuracy: 0.7232 - val_loss: 584.9636 - val_accuracy: 0.8097\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.5785 - accuracy: 0.7199 - val_loss: 583.0918 - val_accuracy: 0.8086\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.9503 - accuracy: 0.7242 - val_loss: 583.2546 - val_accuracy: 0.8093\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 736.3368 - accuracy: 0.7257 - val_loss: 585.1607 - val_accuracy: 0.7890\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 734.6097 - accuracy: 0.7179 - val_loss: 582.2626 - val_accuracy: 0.8059\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 737.1871 - accuracy: 0.7294 - val_loss: 584.5257 - val_accuracy: 0.8100\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 736.3657 - accuracy: 0.7220 - val_loss: 582.5317 - val_accuracy: 0.8078\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.1818 - accuracy: 0.7243 - val_loss: 593.3833 - val_accuracy: 0.8083\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 736.5191 - accuracy: 0.7207 - val_loss: 586.6953 - val_accuracy: 0.7995\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 736.7206 - accuracy: 0.7196 - val_loss: 581.8781 - val_accuracy: 0.8104\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.4760 - accuracy: 0.7258 - val_loss: 581.4456 - val_accuracy: 0.8065\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 732.8547 - accuracy: 0.7210 - val_loss: 584.2678 - val_accuracy: 0.8081\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 739.1155 - accuracy: 0.7292 - val_loss: 585.6313 - val_accuracy: 0.8082\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 738.9918 - accuracy: 0.7176 - val_loss: 588.6688 - val_accuracy: 0.8071\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.1086 - accuracy: 0.7265 - val_loss: 598.1718 - val_accuracy: 0.7985\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 747.5777 - accuracy: 0.7200 - val_loss: 602.9998 - val_accuracy: 0.8069\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 747.9189 - accuracy: 0.7183 - val_loss: 585.8900 - val_accuracy: 0.8093\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 747.6248 - accuracy: 0.7207 - val_loss: 591.8692 - val_accuracy: 0.7959\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 740.4490 - accuracy: 0.7237 - val_loss: 585.8018 - val_accuracy: 0.8046\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 746.3298 - accuracy: 0.7185 - val_loss: 590.2443 - val_accuracy: 0.8067\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 741.5463 - accuracy: 0.7247 - val_loss: 592.5450 - val_accuracy: 0.8053\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.5518 - accuracy: 0.7201 - val_loss: 588.8904 - val_accuracy: 0.7995\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 738.2761 - accuracy: 0.7286 - val_loss: 582.7791 - val_accuracy: 0.8114\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 736.3602 - accuracy: 0.7262 - val_loss: 583.7947 - val_accuracy: 0.8108\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 736.3616 - accuracy: 0.7207 - val_loss: 585.0232 - val_accuracy: 0.7943\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.9060 - accuracy: 0.7216 - val_loss: 582.9736 - val_accuracy: 0.8095\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.5931 - accuracy: 0.7247 - val_loss: 585.6672 - val_accuracy: 0.7989\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 733.6523 - accuracy: 0.7229 - val_loss: 585.1259 - val_accuracy: 0.8010\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 743.5426 - accuracy: 0.7244 - val_loss: 588.8037 - val_accuracy: 0.8048\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 748.0469 - accuracy: 0.7203 - val_loss: 588.7639 - val_accuracy: 0.7948\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 737.1655 - accuracy: 0.7256 - val_loss: 582.5232 - val_accuracy: 0.8087\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 735.0960 - accuracy: 0.7229 - val_loss: 579.3519 - val_accuracy: 0.8078\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.0002 - accuracy: 0.7262 - val_loss: 579.5011 - val_accuracy: 0.8069\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.0312 - accuracy: 0.7175 - val_loss: 581.8996 - val_accuracy: 0.8052\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 733.9646 - accuracy: 0.7234 - val_loss: 581.3486 - val_accuracy: 0.8080\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 732.4175 - accuracy: 0.7221 - val_loss: 581.8144 - val_accuracy: 0.8076\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 735.1575 - accuracy: 0.7301 - val_loss: 581.7532 - val_accuracy: 0.8062\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.0911 - accuracy: 0.7239 - val_loss: 582.7848 - val_accuracy: 0.8053\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 736.0397 - accuracy: 0.7282 - val_loss: 586.8824 - val_accuracy: 0.7962\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 738.5474 - accuracy: 0.7258 - val_loss: 584.4724 - val_accuracy: 0.7988\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 735.0775 - accuracy: 0.7151 - val_loss: 584.0931 - val_accuracy: 0.8069\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 736.0898 - accuracy: 0.7252 - val_loss: 583.8246 - val_accuracy: 0.8041\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 737.1353 - accuracy: 0.7160 - val_loss: 580.2869 - val_accuracy: 0.8076\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 735.2029 - accuracy: 0.7232 - val_loss: 582.4037 - val_accuracy: 0.7983\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 733.6153 - accuracy: 0.7258 - val_loss: 585.4134 - val_accuracy: 0.8045\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 730.9673 - accuracy: 0.7249 - val_loss: 588.7000 - val_accuracy: 0.8037\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 736.6295 - accuracy: 0.7188 - val_loss: 585.8126 - val_accuracy: 0.8029\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 738.7450 - accuracy: 0.7246 - val_loss: 586.0848 - val_accuracy: 0.8072\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 747.8577 - accuracy: 0.7229 - val_loss: 588.3260 - val_accuracy: 0.8006\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 743.7429 - accuracy: 0.7138 - val_loss: 589.0615 - val_accuracy: 0.8036\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 739.2060 - accuracy: 0.7236 - val_loss: 591.1761 - val_accuracy: 0.8078\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.9466 - accuracy: 0.7266 - val_loss: 582.6785 - val_accuracy: 0.7999\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.0526 - accuracy: 0.7261 - val_loss: 579.4963 - val_accuracy: 0.8074\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 730.5172 - accuracy: 0.7226 - val_loss: 580.3345 - val_accuracy: 0.8032\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 736.3790 - accuracy: 0.7265 - val_loss: 592.9938 - val_accuracy: 0.8081\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 737.7821 - accuracy: 0.7193 - val_loss: 586.8445 - val_accuracy: 0.7916\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 736.2792 - accuracy: 0.7243 - val_loss: 591.5914 - val_accuracy: 0.8045\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 734.6190 - accuracy: 0.7266 - val_loss: 585.0331 - val_accuracy: 0.8036\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 735.6840 - accuracy: 0.7204 - val_loss: 584.7872 - val_accuracy: 0.8078\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 736.9565 - accuracy: 0.7248 - val_loss: 579.7903 - val_accuracy: 0.8067\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 733.9540 - accuracy: 0.7220 - val_loss: 587.2615 - val_accuracy: 0.8050\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 738.7954 - accuracy: 0.7264 - val_loss: 589.1252 - val_accuracy: 0.7956\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 738.4437 - accuracy: 0.7249 - val_loss: 585.3129 - val_accuracy: 0.8042\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.9996 - accuracy: 0.7206 - val_loss: 580.5289 - val_accuracy: 0.8072\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 731.1297 - accuracy: 0.7257 - val_loss: 582.9153 - val_accuracy: 0.8074\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 729.2243 - accuracy: 0.7266 - val_loss: 581.0406 - val_accuracy: 0.8043\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 731.1170 - accuracy: 0.7181 - val_loss: 579.8410 - val_accuracy: 0.8070\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.3823 - accuracy: 0.7276 - val_loss: 586.4335 - val_accuracy: 0.8069\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.2478 - accuracy: 0.7206 - val_loss: 587.3478 - val_accuracy: 0.8046\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 741.1847 - accuracy: 0.7170 - val_loss: 581.2569 - val_accuracy: 0.8036\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 732.3168 - accuracy: 0.7227 - val_loss: 579.5875 - val_accuracy: 0.7972\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 732.0352 - accuracy: 0.7228 - val_loss: 584.1236 - val_accuracy: 0.8034\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 731.7080 - accuracy: 0.7283 - val_loss: 586.5372 - val_accuracy: 0.8057\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 731.1246 - accuracy: 0.7214 - val_loss: 579.7274 - val_accuracy: 0.8083\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 732.6311 - accuracy: 0.7208 - val_loss: 582.2354 - val_accuracy: 0.8024\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 731.5424 - accuracy: 0.7217 - val_loss: 583.8073 - val_accuracy: 0.7871\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 735.1293 - accuracy: 0.7239 - val_loss: 584.4619 - val_accuracy: 0.7990\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 735.6824 - accuracy: 0.7186 - val_loss: 581.2050 - val_accuracy: 0.8060\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 730.9612 - accuracy: 0.7226 - val_loss: 577.9866 - val_accuracy: 0.8067\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 732.2628 - accuracy: 0.7295 - val_loss: 584.9590 - val_accuracy: 0.8053\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 732.1561 - accuracy: 0.7260 - val_loss: 579.5181 - val_accuracy: 0.8026\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 732.5219 - accuracy: 0.7260 - val_loss: 579.7661 - val_accuracy: 0.8092\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 732.4957 - accuracy: 0.7279 - val_loss: 581.8743 - val_accuracy: 0.7968\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 731.0331 - accuracy: 0.7249 - val_loss: 580.8608 - val_accuracy: 0.7934\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 737.2596 - accuracy: 0.7184 - val_loss: 594.6558 - val_accuracy: 0.7938\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 738.1132 - accuracy: 0.7194 - val_loss: 581.4824 - val_accuracy: 0.8037\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 739.2548 - accuracy: 0.7219 - val_loss: 586.0332 - val_accuracy: 0.8041\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.9207 - accuracy: 0.7275 - val_loss: 582.3860 - val_accuracy: 0.8010\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 732.7959 - accuracy: 0.7181 - val_loss: 586.0137 - val_accuracy: 0.7810\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 735.9414 - accuracy: 0.7257 - val_loss: 586.1332 - val_accuracy: 0.7892\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 732.1923 - accuracy: 0.7262 - val_loss: 584.3903 - val_accuracy: 0.7900\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 728.9147 - accuracy: 0.7239 - val_loss: 581.2344 - val_accuracy: 0.8018\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.2700 - accuracy: 0.7223 - val_loss: 585.1788 - val_accuracy: 0.8073\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 733.3489 - accuracy: 0.7289 - val_loss: 589.9489 - val_accuracy: 0.7900\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.3139 - accuracy: 0.7162 - val_loss: 579.3132 - val_accuracy: 0.7966\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 738.1089 - accuracy: 0.7194 - val_loss: 594.4789 - val_accuracy: 0.8039\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 731.5218 - accuracy: 0.7256 - val_loss: 579.9830 - val_accuracy: 0.8043\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 730.8840 - accuracy: 0.7258 - val_loss: 579.0839 - val_accuracy: 0.7987\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 744.4641 - accuracy: 0.7239 - val_loss: 603.8180 - val_accuracy: 0.7853\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 738.8064 - accuracy: 0.7172 - val_loss: 587.4849 - val_accuracy: 0.8053\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 732.3181 - accuracy: 0.7251 - val_loss: 581.1052 - val_accuracy: 0.8077\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 727.8949 - accuracy: 0.7246 - val_loss: 578.7499 - val_accuracy: 0.7936\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 728.5986 - accuracy: 0.7209 - val_loss: 579.0000 - val_accuracy: 0.8074\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 729.6141 - accuracy: 0.7265 - val_loss: 579.0050 - val_accuracy: 0.8069\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 730.3186 - accuracy: 0.7241 - val_loss: 583.3692 - val_accuracy: 0.7983\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 727.5987 - accuracy: 0.7299 - val_loss: 578.6215 - val_accuracy: 0.8051\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 735.4358 - accuracy: 0.7185 - val_loss: 595.5829 - val_accuracy: 0.8043\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 737.1809 - accuracy: 0.7260 - val_loss: 580.2249 - val_accuracy: 0.8015\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.0748 - accuracy: 0.7223 - val_loss: 582.4540 - val_accuracy: 0.8054\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 732.5364 - accuracy: 0.7213 - val_loss: 584.4083 - val_accuracy: 0.7960\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 734.0753 - accuracy: 0.7266 - val_loss: 589.4302 - val_accuracy: 0.8031\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 732.3316 - accuracy: 0.7242 - val_loss: 579.5384 - val_accuracy: 0.8099\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 727.5468 - accuracy: 0.7246 - val_loss: 579.3103 - val_accuracy: 0.8054\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 728.0024 - accuracy: 0.7255 - val_loss: 578.8828 - val_accuracy: 0.8072\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 731.1497 - accuracy: 0.7199 - val_loss: 586.4372 - val_accuracy: 0.7987\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 732.5631 - accuracy: 0.7245 - val_loss: 581.5479 - val_accuracy: 0.8005\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 731.6491 - accuracy: 0.7223 - val_loss: 585.4091 - val_accuracy: 0.8065\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 732.0296 - accuracy: 0.7272 - val_loss: 577.4603 - val_accuracy: 0.8028\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 726.7643 - accuracy: 0.7264 - val_loss: 577.8876 - val_accuracy: 0.8037\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 727.8345 - accuracy: 0.7244 - val_loss: 577.0937 - val_accuracy: 0.8034\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 741.5786 - accuracy: 0.7151 - val_loss: 588.9122 - val_accuracy: 0.7949\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 734.6494 - accuracy: 0.7275 - val_loss: 579.0753 - val_accuracy: 0.7925\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 728.0745 - accuracy: 0.7191 - val_loss: 579.7704 - val_accuracy: 0.8073\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 733.9633 - accuracy: 0.7262 - val_loss: 581.2089 - val_accuracy: 0.7995\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 729.4203 - accuracy: 0.7246 - val_loss: 583.5839 - val_accuracy: 0.8080\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 730.0452 - accuracy: 0.7250 - val_loss: 579.5757 - val_accuracy: 0.8072\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 729.1163 - accuracy: 0.7259 - val_loss: 591.8135 - val_accuracy: 0.7985\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 743.2288 - accuracy: 0.7193 - val_loss: 580.8887 - val_accuracy: 0.8052\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 730.7802 - accuracy: 0.7232 - val_loss: 581.4304 - val_accuracy: 0.8080\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 727.0593 - accuracy: 0.7246 - val_loss: 582.7729 - val_accuracy: 0.7983\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 737.3353 - accuracy: 0.7224 - val_loss: 602.6760 - val_accuracy: 0.7916\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 728.9147 - accuracy: 0.7281 - val_loss: 580.4499 - val_accuracy: 0.7883\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 730.0230 - accuracy: 0.7144 - val_loss: 588.1777 - val_accuracy: 0.8055\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 729.2889 - accuracy: 0.7302 - val_loss: 578.0062 - val_accuracy: 0.8048\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 725.7073 - accuracy: 0.7233 - val_loss: 576.2227 - val_accuracy: 0.8080\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 725.5044 - accuracy: 0.7313 - val_loss: 576.4333 - val_accuracy: 0.7968\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.7363 - accuracy: 0.7166 - val_loss: 582.3406 - val_accuracy: 0.7937\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 727.7921 - accuracy: 0.7304 - val_loss: 579.1747 - val_accuracy: 0.7928\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 731.7053 - accuracy: 0.7196 - val_loss: 577.8568 - val_accuracy: 0.7992\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 731.5159 - accuracy: 0.7287 - val_loss: 586.1141 - val_accuracy: 0.8043\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 740.7964 - accuracy: 0.7226 - val_loss: 587.7152 - val_accuracy: 0.7948\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 728.2527 - accuracy: 0.7229 - val_loss: 585.0767 - val_accuracy: 0.8064\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 725.2103 - accuracy: 0.7300 - val_loss: 579.8132 - val_accuracy: 0.8092\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 724.7498 - accuracy: 0.7250 - val_loss: 575.2682 - val_accuracy: 0.8052\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 721.8258 - accuracy: 0.7331 - val_loss: 580.0891 - val_accuracy: 0.8026\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 724.9199 - accuracy: 0.7198 - val_loss: 576.0399 - val_accuracy: 0.8047\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 728.7886 - accuracy: 0.7293 - val_loss: 580.7491 - val_accuracy: 0.8051\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 726.8099 - accuracy: 0.7223 - val_loss: 579.3101 - val_accuracy: 0.8044\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 726.3384 - accuracy: 0.7307 - val_loss: 576.6174 - val_accuracy: 0.8009\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 726.2284 - accuracy: 0.7261 - val_loss: 579.5737 - val_accuracy: 0.8050\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 722.2023 - accuracy: 0.7265 - val_loss: 575.9655 - val_accuracy: 0.7978\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 721.7037 - accuracy: 0.7277 - val_loss: 576.8399 - val_accuracy: 0.8062\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.6511 - accuracy: 0.7316 - val_loss: 581.9213 - val_accuracy: 0.8030\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 732.0208 - accuracy: 0.7174 - val_loss: 575.5754 - val_accuracy: 0.8051\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 723.8432 - accuracy: 0.7301 - val_loss: 576.1511 - val_accuracy: 0.8029\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 729.9558 - accuracy: 0.7268 - val_loss: 583.2776 - val_accuracy: 0.7965\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 738.8785 - accuracy: 0.7140 - val_loss: 579.7566 - val_accuracy: 0.8073\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 729.2909 - accuracy: 0.7206 - val_loss: 578.1324 - val_accuracy: 0.8078\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 730.8684 - accuracy: 0.7225 - val_loss: 592.8345 - val_accuracy: 0.7980\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 729.7808 - accuracy: 0.7279 - val_loss: 584.3761 - val_accuracy: 0.7772\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 727.1525 - accuracy: 0.7242 - val_loss: 583.0349 - val_accuracy: 0.7947\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 732.0969 - accuracy: 0.7267 - val_loss: 593.7212 - val_accuracy: 0.8082\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 735.0364 - accuracy: 0.7255 - val_loss: 608.3294 - val_accuracy: 0.7983\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 743.3792 - accuracy: 0.7252 - val_loss: 580.7764 - val_accuracy: 0.7986\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 729.0458 - accuracy: 0.7259 - val_loss: 609.6005 - val_accuracy: 0.8064\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 748.4922 - accuracy: 0.7279 - val_loss: 585.6213 - val_accuracy: 0.7886\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 738.3261 - accuracy: 0.7215 - val_loss: 579.8610 - val_accuracy: 0.7962\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 727.2048 - accuracy: 0.7248 - val_loss: 578.1680 - val_accuracy: 0.7981\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 725.5019 - accuracy: 0.7270 - val_loss: 584.9510 - val_accuracy: 0.8000\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 730.5638 - accuracy: 0.7227 - val_loss: 574.7281 - val_accuracy: 0.8039\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 725.1667 - accuracy: 0.7279 - val_loss: 582.7565 - val_accuracy: 0.8048\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 728.9694 - accuracy: 0.7224 - val_loss: 580.7946 - val_accuracy: 0.7953\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 724.5548 - accuracy: 0.7277 - val_loss: 575.8962 - val_accuracy: 0.7913\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 721.2021 - accuracy: 0.7254 - val_loss: 575.7125 - val_accuracy: 0.7907\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.9849 - accuracy: 0.7264 - val_loss: 574.7281 - val_accuracy: 0.8023\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 717.9642 - accuracy: 0.7350 - val_loss: 574.7331 - val_accuracy: 0.8064\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 723.8043 - accuracy: 0.7234 - val_loss: 579.0685 - val_accuracy: 0.8019\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 723.0518 - accuracy: 0.7283 - val_loss: 575.9227 - val_accuracy: 0.8014\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 722.0807 - accuracy: 0.7215 - val_loss: 582.7830 - val_accuracy: 0.8055\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.4835 - accuracy: 0.7245 - val_loss: 586.3604 - val_accuracy: 0.8037\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 745.6287 - accuracy: 0.7202 - val_loss: 587.5200 - val_accuracy: 0.8019\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.5487 - accuracy: 0.7234 - val_loss: 587.5052 - val_accuracy: 0.7948\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 728.5232 - accuracy: 0.7189 - val_loss: 588.7426 - val_accuracy: 0.7989\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 727.8190 - accuracy: 0.7268 - val_loss: 578.6105 - val_accuracy: 0.7971\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 728.7695 - accuracy: 0.7284 - val_loss: 578.4274 - val_accuracy: 0.7933\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 721.4924 - accuracy: 0.7285 - val_loss: 573.5762 - val_accuracy: 0.8049\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.5435 - accuracy: 0.7298 - val_loss: 589.4063 - val_accuracy: 0.7839\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 734.6345 - accuracy: 0.7208 - val_loss: 585.8828 - val_accuracy: 0.8038\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 725.7681 - accuracy: 0.7308 - val_loss: 578.0176 - val_accuracy: 0.8021\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 722.5903 - accuracy: 0.7262 - val_loss: 582.1214 - val_accuracy: 0.8051\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 727.3177 - accuracy: 0.7225 - val_loss: 583.9113 - val_accuracy: 0.8000\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 742.0828 - accuracy: 0.7289 - val_loss: 579.9312 - val_accuracy: 0.7878\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 737.5937 - accuracy: 0.7216 - val_loss: 593.4673 - val_accuracy: 0.7973\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 729.0219 - accuracy: 0.7205 - val_loss: 581.6931 - val_accuracy: 0.8064\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 725.5212 - accuracy: 0.7248 - val_loss: 580.0527 - val_accuracy: 0.7957\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 721.2040 - accuracy: 0.7296 - val_loss: 576.4685 - val_accuracy: 0.8055\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 718.1738 - accuracy: 0.7273 - val_loss: 576.7217 - val_accuracy: 0.8034\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 723.2453 - accuracy: 0.7181 - val_loss: 579.3006 - val_accuracy: 0.8048\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 724.7349 - accuracy: 0.7295 - val_loss: 589.0563 - val_accuracy: 0.8024\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 719.6268 - accuracy: 0.7300 - val_loss: 574.1126 - val_accuracy: 0.8056\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 717.3638 - accuracy: 0.7314 - val_loss: 577.0574 - val_accuracy: 0.8024\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 725.8154 - accuracy: 0.7273 - val_loss: 578.9938 - val_accuracy: 0.8045\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 723.9989 - accuracy: 0.7231 - val_loss: 581.2899 - val_accuracy: 0.8061\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 729.3140 - accuracy: 0.7317 - val_loss: 590.4109 - val_accuracy: 0.8042\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 742.3201 - accuracy: 0.7183 - val_loss: 591.7216 - val_accuracy: 0.7892\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 730.5579 - accuracy: 0.7241 - val_loss: 575.7576 - val_accuracy: 0.7990\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 729.4478 - accuracy: 0.7228 - val_loss: 581.5734 - val_accuracy: 0.8007\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 726.7206 - accuracy: 0.7215 - val_loss: 575.5296 - val_accuracy: 0.8067\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 724.1930 - accuracy: 0.7269 - val_loss: 577.1274 - val_accuracy: 0.7986\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 721.8730 - accuracy: 0.7239 - val_loss: 582.3682 - val_accuracy: 0.7940\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 720.3548 - accuracy: 0.7248 - val_loss: 575.5783 - val_accuracy: 0.8017\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 719.2972 - accuracy: 0.7249 - val_loss: 576.9260 - val_accuracy: 0.8002\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.4937 - accuracy: 0.7256 - val_loss: 575.9907 - val_accuracy: 0.8015\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 722.0988 - accuracy: 0.7325 - val_loss: 583.8590 - val_accuracy: 0.8063\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 731.6392 - accuracy: 0.7229 - val_loss: 588.6964 - val_accuracy: 0.7750\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 736.2613 - accuracy: 0.7245 - val_loss: 579.3162 - val_accuracy: 0.8051\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 725.9713 - accuracy: 0.7190 - val_loss: 579.9631 - val_accuracy: 0.7999\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 723.2304 - accuracy: 0.7238 - val_loss: 582.3755 - val_accuracy: 0.7950\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.3267 - accuracy: 0.7286 - val_loss: 576.2640 - val_accuracy: 0.8041\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 718.9352 - accuracy: 0.7268 - val_loss: 576.5037 - val_accuracy: 0.8037\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 721.9098 - accuracy: 0.7257 - val_loss: 587.4554 - val_accuracy: 0.8037\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.1769 - accuracy: 0.7256 - val_loss: 588.6569 - val_accuracy: 0.8022\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 723.3760 - accuracy: 0.7282 - val_loss: 579.9679 - val_accuracy: 0.8001\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 732.3853 - accuracy: 0.7293 - val_loss: 577.0845 - val_accuracy: 0.7879\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 722.8766 - accuracy: 0.7244 - val_loss: 575.3519 - val_accuracy: 0.7957\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 718.5250 - accuracy: 0.7267 - val_loss: 578.7175 - val_accuracy: 0.7958\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 728.1793 - accuracy: 0.7260 - val_loss: 583.8790 - val_accuracy: 0.8037\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 727.2197 - accuracy: 0.7309 - val_loss: 588.8549 - val_accuracy: 0.8074\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 726.6017 - accuracy: 0.7166 - val_loss: 573.9279 - val_accuracy: 0.8018\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 718.0530 - accuracy: 0.7314 - val_loss: 577.7387 - val_accuracy: 0.8021\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 716.2439 - accuracy: 0.7320 - val_loss: 573.5179 - val_accuracy: 0.8044\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 723.1159 - accuracy: 0.7193 - val_loss: 576.0944 - val_accuracy: 0.7961\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 718.9925 - accuracy: 0.7287 - val_loss: 574.5938 - val_accuracy: 0.7817\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 717.8283 - accuracy: 0.7267 - val_loss: 578.7475 - val_accuracy: 0.8005\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 718.4446 - accuracy: 0.7296 - val_loss: 577.5775 - val_accuracy: 0.8093\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 725.1559 - accuracy: 0.7237 - val_loss: 589.2079 - val_accuracy: 0.7972\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 728.1786 - accuracy: 0.7258 - val_loss: 578.4048 - val_accuracy: 0.7885\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 719.8218 - accuracy: 0.7307 - val_loss: 577.2879 - val_accuracy: 0.8019\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 717.0471 - accuracy: 0.7304 - val_loss: 578.8143 - val_accuracy: 0.8080\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 723.3521 - accuracy: 0.7314 - val_loss: 577.4196 - val_accuracy: 0.7920\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 717.5297 - accuracy: 0.7293 - val_loss: 576.3960 - val_accuracy: 0.8024\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 731.8718 - accuracy: 0.7187 - val_loss: 580.3859 - val_accuracy: 0.8042\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 737.6852 - accuracy: 0.7248 - val_loss: 588.2549 - val_accuracy: 0.8065\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 734.4968 - accuracy: 0.7208 - val_loss: 576.0648 - val_accuracy: 0.7916\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 725.4472 - accuracy: 0.7312 - val_loss: 577.3785 - val_accuracy: 0.7927\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 720.1301 - accuracy: 0.7258 - val_loss: 578.6132 - val_accuracy: 0.8054\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 723.0616 - accuracy: 0.7277 - val_loss: 573.9352 - val_accuracy: 0.8071\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.3945 - accuracy: 0.7254 - val_loss: 574.0169 - val_accuracy: 0.7985\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 720.7507 - accuracy: 0.7313 - val_loss: 586.8755 - val_accuracy: 0.7974\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 725.9180 - accuracy: 0.7214 - val_loss: 580.1643 - val_accuracy: 0.7946\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 720.5823 - accuracy: 0.7309 - val_loss: 574.4170 - val_accuracy: 0.7981\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 723.1990 - accuracy: 0.7231 - val_loss: 574.4361 - val_accuracy: 0.8009\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 723.2269 - accuracy: 0.7253 - val_loss: 603.6303 - val_accuracy: 0.8047\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 753.3185 - accuracy: 0.7283 - val_loss: 604.0746 - val_accuracy: 0.8081\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 739.3378 - accuracy: 0.7273 - val_loss: 589.1633 - val_accuracy: 0.7937\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 722.3349 - accuracy: 0.7205 - val_loss: 579.9512 - val_accuracy: 0.7999\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 722.7911 - accuracy: 0.7331 - val_loss: 577.1533 - val_accuracy: 0.7984\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 727.7894 - accuracy: 0.7224 - val_loss: 575.6017 - val_accuracy: 0.8035\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 727.6858 - accuracy: 0.7273 - val_loss: 577.4234 - val_accuracy: 0.8069\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 724.7989 - accuracy: 0.7280 - val_loss: 583.1155 - val_accuracy: 0.7951\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 722.7770 - accuracy: 0.7309 - val_loss: 575.3330 - val_accuracy: 0.8012\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 720.8111 - accuracy: 0.7311 - val_loss: 574.5038 - val_accuracy: 0.7986\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 718.7365 - accuracy: 0.7222 - val_loss: 575.3112 - val_accuracy: 0.8047\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 717.5944 - accuracy: 0.7283 - val_loss: 573.4100 - val_accuracy: 0.8038\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 717.0396 - accuracy: 0.7284 - val_loss: 572.2631 - val_accuracy: 0.8046\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 717.2273 - accuracy: 0.7311 - val_loss: 575.8069 - val_accuracy: 0.8057\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 714.0660 - accuracy: 0.7319 - val_loss: 574.2062 - val_accuracy: 0.7963\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 719.8704 - accuracy: 0.7242 - val_loss: 576.2156 - val_accuracy: 0.8020\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 722.3566 - accuracy: 0.7305 - val_loss: 575.7150 - val_accuracy: 0.8057\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 715.8212 - accuracy: 0.7268 - val_loss: 574.6989 - val_accuracy: 0.8027\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 717.5746 - accuracy: 0.7362 - val_loss: 574.8701 - val_accuracy: 0.7948\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 716.2623 - accuracy: 0.7193 - val_loss: 585.2020 - val_accuracy: 0.7987\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 719.1447 - accuracy: 0.7280 - val_loss: 580.2808 - val_accuracy: 0.8060\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 718.5829 - accuracy: 0.7260 - val_loss: 575.8151 - val_accuracy: 0.8030\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 718.8011 - accuracy: 0.7279 - val_loss: 574.0485 - val_accuracy: 0.7972\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 714.9480 - accuracy: 0.7309 - val_loss: 578.5987 - val_accuracy: 0.8061\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 718.9196 - accuracy: 0.7249 - val_loss: 578.2819 - val_accuracy: 0.8060\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 716.4709 - accuracy: 0.7298 - val_loss: 575.0282 - val_accuracy: 0.8022\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 719.5264 - accuracy: 0.7251 - val_loss: 578.4532 - val_accuracy: 0.7964\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 717.8938 - accuracy: 0.7359 - val_loss: 586.8328 - val_accuracy: 0.7985\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 730.7994 - accuracy: 0.7209 - val_loss: 590.1332 - val_accuracy: 0.8025\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 732.4427 - accuracy: 0.7289 - val_loss: 583.2057 - val_accuracy: 0.7908\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 725.3936 - accuracy: 0.7169 - val_loss: 583.1853 - val_accuracy: 0.8068\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 730.1708 - accuracy: 0.7313 - val_loss: 602.8179 - val_accuracy: 0.7939\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 741.9706 - accuracy: 0.7217 - val_loss: 585.0674 - val_accuracy: 0.7994\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 727.8624 - accuracy: 0.7255 - val_loss: 583.2414 - val_accuracy: 0.7947\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 731.6312 - accuracy: 0.7089 - val_loss: 588.6021 - val_accuracy: 0.8028\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 726.2400 - accuracy: 0.7269 - val_loss: 584.3563 - val_accuracy: 0.8025\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 720.6041 - accuracy: 0.7288 - val_loss: 576.4801 - val_accuracy: 0.7973\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 721.9459 - accuracy: 0.7261 - val_loss: 576.8145 - val_accuracy: 0.8035\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 717.4849 - accuracy: 0.7276 - val_loss: 578.0936 - val_accuracy: 0.7911\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 717.2980 - accuracy: 0.7320 - val_loss: 577.0533 - val_accuracy: 0.7941\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 717.4928 - accuracy: 0.7261 - val_loss: 574.4448 - val_accuracy: 0.7993\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 716.0172 - accuracy: 0.7299 - val_loss: 575.3251 - val_accuracy: 0.7963\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 718.2036 - accuracy: 0.7278 - val_loss: 577.3997 - val_accuracy: 0.8046\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 719.6610 - accuracy: 0.7276 - val_loss: 579.6788 - val_accuracy: 0.8046\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 721.4122 - accuracy: 0.7231 - val_loss: 576.6721 - val_accuracy: 0.7995\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 714.5964 - accuracy: 0.7277 - val_loss: 576.2933 - val_accuracy: 0.8025\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 713.2327 - accuracy: 0.7359 - val_loss: 573.8448 - val_accuracy: 0.8023\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 717.0836 - accuracy: 0.7303 - val_loss: 577.0957 - val_accuracy: 0.8052\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 722.2737 - accuracy: 0.7286 - val_loss: 574.6407 - val_accuracy: 0.7989\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 714.8537 - accuracy: 0.7339 - val_loss: 574.4097 - val_accuracy: 0.8022\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 721.7709 - accuracy: 0.7224 - val_loss: 590.3256 - val_accuracy: 0.8069\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 725.3700 - accuracy: 0.7330 - val_loss: 579.0950 - val_accuracy: 0.8019\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 726.6685 - accuracy: 0.7248 - val_loss: 580.1115 - val_accuracy: 0.7966\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 731.7543 - accuracy: 0.7223 - val_loss: 583.4178 - val_accuracy: 0.7968\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 723.1465 - accuracy: 0.7289 - val_loss: 574.2060 - val_accuracy: 0.7992\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 719.9203 - accuracy: 0.7243 - val_loss: 585.3293 - val_accuracy: 0.8046\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 719.8051 - accuracy: 0.7226 - val_loss: 576.2112 - val_accuracy: 0.8007\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 719.2372 - accuracy: 0.7282 - val_loss: 575.3812 - val_accuracy: 0.8010\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 722.0579 - accuracy: 0.7209 - val_loss: 581.6786 - val_accuracy: 0.7905\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 720.8438 - accuracy: 0.7219 - val_loss: 584.5814 - val_accuracy: 0.8029\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 722.5834 - accuracy: 0.7259 - val_loss: 589.7829 - val_accuracy: 0.8025\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 721.4958 - accuracy: 0.7204 - val_loss: 589.9169 - val_accuracy: 0.8002\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 727.4261 - accuracy: 0.7245 - val_loss: 578.1554 - val_accuracy: 0.7979\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 729.4112 - accuracy: 0.7280 - val_loss: 581.0397 - val_accuracy: 0.8068\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 718.1041 - accuracy: 0.7256 - val_loss: 574.7803 - val_accuracy: 0.8032\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 718.0792 - accuracy: 0.7226 - val_loss: 575.2513 - val_accuracy: 0.8043\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 715.1910 - accuracy: 0.7328 - val_loss: 575.4986 - val_accuracy: 0.8026\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 713.7427 - accuracy: 0.7334 - val_loss: 571.8096 - val_accuracy: 0.8029\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 713.6266 - accuracy: 0.7290 - val_loss: 574.5953 - val_accuracy: 0.8073\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 723.0035 - accuracy: 0.7261 - val_loss: 574.9794 - val_accuracy: 0.7841\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 727.2265 - accuracy: 0.7284 - val_loss: 581.7325 - val_accuracy: 0.7964\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 724.8009 - accuracy: 0.7233 - val_loss: 579.7863 - val_accuracy: 0.8036\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 724.3962 - accuracy: 0.7231 - val_loss: 578.4523 - val_accuracy: 0.8023\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 716.9766 - accuracy: 0.7245 - val_loss: 572.8981 - val_accuracy: 0.8022\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 712.7990 - accuracy: 0.7308 - val_loss: 575.3854 - val_accuracy: 0.8023\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 712.0132 - accuracy: 0.7347 - val_loss: 575.8112 - val_accuracy: 0.8044\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 712.1348 - accuracy: 0.7308 - val_loss: 576.8483 - val_accuracy: 0.8007\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 718.7294 - accuracy: 0.7214 - val_loss: 574.1797 - val_accuracy: 0.8064\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 717.7906 - accuracy: 0.7304 - val_loss: 574.0931 - val_accuracy: 0.8044\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 714.2869 - accuracy: 0.7233 - val_loss: 574.7877 - val_accuracy: 0.8068\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 714.8772 - accuracy: 0.7270 - val_loss: 577.3998 - val_accuracy: 0.8043\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 719.6588 - accuracy: 0.7261 - val_loss: 599.1371 - val_accuracy: 0.8019\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 782.0338 - accuracy: 0.7266 - val_loss: 590.1191 - val_accuracy: 0.7880\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 753.4109 - accuracy: 0.7332 - val_loss: 580.7531 - val_accuracy: 0.8000\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 733.9316 - accuracy: 0.7194 - val_loss: 575.8210 - val_accuracy: 0.7784\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 724.0247 - accuracy: 0.7226 - val_loss: 583.1001 - val_accuracy: 0.8032\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 725.2402 - accuracy: 0.7321 - val_loss: 583.1420 - val_accuracy: 0.7992\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 731.9279 - accuracy: 0.7212 - val_loss: 582.4553 - val_accuracy: 0.8087\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 719.7023 - accuracy: 0.7283 - val_loss: 575.9810 - val_accuracy: 0.7943\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 713.8422 - accuracy: 0.7309 - val_loss: 576.2521 - val_accuracy: 0.8081\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 725.3463 - accuracy: 0.7156 - val_loss: 578.8386 - val_accuracy: 0.8047\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 720.6671 - accuracy: 0.7267 - val_loss: 572.4799 - val_accuracy: 0.8061\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 716.6622 - accuracy: 0.7252 - val_loss: 576.0576 - val_accuracy: 0.8025\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 714.8979 - accuracy: 0.7317 - val_loss: 575.4755 - val_accuracy: 0.8024\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 712.1362 - accuracy: 0.7321 - val_loss: 575.0923 - val_accuracy: 0.8076\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 721.6272 - accuracy: 0.7195 - val_loss: 575.5273 - val_accuracy: 0.7829\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 718.6042 - accuracy: 0.7289 - val_loss: 575.8470 - val_accuracy: 0.7954\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 713.9977 - accuracy: 0.7279 - val_loss: 576.0411 - val_accuracy: 0.8036\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 715.5582 - accuracy: 0.7286 - val_loss: 582.2071 - val_accuracy: 0.8009\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 716.9716 - accuracy: 0.7250 - val_loss: 586.6533 - val_accuracy: 0.7997\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 715.5737 - accuracy: 0.7330 - val_loss: 574.0469 - val_accuracy: 0.8048\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 714.7925 - accuracy: 0.7224 - val_loss: 581.4944 - val_accuracy: 0.7972\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 716.1116 - accuracy: 0.7262 - val_loss: 580.7640 - val_accuracy: 0.8011\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 714.3132 - accuracy: 0.7298 - val_loss: 577.6634 - val_accuracy: 0.8041\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 713.6965 - accuracy: 0.7293 - val_loss: 576.1385 - val_accuracy: 0.7992\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 711.8296 - accuracy: 0.7318 - val_loss: 580.1978 - val_accuracy: 0.8053\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 718.6904 - accuracy: 0.7234 - val_loss: 574.6098 - val_accuracy: 0.8028\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 713.5347 - accuracy: 0.7344 - val_loss: 575.8218 - val_accuracy: 0.8030\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 736.1283 - accuracy: 0.6928 - val_loss: 579.4332 - val_accuracy: 0.7534\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 723.9401 - accuracy: 0.7242 - val_loss: 575.8452 - val_accuracy: 0.7870\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 718.8984 - accuracy: 0.7230 - val_loss: 575.1371 - val_accuracy: 0.7994\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 716.5372 - accuracy: 0.7314 - val_loss: 574.4784 - val_accuracy: 0.8088\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 716.3245 - accuracy: 0.7268 - val_loss: 575.0687 - val_accuracy: 0.7921\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 711.7427 - accuracy: 0.7325 - val_loss: 574.5565 - val_accuracy: 0.7826\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 716.0194 - accuracy: 0.7236 - val_loss: 574.2447 - val_accuracy: 0.7987\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 717.1877 - accuracy: 0.7314 - val_loss: 578.1008 - val_accuracy: 0.8036\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 722.9886 - accuracy: 0.7204 - val_loss: 576.2255 - val_accuracy: 0.8017\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 714.7690 - accuracy: 0.7287 - val_loss: 574.7372 - val_accuracy: 0.8061\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 713.8283 - accuracy: 0.7302 - val_loss: 575.6996 - val_accuracy: 0.8013\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 711.5579 - accuracy: 0.7295 - val_loss: 574.6579 - val_accuracy: 0.8053\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 709.7937 - accuracy: 0.7330 - val_loss: 572.4339 - val_accuracy: 0.8026\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 708.8401 - accuracy: 0.7357 - val_loss: 574.9038 - val_accuracy: 0.7955\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 714.5942 - accuracy: 0.7281 - val_loss: 574.4053 - val_accuracy: 0.7991\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 715.9172 - accuracy: 0.7316 - val_loss: 579.7512 - val_accuracy: 0.7994\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 716.6281 - accuracy: 0.7317 - val_loss: 579.6306 - val_accuracy: 0.8030\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 714.9706 - accuracy: 0.7307 - val_loss: 576.7379 - val_accuracy: 0.7832\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 712.6932 - accuracy: 0.7313 - val_loss: 573.8848 - val_accuracy: 0.7988\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 713.1826 - accuracy: 0.7311 - val_loss: 577.1578 - val_accuracy: 0.8035\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 715.6622 - accuracy: 0.7228 - val_loss: 576.3420 - val_accuracy: 0.8028\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 715.2498 - accuracy: 0.7309 - val_loss: 577.5195 - val_accuracy: 0.8058\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 712.7708 - accuracy: 0.7303 - val_loss: 574.4792 - val_accuracy: 0.8018\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 712.6400 - accuracy: 0.7283 - val_loss: 574.3427 - val_accuracy: 0.7902\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 713.1786 - accuracy: 0.7293 - val_loss: 572.6259 - val_accuracy: 0.8046\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 716.7349 - accuracy: 0.7135 - val_loss: 578.7970 - val_accuracy: 0.8000\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 712.4092 - accuracy: 0.7298 - val_loss: 580.3167 - val_accuracy: 0.8064\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 723.1281 - accuracy: 0.7254 - val_loss: 574.5449 - val_accuracy: 0.8028\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 718.0432 - accuracy: 0.7224 - val_loss: 574.5271 - val_accuracy: 0.8019\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 713.8031 - accuracy: 0.7236 - val_loss: 579.0905 - val_accuracy: 0.8054\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 715.8475 - accuracy: 0.7300 - val_loss: 577.0848 - val_accuracy: 0.7833\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 716.8178 - accuracy: 0.7219 - val_loss: 576.9295 - val_accuracy: 0.8040\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 713.4238 - accuracy: 0.7317 - val_loss: 575.6459 - val_accuracy: 0.8001\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 715.7587 - accuracy: 0.7183 - val_loss: 576.4678 - val_accuracy: 0.8067\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 714.1204 - accuracy: 0.7327 - val_loss: 577.3193 - val_accuracy: 0.8039\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 714.2781 - accuracy: 0.7295 - val_loss: 576.0319 - val_accuracy: 0.8006\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 716.0094 - accuracy: 0.7233 - val_loss: 580.5853 - val_accuracy: 0.7966\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 719.0079 - accuracy: 0.7287 - val_loss: 581.2375 - val_accuracy: 0.7891\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 713.8501 - accuracy: 0.7290 - val_loss: 578.2037 - val_accuracy: 0.7937\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 713.1636 - accuracy: 0.7273 - val_loss: 577.7080 - val_accuracy: 0.8018\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 712.7411 - accuracy: 0.7296 - val_loss: 573.7777 - val_accuracy: 0.8022\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 710.1380 - accuracy: 0.7282 - val_loss: 572.8954 - val_accuracy: 0.8056\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 709.5441 - accuracy: 0.7339 - val_loss: 574.5843 - val_accuracy: 0.8004\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 710.4385 - accuracy: 0.7242 - val_loss: 574.2271 - val_accuracy: 0.8023\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 710.2691 - accuracy: 0.7369 - val_loss: 573.5896 - val_accuracy: 0.8022\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 710.6484 - accuracy: 0.7317 - val_loss: 575.8171 - val_accuracy: 0.7926\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 712.3263 - accuracy: 0.7323 - val_loss: 579.2358 - val_accuracy: 0.8049\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample1)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer1)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool2)\n",
        "\n",
        "# Define the convolutional layer\n",
        "#conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(input_layer1)\n",
        "upsample = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv4 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer2)\n",
        "pool4 = layers.MaxPooling2D(pool_size=(1, 1))(conv4)\n",
        "conv5 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool4)\n",
        "pool5 = layers.MaxPooling2D(pool_size=(1, 1))(conv5)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool5)\n",
        "# Define the output layer\n",
        "output_layer = layers.Add()([output_layer1, output_layer2 ])\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNu0ygUl7Q27",
        "outputId": "7623ffb5-2aa7-439c-fe16-ef93de979cbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 64ms/step - loss: 8473.9160 - accuracy: 0.0141 - val_loss: 5301.2915 - val_accuracy: 0.0171\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 5824.8960 - accuracy: 0.0316 - val_loss: 3812.9812 - val_accuracy: 0.1134\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 4111.6006 - accuracy: 0.0455 - val_loss: 2603.9600 - val_accuracy: 0.0404\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 2819.6997 - accuracy: 0.0585 - val_loss: 2007.6395 - val_accuracy: 0.3687\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 2015.6654 - accuracy: 0.1132 - val_loss: 1515.9672 - val_accuracy: 0.3946\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1559.6344 - accuracy: 0.1675 - val_loss: 1199.2958 - val_accuracy: 0.3388\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 1354.0702 - accuracy: 0.3052 - val_loss: 1054.5759 - val_accuracy: 0.5298\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 1211.5569 - accuracy: 0.4177 - val_loss: 962.2643 - val_accuracy: 0.5705\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1127.8314 - accuracy: 0.4436 - val_loss: 896.6768 - val_accuracy: 0.5659\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1071.5059 - accuracy: 0.5199 - val_loss: 843.1602 - val_accuracy: 0.6162\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 1024.2319 - accuracy: 0.5502 - val_loss: 798.8795 - val_accuracy: 0.6414\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 990.3835 - accuracy: 0.5769 - val_loss: 751.5740 - val_accuracy: 0.6138\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 960.4160 - accuracy: 0.6076 - val_loss: 740.1924 - val_accuracy: 0.6231\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 927.7349 - accuracy: 0.6161 - val_loss: 721.0963 - val_accuracy: 0.6308\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 907.1480 - accuracy: 0.6172 - val_loss: 695.9185 - val_accuracy: 0.6567\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 893.0266 - accuracy: 0.6241 - val_loss: 685.9595 - val_accuracy: 0.6490\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 885.6078 - accuracy: 0.6272 - val_loss: 679.3812 - val_accuracy: 0.6935\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 870.4579 - accuracy: 0.6246 - val_loss: 678.7600 - val_accuracy: 0.6746\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 862.3380 - accuracy: 0.6257 - val_loss: 663.9583 - val_accuracy: 0.6861\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 852.4570 - accuracy: 0.6347 - val_loss: 652.0743 - val_accuracy: 0.6989\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 849.1736 - accuracy: 0.6398 - val_loss: 656.0768 - val_accuracy: 0.6949\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 844.6340 - accuracy: 0.6431 - val_loss: 651.2258 - val_accuracy: 0.7129\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 851.9173 - accuracy: 0.6338 - val_loss: 669.5599 - val_accuracy: 0.7201\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 850.9244 - accuracy: 0.6507 - val_loss: 666.6898 - val_accuracy: 0.6866\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 1s 62ms/step - loss: 843.8046 - accuracy: 0.6492 - val_loss: 638.5588 - val_accuracy: 0.6818\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 834.0316 - accuracy: 0.6404 - val_loss: 645.0582 - val_accuracy: 0.7281\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 824.3281 - accuracy: 0.6471 - val_loss: 632.9711 - val_accuracy: 0.7179\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 818.7494 - accuracy: 0.6593 - val_loss: 634.7625 - val_accuracy: 0.7201\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 817.3894 - accuracy: 0.6540 - val_loss: 637.1272 - val_accuracy: 0.7142\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 819.9821 - accuracy: 0.6632 - val_loss: 632.0186 - val_accuracy: 0.7316\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 819.2271 - accuracy: 0.6607 - val_loss: 624.5112 - val_accuracy: 0.7107\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 810.2938 - accuracy: 0.6614 - val_loss: 621.0328 - val_accuracy: 0.7205\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 807.1277 - accuracy: 0.6695 - val_loss: 619.8558 - val_accuracy: 0.7028\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 803.5520 - accuracy: 0.6643 - val_loss: 621.0577 - val_accuracy: 0.7296\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 804.2469 - accuracy: 0.6700 - val_loss: 613.2262 - val_accuracy: 0.7181\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 1s 58ms/step - loss: 803.2510 - accuracy: 0.6651 - val_loss: 630.5648 - val_accuracy: 0.7260\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 815.3545 - accuracy: 0.6763 - val_loss: 632.1729 - val_accuracy: 0.7299\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 806.3148 - accuracy: 0.6687 - val_loss: 622.3024 - val_accuracy: 0.7222\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 794.9363 - accuracy: 0.6700 - val_loss: 614.5844 - val_accuracy: 0.7270\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 793.7185 - accuracy: 0.6650 - val_loss: 612.8606 - val_accuracy: 0.7203\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 791.8347 - accuracy: 0.6768 - val_loss: 611.5784 - val_accuracy: 0.7296\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 790.7148 - accuracy: 0.6742 - val_loss: 610.2449 - val_accuracy: 0.7311\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 790.9969 - accuracy: 0.6745 - val_loss: 615.1049 - val_accuracy: 0.7345\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 791.1417 - accuracy: 0.6783 - val_loss: 611.8666 - val_accuracy: 0.7413\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 794.8045 - accuracy: 0.6699 - val_loss: 604.5674 - val_accuracy: 0.7355\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 781.2308 - accuracy: 0.6825 - val_loss: 605.2980 - val_accuracy: 0.7381\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.8826 - accuracy: 0.6772 - val_loss: 609.4027 - val_accuracy: 0.7382\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 781.2076 - accuracy: 0.6801 - val_loss: 602.9346 - val_accuracy: 0.7307\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 776.6396 - accuracy: 0.6812 - val_loss: 602.7996 - val_accuracy: 0.7398\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 788.1089 - accuracy: 0.6867 - val_loss: 642.4221 - val_accuracy: 0.7319\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 793.8475 - accuracy: 0.6788 - val_loss: 619.9009 - val_accuracy: 0.7437\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 780.4606 - accuracy: 0.6781 - val_loss: 603.7337 - val_accuracy: 0.7406\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.7046 - accuracy: 0.6791 - val_loss: 607.3974 - val_accuracy: 0.7350\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 774.1996 - accuracy: 0.6801 - val_loss: 606.1598 - val_accuracy: 0.7421\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 777.7703 - accuracy: 0.6831 - val_loss: 601.9675 - val_accuracy: 0.7399\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 774.4212 - accuracy: 0.6830 - val_loss: 600.0223 - val_accuracy: 0.7412\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 771.3353 - accuracy: 0.6885 - val_loss: 600.3245 - val_accuracy: 0.7456\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 766.3749 - accuracy: 0.6870 - val_loss: 599.1676 - val_accuracy: 0.7437\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 772.2587 - accuracy: 0.6881 - val_loss: 598.0617 - val_accuracy: 0.7483\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 766.7349 - accuracy: 0.6836 - val_loss: 601.6483 - val_accuracy: 0.7491\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 764.1091 - accuracy: 0.6859 - val_loss: 599.8866 - val_accuracy: 0.7445\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 767.8657 - accuracy: 0.6835 - val_loss: 615.9616 - val_accuracy: 0.7492\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 778.9944 - accuracy: 0.6941 - val_loss: 605.3054 - val_accuracy: 0.7575\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 770.8012 - accuracy: 0.6925 - val_loss: 593.4504 - val_accuracy: 0.7553\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 770.6817 - accuracy: 0.6920 - val_loss: 596.2597 - val_accuracy: 0.7530\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.4654 - accuracy: 0.6911 - val_loss: 600.4745 - val_accuracy: 0.7506\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 763.9175 - accuracy: 0.6949 - val_loss: 597.6559 - val_accuracy: 0.7553\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 762.9500 - accuracy: 0.6911 - val_loss: 589.7667 - val_accuracy: 0.7540\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 763.3954 - accuracy: 0.6944 - val_loss: 591.1266 - val_accuracy: 0.7626\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 758.9295 - accuracy: 0.6940 - val_loss: 595.7498 - val_accuracy: 0.7567\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 758.2501 - accuracy: 0.6972 - val_loss: 590.3561 - val_accuracy: 0.7563\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 756.4020 - accuracy: 0.6880 - val_loss: 587.1600 - val_accuracy: 0.7588\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 753.7323 - accuracy: 0.6991 - val_loss: 584.2255 - val_accuracy: 0.7607\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 750.3981 - accuracy: 0.6920 - val_loss: 589.3785 - val_accuracy: 0.7610\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 759.0950 - accuracy: 0.6986 - val_loss: 605.6017 - val_accuracy: 0.7557\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 759.3508 - accuracy: 0.7010 - val_loss: 586.4169 - val_accuracy: 0.7674\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 751.2233 - accuracy: 0.6974 - val_loss: 590.0009 - val_accuracy: 0.7580\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 749.3356 - accuracy: 0.6976 - val_loss: 585.1497 - val_accuracy: 0.7633\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 749.0103 - accuracy: 0.6902 - val_loss: 586.6808 - val_accuracy: 0.7612\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 752.3271 - accuracy: 0.6965 - val_loss: 607.7485 - val_accuracy: 0.7655\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 756.4480 - accuracy: 0.6962 - val_loss: 588.1324 - val_accuracy: 0.7655\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.3256 - accuracy: 0.6960 - val_loss: 595.9877 - val_accuracy: 0.7637\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 749.6608 - accuracy: 0.6944 - val_loss: 583.6584 - val_accuracy: 0.7576\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 745.8954 - accuracy: 0.6920 - val_loss: 592.6215 - val_accuracy: 0.7666\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 750.9850 - accuracy: 0.6961 - val_loss: 578.9097 - val_accuracy: 0.7664\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 744.9064 - accuracy: 0.6957 - val_loss: 592.1388 - val_accuracy: 0.7620\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 750.2386 - accuracy: 0.6948 - val_loss: 579.0503 - val_accuracy: 0.7667\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 741.1243 - accuracy: 0.6957 - val_loss: 576.2653 - val_accuracy: 0.7663\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 739.4786 - accuracy: 0.6959 - val_loss: 577.5592 - val_accuracy: 0.7628\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 739.8748 - accuracy: 0.6954 - val_loss: 576.6330 - val_accuracy: 0.7690\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 738.4554 - accuracy: 0.6990 - val_loss: 578.0532 - val_accuracy: 0.7618\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 740.6197 - accuracy: 0.6999 - val_loss: 580.9232 - val_accuracy: 0.7633\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 745.4957 - accuracy: 0.6993 - val_loss: 582.9127 - val_accuracy: 0.7579\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 752.9182 - accuracy: 0.6966 - val_loss: 583.2042 - val_accuracy: 0.7661\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 740.6519 - accuracy: 0.6960 - val_loss: 571.1733 - val_accuracy: 0.7648\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 738.3397 - accuracy: 0.6994 - val_loss: 572.2034 - val_accuracy: 0.7660\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 733.7159 - accuracy: 0.7009 - val_loss: 578.1528 - val_accuracy: 0.7669\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 746.4178 - accuracy: 0.6978 - val_loss: 571.2190 - val_accuracy: 0.7684\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 737.6271 - accuracy: 0.6925 - val_loss: 579.6519 - val_accuracy: 0.7657\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 738.2601 - accuracy: 0.7017 - val_loss: 580.5719 - val_accuracy: 0.7705\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample1)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer1)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool2)\n",
        "\n",
        "# Define the convolutional layer\n",
        "#conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(input_layer1)\n",
        "upsample = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv4 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer2)\n",
        "pool4 = layers.MaxPooling2D(pool_size=(1, 1))(conv4)\n",
        "conv5 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool4)\n",
        "pool5 = layers.MaxPooling2D(pool_size=(1, 1))(conv5)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool5)\n",
        "# Define the output layer\n",
        "output_layer = layers.Add()([output_layer1, output_layer2 ])\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=None, validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PJ-ntPW7Voa",
        "outputId": "3ab9d9b4-eaa6-4758-e2e1-4f46b87afe4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 2s 103ms/step - loss: 7980.8306 - accuracy: 0.0315 - val_loss: 4672.6118 - val_accuracy: 0.1187\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 5009.8433 - accuracy: 0.0481 - val_loss: 2920.9985 - val_accuracy: 0.2758\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 3359.0894 - accuracy: 0.1676 - val_loss: 2279.3511 - val_accuracy: 0.1771\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 2467.4495 - accuracy: 0.1931 - val_loss: 1825.0149 - val_accuracy: 0.0703\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 2009.4700 - accuracy: 0.2162 - val_loss: 1528.6261 - val_accuracy: 0.1928\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 1715.4910 - accuracy: 0.3498 - val_loss: 1357.0455 - val_accuracy: 0.2349\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 1532.6339 - accuracy: 0.3297 - val_loss: 1218.9728 - val_accuracy: 0.2576\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 1374.8939 - accuracy: 0.4354 - val_loss: 1066.7964 - val_accuracy: 0.2671\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1269.7426 - accuracy: 0.4746 - val_loss: 1004.3160 - val_accuracy: 0.5519\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1204.7086 - accuracy: 0.5460 - val_loss: 959.4095 - val_accuracy: 0.5695\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1144.9768 - accuracy: 0.5937 - val_loss: 907.1554 - val_accuracy: 0.5930\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 1110.0156 - accuracy: 0.5757 - val_loss: 888.2870 - val_accuracy: 0.6034\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1079.8513 - accuracy: 0.5580 - val_loss: 855.9879 - val_accuracy: 0.5966\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1054.5863 - accuracy: 0.5611 - val_loss: 830.5402 - val_accuracy: 0.5899\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1037.3345 - accuracy: 0.5705 - val_loss: 814.4492 - val_accuracy: 0.6222\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 1023.1852 - accuracy: 0.5534 - val_loss: 789.7472 - val_accuracy: 0.6318\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 1011.5872 - accuracy: 0.5918 - val_loss: 781.2385 - val_accuracy: 0.6412\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1001.9355 - accuracy: 0.5850 - val_loss: 782.0782 - val_accuracy: 0.6408\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 993.4109 - accuracy: 0.5898 - val_loss: 761.7767 - val_accuracy: 0.6509\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 983.6035 - accuracy: 0.6000 - val_loss: 743.9117 - val_accuracy: 0.6373\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 971.2027 - accuracy: 0.6024 - val_loss: 741.3394 - val_accuracy: 0.6605\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 967.3583 - accuracy: 0.6232 - val_loss: 735.8353 - val_accuracy: 0.6823\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 961.9030 - accuracy: 0.6079 - val_loss: 734.7710 - val_accuracy: 0.6575\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 955.6417 - accuracy: 0.6286 - val_loss: 720.5186 - val_accuracy: 0.6976\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 951.8181 - accuracy: 0.6304 - val_loss: 716.6794 - val_accuracy: 0.6672\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 943.0483 - accuracy: 0.6343 - val_loss: 716.5737 - val_accuracy: 0.7076\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 941.8300 - accuracy: 0.6309 - val_loss: 723.3287 - val_accuracy: 0.7074\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 939.3554 - accuracy: 0.6491 - val_loss: 711.6994 - val_accuracy: 0.6930\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 939.0463 - accuracy: 0.6421 - val_loss: 718.5414 - val_accuracy: 0.7083\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 936.8530 - accuracy: 0.6371 - val_loss: 714.4517 - val_accuracy: 0.6906\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 928.8723 - accuracy: 0.6564 - val_loss: 711.5720 - val_accuracy: 0.7181\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 922.4616 - accuracy: 0.6363 - val_loss: 700.1195 - val_accuracy: 0.7357\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 932.3653 - accuracy: 0.6502 - val_loss: 700.8578 - val_accuracy: 0.7197\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 922.1201 - accuracy: 0.6406 - val_loss: 693.4709 - val_accuracy: 0.7140\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 920.1700 - accuracy: 0.6639 - val_loss: 694.6415 - val_accuracy: 0.7206\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 917.5814 - accuracy: 0.6566 - val_loss: 706.3230 - val_accuracy: 0.7050\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 914.5600 - accuracy: 0.6605 - val_loss: 693.4075 - val_accuracy: 0.6887\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 910.7064 - accuracy: 0.6560 - val_loss: 701.8549 - val_accuracy: 0.7426\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 911.0124 - accuracy: 0.6581 - val_loss: 716.9633 - val_accuracy: 0.7370\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 913.7610 - accuracy: 0.6686 - val_loss: 690.9389 - val_accuracy: 0.7243\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 905.9108 - accuracy: 0.6660 - val_loss: 683.7685 - val_accuracy: 0.7465\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 902.6500 - accuracy: 0.6605 - val_loss: 689.1462 - val_accuracy: 0.7239\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 905.2083 - accuracy: 0.6570 - val_loss: 700.2162 - val_accuracy: 0.7531\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 913.8731 - accuracy: 0.6718 - val_loss: 691.4037 - val_accuracy: 0.7402\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 912.2090 - accuracy: 0.6672 - val_loss: 679.8093 - val_accuracy: 0.7356\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 900.3999 - accuracy: 0.6651 - val_loss: 686.6923 - val_accuracy: 0.7192\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 896.8912 - accuracy: 0.6690 - val_loss: 680.1930 - val_accuracy: 0.7471\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 899.1785 - accuracy: 0.6656 - val_loss: 685.9560 - val_accuracy: 0.7472\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 896.8734 - accuracy: 0.6717 - val_loss: 674.5670 - val_accuracy: 0.7450\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 892.1959 - accuracy: 0.6745 - val_loss: 679.1879 - val_accuracy: 0.7263\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 889.2302 - accuracy: 0.6781 - val_loss: 676.0378 - val_accuracy: 0.7427\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 885.0566 - accuracy: 0.6673 - val_loss: 679.7526 - val_accuracy: 0.7472\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 886.8962 - accuracy: 0.6738 - val_loss: 676.9086 - val_accuracy: 0.7550\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 888.8101 - accuracy: 0.6755 - val_loss: 676.0198 - val_accuracy: 0.7338\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 884.8559 - accuracy: 0.6695 - val_loss: 677.1433 - val_accuracy: 0.7376\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 887.6086 - accuracy: 0.6666 - val_loss: 688.9882 - val_accuracy: 0.7498\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 886.6141 - accuracy: 0.6737 - val_loss: 670.4530 - val_accuracy: 0.7475\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 883.6188 - accuracy: 0.6658 - val_loss: 668.1859 - val_accuracy: 0.7423\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 882.2540 - accuracy: 0.6671 - val_loss: 675.4365 - val_accuracy: 0.7435\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 879.6121 - accuracy: 0.6788 - val_loss: 673.1914 - val_accuracy: 0.7395\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 882.2916 - accuracy: 0.6681 - val_loss: 673.1404 - val_accuracy: 0.7585\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 874.8240 - accuracy: 0.6800 - val_loss: 669.4470 - val_accuracy: 0.7416\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 872.6517 - accuracy: 0.6672 - val_loss: 672.3114 - val_accuracy: 0.7592\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 874.2008 - accuracy: 0.6713 - val_loss: 670.9521 - val_accuracy: 0.7305\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 873.7143 - accuracy: 0.6733 - val_loss: 671.4104 - val_accuracy: 0.7637\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 869.0688 - accuracy: 0.6764 - val_loss: 669.8480 - val_accuracy: 0.7433\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 872.1434 - accuracy: 0.6695 - val_loss: 664.2818 - val_accuracy: 0.7495\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 868.8006 - accuracy: 0.6796 - val_loss: 665.1567 - val_accuracy: 0.7373\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 865.8326 - accuracy: 0.6743 - val_loss: 665.9843 - val_accuracy: 0.7471\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 866.1354 - accuracy: 0.6792 - val_loss: 666.6066 - val_accuracy: 0.7430\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 864.9233 - accuracy: 0.6713 - val_loss: 666.5704 - val_accuracy: 0.7620\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 865.0419 - accuracy: 0.6855 - val_loss: 663.0239 - val_accuracy: 0.7236\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 863.5377 - accuracy: 0.6812 - val_loss: 669.2473 - val_accuracy: 0.7574\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 864.1860 - accuracy: 0.6740 - val_loss: 668.8393 - val_accuracy: 0.7396\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 864.5243 - accuracy: 0.6808 - val_loss: 671.1335 - val_accuracy: 0.7561\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 859.7255 - accuracy: 0.6771 - val_loss: 657.4681 - val_accuracy: 0.7533\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 857.6116 - accuracy: 0.6790 - val_loss: 664.0203 - val_accuracy: 0.7476\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 858.0286 - accuracy: 0.6790 - val_loss: 663.0238 - val_accuracy: 0.7592\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 857.2156 - accuracy: 0.6851 - val_loss: 663.0419 - val_accuracy: 0.7456\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 854.2235 - accuracy: 0.6788 - val_loss: 662.3351 - val_accuracy: 0.7593\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 856.0167 - accuracy: 0.6859 - val_loss: 673.4692 - val_accuracy: 0.7629\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 858.1207 - accuracy: 0.6865 - val_loss: 663.0719 - val_accuracy: 0.7566\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 852.1595 - accuracy: 0.6751 - val_loss: 664.4258 - val_accuracy: 0.7396\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 856.6545 - accuracy: 0.6934 - val_loss: 674.1745 - val_accuracy: 0.7554\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 857.0876 - accuracy: 0.6766 - val_loss: 662.3293 - val_accuracy: 0.7707\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 854.7722 - accuracy: 0.6785 - val_loss: 667.3917 - val_accuracy: 0.7535\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 855.4454 - accuracy: 0.6773 - val_loss: 678.8358 - val_accuracy: 0.7444\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 862.7601 - accuracy: 0.6828 - val_loss: 660.5463 - val_accuracy: 0.7627\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 859.7044 - accuracy: 0.6670 - val_loss: 663.9424 - val_accuracy: 0.7417\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 849.9760 - accuracy: 0.6820 - val_loss: 656.9219 - val_accuracy: 0.7587\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 845.5969 - accuracy: 0.6893 - val_loss: 660.1940 - val_accuracy: 0.7560\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 842.9380 - accuracy: 0.6845 - val_loss: 655.5424 - val_accuracy: 0.7492\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 841.1180 - accuracy: 0.6863 - val_loss: 660.1520 - val_accuracy: 0.7658\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 842.5358 - accuracy: 0.6913 - val_loss: 656.2305 - val_accuracy: 0.7588\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 841.3557 - accuracy: 0.6838 - val_loss: 658.8348 - val_accuracy: 0.7581\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 840.9377 - accuracy: 0.6866 - val_loss: 665.3808 - val_accuracy: 0.7574\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 843.9889 - accuracy: 0.6821 - val_loss: 668.8304 - val_accuracy: 0.7618\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 841.5186 - accuracy: 0.6894 - val_loss: 666.0143 - val_accuracy: 0.7454\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 847.5374 - accuracy: 0.6793 - val_loss: 666.3333 - val_accuracy: 0.7682\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 851.5571 - accuracy: 0.6815 - val_loss: 667.5735 - val_accuracy: 0.7660\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 850.4642 - accuracy: 0.6867 - val_loss: 658.6078 - val_accuracy: 0.7588\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 839.2946 - accuracy: 0.6884 - val_loss: 665.0367 - val_accuracy: 0.7570\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 836.5796 - accuracy: 0.6835 - val_loss: 658.2305 - val_accuracy: 0.7694\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 836.6540 - accuracy: 0.6884 - val_loss: 670.2414 - val_accuracy: 0.7571\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 839.0181 - accuracy: 0.6839 - val_loss: 652.3452 - val_accuracy: 0.7572\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 838.9209 - accuracy: 0.6975 - val_loss: 656.4407 - val_accuracy: 0.7629\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 837.1182 - accuracy: 0.6877 - val_loss: 658.1826 - val_accuracy: 0.7570\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 835.7018 - accuracy: 0.6895 - val_loss: 664.7567 - val_accuracy: 0.7587\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 840.0568 - accuracy: 0.6875 - val_loss: 660.1176 - val_accuracy: 0.7505\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 841.1078 - accuracy: 0.6692 - val_loss: 653.2486 - val_accuracy: 0.7602\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 838.9296 - accuracy: 0.6922 - val_loss: 661.8732 - val_accuracy: 0.7675\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 835.8600 - accuracy: 0.6750 - val_loss: 656.9657 - val_accuracy: 0.7692\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 830.6110 - accuracy: 0.6777 - val_loss: 654.0258 - val_accuracy: 0.7603\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 828.3658 - accuracy: 0.6884 - val_loss: 651.3337 - val_accuracy: 0.7649\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 826.9532 - accuracy: 0.6882 - val_loss: 651.9150 - val_accuracy: 0.7627\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 826.3682 - accuracy: 0.6783 - val_loss: 658.1855 - val_accuracy: 0.7641\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 824.8085 - accuracy: 0.6832 - val_loss: 656.2211 - val_accuracy: 0.7540\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 825.5483 - accuracy: 0.7023 - val_loss: 652.8119 - val_accuracy: 0.7565\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 822.4149 - accuracy: 0.6864 - val_loss: 652.1179 - val_accuracy: 0.7658\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 821.8987 - accuracy: 0.6788 - val_loss: 650.0720 - val_accuracy: 0.7671\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 821.1811 - accuracy: 0.7008 - val_loss: 676.9664 - val_accuracy: 0.7608\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 832.7994 - accuracy: 0.6820 - val_loss: 656.3982 - val_accuracy: 0.7555\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 836.7848 - accuracy: 0.6835 - val_loss: 667.6902 - val_accuracy: 0.7684\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 848.2876 - accuracy: 0.6847 - val_loss: 663.9985 - val_accuracy: 0.7608\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 831.6840 - accuracy: 0.6927 - val_loss: 682.6992 - val_accuracy: 0.7530\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 825.6721 - accuracy: 0.6908 - val_loss: 655.0156 - val_accuracy: 0.7696\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 820.9685 - accuracy: 0.6882 - val_loss: 661.4317 - val_accuracy: 0.7557\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 822.3969 - accuracy: 0.6887 - val_loss: 655.5243 - val_accuracy: 0.7617\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 819.1787 - accuracy: 0.6837 - val_loss: 655.3314 - val_accuracy: 0.7626\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 821.9017 - accuracy: 0.6807 - val_loss: 656.0023 - val_accuracy: 0.7534\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 821.0684 - accuracy: 0.6865 - val_loss: 657.8204 - val_accuracy: 0.7705\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 820.7068 - accuracy: 0.6763 - val_loss: 657.7263 - val_accuracy: 0.7705\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 819.4081 - accuracy: 0.6870 - val_loss: 651.5607 - val_accuracy: 0.7610\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 816.6084 - accuracy: 0.6886 - val_loss: 653.4065 - val_accuracy: 0.7676\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 820.5458 - accuracy: 0.6887 - val_loss: 657.5729 - val_accuracy: 0.7517\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 821.2391 - accuracy: 0.6837 - val_loss: 656.7989 - val_accuracy: 0.7703\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 819.9757 - accuracy: 0.6964 - val_loss: 660.9902 - val_accuracy: 0.7652\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 820.1326 - accuracy: 0.6807 - val_loss: 654.0865 - val_accuracy: 0.7636\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 817.2987 - accuracy: 0.6842 - val_loss: 659.7560 - val_accuracy: 0.7649\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 822.7875 - accuracy: 0.6824 - val_loss: 667.0505 - val_accuracy: 0.7708\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 824.8412 - accuracy: 0.6847 - val_loss: 660.0136 - val_accuracy: 0.7674\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 818.1278 - accuracy: 0.6923 - val_loss: 665.2182 - val_accuracy: 0.7648\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 818.4777 - accuracy: 0.6785 - val_loss: 657.6354 - val_accuracy: 0.7599\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 814.5008 - accuracy: 0.6958 - val_loss: 650.4582 - val_accuracy: 0.7703\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 813.9749 - accuracy: 0.6817 - val_loss: 655.5319 - val_accuracy: 0.7700\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 814.7597 - accuracy: 0.6816 - val_loss: 654.1888 - val_accuracy: 0.7653\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 818.5457 - accuracy: 0.6902 - val_loss: 660.1588 - val_accuracy: 0.7691\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 818.2426 - accuracy: 0.6897 - val_loss: 652.6083 - val_accuracy: 0.7684\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 813.5186 - accuracy: 0.6830 - val_loss: 655.1949 - val_accuracy: 0.7693\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 816.8890 - accuracy: 0.6967 - val_loss: 657.2226 - val_accuracy: 0.7690\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 819.8001 - accuracy: 0.6875 - val_loss: 655.9872 - val_accuracy: 0.7495\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 819.0835 - accuracy: 0.6884 - val_loss: 656.9384 - val_accuracy: 0.7720\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 813.6232 - accuracy: 0.6850 - val_loss: 661.4573 - val_accuracy: 0.7636\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 815.5223 - accuracy: 0.6861 - val_loss: 656.7610 - val_accuracy: 0.7649\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 814.0963 - accuracy: 0.6944 - val_loss: 654.3695 - val_accuracy: 0.7642\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 810.9881 - accuracy: 0.6887 - val_loss: 654.8729 - val_accuracy: 0.7676\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 813.0593 - accuracy: 0.6847 - val_loss: 654.1295 - val_accuracy: 0.7532\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 812.6486 - accuracy: 0.6922 - val_loss: 657.3399 - val_accuracy: 0.7720\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 812.5530 - accuracy: 0.6837 - val_loss: 662.0363 - val_accuracy: 0.7715\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 821.9058 - accuracy: 0.6769 - val_loss: 651.8889 - val_accuracy: 0.7660\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 810.8620 - accuracy: 0.6929 - val_loss: 654.0526 - val_accuracy: 0.7562\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 808.1376 - accuracy: 0.6954 - val_loss: 652.7582 - val_accuracy: 0.7659\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 810.5648 - accuracy: 0.6776 - val_loss: 655.1067 - val_accuracy: 0.7497\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 811.0049 - accuracy: 0.6880 - val_loss: 658.0606 - val_accuracy: 0.7672\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 809.1850 - accuracy: 0.6954 - val_loss: 655.4763 - val_accuracy: 0.7674\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 807.9400 - accuracy: 0.6840 - val_loss: 653.8419 - val_accuracy: 0.7660\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 807.6544 - accuracy: 0.6936 - val_loss: 657.3324 - val_accuracy: 0.7695\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 812.6161 - accuracy: 0.6829 - val_loss: 656.2632 - val_accuracy: 0.7655\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 810.7044 - accuracy: 0.6871 - val_loss: 650.9584 - val_accuracy: 0.7648\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 808.0513 - accuracy: 0.6816 - val_loss: 646.4460 - val_accuracy: 0.7653\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 809.0231 - accuracy: 0.6833 - val_loss: 656.6941 - val_accuracy: 0.7658\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 810.6907 - accuracy: 0.7059 - val_loss: 648.4443 - val_accuracy: 0.7701\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 807.8127 - accuracy: 0.6769 - val_loss: 655.5215 - val_accuracy: 0.7669\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 807.1600 - accuracy: 0.6893 - val_loss: 645.7347 - val_accuracy: 0.7640\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 805.6523 - accuracy: 0.6876 - val_loss: 657.8653 - val_accuracy: 0.7649\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 808.7434 - accuracy: 0.6940 - val_loss: 654.5609 - val_accuracy: 0.7560\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 812.3036 - accuracy: 0.6832 - val_loss: 668.7136 - val_accuracy: 0.7542\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 827.0761 - accuracy: 0.6892 - val_loss: 659.6486 - val_accuracy: 0.7678\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 808.5311 - accuracy: 0.6898 - val_loss: 655.9251 - val_accuracy: 0.7597\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 804.3283 - accuracy: 0.6981 - val_loss: 651.4523 - val_accuracy: 0.7574\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 802.9685 - accuracy: 0.6849 - val_loss: 654.5594 - val_accuracy: 0.7692\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 804.5751 - accuracy: 0.6909 - val_loss: 649.9928 - val_accuracy: 0.7671\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 804.9005 - accuracy: 0.6932 - val_loss: 653.9902 - val_accuracy: 0.7633\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 804.7435 - accuracy: 0.6776 - val_loss: 647.8775 - val_accuracy: 0.7662\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 804.9695 - accuracy: 0.6987 - val_loss: 653.7025 - val_accuracy: 0.7690\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 803.1937 - accuracy: 0.6866 - val_loss: 649.0048 - val_accuracy: 0.7713\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 803.7375 - accuracy: 0.6848 - val_loss: 646.6334 - val_accuracy: 0.7710\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 803.0987 - accuracy: 0.6970 - val_loss: 651.4611 - val_accuracy: 0.7677\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 802.0327 - accuracy: 0.6869 - val_loss: 647.9682 - val_accuracy: 0.7619\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 803.7715 - accuracy: 0.6881 - val_loss: 650.7308 - val_accuracy: 0.7745\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 801.9828 - accuracy: 0.6859 - val_loss: 649.1138 - val_accuracy: 0.7648\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 800.7773 - accuracy: 0.6936 - val_loss: 649.9737 - val_accuracy: 0.7673\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 803.7225 - accuracy: 0.6869 - val_loss: 648.4103 - val_accuracy: 0.7584\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 801.7706 - accuracy: 0.6903 - val_loss: 650.4025 - val_accuracy: 0.7689\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 801.6856 - accuracy: 0.6792 - val_loss: 650.8846 - val_accuracy: 0.7696\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 802.6217 - accuracy: 0.6898 - val_loss: 650.4316 - val_accuracy: 0.7622\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 804.9828 - accuracy: 0.6914 - val_loss: 649.6536 - val_accuracy: 0.7690\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 808.6652 - accuracy: 0.6860 - val_loss: 665.0972 - val_accuracy: 0.7725\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 816.0586 - accuracy: 0.6928 - val_loss: 668.6658 - val_accuracy: 0.7751\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 812.6257 - accuracy: 0.6885 - val_loss: 668.5184 - val_accuracy: 0.7652\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 826.6170 - accuracy: 0.6780 - val_loss: 650.5283 - val_accuracy: 0.7610\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 823.4286 - accuracy: 0.6982 - val_loss: 674.0640 - val_accuracy: 0.7584\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 812.3721 - accuracy: 0.6894 - val_loss: 659.1753 - val_accuracy: 0.7571\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 802.8834 - accuracy: 0.6894 - val_loss: 647.6471 - val_accuracy: 0.7679\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 801.8535 - accuracy: 0.6854 - val_loss: 650.5910 - val_accuracy: 0.7649\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 804.4114 - accuracy: 0.6934 - val_loss: 649.7994 - val_accuracy: 0.7670\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 803.1812 - accuracy: 0.6926 - val_loss: 652.1849 - val_accuracy: 0.7679\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 800.9213 - accuracy: 0.6884 - val_loss: 647.3798 - val_accuracy: 0.7617\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 801.4689 - accuracy: 0.6906 - val_loss: 649.3802 - val_accuracy: 0.7563\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 800.8961 - accuracy: 0.6915 - val_loss: 647.3688 - val_accuracy: 0.7731\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 799.9521 - accuracy: 0.6915 - val_loss: 655.2052 - val_accuracy: 0.7698\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 801.4966 - accuracy: 0.6951 - val_loss: 646.7140 - val_accuracy: 0.7629\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 798.2627 - accuracy: 0.6893 - val_loss: 652.1505 - val_accuracy: 0.7686\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 799.0248 - accuracy: 0.6881 - val_loss: 652.7045 - val_accuracy: 0.7701\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 798.6378 - accuracy: 0.7027 - val_loss: 650.5981 - val_accuracy: 0.7564\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 802.5905 - accuracy: 0.6832 - val_loss: 654.8950 - val_accuracy: 0.7712\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 797.8774 - accuracy: 0.6942 - val_loss: 650.0139 - val_accuracy: 0.7689\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 805.6196 - accuracy: 0.6943 - val_loss: 663.1816 - val_accuracy: 0.7664\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 813.2185 - accuracy: 0.6748 - val_loss: 663.7903 - val_accuracy: 0.7601\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 807.1451 - accuracy: 0.6922 - val_loss: 646.9727 - val_accuracy: 0.7670\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 795.9388 - accuracy: 0.6867 - val_loss: 643.9601 - val_accuracy: 0.7723\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 804.0037 - accuracy: 0.6891 - val_loss: 658.0196 - val_accuracy: 0.7687\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 806.2495 - accuracy: 0.6977 - val_loss: 649.2606 - val_accuracy: 0.7694\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 798.7573 - accuracy: 0.6932 - val_loss: 654.7386 - val_accuracy: 0.7613\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 797.7444 - accuracy: 0.6941 - val_loss: 648.1100 - val_accuracy: 0.7697\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 796.2203 - accuracy: 0.6860 - val_loss: 649.6478 - val_accuracy: 0.7733\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 798.9431 - accuracy: 0.6936 - val_loss: 653.9225 - val_accuracy: 0.7685\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 796.6655 - accuracy: 0.6899 - val_loss: 644.9473 - val_accuracy: 0.7707\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 793.8193 - accuracy: 0.6905 - val_loss: 645.8304 - val_accuracy: 0.7707\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 798.4642 - accuracy: 0.6929 - val_loss: 681.8835 - val_accuracy: 0.7297\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 807.1910 - accuracy: 0.6870 - val_loss: 655.4068 - val_accuracy: 0.7692\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 800.7856 - accuracy: 0.6953 - val_loss: 651.5404 - val_accuracy: 0.7706\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 807.6152 - accuracy: 0.6869 - val_loss: 657.3084 - val_accuracy: 0.7699\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 806.1923 - accuracy: 0.6852 - val_loss: 653.0693 - val_accuracy: 0.7660\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 803.1474 - accuracy: 0.6871 - val_loss: 651.0592 - val_accuracy: 0.7712\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 796.8328 - accuracy: 0.6973 - val_loss: 646.4489 - val_accuracy: 0.7647\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 794.0508 - accuracy: 0.6908 - val_loss: 650.6353 - val_accuracy: 0.7680\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 794.8262 - accuracy: 0.6983 - val_loss: 653.8318 - val_accuracy: 0.7703\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 795.1257 - accuracy: 0.6873 - val_loss: 647.6420 - val_accuracy: 0.7672\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 797.2740 - accuracy: 0.6947 - val_loss: 659.8952 - val_accuracy: 0.7603\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 820.7315 - accuracy: 0.6996 - val_loss: 662.5148 - val_accuracy: 0.7661\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 828.0576 - accuracy: 0.6821 - val_loss: 666.3522 - val_accuracy: 0.7695\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 803.7927 - accuracy: 0.6922 - val_loss: 650.4671 - val_accuracy: 0.7578\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 797.1205 - accuracy: 0.6860 - val_loss: 651.0582 - val_accuracy: 0.7751\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 794.8355 - accuracy: 0.6912 - val_loss: 660.7846 - val_accuracy: 0.7458\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 797.0120 - accuracy: 0.6960 - val_loss: 650.3229 - val_accuracy: 0.7763\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 794.6359 - accuracy: 0.6939 - val_loss: 645.3816 - val_accuracy: 0.7694\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 795.0755 - accuracy: 0.6918 - val_loss: 656.9316 - val_accuracy: 0.7688\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 799.3264 - accuracy: 0.7002 - val_loss: 646.9757 - val_accuracy: 0.7587\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 793.9499 - accuracy: 0.6866 - val_loss: 652.8339 - val_accuracy: 0.7751\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 1s 61ms/step - loss: 795.1880 - accuracy: 0.6823 - val_loss: 645.6550 - val_accuracy: 0.7708\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 793.9293 - accuracy: 0.7002 - val_loss: 646.2925 - val_accuracy: 0.7683\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 1s 60ms/step - loss: 799.5530 - accuracy: 0.6897 - val_loss: 655.9555 - val_accuracy: 0.7736\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 796.0593 - accuracy: 0.6978 - val_loss: 643.9247 - val_accuracy: 0.7672\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 791.8615 - accuracy: 0.7006 - val_loss: 650.4786 - val_accuracy: 0.7712\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 792.7054 - accuracy: 0.6965 - val_loss: 644.0366 - val_accuracy: 0.7695\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 794.5046 - accuracy: 0.6898 - val_loss: 648.2177 - val_accuracy: 0.7691\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 795.4180 - accuracy: 0.6964 - val_loss: 643.8109 - val_accuracy: 0.7739\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 794.1908 - accuracy: 0.6925 - val_loss: 645.0196 - val_accuracy: 0.7741\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 792.8850 - accuracy: 0.7015 - val_loss: 642.8530 - val_accuracy: 0.7693\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 790.2097 - accuracy: 0.6890 - val_loss: 644.8267 - val_accuracy: 0.7746\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 790.7005 - accuracy: 0.6989 - val_loss: 643.8917 - val_accuracy: 0.7636\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 790.6365 - accuracy: 0.6934 - val_loss: 651.7054 - val_accuracy: 0.7751\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 796.2570 - accuracy: 0.6935 - val_loss: 654.1249 - val_accuracy: 0.7749\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 793.1578 - accuracy: 0.6933 - val_loss: 648.6377 - val_accuracy: 0.7739\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 790.5738 - accuracy: 0.6892 - val_loss: 645.5925 - val_accuracy: 0.7694\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 790.2405 - accuracy: 0.6939 - val_loss: 655.7604 - val_accuracy: 0.7568\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 810.4357 - accuracy: 0.6906 - val_loss: 656.6324 - val_accuracy: 0.7820\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 810.7476 - accuracy: 0.6925 - val_loss: 662.7818 - val_accuracy: 0.7793\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 810.3600 - accuracy: 0.6971 - val_loss: 651.2254 - val_accuracy: 0.7723\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 802.6679 - accuracy: 0.6918 - val_loss: 659.5875 - val_accuracy: 0.7779\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 795.0321 - accuracy: 0.6814 - val_loss: 647.8896 - val_accuracy: 0.7748\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 792.9496 - accuracy: 0.6960 - val_loss: 647.4334 - val_accuracy: 0.7660\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 790.3990 - accuracy: 0.6843 - val_loss: 643.5937 - val_accuracy: 0.7768\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 790.4423 - accuracy: 0.6971 - val_loss: 652.1995 - val_accuracy: 0.7726\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 791.6140 - accuracy: 0.6993 - val_loss: 646.2755 - val_accuracy: 0.7689\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 791.0446 - accuracy: 0.6919 - val_loss: 657.3661 - val_accuracy: 0.7769\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 794.0333 - accuracy: 0.6975 - val_loss: 648.2764 - val_accuracy: 0.7705\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 789.8774 - accuracy: 0.6948 - val_loss: 644.9681 - val_accuracy: 0.7701\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 789.2776 - accuracy: 0.6900 - val_loss: 647.2130 - val_accuracy: 0.7798\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 788.1819 - accuracy: 0.6958 - val_loss: 648.5232 - val_accuracy: 0.7735\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 789.2397 - accuracy: 0.6971 - val_loss: 644.0786 - val_accuracy: 0.7704\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 789.5322 - accuracy: 0.6932 - val_loss: 641.9689 - val_accuracy: 0.7723\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 791.5035 - accuracy: 0.6971 - val_loss: 648.8070 - val_accuracy: 0.7706\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 806.7087 - accuracy: 0.6856 - val_loss: 648.0088 - val_accuracy: 0.7758\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 797.4222 - accuracy: 0.6954 - val_loss: 650.9833 - val_accuracy: 0.7740\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 788.1864 - accuracy: 0.6985 - val_loss: 650.2813 - val_accuracy: 0.7737\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 793.2410 - accuracy: 0.6950 - val_loss: 653.3447 - val_accuracy: 0.7685\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 789.9014 - accuracy: 0.6943 - val_loss: 651.9474 - val_accuracy: 0.7691\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 788.5374 - accuracy: 0.6964 - val_loss: 645.0830 - val_accuracy: 0.7723\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 788.6252 - accuracy: 0.6867 - val_loss: 644.5111 - val_accuracy: 0.7740\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 787.8228 - accuracy: 0.7004 - val_loss: 643.3293 - val_accuracy: 0.7720\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 787.9625 - accuracy: 0.6993 - val_loss: 647.1901 - val_accuracy: 0.7782\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 787.8256 - accuracy: 0.6934 - val_loss: 646.0507 - val_accuracy: 0.7735\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 788.1145 - accuracy: 0.6989 - val_loss: 645.2133 - val_accuracy: 0.7784\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 787.8467 - accuracy: 0.6969 - val_loss: 652.3585 - val_accuracy: 0.7710\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 790.2929 - accuracy: 0.6939 - val_loss: 650.1634 - val_accuracy: 0.7792\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 787.4932 - accuracy: 0.6961 - val_loss: 650.4945 - val_accuracy: 0.7760\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 790.6306 - accuracy: 0.6942 - val_loss: 645.1579 - val_accuracy: 0.7776\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 785.8181 - accuracy: 0.6947 - val_loss: 645.1906 - val_accuracy: 0.7721\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 785.0904 - accuracy: 0.6975 - val_loss: 643.0677 - val_accuracy: 0.7739\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.0143 - accuracy: 0.7013 - val_loss: 648.6584 - val_accuracy: 0.7710\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 789.7899 - accuracy: 0.6928 - val_loss: 649.2388 - val_accuracy: 0.7737\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 791.2335 - accuracy: 0.6902 - val_loss: 653.1787 - val_accuracy: 0.7781\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 793.6087 - accuracy: 0.6963 - val_loss: 647.3382 - val_accuracy: 0.7744\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 790.4876 - accuracy: 0.6907 - val_loss: 642.0195 - val_accuracy: 0.7717\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 795.2969 - accuracy: 0.6955 - val_loss: 667.0964 - val_accuracy: 0.7737\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 795.7659 - accuracy: 0.6959 - val_loss: 645.2285 - val_accuracy: 0.7746\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 793.9064 - accuracy: 0.7009 - val_loss: 640.7747 - val_accuracy: 0.7798\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 791.1488 - accuracy: 0.6918 - val_loss: 648.7720 - val_accuracy: 0.7802\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 789.2155 - accuracy: 0.7004 - val_loss: 646.2830 - val_accuracy: 0.7749\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 788.0707 - accuracy: 0.6893 - val_loss: 646.1921 - val_accuracy: 0.7741\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.5140 - accuracy: 0.6964 - val_loss: 650.5954 - val_accuracy: 0.7700\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 787.4081 - accuracy: 0.6984 - val_loss: 648.1234 - val_accuracy: 0.7713\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 787.9486 - accuracy: 0.7031 - val_loss: 638.1059 - val_accuracy: 0.7723\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.0095 - accuracy: 0.6934 - val_loss: 641.9144 - val_accuracy: 0.7748\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.0062 - accuracy: 0.7009 - val_loss: 641.2698 - val_accuracy: 0.7732\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.1935 - accuracy: 0.6971 - val_loss: 640.1569 - val_accuracy: 0.7776\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.1627 - accuracy: 0.6921 - val_loss: 641.5898 - val_accuracy: 0.7733\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 784.6925 - accuracy: 0.7009 - val_loss: 638.7304 - val_accuracy: 0.7729\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.6542 - accuracy: 0.6964 - val_loss: 640.8991 - val_accuracy: 0.7761\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 787.2220 - accuracy: 0.6942 - val_loss: 641.2416 - val_accuracy: 0.7834\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 785.4083 - accuracy: 0.6927 - val_loss: 644.4521 - val_accuracy: 0.7745\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 786.1281 - accuracy: 0.6969 - val_loss: 642.5110 - val_accuracy: 0.7783\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.1326 - accuracy: 0.7002 - val_loss: 646.1494 - val_accuracy: 0.7768\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 790.0833 - accuracy: 0.6871 - val_loss: 641.0775 - val_accuracy: 0.7737\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 791.7289 - accuracy: 0.6921 - val_loss: 649.4645 - val_accuracy: 0.7808\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 792.2134 - accuracy: 0.7022 - val_loss: 653.6505 - val_accuracy: 0.7664\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 792.6065 - accuracy: 0.6940 - val_loss: 643.2117 - val_accuracy: 0.7750\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 787.4994 - accuracy: 0.6896 - val_loss: 650.4654 - val_accuracy: 0.7801\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 789.6011 - accuracy: 0.6906 - val_loss: 646.8490 - val_accuracy: 0.7620\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 791.1218 - accuracy: 0.7059 - val_loss: 647.3345 - val_accuracy: 0.7814\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 789.7365 - accuracy: 0.6869 - val_loss: 642.8574 - val_accuracy: 0.7735\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 787.2670 - accuracy: 0.6942 - val_loss: 660.1686 - val_accuracy: 0.7707\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 794.6448 - accuracy: 0.7007 - val_loss: 648.4443 - val_accuracy: 0.7744\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 800.5506 - accuracy: 0.6975 - val_loss: 650.0984 - val_accuracy: 0.7826\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 795.8082 - accuracy: 0.6884 - val_loss: 652.8052 - val_accuracy: 0.7777\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 790.8617 - accuracy: 0.7067 - val_loss: 643.1066 - val_accuracy: 0.7725\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 785.5898 - accuracy: 0.6934 - val_loss: 646.0919 - val_accuracy: 0.7734\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.6057 - accuracy: 0.6953 - val_loss: 645.1259 - val_accuracy: 0.7784\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 785.4431 - accuracy: 0.6965 - val_loss: 641.8020 - val_accuracy: 0.7730\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.0525 - accuracy: 0.6975 - val_loss: 645.0859 - val_accuracy: 0.7802\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 786.2367 - accuracy: 0.6977 - val_loss: 645.1544 - val_accuracy: 0.7704\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.3216 - accuracy: 0.7025 - val_loss: 642.2372 - val_accuracy: 0.7778\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 785.3582 - accuracy: 0.6995 - val_loss: 643.5068 - val_accuracy: 0.7808\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 784.6904 - accuracy: 0.6957 - val_loss: 645.2068 - val_accuracy: 0.7718\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.1284 - accuracy: 0.6894 - val_loss: 639.0245 - val_accuracy: 0.7726\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 785.2488 - accuracy: 0.6962 - val_loss: 645.5674 - val_accuracy: 0.7761\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 787.8993 - accuracy: 0.7016 - val_loss: 641.9496 - val_accuracy: 0.7751\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 785.0140 - accuracy: 0.6907 - val_loss: 643.1273 - val_accuracy: 0.7702\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 783.0842 - accuracy: 0.6980 - val_loss: 643.0390 - val_accuracy: 0.7800\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.4613 - accuracy: 0.7023 - val_loss: 644.1090 - val_accuracy: 0.7787\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 782.5118 - accuracy: 0.6986 - val_loss: 642.5751 - val_accuracy: 0.7725\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 783.5535 - accuracy: 0.7004 - val_loss: 646.4609 - val_accuracy: 0.7758\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 798.2500 - accuracy: 0.6950 - val_loss: 669.8391 - val_accuracy: 0.7762\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 785.9216 - accuracy: 0.6961 - val_loss: 643.9501 - val_accuracy: 0.7722\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 781.5502 - accuracy: 0.6967 - val_loss: 639.2419 - val_accuracy: 0.7769\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 781.8795 - accuracy: 0.6974 - val_loss: 639.5699 - val_accuracy: 0.7625\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 780.8823 - accuracy: 0.6991 - val_loss: 637.7927 - val_accuracy: 0.7712\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 781.2116 - accuracy: 0.6971 - val_loss: 641.0807 - val_accuracy: 0.7776\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 785.2054 - accuracy: 0.6932 - val_loss: 662.9617 - val_accuracy: 0.7756\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 788.6042 - accuracy: 0.6976 - val_loss: 643.0820 - val_accuracy: 0.7783\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 784.6287 - accuracy: 0.6941 - val_loss: 644.9012 - val_accuracy: 0.7730\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.4739 - accuracy: 0.6992 - val_loss: 649.3264 - val_accuracy: 0.7681\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 786.6460 - accuracy: 0.6959 - val_loss: 643.8526 - val_accuracy: 0.7768\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 785.2487 - accuracy: 0.6971 - val_loss: 641.8289 - val_accuracy: 0.7740\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.8425 - accuracy: 0.6954 - val_loss: 652.7729 - val_accuracy: 0.7440\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 785.8086 - accuracy: 0.6937 - val_loss: 643.4756 - val_accuracy: 0.7773\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 781.9255 - accuracy: 0.7043 - val_loss: 640.9026 - val_accuracy: 0.7708\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 782.8952 - accuracy: 0.6996 - val_loss: 645.4397 - val_accuracy: 0.7803\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 785.3820 - accuracy: 0.6976 - val_loss: 639.6357 - val_accuracy: 0.7755\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 785.3970 - accuracy: 0.6942 - val_loss: 642.8704 - val_accuracy: 0.7731\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 1s 41ms/step - loss: 791.8312 - accuracy: 0.7027 - val_loss: 641.9827 - val_accuracy: 0.7670\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 787.9834 - accuracy: 0.7074 - val_loss: 645.1036 - val_accuracy: 0.7810\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 786.3919 - accuracy: 0.6881 - val_loss: 642.8724 - val_accuracy: 0.7794\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 783.0495 - accuracy: 0.6930 - val_loss: 641.9888 - val_accuracy: 0.7779\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 781.8886 - accuracy: 0.7017 - val_loss: 639.4717 - val_accuracy: 0.7703\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 782.1742 - accuracy: 0.7003 - val_loss: 638.6239 - val_accuracy: 0.7768\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 781.3532 - accuracy: 0.6949 - val_loss: 638.2311 - val_accuracy: 0.7785\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.0610 - accuracy: 0.7017 - val_loss: 636.7938 - val_accuracy: 0.7728\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 779.1316 - accuracy: 0.7038 - val_loss: 639.5009 - val_accuracy: 0.7671\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 780.2451 - accuracy: 0.6997 - val_loss: 637.9392 - val_accuracy: 0.7719\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 778.5676 - accuracy: 0.6972 - val_loss: 639.3364 - val_accuracy: 0.7790\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.7040 - accuracy: 0.7042 - val_loss: 641.9194 - val_accuracy: 0.7727\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 780.0005 - accuracy: 0.6975 - val_loss: 640.5048 - val_accuracy: 0.7764\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 784.7283 - accuracy: 0.6989 - val_loss: 649.1227 - val_accuracy: 0.7786\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 790.6747 - accuracy: 0.7032 - val_loss: 643.7813 - val_accuracy: 0.7662\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 784.4410 - accuracy: 0.6972 - val_loss: 640.6376 - val_accuracy: 0.7804\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 784.0797 - accuracy: 0.6972 - val_loss: 646.7130 - val_accuracy: 0.7659\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 790.5936 - accuracy: 0.7017 - val_loss: 641.3288 - val_accuracy: 0.7771\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 785.1048 - accuracy: 0.6957 - val_loss: 646.5094 - val_accuracy: 0.7666\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 781.5648 - accuracy: 0.6998 - val_loss: 639.8725 - val_accuracy: 0.7714\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 779.7008 - accuracy: 0.7040 - val_loss: 639.6280 - val_accuracy: 0.7762\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 778.6117 - accuracy: 0.7021 - val_loss: 640.2903 - val_accuracy: 0.7681\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.8532 - accuracy: 0.6989 - val_loss: 637.3160 - val_accuracy: 0.7732\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 780.7299 - accuracy: 0.6999 - val_loss: 642.0631 - val_accuracy: 0.7746\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 780.8761 - accuracy: 0.7056 - val_loss: 640.0549 - val_accuracy: 0.7747\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 782.6210 - accuracy: 0.6953 - val_loss: 641.6804 - val_accuracy: 0.7757\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 782.6853 - accuracy: 0.7035 - val_loss: 635.4352 - val_accuracy: 0.7684\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.9730 - accuracy: 0.7040 - val_loss: 658.0626 - val_accuracy: 0.7759\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 800.0107 - accuracy: 0.6917 - val_loss: 642.2175 - val_accuracy: 0.7615\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 788.0436 - accuracy: 0.7006 - val_loss: 642.9693 - val_accuracy: 0.7692\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 781.9194 - accuracy: 0.6970 - val_loss: 641.4319 - val_accuracy: 0.7680\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 787.4489 - accuracy: 0.6977 - val_loss: 638.9297 - val_accuracy: 0.7745\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 785.4488 - accuracy: 0.6977 - val_loss: 638.9144 - val_accuracy: 0.7598\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 783.1709 - accuracy: 0.6999 - val_loss: 644.6309 - val_accuracy: 0.7680\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.3210 - accuracy: 0.7023 - val_loss: 652.5146 - val_accuracy: 0.7791\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.8209 - accuracy: 0.7044 - val_loss: 639.1338 - val_accuracy: 0.7724\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 777.2046 - accuracy: 0.6982 - val_loss: 635.7520 - val_accuracy: 0.7753\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 777.2052 - accuracy: 0.7015 - val_loss: 637.3127 - val_accuracy: 0.7655\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 778.3483 - accuracy: 0.7024 - val_loss: 640.4167 - val_accuracy: 0.7741\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 778.4749 - accuracy: 0.6969 - val_loss: 638.2221 - val_accuracy: 0.7757\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 781.6949 - accuracy: 0.7010 - val_loss: 639.2149 - val_accuracy: 0.7680\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 786.5278 - accuracy: 0.7010 - val_loss: 641.4382 - val_accuracy: 0.7728\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 782.1697 - accuracy: 0.7029 - val_loss: 638.9501 - val_accuracy: 0.7629\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.3729 - accuracy: 0.6949 - val_loss: 640.7747 - val_accuracy: 0.7779\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 778.0468 - accuracy: 0.7032 - val_loss: 638.9027 - val_accuracy: 0.7722\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 778.5798 - accuracy: 0.6967 - val_loss: 643.0399 - val_accuracy: 0.7768\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 781.9764 - accuracy: 0.6989 - val_loss: 637.9385 - val_accuracy: 0.7720\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 780.0687 - accuracy: 0.6984 - val_loss: 640.9517 - val_accuracy: 0.7748\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.4785 - accuracy: 0.6995 - val_loss: 634.9985 - val_accuracy: 0.7744\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 777.3390 - accuracy: 0.7057 - val_loss: 642.1240 - val_accuracy: 0.7736\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 783.6624 - accuracy: 0.6965 - val_loss: 637.5527 - val_accuracy: 0.7742\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 778.8813 - accuracy: 0.7055 - val_loss: 634.0419 - val_accuracy: 0.7662\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 781.1852 - accuracy: 0.7010 - val_loss: 640.2126 - val_accuracy: 0.7769\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 779.6432 - accuracy: 0.6992 - val_loss: 636.3722 - val_accuracy: 0.7695\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 777.5670 - accuracy: 0.7048 - val_loss: 638.5282 - val_accuracy: 0.7706\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.2909 - accuracy: 0.6978 - val_loss: 641.7594 - val_accuracy: 0.7668\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 778.0870 - accuracy: 0.6969 - val_loss: 638.6188 - val_accuracy: 0.7738\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 783.3684 - accuracy: 0.7026 - val_loss: 638.3785 - val_accuracy: 0.7747\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 781.5421 - accuracy: 0.7047 - val_loss: 640.8683 - val_accuracy: 0.7685\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 781.7582 - accuracy: 0.7033 - val_loss: 637.3775 - val_accuracy: 0.7771\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 783.4675 - accuracy: 0.6866 - val_loss: 641.7920 - val_accuracy: 0.7709\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 781.4595 - accuracy: 0.7144 - val_loss: 652.8031 - val_accuracy: 0.7614\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 788.7087 - accuracy: 0.6840 - val_loss: 642.5355 - val_accuracy: 0.7712\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 781.8994 - accuracy: 0.7014 - val_loss: 640.7354 - val_accuracy: 0.7757\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 779.2236 - accuracy: 0.7046 - val_loss: 641.5845 - val_accuracy: 0.7726\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 776.8862 - accuracy: 0.6956 - val_loss: 642.7924 - val_accuracy: 0.7822\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.0668 - accuracy: 0.6964 - val_loss: 640.2233 - val_accuracy: 0.7677\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 779.6865 - accuracy: 0.6989 - val_loss: 641.3792 - val_accuracy: 0.7608\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 782.9293 - accuracy: 0.7009 - val_loss: 646.1704 - val_accuracy: 0.7709\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 780.9903 - accuracy: 0.6943 - val_loss: 638.2971 - val_accuracy: 0.7799\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 778.2667 - accuracy: 0.6985 - val_loss: 643.1097 - val_accuracy: 0.7711\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.2648 - accuracy: 0.7029 - val_loss: 636.3883 - val_accuracy: 0.7693\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.8096 - accuracy: 0.6998 - val_loss: 640.4789 - val_accuracy: 0.7718\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 776.7070 - accuracy: 0.6994 - val_loss: 645.5397 - val_accuracy: 0.7713\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 780.4817 - accuracy: 0.7019 - val_loss: 637.8969 - val_accuracy: 0.7656\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 778.6093 - accuracy: 0.7009 - val_loss: 636.1229 - val_accuracy: 0.7762\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 779.8664 - accuracy: 0.6986 - val_loss: 636.2625 - val_accuracy: 0.7809\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 778.9918 - accuracy: 0.7020 - val_loss: 637.7708 - val_accuracy: 0.7712\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.6672 - accuracy: 0.6990 - val_loss: 641.1731 - val_accuracy: 0.7812\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.9385 - accuracy: 0.7026 - val_loss: 637.2620 - val_accuracy: 0.7688\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 775.2397 - accuracy: 0.6981 - val_loss: 638.2953 - val_accuracy: 0.7779\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.7321 - accuracy: 0.7016 - val_loss: 637.0414 - val_accuracy: 0.7772\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 777.3387 - accuracy: 0.7018 - val_loss: 638.7126 - val_accuracy: 0.7664\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 777.8184 - accuracy: 0.7021 - val_loss: 641.6200 - val_accuracy: 0.7625\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 776.8065 - accuracy: 0.6973 - val_loss: 645.2853 - val_accuracy: 0.7796\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 782.2355 - accuracy: 0.7002 - val_loss: 636.3801 - val_accuracy: 0.7719\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 777.8624 - accuracy: 0.7059 - val_loss: 634.7078 - val_accuracy: 0.7686\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 773.9725 - accuracy: 0.7013 - val_loss: 632.1670 - val_accuracy: 0.7755\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 777.6719 - accuracy: 0.6972 - val_loss: 634.7128 - val_accuracy: 0.7718\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 1s 55ms/step - loss: 774.8333 - accuracy: 0.7056 - val_loss: 637.1224 - val_accuracy: 0.7724\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 775.2782 - accuracy: 0.7015 - val_loss: 635.6946 - val_accuracy: 0.7768\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 1s 54ms/step - loss: 776.4841 - accuracy: 0.6987 - val_loss: 633.9362 - val_accuracy: 0.7566\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 775.1772 - accuracy: 0.6997 - val_loss: 631.7095 - val_accuracy: 0.7685\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 1s 52ms/step - loss: 779.2917 - accuracy: 0.7028 - val_loss: 639.9566 - val_accuracy: 0.7631\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 775.7679 - accuracy: 0.7036 - val_loss: 632.7000 - val_accuracy: 0.7754\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 779.7738 - accuracy: 0.6967 - val_loss: 638.0989 - val_accuracy: 0.7719\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.4429 - accuracy: 0.7028 - val_loss: 641.6225 - val_accuracy: 0.7707\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.1672 - accuracy: 0.7070 - val_loss: 639.0679 - val_accuracy: 0.7743\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 783.3216 - accuracy: 0.6917 - val_loss: 640.2835 - val_accuracy: 0.7775\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 777.2570 - accuracy: 0.7005 - val_loss: 644.8083 - val_accuracy: 0.7670\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 784.7015 - accuracy: 0.7044 - val_loss: 658.7550 - val_accuracy: 0.7765\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 805.8187 - accuracy: 0.6964 - val_loss: 656.8646 - val_accuracy: 0.7837\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 793.1512 - accuracy: 0.6962 - val_loss: 647.3991 - val_accuracy: 0.7741\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 781.0510 - accuracy: 0.7021 - val_loss: 646.5184 - val_accuracy: 0.7756\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 779.4512 - accuracy: 0.6928 - val_loss: 638.2863 - val_accuracy: 0.7597\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 784.7025 - accuracy: 0.6954 - val_loss: 639.9095 - val_accuracy: 0.7710\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 783.2578 - accuracy: 0.7039 - val_loss: 647.1586 - val_accuracy: 0.7743\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 780.4489 - accuracy: 0.6990 - val_loss: 639.1671 - val_accuracy: 0.7765\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 779.1914 - accuracy: 0.6974 - val_loss: 641.5589 - val_accuracy: 0.7753\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 776.9875 - accuracy: 0.6997 - val_loss: 637.5016 - val_accuracy: 0.7697\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 773.5803 - accuracy: 0.7042 - val_loss: 635.1268 - val_accuracy: 0.7595\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 773.7139 - accuracy: 0.7015 - val_loss: 633.7228 - val_accuracy: 0.7724\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 773.4075 - accuracy: 0.6996 - val_loss: 637.7365 - val_accuracy: 0.7819\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.8275 - accuracy: 0.6989 - val_loss: 640.1049 - val_accuracy: 0.7745\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 778.6999 - accuracy: 0.7044 - val_loss: 634.0544 - val_accuracy: 0.7697\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 775.8857 - accuracy: 0.6985 - val_loss: 638.5944 - val_accuracy: 0.7804\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 776.3936 - accuracy: 0.6903 - val_loss: 637.1857 - val_accuracy: 0.7708\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 775.7698 - accuracy: 0.7037 - val_loss: 638.1205 - val_accuracy: 0.7738\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 778.6149 - accuracy: 0.7002 - val_loss: 642.0364 - val_accuracy: 0.7632\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 780.5330 - accuracy: 0.7009 - val_loss: 666.4721 - val_accuracy: 0.7902\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 792.3217 - accuracy: 0.6968 - val_loss: 661.7050 - val_accuracy: 0.7566\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 795.1578 - accuracy: 0.7026 - val_loss: 659.5253 - val_accuracy: 0.7825\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 790.2539 - accuracy: 0.6800 - val_loss: 640.2291 - val_accuracy: 0.7862\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 780.2119 - accuracy: 0.6970 - val_loss: 644.0710 - val_accuracy: 0.7649\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.6138 - accuracy: 0.7035 - val_loss: 635.7660 - val_accuracy: 0.7777\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 778.2831 - accuracy: 0.7017 - val_loss: 637.6506 - val_accuracy: 0.7819\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 777.7239 - accuracy: 0.7027 - val_loss: 638.8444 - val_accuracy: 0.7619\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 776.2062 - accuracy: 0.7018 - val_loss: 638.7643 - val_accuracy: 0.7684\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 774.6691 - accuracy: 0.7024 - val_loss: 631.2450 - val_accuracy: 0.7772\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 771.2552 - accuracy: 0.7071 - val_loss: 633.5176 - val_accuracy: 0.7704\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.5026 - accuracy: 0.7020 - val_loss: 636.4188 - val_accuracy: 0.7683\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 772.3398 - accuracy: 0.7032 - val_loss: 633.7899 - val_accuracy: 0.7713\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.8472 - accuracy: 0.6978 - val_loss: 633.4141 - val_accuracy: 0.7726\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 771.5959 - accuracy: 0.7040 - val_loss: 632.5190 - val_accuracy: 0.7727\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.4478 - accuracy: 0.7026 - val_loss: 634.6051 - val_accuracy: 0.7677\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 773.1483 - accuracy: 0.7013 - val_loss: 636.0312 - val_accuracy: 0.7752\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 772.6644 - accuracy: 0.7024 - val_loss: 636.9568 - val_accuracy: 0.7807\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 776.1669 - accuracy: 0.7033 - val_loss: 638.0511 - val_accuracy: 0.7701\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.2888 - accuracy: 0.7058 - val_loss: 636.1227 - val_accuracy: 0.7746\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 772.1826 - accuracy: 0.6944 - val_loss: 638.4182 - val_accuracy: 0.7707\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 773.2765 - accuracy: 0.7044 - val_loss: 636.6619 - val_accuracy: 0.7742\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 773.9529 - accuracy: 0.7014 - val_loss: 633.7203 - val_accuracy: 0.7706\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.7786 - accuracy: 0.6986 - val_loss: 641.0070 - val_accuracy: 0.7511\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 777.8082 - accuracy: 0.7063 - val_loss: 632.2393 - val_accuracy: 0.7699\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 781.2255 - accuracy: 0.7029 - val_loss: 648.2976 - val_accuracy: 0.7730\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 786.7133 - accuracy: 0.6977 - val_loss: 665.2842 - val_accuracy: 0.7649\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 794.5683 - accuracy: 0.7024 - val_loss: 634.4423 - val_accuracy: 0.7700\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.3123 - accuracy: 0.7052 - val_loss: 635.7600 - val_accuracy: 0.7773\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 771.4165 - accuracy: 0.6999 - val_loss: 633.5096 - val_accuracy: 0.7764\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.4019 - accuracy: 0.6998 - val_loss: 635.0693 - val_accuracy: 0.7773\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 772.8610 - accuracy: 0.6960 - val_loss: 637.5653 - val_accuracy: 0.7640\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 773.7151 - accuracy: 0.7034 - val_loss: 637.2860 - val_accuracy: 0.7669\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 772.1217 - accuracy: 0.7004 - val_loss: 638.4432 - val_accuracy: 0.7690\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.9109 - accuracy: 0.7020 - val_loss: 636.1672 - val_accuracy: 0.7759\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.6132 - accuracy: 0.7030 - val_loss: 635.6127 - val_accuracy: 0.7595\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 772.0930 - accuracy: 0.7020 - val_loss: 633.1861 - val_accuracy: 0.7686\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 775.4136 - accuracy: 0.7060 - val_loss: 638.6783 - val_accuracy: 0.7743\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.8248 - accuracy: 0.6961 - val_loss: 648.9274 - val_accuracy: 0.7738\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 784.7996 - accuracy: 0.7026 - val_loss: 635.0238 - val_accuracy: 0.7739\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 776.7331 - accuracy: 0.7018 - val_loss: 638.9995 - val_accuracy: 0.7769\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.1735 - accuracy: 0.7011 - val_loss: 635.1838 - val_accuracy: 0.7710\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 774.6910 - accuracy: 0.7023 - val_loss: 641.4086 - val_accuracy: 0.7728\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 771.6129 - accuracy: 0.6974 - val_loss: 634.5606 - val_accuracy: 0.7635\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 773.3183 - accuracy: 0.7138 - val_loss: 639.9097 - val_accuracy: 0.7690\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 776.5701 - accuracy: 0.6947 - val_loss: 636.2131 - val_accuracy: 0.7761\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 773.7573 - accuracy: 0.6972 - val_loss: 627.4197 - val_accuracy: 0.7670\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 773.0500 - accuracy: 0.7075 - val_loss: 635.1215 - val_accuracy: 0.7719\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 773.2370 - accuracy: 0.7023 - val_loss: 634.2280 - val_accuracy: 0.7742\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 772.7205 - accuracy: 0.7052 - val_loss: 635.4496 - val_accuracy: 0.7731\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.5498 - accuracy: 0.7017 - val_loss: 636.1338 - val_accuracy: 0.7724\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 773.8781 - accuracy: 0.7045 - val_loss: 634.5879 - val_accuracy: 0.7759\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.8817 - accuracy: 0.6998 - val_loss: 636.9840 - val_accuracy: 0.7679\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 778.9344 - accuracy: 0.7028 - val_loss: 633.5675 - val_accuracy: 0.7740\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 781.7666 - accuracy: 0.7006 - val_loss: 663.3401 - val_accuracy: 0.7700\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 786.1842 - accuracy: 0.7069 - val_loss: 640.7838 - val_accuracy: 0.7521\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.1184 - accuracy: 0.6972 - val_loss: 634.2691 - val_accuracy: 0.7625\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 772.2568 - accuracy: 0.7064 - val_loss: 634.7424 - val_accuracy: 0.7700\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.8663 - accuracy: 0.7068 - val_loss: 633.0274 - val_accuracy: 0.7631\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 777.1235 - accuracy: 0.6973 - val_loss: 653.2117 - val_accuracy: 0.7797\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 783.9984 - accuracy: 0.7020 - val_loss: 631.3281 - val_accuracy: 0.7784\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 776.0325 - accuracy: 0.7012 - val_loss: 634.0111 - val_accuracy: 0.7783\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 775.1885 - accuracy: 0.7038 - val_loss: 636.5075 - val_accuracy: 0.7719\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.8612 - accuracy: 0.7059 - val_loss: 632.4305 - val_accuracy: 0.7699\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 770.9989 - accuracy: 0.7042 - val_loss: 634.6052 - val_accuracy: 0.7722\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 770.8466 - accuracy: 0.7070 - val_loss: 636.5038 - val_accuracy: 0.7763\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.4100 - accuracy: 0.7024 - val_loss: 640.5759 - val_accuracy: 0.7840\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.7653 - accuracy: 0.7059 - val_loss: 640.6631 - val_accuracy: 0.7734\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 782.1589 - accuracy: 0.6843 - val_loss: 636.5536 - val_accuracy: 0.7768\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 775.5333 - accuracy: 0.7026 - val_loss: 643.1005 - val_accuracy: 0.7731\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 776.2660 - accuracy: 0.7012 - val_loss: 633.9202 - val_accuracy: 0.7706\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 773.5536 - accuracy: 0.7005 - val_loss: 631.0950 - val_accuracy: 0.7720\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 773.6084 - accuracy: 0.7133 - val_loss: 636.3737 - val_accuracy: 0.7778\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.4472 - accuracy: 0.6969 - val_loss: 629.8656 - val_accuracy: 0.7764\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.6401 - accuracy: 0.7076 - val_loss: 632.2034 - val_accuracy: 0.7638\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 768.7794 - accuracy: 0.7028 - val_loss: 633.6187 - val_accuracy: 0.7691\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.2644 - accuracy: 0.7064 - val_loss: 635.0320 - val_accuracy: 0.7701\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.5800 - accuracy: 0.7022 - val_loss: 637.7490 - val_accuracy: 0.7777\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 774.6020 - accuracy: 0.7003 - val_loss: 642.1882 - val_accuracy: 0.7701\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 776.5101 - accuracy: 0.7084 - val_loss: 633.0215 - val_accuracy: 0.7722\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 773.5058 - accuracy: 0.6965 - val_loss: 637.0827 - val_accuracy: 0.7773\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 774.8522 - accuracy: 0.7037 - val_loss: 632.7574 - val_accuracy: 0.7766\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 776.7299 - accuracy: 0.7091 - val_loss: 634.3778 - val_accuracy: 0.7740\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 776.1559 - accuracy: 0.7007 - val_loss: 637.6581 - val_accuracy: 0.7827\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 774.1326 - accuracy: 0.7008 - val_loss: 643.2820 - val_accuracy: 0.7656\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.8951 - accuracy: 0.7004 - val_loss: 637.9973 - val_accuracy: 0.7766\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.3896 - accuracy: 0.7026 - val_loss: 635.3231 - val_accuracy: 0.7722\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 775.6174 - accuracy: 0.6995 - val_loss: 634.2659 - val_accuracy: 0.7744\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 774.0692 - accuracy: 0.7082 - val_loss: 633.8378 - val_accuracy: 0.7774\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 772.3082 - accuracy: 0.6961 - val_loss: 631.7213 - val_accuracy: 0.7749\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.5407 - accuracy: 0.7071 - val_loss: 639.8354 - val_accuracy: 0.7598\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 773.2352 - accuracy: 0.7009 - val_loss: 635.9316 - val_accuracy: 0.7641\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.6873 - accuracy: 0.7060 - val_loss: 634.8442 - val_accuracy: 0.7787\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 771.3906 - accuracy: 0.7014 - val_loss: 632.9595 - val_accuracy: 0.7736\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 772.2975 - accuracy: 0.7008 - val_loss: 634.2326 - val_accuracy: 0.7729\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.3367 - accuracy: 0.7063 - val_loss: 643.5492 - val_accuracy: 0.7793\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.9022 - accuracy: 0.6986 - val_loss: 631.4797 - val_accuracy: 0.7770\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 772.4548 - accuracy: 0.7023 - val_loss: 633.7032 - val_accuracy: 0.7670\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 779.6852 - accuracy: 0.7067 - val_loss: 638.9648 - val_accuracy: 0.7741\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 794.2076 - accuracy: 0.6917 - val_loss: 637.7937 - val_accuracy: 0.7833\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 793.0489 - accuracy: 0.7045 - val_loss: 669.4572 - val_accuracy: 0.7759\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 782.4340 - accuracy: 0.7022 - val_loss: 636.1168 - val_accuracy: 0.7745\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.8243 - accuracy: 0.7076 - val_loss: 637.7720 - val_accuracy: 0.7741\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 772.7177 - accuracy: 0.7025 - val_loss: 635.7239 - val_accuracy: 0.7670\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.2290 - accuracy: 0.7045 - val_loss: 643.4544 - val_accuracy: 0.7680\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.0911 - accuracy: 0.6959 - val_loss: 633.9429 - val_accuracy: 0.7788\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 782.6725 - accuracy: 0.7085 - val_loss: 644.3546 - val_accuracy: 0.7703\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 776.9755 - accuracy: 0.7009 - val_loss: 635.8759 - val_accuracy: 0.7747\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 772.3201 - accuracy: 0.7099 - val_loss: 637.3000 - val_accuracy: 0.7766\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 775.1488 - accuracy: 0.6921 - val_loss: 634.1418 - val_accuracy: 0.7580\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 772.5369 - accuracy: 0.7008 - val_loss: 637.4752 - val_accuracy: 0.7714\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 773.2578 - accuracy: 0.7016 - val_loss: 638.6609 - val_accuracy: 0.7744\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.4260 - accuracy: 0.7045 - val_loss: 632.7366 - val_accuracy: 0.7688\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.0204 - accuracy: 0.7035 - val_loss: 629.2076 - val_accuracy: 0.7746\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.4011 - accuracy: 0.7041 - val_loss: 630.9008 - val_accuracy: 0.7731\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.6957 - accuracy: 0.7066 - val_loss: 631.7961 - val_accuracy: 0.7700\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 767.1661 - accuracy: 0.7004 - val_loss: 637.1078 - val_accuracy: 0.7791\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 773.2679 - accuracy: 0.7063 - val_loss: 633.7656 - val_accuracy: 0.7659\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.4044 - accuracy: 0.7028 - val_loss: 632.8907 - val_accuracy: 0.7735\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.8300 - accuracy: 0.7024 - val_loss: 634.1047 - val_accuracy: 0.7754\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 768.0380 - accuracy: 0.7086 - val_loss: 629.3156 - val_accuracy: 0.7694\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.4213 - accuracy: 0.7020 - val_loss: 633.9752 - val_accuracy: 0.7670\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 767.9573 - accuracy: 0.7018 - val_loss: 629.5048 - val_accuracy: 0.7744\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.9014 - accuracy: 0.7084 - val_loss: 634.0874 - val_accuracy: 0.7709\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.1067 - accuracy: 0.7060 - val_loss: 628.7356 - val_accuracy: 0.7759\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.7574 - accuracy: 0.7056 - val_loss: 631.2919 - val_accuracy: 0.7809\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 766.6550 - accuracy: 0.7064 - val_loss: 627.4696 - val_accuracy: 0.7820\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.6271 - accuracy: 0.7058 - val_loss: 630.3212 - val_accuracy: 0.7691\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 770.7751 - accuracy: 0.7069 - val_loss: 633.0692 - val_accuracy: 0.7746\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 772.4478 - accuracy: 0.6995 - val_loss: 632.2942 - val_accuracy: 0.7784\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.5303 - accuracy: 0.7040 - val_loss: 628.0182 - val_accuracy: 0.7750\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.0598 - accuracy: 0.7051 - val_loss: 634.4114 - val_accuracy: 0.7749\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 770.9846 - accuracy: 0.6945 - val_loss: 635.4123 - val_accuracy: 0.7603\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.3991 - accuracy: 0.7067 - val_loss: 641.8195 - val_accuracy: 0.7708\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.8445 - accuracy: 0.7048 - val_loss: 635.8525 - val_accuracy: 0.7722\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.7311 - accuracy: 0.7018 - val_loss: 635.6884 - val_accuracy: 0.7729\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 767.7806 - accuracy: 0.7006 - val_loss: 630.5498 - val_accuracy: 0.7782\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.9951 - accuracy: 0.7060 - val_loss: 633.6360 - val_accuracy: 0.7660\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.3730 - accuracy: 0.7048 - val_loss: 632.2002 - val_accuracy: 0.7785\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.2463 - accuracy: 0.7026 - val_loss: 631.4389 - val_accuracy: 0.7722\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.9580 - accuracy: 0.7064 - val_loss: 638.6859 - val_accuracy: 0.7689\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 772.1273 - accuracy: 0.7075 - val_loss: 648.1325 - val_accuracy: 0.7736\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 780.0870 - accuracy: 0.7017 - val_loss: 638.7875 - val_accuracy: 0.7769\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 776.4580 - accuracy: 0.7136 - val_loss: 637.8404 - val_accuracy: 0.7672\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 772.0524 - accuracy: 0.7035 - val_loss: 637.5590 - val_accuracy: 0.7785\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 775.6881 - accuracy: 0.7047 - val_loss: 655.8831 - val_accuracy: 0.7715\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 782.3244 - accuracy: 0.7067 - val_loss: 637.1015 - val_accuracy: 0.7815\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 788.0258 - accuracy: 0.6991 - val_loss: 640.5435 - val_accuracy: 0.7280\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 774.5396 - accuracy: 0.7025 - val_loss: 636.4364 - val_accuracy: 0.7728\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.4679 - accuracy: 0.6994 - val_loss: 631.8074 - val_accuracy: 0.7796\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.0157 - accuracy: 0.7054 - val_loss: 629.5323 - val_accuracy: 0.7764\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.1618 - accuracy: 0.6963 - val_loss: 628.4624 - val_accuracy: 0.7761\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.1025 - accuracy: 0.7138 - val_loss: 627.5315 - val_accuracy: 0.7744\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.3201 - accuracy: 0.7016 - val_loss: 629.4104 - val_accuracy: 0.7802\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 766.4662 - accuracy: 0.7082 - val_loss: 630.9967 - val_accuracy: 0.7731\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.6482 - accuracy: 0.7027 - val_loss: 629.1221 - val_accuracy: 0.7833\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.4261 - accuracy: 0.7037 - val_loss: 631.0247 - val_accuracy: 0.7745\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.9831 - accuracy: 0.7031 - val_loss: 634.3799 - val_accuracy: 0.7764\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 769.8710 - accuracy: 0.7051 - val_loss: 628.8049 - val_accuracy: 0.7769\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 770.7203 - accuracy: 0.7047 - val_loss: 633.3995 - val_accuracy: 0.7777\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 795.5339 - accuracy: 0.7065 - val_loss: 643.7775 - val_accuracy: 0.7823\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.7422 - accuracy: 0.7057 - val_loss: 641.7802 - val_accuracy: 0.7827\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 781.1518 - accuracy: 0.7073 - val_loss: 641.6307 - val_accuracy: 0.7802\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 798.0278 - accuracy: 0.6993 - val_loss: 641.2690 - val_accuracy: 0.7539\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 780.6197 - accuracy: 0.7019 - val_loss: 630.9924 - val_accuracy: 0.7621\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 771.3514 - accuracy: 0.7037 - val_loss: 634.0265 - val_accuracy: 0.7688\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.6320 - accuracy: 0.7044 - val_loss: 631.9305 - val_accuracy: 0.7819\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.1531 - accuracy: 0.7083 - val_loss: 631.1743 - val_accuracy: 0.7736\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.6075 - accuracy: 0.7058 - val_loss: 635.7073 - val_accuracy: 0.7607\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.8370 - accuracy: 0.6982 - val_loss: 638.8377 - val_accuracy: 0.7758\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.9821 - accuracy: 0.7034 - val_loss: 643.3193 - val_accuracy: 0.7742\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.7115 - accuracy: 0.7064 - val_loss: 630.9525 - val_accuracy: 0.7766\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.1238 - accuracy: 0.7068 - val_loss: 629.3785 - val_accuracy: 0.7735\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 766.8043 - accuracy: 0.7086 - val_loss: 631.4235 - val_accuracy: 0.7772\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 766.6165 - accuracy: 0.7016 - val_loss: 628.3713 - val_accuracy: 0.7751\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.4312 - accuracy: 0.7073 - val_loss: 629.1749 - val_accuracy: 0.7725\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.0699 - accuracy: 0.7037 - val_loss: 627.9007 - val_accuracy: 0.7841\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.7465 - accuracy: 0.7062 - val_loss: 627.5737 - val_accuracy: 0.7799\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.4408 - accuracy: 0.7100 - val_loss: 634.3119 - val_accuracy: 0.7804\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 766.0735 - accuracy: 0.7032 - val_loss: 626.8290 - val_accuracy: 0.7707\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 766.7812 - accuracy: 0.7091 - val_loss: 630.6810 - val_accuracy: 0.7699\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.0839 - accuracy: 0.7025 - val_loss: 629.5526 - val_accuracy: 0.7830\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 771.5134 - accuracy: 0.6983 - val_loss: 634.0283 - val_accuracy: 0.7775\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.9124 - accuracy: 0.7151 - val_loss: 628.9039 - val_accuracy: 0.7789\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 767.9772 - accuracy: 0.7036 - val_loss: 628.8260 - val_accuracy: 0.7815\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.8151 - accuracy: 0.7096 - val_loss: 630.4287 - val_accuracy: 0.7784\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 772.4442 - accuracy: 0.6999 - val_loss: 627.2177 - val_accuracy: 0.7763\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 765.7682 - accuracy: 0.7082 - val_loss: 633.7337 - val_accuracy: 0.7766\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.2868 - accuracy: 0.7005 - val_loss: 637.2415 - val_accuracy: 0.7760\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.4712 - accuracy: 0.7104 - val_loss: 634.1929 - val_accuracy: 0.7744\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.6894 - accuracy: 0.7031 - val_loss: 637.2745 - val_accuracy: 0.7778\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.8516 - accuracy: 0.7033 - val_loss: 636.1188 - val_accuracy: 0.7779\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.8684 - accuracy: 0.7008 - val_loss: 635.9001 - val_accuracy: 0.7594\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.1645 - accuracy: 0.7097 - val_loss: 633.9232 - val_accuracy: 0.7744\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.0244 - accuracy: 0.6971 - val_loss: 630.2004 - val_accuracy: 0.7877\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 771.5123 - accuracy: 0.7097 - val_loss: 637.5351 - val_accuracy: 0.7712\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 772.5648 - accuracy: 0.7035 - val_loss: 634.2769 - val_accuracy: 0.7720\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.5164 - accuracy: 0.7037 - val_loss: 631.1210 - val_accuracy: 0.7742\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.8916 - accuracy: 0.7077 - val_loss: 631.6392 - val_accuracy: 0.7707\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.0859 - accuracy: 0.7025 - val_loss: 629.8411 - val_accuracy: 0.7731\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.5743 - accuracy: 0.7015 - val_loss: 627.1602 - val_accuracy: 0.7692\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.8142 - accuracy: 0.7086 - val_loss: 627.6288 - val_accuracy: 0.7667\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.4698 - accuracy: 0.7054 - val_loss: 627.1234 - val_accuracy: 0.7761\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.6795 - accuracy: 0.7080 - val_loss: 631.0908 - val_accuracy: 0.7805\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.7623 - accuracy: 0.7041 - val_loss: 628.1113 - val_accuracy: 0.7826\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 765.4384 - accuracy: 0.7091 - val_loss: 639.2136 - val_accuracy: 0.7723\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 768.1588 - accuracy: 0.7047 - val_loss: 628.2001 - val_accuracy: 0.7745\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.3238 - accuracy: 0.7059 - val_loss: 626.0297 - val_accuracy: 0.7755\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 766.5629 - accuracy: 0.7083 - val_loss: 627.3536 - val_accuracy: 0.7739\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.6694 - accuracy: 0.7062 - val_loss: 628.3010 - val_accuracy: 0.7746\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.0682 - accuracy: 0.7087 - val_loss: 629.7914 - val_accuracy: 0.7805\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.0458 - accuracy: 0.7079 - val_loss: 630.4210 - val_accuracy: 0.7815\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 770.9415 - accuracy: 0.7059 - val_loss: 652.6673 - val_accuracy: 0.7610\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 776.7297 - accuracy: 0.7031 - val_loss: 658.1473 - val_accuracy: 0.7881\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 792.2862 - accuracy: 0.6977 - val_loss: 644.7134 - val_accuracy: 0.7792\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.5612 - accuracy: 0.7018 - val_loss: 636.1514 - val_accuracy: 0.7694\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 770.3950 - accuracy: 0.7045 - val_loss: 636.3663 - val_accuracy: 0.7870\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 772.7985 - accuracy: 0.7063 - val_loss: 631.4555 - val_accuracy: 0.7693\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.0344 - accuracy: 0.7073 - val_loss: 625.3154 - val_accuracy: 0.7813\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.5892 - accuracy: 0.7030 - val_loss: 626.0882 - val_accuracy: 0.7721\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 765.3423 - accuracy: 0.7103 - val_loss: 633.1336 - val_accuracy: 0.7795\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.1585 - accuracy: 0.6954 - val_loss: 629.0507 - val_accuracy: 0.7780\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.4135 - accuracy: 0.7073 - val_loss: 630.0736 - val_accuracy: 0.7710\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.9985 - accuracy: 0.7063 - val_loss: 632.0972 - val_accuracy: 0.7772\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.2533 - accuracy: 0.7017 - val_loss: 633.6819 - val_accuracy: 0.7780\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 765.7271 - accuracy: 0.7038 - val_loss: 631.4926 - val_accuracy: 0.7676\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 770.0839 - accuracy: 0.7050 - val_loss: 638.5321 - val_accuracy: 0.7717\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 776.7200 - accuracy: 0.7012 - val_loss: 635.7285 - val_accuracy: 0.7700\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.2354 - accuracy: 0.7018 - val_loss: 629.4271 - val_accuracy: 0.7811\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.5397 - accuracy: 0.7075 - val_loss: 627.1353 - val_accuracy: 0.7712\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.4246 - accuracy: 0.7117 - val_loss: 649.3083 - val_accuracy: 0.7818\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 771.9095 - accuracy: 0.6970 - val_loss: 628.5212 - val_accuracy: 0.7777\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 767.5562 - accuracy: 0.7086 - val_loss: 633.7164 - val_accuracy: 0.7751\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 765.6014 - accuracy: 0.7076 - val_loss: 630.3252 - val_accuracy: 0.7787\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 765.8328 - accuracy: 0.7026 - val_loss: 626.3184 - val_accuracy: 0.7796\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 763.9089 - accuracy: 0.7077 - val_loss: 629.8930 - val_accuracy: 0.7796\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.0110 - accuracy: 0.7083 - val_loss: 629.7175 - val_accuracy: 0.7766\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 766.0876 - accuracy: 0.7106 - val_loss: 629.9568 - val_accuracy: 0.7827\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 766.4714 - accuracy: 0.6965 - val_loss: 627.2587 - val_accuracy: 0.7833\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.8464 - accuracy: 0.7079 - val_loss: 630.6469 - val_accuracy: 0.7628\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.9463 - accuracy: 0.7056 - val_loss: 635.2432 - val_accuracy: 0.7765\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 779.3168 - accuracy: 0.7029 - val_loss: 647.2741 - val_accuracy: 0.7783\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 780.4410 - accuracy: 0.7091 - val_loss: 636.0400 - val_accuracy: 0.7845\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 790.0651 - accuracy: 0.7007 - val_loss: 687.4153 - val_accuracy: 0.7700\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 808.9968 - accuracy: 0.6975 - val_loss: 658.5798 - val_accuracy: 0.7832\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 781.6442 - accuracy: 0.7008 - val_loss: 632.8798 - val_accuracy: 0.7742\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.4614 - accuracy: 0.7087 - val_loss: 631.3114 - val_accuracy: 0.7808\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.7747 - accuracy: 0.6935 - val_loss: 627.9415 - val_accuracy: 0.7853\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.9933 - accuracy: 0.7145 - val_loss: 628.8242 - val_accuracy: 0.7694\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 762.3123 - accuracy: 0.7016 - val_loss: 626.6556 - val_accuracy: 0.7815\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.3253 - accuracy: 0.7125 - val_loss: 624.3599 - val_accuracy: 0.7794\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 761.9968 - accuracy: 0.7056 - val_loss: 625.9287 - val_accuracy: 0.7719\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 762.5339 - accuracy: 0.7074 - val_loss: 626.6924 - val_accuracy: 0.7792\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.6075 - accuracy: 0.7057 - val_loss: 626.1316 - val_accuracy: 0.7822\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 766.0718 - accuracy: 0.7059 - val_loss: 642.3801 - val_accuracy: 0.7816\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 774.6906 - accuracy: 0.7118 - val_loss: 631.3329 - val_accuracy: 0.7732\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 765.4303 - accuracy: 0.7014 - val_loss: 634.2342 - val_accuracy: 0.7689\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.6119 - accuracy: 0.7084 - val_loss: 628.1696 - val_accuracy: 0.7769\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 766.0709 - accuracy: 0.7053 - val_loss: 628.9561 - val_accuracy: 0.7863\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.7535 - accuracy: 0.7076 - val_loss: 627.5439 - val_accuracy: 0.7832\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 763.9319 - accuracy: 0.7045 - val_loss: 629.2231 - val_accuracy: 0.7778\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.7187 - accuracy: 0.7040 - val_loss: 629.0510 - val_accuracy: 0.7788\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.7672 - accuracy: 0.7093 - val_loss: 629.1888 - val_accuracy: 0.7778\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 772.6942 - accuracy: 0.7041 - val_loss: 628.1303 - val_accuracy: 0.7782\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 769.5791 - accuracy: 0.7063 - val_loss: 633.9520 - val_accuracy: 0.7730\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.8279 - accuracy: 0.7037 - val_loss: 627.0427 - val_accuracy: 0.7801\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 763.5143 - accuracy: 0.7115 - val_loss: 632.2792 - val_accuracy: 0.7702\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.2410 - accuracy: 0.7059 - val_loss: 624.3707 - val_accuracy: 0.7831\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 763.7321 - accuracy: 0.7104 - val_loss: 632.6815 - val_accuracy: 0.7772\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 764.8406 - accuracy: 0.7080 - val_loss: 629.0752 - val_accuracy: 0.7755\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 768.5579 - accuracy: 0.7037 - val_loss: 627.4423 - val_accuracy: 0.7742\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 765.4529 - accuracy: 0.7034 - val_loss: 627.4975 - val_accuracy: 0.7762\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 764.1067 - accuracy: 0.7054 - val_loss: 624.9235 - val_accuracy: 0.7713\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 761.8480 - accuracy: 0.7016 - val_loss: 622.5490 - val_accuracy: 0.7736\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 765.1223 - accuracy: 0.7071 - val_loss: 629.2595 - val_accuracy: 0.7695\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.3682 - accuracy: 0.7083 - val_loss: 622.4902 - val_accuracy: 0.7854\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.3804 - accuracy: 0.7037 - val_loss: 627.3406 - val_accuracy: 0.7670\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 762.3018 - accuracy: 0.7076 - val_loss: 628.5035 - val_accuracy: 0.7806\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 763.2982 - accuracy: 0.7088 - val_loss: 630.1296 - val_accuracy: 0.7729\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 763.7142 - accuracy: 0.7016 - val_loss: 627.8635 - val_accuracy: 0.7672\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.5428 - accuracy: 0.7072 - val_loss: 630.7257 - val_accuracy: 0.7701\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.3921 - accuracy: 0.7004 - val_loss: 629.2239 - val_accuracy: 0.7821\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 764.6437 - accuracy: 0.7072 - val_loss: 638.1694 - val_accuracy: 0.7704\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.0192 - accuracy: 0.7015 - val_loss: 627.8114 - val_accuracy: 0.7816\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 761.7343 - accuracy: 0.7100 - val_loss: 627.5290 - val_accuracy: 0.7782\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 762.0757 - accuracy: 0.7033 - val_loss: 626.9443 - val_accuracy: 0.7786\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 761.8689 - accuracy: 0.7154 - val_loss: 627.6491 - val_accuracy: 0.7717\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 761.7469 - accuracy: 0.7027 - val_loss: 626.5881 - val_accuracy: 0.7775\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.1742 - accuracy: 0.7075 - val_loss: 628.9420 - val_accuracy: 0.7772\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.7589 - accuracy: 0.7114 - val_loss: 629.5778 - val_accuracy: 0.7759\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 764.0906 - accuracy: 0.7068 - val_loss: 625.2971 - val_accuracy: 0.7764\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 770.2650 - accuracy: 0.7051 - val_loss: 634.1542 - val_accuracy: 0.7809\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.6936 - accuracy: 0.7156 - val_loss: 635.6285 - val_accuracy: 0.7772\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 770.7115 - accuracy: 0.7047 - val_loss: 625.3054 - val_accuracy: 0.7797\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 772.7913 - accuracy: 0.7051 - val_loss: 629.9305 - val_accuracy: 0.7648\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 791.4205 - accuracy: 0.6993 - val_loss: 643.8059 - val_accuracy: 0.7814\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 788.8221 - accuracy: 0.7036 - val_loss: 637.6678 - val_accuracy: 0.7821\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 781.1123 - accuracy: 0.7048 - val_loss: 637.5489 - val_accuracy: 0.7805\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 775.4427 - accuracy: 0.6960 - val_loss: 628.9984 - val_accuracy: 0.7778\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.6211 - accuracy: 0.7042 - val_loss: 630.5229 - val_accuracy: 0.7646\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.7428 - accuracy: 0.7043 - val_loss: 625.7213 - val_accuracy: 0.7751\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 761.9720 - accuracy: 0.7057 - val_loss: 627.8926 - val_accuracy: 0.7657\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 762.2946 - accuracy: 0.7023 - val_loss: 624.6761 - val_accuracy: 0.7795\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 760.7767 - accuracy: 0.7129 - val_loss: 624.3737 - val_accuracy: 0.7798\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.6059 - accuracy: 0.7049 - val_loss: 627.4983 - val_accuracy: 0.7801\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.7449 - accuracy: 0.7093 - val_loss: 630.0571 - val_accuracy: 0.7789\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 766.8234 - accuracy: 0.7040 - val_loss: 625.2496 - val_accuracy: 0.7762\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 761.3431 - accuracy: 0.7097 - val_loss: 626.7062 - val_accuracy: 0.7837\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 761.7514 - accuracy: 0.7067 - val_loss: 629.2558 - val_accuracy: 0.7840\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.4981 - accuracy: 0.7028 - val_loss: 631.7390 - val_accuracy: 0.7800\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 780.2161 - accuracy: 0.7077 - val_loss: 629.4373 - val_accuracy: 0.7696\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 772.9283 - accuracy: 0.7008 - val_loss: 632.4742 - val_accuracy: 0.7563\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 777.5842 - accuracy: 0.7105 - val_loss: 632.6925 - val_accuracy: 0.7605\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 765.9661 - accuracy: 0.7070 - val_loss: 628.4578 - val_accuracy: 0.7785\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.5792 - accuracy: 0.7038 - val_loss: 623.6965 - val_accuracy: 0.7862\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 760.6219 - accuracy: 0.7093 - val_loss: 625.3693 - val_accuracy: 0.7776\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 759.1990 - accuracy: 0.7116 - val_loss: 623.9879 - val_accuracy: 0.7757\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 762.0103 - accuracy: 0.7046 - val_loss: 624.4237 - val_accuracy: 0.7674\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 762.9473 - accuracy: 0.7109 - val_loss: 627.0994 - val_accuracy: 0.7664\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 761.8102 - accuracy: 0.7022 - val_loss: 626.3574 - val_accuracy: 0.7788\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 760.6147 - accuracy: 0.7129 - val_loss: 625.8017 - val_accuracy: 0.7814\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 760.7093 - accuracy: 0.7035 - val_loss: 624.3336 - val_accuracy: 0.7886\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.0031 - accuracy: 0.7083 - val_loss: 627.3799 - val_accuracy: 0.7704\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 766.5426 - accuracy: 0.7067 - val_loss: 629.9108 - val_accuracy: 0.7806\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.5881 - accuracy: 0.7051 - val_loss: 630.7468 - val_accuracy: 0.7875\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 769.7413 - accuracy: 0.7109 - val_loss: 629.4011 - val_accuracy: 0.7857\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.2866 - accuracy: 0.7081 - val_loss: 626.1405 - val_accuracy: 0.7747\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.5882 - accuracy: 0.7092 - val_loss: 629.0129 - val_accuracy: 0.7821\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.4553 - accuracy: 0.7032 - val_loss: 626.9684 - val_accuracy: 0.7790\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.4170 - accuracy: 0.7006 - val_loss: 625.2795 - val_accuracy: 0.7819\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 764.8474 - accuracy: 0.7092 - val_loss: 628.5255 - val_accuracy: 0.7729\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.3459 - accuracy: 0.7029 - val_loss: 624.2214 - val_accuracy: 0.7786\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.4499 - accuracy: 0.7006 - val_loss: 625.8636 - val_accuracy: 0.7725\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 764.2375 - accuracy: 0.7126 - val_loss: 625.9731 - val_accuracy: 0.7809\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.2236 - accuracy: 0.7013 - val_loss: 627.5099 - val_accuracy: 0.7775\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.1223 - accuracy: 0.7123 - val_loss: 629.6376 - val_accuracy: 0.7755\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.4687 - accuracy: 0.7015 - val_loss: 623.4379 - val_accuracy: 0.7839\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 766.4531 - accuracy: 0.7142 - val_loss: 632.4404 - val_accuracy: 0.7783\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.2399 - accuracy: 0.7076 - val_loss: 624.0458 - val_accuracy: 0.7869\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 761.1241 - accuracy: 0.7009 - val_loss: 624.5859 - val_accuracy: 0.7805\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 761.6639 - accuracy: 0.7065 - val_loss: 624.6514 - val_accuracy: 0.7792\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.4135 - accuracy: 0.7057 - val_loss: 628.8041 - val_accuracy: 0.7744\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 762.1505 - accuracy: 0.7099 - val_loss: 626.0099 - val_accuracy: 0.7804\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 760.1931 - accuracy: 0.7090 - val_loss: 627.2552 - val_accuracy: 0.7786\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.2623 - accuracy: 0.7000 - val_loss: 623.0666 - val_accuracy: 0.7718\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 761.0161 - accuracy: 0.7066 - val_loss: 627.7435 - val_accuracy: 0.7676\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 761.2012 - accuracy: 0.7088 - val_loss: 630.3077 - val_accuracy: 0.7779\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.4019 - accuracy: 0.7048 - val_loss: 625.2958 - val_accuracy: 0.7763\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 766.9866 - accuracy: 0.7040 - val_loss: 635.8325 - val_accuracy: 0.7733\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 771.2936 - accuracy: 0.7129 - val_loss: 629.3138 - val_accuracy: 0.7712\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 763.3818 - accuracy: 0.7034 - val_loss: 628.6590 - val_accuracy: 0.7735\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.2571 - accuracy: 0.7069 - val_loss: 625.0298 - val_accuracy: 0.7802\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 761.3626 - accuracy: 0.7097 - val_loss: 627.3905 - val_accuracy: 0.7815\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.1680 - accuracy: 0.7075 - val_loss: 635.1155 - val_accuracy: 0.7842\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 772.1445 - accuracy: 0.6976 - val_loss: 626.8042 - val_accuracy: 0.7826\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.7495 - accuracy: 0.7110 - val_loss: 627.8717 - val_accuracy: 0.7797\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.9426 - accuracy: 0.7015 - val_loss: 625.4094 - val_accuracy: 0.7734\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.3492 - accuracy: 0.7026 - val_loss: 626.8489 - val_accuracy: 0.7753\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 762.9094 - accuracy: 0.7090 - val_loss: 622.8849 - val_accuracy: 0.7759\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 760.3836 - accuracy: 0.7075 - val_loss: 626.9677 - val_accuracy: 0.7842\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.6966 - accuracy: 0.7027 - val_loss: 624.4402 - val_accuracy: 0.7779\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 760.0138 - accuracy: 0.7059 - val_loss: 624.0808 - val_accuracy: 0.7710\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 759.0842 - accuracy: 0.7102 - val_loss: 625.9986 - val_accuracy: 0.7827\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 759.3854 - accuracy: 0.7052 - val_loss: 623.2911 - val_accuracy: 0.7833\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 761.0311 - accuracy: 0.7135 - val_loss: 627.3781 - val_accuracy: 0.7704\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 760.5046 - accuracy: 0.7028 - val_loss: 628.5960 - val_accuracy: 0.7750\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 760.0764 - accuracy: 0.7036 - val_loss: 629.6098 - val_accuracy: 0.7801\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.2772 - accuracy: 0.7061 - val_loss: 637.9790 - val_accuracy: 0.7787\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.1318 - accuracy: 0.7061 - val_loss: 637.3471 - val_accuracy: 0.7770\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 766.3952 - accuracy: 0.7089 - val_loss: 628.5109 - val_accuracy: 0.7839\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.1791 - accuracy: 0.7040 - val_loss: 624.5377 - val_accuracy: 0.7743\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 762.1096 - accuracy: 0.7131 - val_loss: 625.8640 - val_accuracy: 0.7737\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 762.1859 - accuracy: 0.6936 - val_loss: 626.4995 - val_accuracy: 0.7736\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 759.3665 - accuracy: 0.7112 - val_loss: 627.7952 - val_accuracy: 0.7670\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 761.0393 - accuracy: 0.7007 - val_loss: 628.1427 - val_accuracy: 0.7716\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 759.2479 - accuracy: 0.7124 - val_loss: 623.1556 - val_accuracy: 0.7832\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 759.7151 - accuracy: 0.7022 - val_loss: 626.3798 - val_accuracy: 0.7854\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.8502 - accuracy: 0.7088 - val_loss: 627.2115 - val_accuracy: 0.7799\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 759.2818 - accuracy: 0.7117 - val_loss: 621.5662 - val_accuracy: 0.7837\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.2253 - accuracy: 0.7040 - val_loss: 638.6492 - val_accuracy: 0.7762\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 783.7927 - accuracy: 0.7113 - val_loss: 634.9677 - val_accuracy: 0.7151\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 769.3261 - accuracy: 0.7038 - val_loss: 637.3776 - val_accuracy: 0.7811\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.8404 - accuracy: 0.7024 - val_loss: 627.4999 - val_accuracy: 0.7763\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.3726 - accuracy: 0.7052 - val_loss: 638.2163 - val_accuracy: 0.7790\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 763.7332 - accuracy: 0.7087 - val_loss: 626.7571 - val_accuracy: 0.7841\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 762.8789 - accuracy: 0.7073 - val_loss: 628.4958 - val_accuracy: 0.7813\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 759.4952 - accuracy: 0.7067 - val_loss: 621.5884 - val_accuracy: 0.7723\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 758.4020 - accuracy: 0.7099 - val_loss: 627.0779 - val_accuracy: 0.7729\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 762.7795 - accuracy: 0.6984 - val_loss: 627.6506 - val_accuracy: 0.7775\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 758.9883 - accuracy: 0.7099 - val_loss: 624.0330 - val_accuracy: 0.7828\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 757.2304 - accuracy: 0.7040 - val_loss: 625.6902 - val_accuracy: 0.7722\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 757.5082 - accuracy: 0.7140 - val_loss: 625.0839 - val_accuracy: 0.7757\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.9873 - accuracy: 0.7050 - val_loss: 632.5189 - val_accuracy: 0.7822\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.9455 - accuracy: 0.7081 - val_loss: 626.1841 - val_accuracy: 0.7802\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 760.0469 - accuracy: 0.7061 - val_loss: 638.5220 - val_accuracy: 0.7669\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.2872 - accuracy: 0.7079 - val_loss: 630.1622 - val_accuracy: 0.7710\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 760.7928 - accuracy: 0.7050 - val_loss: 622.5997 - val_accuracy: 0.7713\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 759.7868 - accuracy: 0.7040 - val_loss: 626.5648 - val_accuracy: 0.7807\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.3844 - accuracy: 0.7101 - val_loss: 639.1707 - val_accuracy: 0.7769\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.9867 - accuracy: 0.7098 - val_loss: 629.5873 - val_accuracy: 0.7691\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 768.6820 - accuracy: 0.7069 - val_loss: 627.3910 - val_accuracy: 0.7668\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 771.9442 - accuracy: 0.7031 - val_loss: 629.5619 - val_accuracy: 0.7869\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.1042 - accuracy: 0.7032 - val_loss: 626.2930 - val_accuracy: 0.7787\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 763.1208 - accuracy: 0.7032 - val_loss: 636.1797 - val_accuracy: 0.7689\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 779.0713 - accuracy: 0.7147 - val_loss: 631.3291 - val_accuracy: 0.7793\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 773.9719 - accuracy: 0.7010 - val_loss: 626.3132 - val_accuracy: 0.7839\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 767.4603 - accuracy: 0.7069 - val_loss: 625.2132 - val_accuracy: 0.7703\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.5740 - accuracy: 0.7080 - val_loss: 629.0186 - val_accuracy: 0.7782\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 762.2341 - accuracy: 0.7028 - val_loss: 628.1993 - val_accuracy: 0.7759\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 760.6688 - accuracy: 0.7099 - val_loss: 624.7939 - val_accuracy: 0.7745\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 757.6123 - accuracy: 0.7026 - val_loss: 620.6414 - val_accuracy: 0.7739\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 760.3304 - accuracy: 0.7053 - val_loss: 630.4104 - val_accuracy: 0.7826\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 764.0216 - accuracy: 0.7069 - val_loss: 626.2775 - val_accuracy: 0.7787\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.4949 - accuracy: 0.7084 - val_loss: 624.4755 - val_accuracy: 0.7809\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 759.6402 - accuracy: 0.7088 - val_loss: 626.0814 - val_accuracy: 0.7835\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 758.2998 - accuracy: 0.7063 - val_loss: 627.3851 - val_accuracy: 0.7836\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 762.0471 - accuracy: 0.7032 - val_loss: 636.9596 - val_accuracy: 0.7665\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 773.1458 - accuracy: 0.7124 - val_loss: 628.4921 - val_accuracy: 0.7662\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 763.4792 - accuracy: 0.6993 - val_loss: 622.3521 - val_accuracy: 0.7820\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 758.7518 - accuracy: 0.7087 - val_loss: 623.1832 - val_accuracy: 0.7564\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 757.1021 - accuracy: 0.7048 - val_loss: 622.4633 - val_accuracy: 0.7857\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 756.3606 - accuracy: 0.7057 - val_loss: 623.5510 - val_accuracy: 0.7794\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 756.8633 - accuracy: 0.7105 - val_loss: 624.0601 - val_accuracy: 0.7559\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 1s 57ms/step - loss: 755.5305 - accuracy: 0.7096 - val_loss: 623.0479 - val_accuracy: 0.7765\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 758.4523 - accuracy: 0.7098 - val_loss: 627.4134 - val_accuracy: 0.7811\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 1s 56ms/step - loss: 759.0575 - accuracy: 0.7091 - val_loss: 625.6685 - val_accuracy: 0.7783\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 757.2890 - accuracy: 0.7085 - val_loss: 623.6019 - val_accuracy: 0.7831\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 1s 53ms/step - loss: 756.5462 - accuracy: 0.7062 - val_loss: 624.1517 - val_accuracy: 0.7743\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 1s 59ms/step - loss: 759.9340 - accuracy: 0.7100 - val_loss: 626.3400 - val_accuracy: 0.7822\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 1s 50ms/step - loss: 758.5732 - accuracy: 0.7017 - val_loss: 624.1143 - val_accuracy: 0.7867\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 758.6531 - accuracy: 0.7108 - val_loss: 632.6234 - val_accuracy: 0.7705\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 759.9893 - accuracy: 0.7037 - val_loss: 624.1777 - val_accuracy: 0.7806\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 761.1838 - accuracy: 0.7086 - val_loss: 625.0938 - val_accuracy: 0.7697\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 758.3649 - accuracy: 0.7070 - val_loss: 624.2576 - val_accuracy: 0.7707\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 759.7598 - accuracy: 0.7128 - val_loss: 625.0561 - val_accuracy: 0.7835\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 762.8120 - accuracy: 0.6951 - val_loss: 627.2802 - val_accuracy: 0.7795\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 765.1404 - accuracy: 0.7103 - val_loss: 623.6708 - val_accuracy: 0.7777\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 760.9858 - accuracy: 0.7072 - val_loss: 622.9643 - val_accuracy: 0.7789\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.4671 - accuracy: 0.7071 - val_loss: 625.3268 - val_accuracy: 0.7798\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 760.9510 - accuracy: 0.7060 - val_loss: 626.2019 - val_accuracy: 0.7676\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 761.9945 - accuracy: 0.7055 - val_loss: 626.8901 - val_accuracy: 0.7803\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 765.4072 - accuracy: 0.7047 - val_loss: 626.8843 - val_accuracy: 0.7733\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.7941 - accuracy: 0.7088 - val_loss: 631.5112 - val_accuracy: 0.7804\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.0175 - accuracy: 0.7037 - val_loss: 621.6165 - val_accuracy: 0.7796\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 763.5748 - accuracy: 0.7061 - val_loss: 623.4285 - val_accuracy: 0.7785\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.1966 - accuracy: 0.7019 - val_loss: 619.1541 - val_accuracy: 0.7780\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.8349 - accuracy: 0.7060 - val_loss: 623.2631 - val_accuracy: 0.7836\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 761.4980 - accuracy: 0.7138 - val_loss: 624.3940 - val_accuracy: 0.7706\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 758.3600 - accuracy: 0.7028 - val_loss: 622.8180 - val_accuracy: 0.7902\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 758.0731 - accuracy: 0.7095 - val_loss: 625.1110 - val_accuracy: 0.7738\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 758.1641 - accuracy: 0.7104 - val_loss: 622.3531 - val_accuracy: 0.7752\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 756.4852 - accuracy: 0.7045 - val_loss: 622.4027 - val_accuracy: 0.7823\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 757.2953 - accuracy: 0.7131 - val_loss: 624.2798 - val_accuracy: 0.7788\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 755.3859 - accuracy: 0.7062 - val_loss: 623.6992 - val_accuracy: 0.7787\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 754.0347 - accuracy: 0.7098 - val_loss: 621.8597 - val_accuracy: 0.7771\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 755.6240 - accuracy: 0.7075 - val_loss: 622.2283 - val_accuracy: 0.7881\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 757.5839 - accuracy: 0.7084 - val_loss: 623.6138 - val_accuracy: 0.7748\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 760.5830 - accuracy: 0.7055 - val_loss: 624.7194 - val_accuracy: 0.7867\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 758.7291 - accuracy: 0.7074 - val_loss: 625.4833 - val_accuracy: 0.7754\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.7529 - accuracy: 0.7085 - val_loss: 634.8491 - val_accuracy: 0.7853\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 774.9595 - accuracy: 0.6990 - val_loss: 637.2496 - val_accuracy: 0.7798\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 767.8153 - accuracy: 0.7016 - val_loss: 645.8808 - val_accuracy: 0.7877\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 766.7173 - accuracy: 0.7064 - val_loss: 624.3520 - val_accuracy: 0.7525\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 758.8246 - accuracy: 0.7020 - val_loss: 622.9113 - val_accuracy: 0.7870\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 758.0067 - accuracy: 0.7086 - val_loss: 626.8112 - val_accuracy: 0.7833\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.6312 - accuracy: 0.7066 - val_loss: 626.9890 - val_accuracy: 0.7831\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 774.4691 - accuracy: 0.7051 - val_loss: 644.9474 - val_accuracy: 0.7634\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 767.5148 - accuracy: 0.7060 - val_loss: 628.0698 - val_accuracy: 0.7590\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 785.2757 - accuracy: 0.7068 - val_loss: 633.2581 - val_accuracy: 0.7804\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 772.7877 - accuracy: 0.7039 - val_loss: 626.3030 - val_accuracy: 0.7763\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 763.3360 - accuracy: 0.7117 - val_loss: 628.2740 - val_accuracy: 0.7476\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 764.4922 - accuracy: 0.7000 - val_loss: 624.5261 - val_accuracy: 0.7681\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 758.8201 - accuracy: 0.7073 - val_loss: 625.8279 - val_accuracy: 0.7738\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 756.1730 - accuracy: 0.7117 - val_loss: 622.5730 - val_accuracy: 0.7800\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 754.1431 - accuracy: 0.7029 - val_loss: 618.8809 - val_accuracy: 0.7788\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 753.7845 - accuracy: 0.7132 - val_loss: 620.7909 - val_accuracy: 0.7822\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 753.6466 - accuracy: 0.7126 - val_loss: 615.8605 - val_accuracy: 0.7846\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 752.8848 - accuracy: 0.7058 - val_loss: 619.4856 - val_accuracy: 0.7818\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 757.6472 - accuracy: 0.7098 - val_loss: 624.4050 - val_accuracy: 0.7688\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 761.9901 - accuracy: 0.7092 - val_loss: 623.4000 - val_accuracy: 0.7864\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.2618 - accuracy: 0.7000 - val_loss: 623.6272 - val_accuracy: 0.7781\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 761.5429 - accuracy: 0.7097 - val_loss: 627.2532 - val_accuracy: 0.7700\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 762.1874 - accuracy: 0.7006 - val_loss: 629.3499 - val_accuracy: 0.7917\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 757.5058 - accuracy: 0.7067 - val_loss: 627.2963 - val_accuracy: 0.7743\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.2980 - accuracy: 0.7049 - val_loss: 621.0538 - val_accuracy: 0.7844\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 754.0742 - accuracy: 0.7099 - val_loss: 623.3637 - val_accuracy: 0.7726\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 757.6117 - accuracy: 0.7044 - val_loss: 625.4313 - val_accuracy: 0.7639\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 757.9457 - accuracy: 0.7117 - val_loss: 622.3174 - val_accuracy: 0.7765\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 755.8043 - accuracy: 0.7064 - val_loss: 621.1951 - val_accuracy: 0.7620\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 755.2087 - accuracy: 0.7107 - val_loss: 623.8619 - val_accuracy: 0.7792\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 757.0469 - accuracy: 0.7028 - val_loss: 621.6096 - val_accuracy: 0.7874\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.1651 - accuracy: 0.7062 - val_loss: 625.4572 - val_accuracy: 0.7720\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 755.5220 - accuracy: 0.7079 - val_loss: 622.8534 - val_accuracy: 0.7846\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 759.8990 - accuracy: 0.7097 - val_loss: 635.3492 - val_accuracy: 0.7897\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 783.6992 - accuracy: 0.7045 - val_loss: 640.6208 - val_accuracy: 0.7761\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 771.0706 - accuracy: 0.7088 - val_loss: 636.0088 - val_accuracy: 0.7821\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 775.4024 - accuracy: 0.7045 - val_loss: 631.8892 - val_accuracy: 0.7709\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 770.1376 - accuracy: 0.7055 - val_loss: 634.7950 - val_accuracy: 0.7751\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 760.6316 - accuracy: 0.7068 - val_loss: 621.2385 - val_accuracy: 0.7668\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 756.0434 - accuracy: 0.7073 - val_loss: 627.0917 - val_accuracy: 0.7867\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.2224 - accuracy: 0.7116 - val_loss: 625.8148 - val_accuracy: 0.7823\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 763.9918 - accuracy: 0.7046 - val_loss: 626.4728 - val_accuracy: 0.7857\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 760.9462 - accuracy: 0.7053 - val_loss: 627.6995 - val_accuracy: 0.7827\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 763.6912 - accuracy: 0.7093 - val_loss: 628.4780 - val_accuracy: 0.7774\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 763.1969 - accuracy: 0.7013 - val_loss: 627.7010 - val_accuracy: 0.7978\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 1s 43ms/step - loss: 760.6553 - accuracy: 0.7064 - val_loss: 628.8270 - val_accuracy: 0.7803\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 1s 45ms/step - loss: 759.7736 - accuracy: 0.7096 - val_loss: 621.8700 - val_accuracy: 0.7816\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 758.8591 - accuracy: 0.7048 - val_loss: 623.3779 - val_accuracy: 0.7813\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 757.2595 - accuracy: 0.7156 - val_loss: 634.9905 - val_accuracy: 0.7815\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample1)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer1)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool2)\n",
        "\n",
        "# Define the convolutional layer\n",
        "#conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(input_layer1)\n",
        "upsample = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv4 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer2)\n",
        "pool4 = layers.MaxPooling2D(pool_size=(1, 1))(conv4)\n",
        "conv5 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool4)\n",
        "pool5 = layers.MaxPooling2D(pool_size=(1, 1))(conv5)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool5)\n",
        "# Define the output layer\n",
        "output_layer = layers.Add()([output_layer1, output_layer2 ])\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=32, validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zy05z3Z7ZUc",
        "outputId": "d3ccb649-6c14-461d-dd82-92be04522517"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 49ms/step - loss: 8378.8906 - accuracy: 0.0183 - val_loss: 6011.7480 - val_accuracy: 0.0058\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 6712.8682 - accuracy: 0.0183 - val_loss: 4914.2310 - val_accuracy: 0.0044\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 5219.0054 - accuracy: 0.0627 - val_loss: 4186.1943 - val_accuracy: 0.0075\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 4237.2812 - accuracy: 0.0201 - val_loss: 3603.6882 - val_accuracy: 0.0141\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 3520.6104 - accuracy: 0.0681 - val_loss: 2966.2749 - val_accuracy: 0.0497\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 2936.1086 - accuracy: 0.0595 - val_loss: 2458.1980 - val_accuracy: 0.0309\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 2422.3650 - accuracy: 0.1251 - val_loss: 2063.2795 - val_accuracy: 0.1676\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 2142.0759 - accuracy: 0.2209 - val_loss: 1870.4133 - val_accuracy: 0.1852\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1937.6356 - accuracy: 0.2211 - val_loss: 1734.7639 - val_accuracy: 0.1180\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1776.4199 - accuracy: 0.1708 - val_loss: 1559.9083 - val_accuracy: 0.1852\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1640.1180 - accuracy: 0.2401 - val_loss: 1431.3467 - val_accuracy: 0.1994\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1525.2352 - accuracy: 0.2212 - val_loss: 1335.9117 - val_accuracy: 0.2116\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1440.5240 - accuracy: 0.2797 - val_loss: 1281.9106 - val_accuracy: 0.2452\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1376.9432 - accuracy: 0.2903 - val_loss: 1212.5760 - val_accuracy: 0.2478\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1334.1816 - accuracy: 0.3301 - val_loss: 1169.9409 - val_accuracy: 0.4925\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1290.5525 - accuracy: 0.4161 - val_loss: 1123.9243 - val_accuracy: 0.5591\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1255.1993 - accuracy: 0.4560 - val_loss: 1052.0342 - val_accuracy: 0.5769\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1195.8136 - accuracy: 0.4065 - val_loss: 951.6125 - val_accuracy: 0.3080\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1155.4197 - accuracy: 0.4286 - val_loss: 915.4930 - val_accuracy: 0.3610\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1129.6610 - accuracy: 0.4480 - val_loss: 884.4312 - val_accuracy: 0.5530\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1107.9596 - accuracy: 0.5137 - val_loss: 858.2142 - val_accuracy: 0.5222\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1081.4961 - accuracy: 0.5402 - val_loss: 839.8160 - val_accuracy: 0.6022\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1068.0452 - accuracy: 0.5533 - val_loss: 826.5099 - val_accuracy: 0.6415\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1056.1552 - accuracy: 0.5588 - val_loss: 819.8815 - val_accuracy: 0.6478\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1039.2096 - accuracy: 0.5570 - val_loss: 804.6918 - val_accuracy: 0.6443\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1027.2781 - accuracy: 0.5671 - val_loss: 792.0107 - val_accuracy: 0.6266\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1026.2374 - accuracy: 0.5671 - val_loss: 788.9550 - val_accuracy: 0.6293\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1013.1659 - accuracy: 0.5717 - val_loss: 775.3785 - val_accuracy: 0.6247\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1006.9866 - accuracy: 0.5653 - val_loss: 775.9182 - val_accuracy: 0.6400\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1002.5791 - accuracy: 0.5704 - val_loss: 769.2887 - val_accuracy: 0.6254\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 999.0975 - accuracy: 0.5676 - val_loss: 774.7370 - val_accuracy: 0.6301\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 992.0101 - accuracy: 0.5715 - val_loss: 764.4601 - val_accuracy: 0.6116\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 984.2632 - accuracy: 0.5673 - val_loss: 766.4354 - val_accuracy: 0.6286\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 981.6287 - accuracy: 0.5728 - val_loss: 763.6330 - val_accuracy: 0.6223\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 976.6122 - accuracy: 0.5693 - val_loss: 760.1240 - val_accuracy: 0.6257\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 973.3647 - accuracy: 0.5683 - val_loss: 750.0070 - val_accuracy: 0.6398\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 963.9586 - accuracy: 0.5718 - val_loss: 747.0362 - val_accuracy: 0.6369\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 963.5242 - accuracy: 0.5746 - val_loss: 744.1437 - val_accuracy: 0.6174\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 960.7498 - accuracy: 0.5728 - val_loss: 748.0609 - val_accuracy: 0.6377\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 957.3082 - accuracy: 0.5763 - val_loss: 745.6935 - val_accuracy: 0.6294\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 955.4370 - accuracy: 0.5750 - val_loss: 740.1732 - val_accuracy: 0.6349\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 952.6287 - accuracy: 0.5739 - val_loss: 743.6451 - val_accuracy: 0.6492\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 951.6042 - accuracy: 0.5742 - val_loss: 738.1351 - val_accuracy: 0.6385\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 948.4095 - accuracy: 0.5791 - val_loss: 736.9817 - val_accuracy: 0.6368\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 950.7380 - accuracy: 0.5760 - val_loss: 733.1483 - val_accuracy: 0.6562\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 946.4400 - accuracy: 0.5882 - val_loss: 736.8767 - val_accuracy: 0.6573\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 944.5671 - accuracy: 0.5788 - val_loss: 733.5740 - val_accuracy: 0.6628\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 941.4573 - accuracy: 0.5843 - val_loss: 732.6597 - val_accuracy: 0.6468\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 938.1664 - accuracy: 0.5926 - val_loss: 733.2426 - val_accuracy: 0.6564\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 940.1412 - accuracy: 0.5832 - val_loss: 728.7070 - val_accuracy: 0.6542\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 934.5752 - accuracy: 0.5881 - val_loss: 728.2146 - val_accuracy: 0.6722\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 936.4980 - accuracy: 0.5998 - val_loss: 728.0394 - val_accuracy: 0.6440\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 929.9551 - accuracy: 0.5926 - val_loss: 726.3356 - val_accuracy: 0.6724\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 931.1644 - accuracy: 0.5929 - val_loss: 726.2623 - val_accuracy: 0.6362\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 932.5807 - accuracy: 0.5831 - val_loss: 725.9017 - val_accuracy: 0.6520\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 928.1581 - accuracy: 0.5976 - val_loss: 727.3834 - val_accuracy: 0.6847\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 925.8131 - accuracy: 0.6023 - val_loss: 722.6009 - val_accuracy: 0.6489\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 927.8752 - accuracy: 0.5964 - val_loss: 724.3750 - val_accuracy: 0.6555\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 922.0482 - accuracy: 0.5949 - val_loss: 719.4024 - val_accuracy: 0.6589\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 921.2804 - accuracy: 0.5980 - val_loss: 721.3604 - val_accuracy: 0.6705\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 921.4638 - accuracy: 0.5927 - val_loss: 718.9184 - val_accuracy: 0.6676\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 921.9056 - accuracy: 0.6028 - val_loss: 729.3478 - val_accuracy: 0.6512\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 920.7845 - accuracy: 0.6003 - val_loss: 715.7653 - val_accuracy: 0.6572\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 915.3309 - accuracy: 0.5953 - val_loss: 724.4177 - val_accuracy: 0.6564\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 918.6203 - accuracy: 0.5985 - val_loss: 716.2167 - val_accuracy: 0.6597\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 914.3910 - accuracy: 0.6017 - val_loss: 731.6497 - val_accuracy: 0.6651\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 918.8335 - accuracy: 0.5961 - val_loss: 711.2549 - val_accuracy: 0.6698\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 912.2059 - accuracy: 0.6023 - val_loss: 714.7949 - val_accuracy: 0.6571\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 911.1904 - accuracy: 0.6032 - val_loss: 714.4424 - val_accuracy: 0.6847\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 907.9251 - accuracy: 0.6076 - val_loss: 710.4948 - val_accuracy: 0.6786\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 910.0753 - accuracy: 0.6078 - val_loss: 714.1252 - val_accuracy: 0.6837\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 910.4819 - accuracy: 0.6058 - val_loss: 711.2203 - val_accuracy: 0.6856\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 909.9099 - accuracy: 0.6157 - val_loss: 710.6990 - val_accuracy: 0.6572\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 906.7203 - accuracy: 0.6040 - val_loss: 716.0931 - val_accuracy: 0.6829\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 911.5641 - accuracy: 0.6116 - val_loss: 708.2086 - val_accuracy: 0.6838\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 906.8357 - accuracy: 0.6132 - val_loss: 707.7327 - val_accuracy: 0.6852\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 903.7915 - accuracy: 0.6145 - val_loss: 705.2252 - val_accuracy: 0.6790\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 901.8836 - accuracy: 0.6099 - val_loss: 707.5755 - val_accuracy: 0.6742\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 903.1503 - accuracy: 0.6079 - val_loss: 706.5522 - val_accuracy: 0.6750\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 903.8534 - accuracy: 0.6100 - val_loss: 711.0969 - val_accuracy: 0.6974\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 903.5989 - accuracy: 0.6081 - val_loss: 707.0530 - val_accuracy: 0.7050\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 902.4920 - accuracy: 0.6138 - val_loss: 704.2468 - val_accuracy: 0.6723\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 903.7111 - accuracy: 0.6091 - val_loss: 704.3752 - val_accuracy: 0.6934\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 898.8295 - accuracy: 0.6148 - val_loss: 703.1121 - val_accuracy: 0.6937\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 896.5216 - accuracy: 0.6135 - val_loss: 700.3739 - val_accuracy: 0.6773\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 895.6948 - accuracy: 0.6200 - val_loss: 703.8920 - val_accuracy: 0.6840\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 902.6608 - accuracy: 0.6197 - val_loss: 700.4674 - val_accuracy: 0.6794\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 898.0963 - accuracy: 0.6191 - val_loss: 708.4747 - val_accuracy: 0.6884\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 900.3393 - accuracy: 0.6179 - val_loss: 701.3770 - val_accuracy: 0.6978\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 896.0604 - accuracy: 0.6193 - val_loss: 700.5245 - val_accuracy: 0.6951\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 895.2386 - accuracy: 0.6191 - val_loss: 700.4179 - val_accuracy: 0.6968\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 897.9836 - accuracy: 0.6142 - val_loss: 700.3232 - val_accuracy: 0.6879\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 901.6274 - accuracy: 0.6197 - val_loss: 709.1374 - val_accuracy: 0.6991\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 899.6035 - accuracy: 0.6133 - val_loss: 704.6686 - val_accuracy: 0.7187\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 895.3525 - accuracy: 0.6192 - val_loss: 702.1833 - val_accuracy: 0.6849\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 892.8608 - accuracy: 0.6113 - val_loss: 698.5225 - val_accuracy: 0.7029\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 890.0701 - accuracy: 0.6210 - val_loss: 695.2168 - val_accuracy: 0.6917\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 887.4738 - accuracy: 0.6223 - val_loss: 698.1906 - val_accuracy: 0.6989\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 888.7762 - accuracy: 0.6232 - val_loss: 701.4009 - val_accuracy: 0.6881\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 891.2023 - accuracy: 0.6230 - val_loss: 694.3618 - val_accuracy: 0.7075\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample1)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer1)\n",
        "pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "#conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "#pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "#conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(input_layer1)\n",
        "upsample = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "conv4 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer2)\n",
        "pool4 = layers.MaxPooling2D(pool_size=(1, 1))(conv4)\n",
        "#conv5 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool4)\n",
        "#pool5 = layers.MaxPooling2D(pool_size=(1, 1))(conv5)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(pool4)\n",
        "# Define the output layer\n",
        "output_layer = layers.Add()([output_layer1, output_layer2 ])\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=None, validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6p3Feep7ySd",
        "outputId": "cd46a52c-c114-49c6-a4c9-8dcad4b7ebfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 36ms/step - loss: 7570.9771 - accuracy: 0.0084 - val_loss: 5784.8579 - val_accuracy: 0.0034\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 6668.8320 - accuracy: 0.0116 - val_loss: 5220.2529 - val_accuracy: 0.0017\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 5834.9824 - accuracy: 0.0104 - val_loss: 4685.2505 - val_accuracy: 0.0036\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 5035.6514 - accuracy: 0.0123 - val_loss: 4020.9688 - val_accuracy: 0.0126\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 4252.8042 - accuracy: 0.0113 - val_loss: 3430.6367 - val_accuracy: 0.0167\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 3621.6414 - accuracy: 0.0113 - val_loss: 2927.2805 - val_accuracy: 0.0214\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3139.8315 - accuracy: 0.0078 - val_loss: 2588.7192 - val_accuracy: 0.0208\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 2761.1355 - accuracy: 0.0157 - val_loss: 2283.0315 - val_accuracy: 0.0122\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 2426.4163 - accuracy: 0.0446 - val_loss: 2046.2562 - val_accuracy: 0.0181\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 2213.5991 - accuracy: 0.1482 - val_loss: 1869.3716 - val_accuracy: 0.0487\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 2059.8472 - accuracy: 0.1361 - val_loss: 1738.2195 - val_accuracy: 0.0511\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1935.8792 - accuracy: 0.1458 - val_loss: 1648.6516 - val_accuracy: 0.0564\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1827.6855 - accuracy: 0.1904 - val_loss: 1547.1146 - val_accuracy: 0.0880\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1715.6982 - accuracy: 0.3306 - val_loss: 1406.1071 - val_accuracy: 0.1442\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1605.3574 - accuracy: 0.4090 - val_loss: 1301.2759 - val_accuracy: 0.1590\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1510.5210 - accuracy: 0.4028 - val_loss: 1233.6224 - val_accuracy: 0.1467\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1433.4078 - accuracy: 0.3665 - val_loss: 1216.1216 - val_accuracy: 0.1452\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1359.7006 - accuracy: 0.4153 - val_loss: 1141.7900 - val_accuracy: 0.1665\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1285.7147 - accuracy: 0.4260 - val_loss: 1015.3752 - val_accuracy: 0.1895\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1218.8274 - accuracy: 0.3617 - val_loss: 991.4557 - val_accuracy: 0.1100\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1184.7349 - accuracy: 0.3054 - val_loss: 965.7113 - val_accuracy: 0.1464\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1159.1844 - accuracy: 0.2848 - val_loss: 948.2194 - val_accuracy: 0.1722\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1134.4747 - accuracy: 0.3398 - val_loss: 929.7523 - val_accuracy: 0.1838\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1116.0615 - accuracy: 0.3265 - val_loss: 908.6137 - val_accuracy: 0.2144\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1098.1958 - accuracy: 0.3285 - val_loss: 893.8036 - val_accuracy: 0.2530\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1087.4236 - accuracy: 0.3360 - val_loss: 884.7429 - val_accuracy: 0.3102\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1072.3313 - accuracy: 0.3318 - val_loss: 869.5812 - val_accuracy: 0.3165\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1061.5679 - accuracy: 0.3463 - val_loss: 853.5526 - val_accuracy: 0.3191\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1050.0605 - accuracy: 0.3562 - val_loss: 847.1351 - val_accuracy: 0.3459\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1040.2820 - accuracy: 0.3723 - val_loss: 836.2691 - val_accuracy: 0.3579\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1032.2006 - accuracy: 0.3805 - val_loss: 824.6141 - val_accuracy: 0.4028\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1025.7765 - accuracy: 0.4045 - val_loss: 814.2763 - val_accuracy: 0.4608\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1019.6347 - accuracy: 0.4265 - val_loss: 811.5619 - val_accuracy: 0.5273\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1016.1937 - accuracy: 0.4342 - val_loss: 797.8345 - val_accuracy: 0.5459\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1008.9633 - accuracy: 0.4534 - val_loss: 793.8222 - val_accuracy: 0.5828\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1003.2902 - accuracy: 0.4746 - val_loss: 790.5319 - val_accuracy: 0.5873\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 999.6901 - accuracy: 0.4826 - val_loss: 785.6776 - val_accuracy: 0.5920\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 991.8711 - accuracy: 0.5089 - val_loss: 777.3303 - val_accuracy: 0.6278\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 988.6180 - accuracy: 0.5243 - val_loss: 768.0339 - val_accuracy: 0.6465\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 983.2658 - accuracy: 0.5437 - val_loss: 770.4344 - val_accuracy: 0.6550\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 979.4219 - accuracy: 0.5545 - val_loss: 759.6309 - val_accuracy: 0.6414\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 974.8820 - accuracy: 0.5591 - val_loss: 757.5807 - val_accuracy: 0.6513\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 970.8226 - accuracy: 0.5739 - val_loss: 751.6649 - val_accuracy: 0.6220\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 966.6536 - accuracy: 0.5703 - val_loss: 751.0009 - val_accuracy: 0.6167\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 962.6636 - accuracy: 0.5739 - val_loss: 750.8800 - val_accuracy: 0.6194\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 960.5787 - accuracy: 0.5790 - val_loss: 745.2432 - val_accuracy: 0.6370\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 956.3276 - accuracy: 0.5807 - val_loss: 743.3180 - val_accuracy: 0.6388\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 953.9449 - accuracy: 0.5828 - val_loss: 740.1234 - val_accuracy: 0.6696\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 953.1700 - accuracy: 0.5894 - val_loss: 739.7502 - val_accuracy: 0.6441\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 950.4609 - accuracy: 0.5907 - val_loss: 735.8002 - val_accuracy: 0.6541\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 947.6343 - accuracy: 0.5915 - val_loss: 733.0666 - val_accuracy: 0.6466\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 945.0409 - accuracy: 0.5964 - val_loss: 728.4858 - val_accuracy: 0.6402\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 943.8302 - accuracy: 0.5897 - val_loss: 725.6620 - val_accuracy: 0.6899\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 940.0212 - accuracy: 0.6011 - val_loss: 727.7318 - val_accuracy: 0.6666\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 939.1898 - accuracy: 0.5946 - val_loss: 726.6923 - val_accuracy: 0.6755\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 937.3610 - accuracy: 0.6028 - val_loss: 725.8196 - val_accuracy: 0.6736\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 938.2001 - accuracy: 0.5984 - val_loss: 720.7704 - val_accuracy: 0.6687\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 935.2095 - accuracy: 0.5977 - val_loss: 716.8455 - val_accuracy: 0.6751\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 933.7361 - accuracy: 0.5998 - val_loss: 716.7159 - val_accuracy: 0.6645\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 934.6665 - accuracy: 0.6032 - val_loss: 722.5244 - val_accuracy: 0.6670\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 930.9730 - accuracy: 0.5991 - val_loss: 710.3057 - val_accuracy: 0.6956\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 928.0056 - accuracy: 0.6070 - val_loss: 709.8774 - val_accuracy: 0.7027\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 926.1365 - accuracy: 0.6124 - val_loss: 712.5800 - val_accuracy: 0.6880\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 926.2663 - accuracy: 0.6105 - val_loss: 712.0396 - val_accuracy: 0.6788\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 926.4576 - accuracy: 0.6054 - val_loss: 707.9587 - val_accuracy: 0.6797\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 921.7259 - accuracy: 0.6108 - val_loss: 706.2495 - val_accuracy: 0.6724\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 920.3915 - accuracy: 0.6092 - val_loss: 705.1537 - val_accuracy: 0.6696\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 918.3644 - accuracy: 0.6164 - val_loss: 706.2223 - val_accuracy: 0.7104\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 918.0331 - accuracy: 0.6103 - val_loss: 704.2998 - val_accuracy: 0.6825\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 917.6006 - accuracy: 0.6172 - val_loss: 701.7153 - val_accuracy: 0.6953\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 916.3032 - accuracy: 0.6228 - val_loss: 699.2995 - val_accuracy: 0.7105\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 915.8972 - accuracy: 0.6179 - val_loss: 699.7798 - val_accuracy: 0.6808\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 914.8216 - accuracy: 0.6154 - val_loss: 698.2031 - val_accuracy: 0.7010\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 912.9229 - accuracy: 0.6229 - val_loss: 697.2590 - val_accuracy: 0.7079\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 913.0803 - accuracy: 0.6220 - val_loss: 700.6697 - val_accuracy: 0.6957\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 911.2885 - accuracy: 0.6215 - val_loss: 703.0993 - val_accuracy: 0.7000\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 912.5421 - accuracy: 0.6107 - val_loss: 697.8185 - val_accuracy: 0.6819\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 909.4216 - accuracy: 0.6231 - val_loss: 696.2565 - val_accuracy: 0.7059\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 909.1657 - accuracy: 0.6278 - val_loss: 697.8998 - val_accuracy: 0.7060\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 909.7510 - accuracy: 0.6309 - val_loss: 693.8486 - val_accuracy: 0.7072\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 906.7663 - accuracy: 0.6278 - val_loss: 694.4860 - val_accuracy: 0.7049\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 908.4196 - accuracy: 0.6271 - val_loss: 691.9058 - val_accuracy: 0.7132\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 907.0004 - accuracy: 0.6202 - val_loss: 693.4794 - val_accuracy: 0.6946\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 905.1204 - accuracy: 0.6271 - val_loss: 689.6683 - val_accuracy: 0.7058\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 902.4383 - accuracy: 0.6282 - val_loss: 694.5875 - val_accuracy: 0.7113\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 904.2346 - accuracy: 0.6305 - val_loss: 689.3813 - val_accuracy: 0.7094\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 902.4310 - accuracy: 0.6350 - val_loss: 690.0776 - val_accuracy: 0.7040\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 901.5341 - accuracy: 0.6263 - val_loss: 689.3041 - val_accuracy: 0.7050\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 900.3528 - accuracy: 0.6297 - val_loss: 688.4124 - val_accuracy: 0.6995\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 899.9453 - accuracy: 0.6369 - val_loss: 685.6522 - val_accuracy: 0.7132\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 898.6161 - accuracy: 0.6363 - val_loss: 685.2244 - val_accuracy: 0.7064\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 897.0868 - accuracy: 0.6340 - val_loss: 687.3194 - val_accuracy: 0.7124\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 897.9567 - accuracy: 0.6334 - val_loss: 688.5160 - val_accuracy: 0.6945\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 898.0215 - accuracy: 0.6400 - val_loss: 685.0798 - val_accuracy: 0.6963\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 896.5350 - accuracy: 0.6357 - val_loss: 684.2943 - val_accuracy: 0.7014\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 896.0576 - accuracy: 0.6363 - val_loss: 682.5170 - val_accuracy: 0.6939\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 895.7952 - accuracy: 0.6357 - val_loss: 681.9511 - val_accuracy: 0.6925\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 895.5333 - accuracy: 0.6379 - val_loss: 680.4483 - val_accuracy: 0.7181\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 894.4882 - accuracy: 0.6408 - val_loss: 684.3047 - val_accuracy: 0.7176\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 893.3047 - accuracy: 0.6414 - val_loss: 680.9243 - val_accuracy: 0.7009\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample1)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "#conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer1)\n",
        "#pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "#conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "#pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "#conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(input_layer1)\n",
        "upsample = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "#conv4 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer2)\n",
        "#pool4 = layers.MaxPooling2D(pool_size=(1, 1))(conv4)\n",
        "#conv5 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool4)\n",
        "#pool5 = layers.MaxPooling2D(pool_size=(1, 1))(conv5)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "# Define the output layer\n",
        "output_layer = layers.Add()([output_layer1, output_layer2 ])\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=None, validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt3InmKM-NdC",
        "outputId": "b7bed9d0-7ed3-4d3a-d57c-ba414bdc6eab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 34ms/step - loss: 7094.9150 - accuracy: 0.0064 - val_loss: 5836.2363 - val_accuracy: 0.0072\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 6635.6396 - accuracy: 0.0303 - val_loss: 5498.8525 - val_accuracy: 0.1160\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 6143.3169 - accuracy: 0.0850 - val_loss: 5144.0757 - val_accuracy: 0.3276\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 5604.7627 - accuracy: 0.1138 - val_loss: 4779.7012 - val_accuracy: 0.3540\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 5048.2920 - accuracy: 0.1182 - val_loss: 4382.3638 - val_accuracy: 0.3642\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 4449.4062 - accuracy: 0.1217 - val_loss: 3950.1997 - val_accuracy: 0.3660\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 3930.4309 - accuracy: 0.1192 - val_loss: 3558.0200 - val_accuracy: 0.3681\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 3515.9565 - accuracy: 0.1626 - val_loss: 3211.3230 - val_accuracy: 0.3700\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 3172.8708 - accuracy: 0.2028 - val_loss: 2917.2952 - val_accuracy: 0.3735\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 2923.3652 - accuracy: 0.1717 - val_loss: 2710.2732 - val_accuracy: 0.3830\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 2708.4924 - accuracy: 0.1533 - val_loss: 2500.9507 - val_accuracy: 0.4678\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 2519.3687 - accuracy: 0.2238 - val_loss: 2308.9075 - val_accuracy: 0.5365\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 2355.7161 - accuracy: 0.3127 - val_loss: 2153.2959 - val_accuracy: 0.5539\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 2210.0586 - accuracy: 0.3610 - val_loss: 1968.0040 - val_accuracy: 0.5572\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 2064.7100 - accuracy: 0.3405 - val_loss: 1784.8684 - val_accuracy: 0.5541\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1929.4379 - accuracy: 0.3541 - val_loss: 1636.2267 - val_accuracy: 0.5564\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1816.1561 - accuracy: 0.3564 - val_loss: 1523.2567 - val_accuracy: 0.5588\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1723.5609 - accuracy: 0.3412 - val_loss: 1437.1902 - val_accuracy: 0.5587\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1645.6450 - accuracy: 0.3438 - val_loss: 1367.9902 - val_accuracy: 0.5620\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1583.9877 - accuracy: 0.3467 - val_loss: 1311.7650 - val_accuracy: 0.5673\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1534.7065 - accuracy: 0.3519 - val_loss: 1272.9479 - val_accuracy: 0.5717\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1495.2434 - accuracy: 0.3705 - val_loss: 1238.0679 - val_accuracy: 0.5736\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1459.8976 - accuracy: 0.3672 - val_loss: 1209.9584 - val_accuracy: 0.5749\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1429.7625 - accuracy: 0.3616 - val_loss: 1184.4617 - val_accuracy: 0.5767\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1403.2533 - accuracy: 0.3784 - val_loss: 1158.5748 - val_accuracy: 0.5812\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1377.7388 - accuracy: 0.3712 - val_loss: 1141.0134 - val_accuracy: 0.5858\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1354.8287 - accuracy: 0.3847 - val_loss: 1117.9203 - val_accuracy: 0.5929\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1334.1927 - accuracy: 0.3816 - val_loss: 1096.7915 - val_accuracy: 0.5994\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1314.6732 - accuracy: 0.3941 - val_loss: 1081.9625 - val_accuracy: 0.6028\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1296.1239 - accuracy: 0.4145 - val_loss: 1063.7395 - val_accuracy: 0.6046\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1279.1982 - accuracy: 0.4267 - val_loss: 1051.6792 - val_accuracy: 0.6089\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1263.6791 - accuracy: 0.4350 - val_loss: 1038.1499 - val_accuracy: 0.6102\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1248.0690 - accuracy: 0.4376 - val_loss: 1025.1284 - val_accuracy: 0.6146\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1233.7439 - accuracy: 0.4659 - val_loss: 1013.6185 - val_accuracy: 0.6148\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1220.4514 - accuracy: 0.4704 - val_loss: 1004.7309 - val_accuracy: 0.6139\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1208.6619 - accuracy: 0.4633 - val_loss: 993.4844 - val_accuracy: 0.6119\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1198.3971 - accuracy: 0.4808 - val_loss: 985.9978 - val_accuracy: 0.6183\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1187.9830 - accuracy: 0.4712 - val_loss: 978.1820 - val_accuracy: 0.6112\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1176.0613 - accuracy: 0.4747 - val_loss: 967.9556 - val_accuracy: 0.6182\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1165.3037 - accuracy: 0.4788 - val_loss: 962.3175 - val_accuracy: 0.6152\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1155.9796 - accuracy: 0.4820 - val_loss: 952.8839 - val_accuracy: 0.6150\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1146.3278 - accuracy: 0.4808 - val_loss: 944.6213 - val_accuracy: 0.6150\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1137.6301 - accuracy: 0.4880 - val_loss: 936.1804 - val_accuracy: 0.6174\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 1130.0004 - accuracy: 0.5043 - val_loss: 931.3193 - val_accuracy: 0.6144\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1121.7173 - accuracy: 0.4970 - val_loss: 920.7192 - val_accuracy: 0.6172\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1113.9612 - accuracy: 0.5048 - val_loss: 912.5693 - val_accuracy: 0.6160\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1105.4548 - accuracy: 0.5198 - val_loss: 906.2521 - val_accuracy: 0.6190\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1098.3977 - accuracy: 0.5190 - val_loss: 897.6550 - val_accuracy: 0.6156\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1091.0791 - accuracy: 0.5302 - val_loss: 892.9032 - val_accuracy: 0.6248\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1084.6194 - accuracy: 0.5251 - val_loss: 884.2562 - val_accuracy: 0.6181\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 1078.0999 - accuracy: 0.5467 - val_loss: 880.8132 - val_accuracy: 0.6269\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1073.0243 - accuracy: 0.5372 - val_loss: 866.6401 - val_accuracy: 0.6262\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1065.3595 - accuracy: 0.5558 - val_loss: 865.6137 - val_accuracy: 0.6317\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1059.3545 - accuracy: 0.5544 - val_loss: 861.3631 - val_accuracy: 0.6281\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1054.1796 - accuracy: 0.5632 - val_loss: 852.2272 - val_accuracy: 0.6427\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1047.7040 - accuracy: 0.5628 - val_loss: 849.9409 - val_accuracy: 0.6391\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1042.8763 - accuracy: 0.5821 - val_loss: 843.1842 - val_accuracy: 0.6482\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1037.8469 - accuracy: 0.5827 - val_loss: 839.1679 - val_accuracy: 0.6529\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1034.0664 - accuracy: 0.5956 - val_loss: 833.2986 - val_accuracy: 0.6581\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1027.6031 - accuracy: 0.5862 - val_loss: 825.5458 - val_accuracy: 0.6655\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1024.3179 - accuracy: 0.6013 - val_loss: 828.5432 - val_accuracy: 0.6684\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1021.6418 - accuracy: 0.6065 - val_loss: 823.3849 - val_accuracy: 0.6688\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1013.3874 - accuracy: 0.6123 - val_loss: 814.9910 - val_accuracy: 0.6756\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1008.6885 - accuracy: 0.6148 - val_loss: 810.5331 - val_accuracy: 0.6845\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 1004.0508 - accuracy: 0.6143 - val_loss: 806.2786 - val_accuracy: 0.6885\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 1001.7304 - accuracy: 0.6245 - val_loss: 799.4734 - val_accuracy: 0.6853\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 996.3198 - accuracy: 0.6208 - val_loss: 794.7111 - val_accuracy: 0.6903\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 992.8109 - accuracy: 0.6225 - val_loss: 791.3705 - val_accuracy: 0.6965\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 988.6901 - accuracy: 0.6303 - val_loss: 793.0979 - val_accuracy: 0.6948\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 985.7666 - accuracy: 0.6268 - val_loss: 782.9423 - val_accuracy: 0.6987\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 981.7599 - accuracy: 0.6299 - val_loss: 782.9075 - val_accuracy: 0.6972\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 977.3330 - accuracy: 0.6313 - val_loss: 777.5450 - val_accuracy: 0.7028\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 974.0241 - accuracy: 0.6346 - val_loss: 770.7222 - val_accuracy: 0.7005\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 971.0140 - accuracy: 0.6335 - val_loss: 767.6889 - val_accuracy: 0.7065\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 967.5312 - accuracy: 0.6320 - val_loss: 763.5068 - val_accuracy: 0.7058\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 964.7017 - accuracy: 0.6343 - val_loss: 764.0162 - val_accuracy: 0.7089\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 961.6514 - accuracy: 0.6357 - val_loss: 759.9487 - val_accuracy: 0.7121\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 958.7963 - accuracy: 0.6356 - val_loss: 754.5090 - val_accuracy: 0.7144\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 955.4557 - accuracy: 0.6376 - val_loss: 752.8885 - val_accuracy: 0.7152\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 952.8033 - accuracy: 0.6379 - val_loss: 747.5168 - val_accuracy: 0.7171\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 18ms/step - loss: 950.6320 - accuracy: 0.6387 - val_loss: 749.9711 - val_accuracy: 0.7178\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 948.2266 - accuracy: 0.6387 - val_loss: 743.5345 - val_accuracy: 0.7197\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 945.6266 - accuracy: 0.6359 - val_loss: 741.3840 - val_accuracy: 0.7194\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 942.7148 - accuracy: 0.6426 - val_loss: 739.2411 - val_accuracy: 0.7210\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 940.7064 - accuracy: 0.6405 - val_loss: 734.6669 - val_accuracy: 0.7241\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 938.3555 - accuracy: 0.6327 - val_loss: 736.7594 - val_accuracy: 0.7242\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 19ms/step - loss: 935.8382 - accuracy: 0.6429 - val_loss: 731.9976 - val_accuracy: 0.7181\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 934.2051 - accuracy: 0.6354 - val_loss: 730.4902 - val_accuracy: 0.7269\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 931.4772 - accuracy: 0.6362 - val_loss: 726.1619 - val_accuracy: 0.7252\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 930.3915 - accuracy: 0.6436 - val_loss: 726.8204 - val_accuracy: 0.7206\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 928.4019 - accuracy: 0.6360 - val_loss: 721.7601 - val_accuracy: 0.7274\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 927.2375 - accuracy: 0.6431 - val_loss: 719.0177 - val_accuracy: 0.7220\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 923.9589 - accuracy: 0.6390 - val_loss: 717.6790 - val_accuracy: 0.7279\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 922.0424 - accuracy: 0.6434 - val_loss: 718.4646 - val_accuracy: 0.7229\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 920.1756 - accuracy: 0.6386 - val_loss: 711.9466 - val_accuracy: 0.7284\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 918.3507 - accuracy: 0.6417 - val_loss: 712.5018 - val_accuracy: 0.7253\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 20ms/step - loss: 916.4062 - accuracy: 0.6400 - val_loss: 709.6630 - val_accuracy: 0.7276\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 21ms/step - loss: 914.6729 - accuracy: 0.6445 - val_loss: 706.0582 - val_accuracy: 0.7272\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 912.4982 - accuracy: 0.6427 - val_loss: 704.7952 - val_accuracy: 0.7277\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 911.0198 - accuracy: 0.6378 - val_loss: 700.8136 - val_accuracy: 0.7289\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "#conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample1)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "#conv1 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer1)\n",
        "#pool1 = layers.MaxPooling2D(pool_size=(1, 1))(conv1)\n",
        "#conv2 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool1)\n",
        "#pool2 = layers.MaxPooling2D(pool_size=(1, 1))(conv2)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample1)\n",
        "\n",
        "# Define the convolutional layer\n",
        "#conv_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(input_layer1)\n",
        "upsample = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "#conv_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample)\n",
        "# Add more convolutional layers with increasing number of filters\n",
        "#conv4 = layers.Conv2D(64, kernel_size=1, activation='relu')(conv_layer2)\n",
        "#pool4 = layers.MaxPooling2D(pool_size=(1, 1))(conv4)\n",
        "#conv5 = layers.Conv2D(128, kernel_size=1, activation='relu')(pool4)\n",
        "#pool5 = layers.MaxPooling2D(pool_size=(1, 1))(conv5)\n",
        "# Define the output layer as a convolutional layer with 31 filters\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(upsample)\n",
        "# Define the output layer\n",
        "output_layer = layers.Add()([output_layer1, output_layer2 ])\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=None, validation_split=0.2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oXznmzj-mgS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTbnm1qk-miw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzoiTPE8-r-G"
      },
      "source": [
        "# **chose best result model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEOix3i3-mlY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1P-kWZ7-qEg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rObCvD9J-mn8",
        "outputId": "ba78f3dd-8251-4100-e91a-3301dd9c293d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 51ms/step - loss: 7492.3647 - accuracy: 0.0089 - val_loss: 5103.8828 - val_accuracy: 0.0286\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 6085.6377 - accuracy: 0.0152 - val_loss: 4066.1428 - val_accuracy: 0.0437\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 4548.8335 - accuracy: 0.0953 - val_loss: 3078.2173 - val_accuracy: 0.3699\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 3281.9014 - accuracy: 0.1510 - val_loss: 2355.2302 - val_accuracy: 0.4218\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 2538.0691 - accuracy: 0.1369 - val_loss: 1861.1837 - val_accuracy: 0.3800\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 2077.2971 - accuracy: 0.1807 - val_loss: 1584.0593 - val_accuracy: 0.3988\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1786.7731 - accuracy: 0.2258 - val_loss: 1414.7812 - val_accuracy: 0.3983\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1585.1284 - accuracy: 0.2931 - val_loss: 1262.3268 - val_accuracy: 0.4029\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1422.2512 - accuracy: 0.2836 - val_loss: 1139.0358 - val_accuracy: 0.3750\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1311.6161 - accuracy: 0.3215 - val_loss: 1056.7894 - val_accuracy: 0.3914\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1229.9565 - accuracy: 0.3299 - val_loss: 1005.7595 - val_accuracy: 0.4401\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1171.9773 - accuracy: 0.3618 - val_loss: 947.3844 - val_accuracy: 0.5154\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1124.4115 - accuracy: 0.3856 - val_loss: 915.5707 - val_accuracy: 0.5654\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1089.4366 - accuracy: 0.3757 - val_loss: 885.7037 - val_accuracy: 0.5068\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1064.1888 - accuracy: 0.3992 - val_loss: 854.0980 - val_accuracy: 0.5106\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 1044.4767 - accuracy: 0.4071 - val_loss: 835.1860 - val_accuracy: 0.5177\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 1026.2975 - accuracy: 0.4095 - val_loss: 809.4893 - val_accuracy: 0.5064\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1011.5666 - accuracy: 0.4252 - val_loss: 793.8538 - val_accuracy: 0.5410\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 997.8587 - accuracy: 0.4404 - val_loss: 783.5219 - val_accuracy: 0.5388\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 985.6523 - accuracy: 0.4491 - val_loss: 774.6634 - val_accuracy: 0.5706\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 981.1306 - accuracy: 0.4523 - val_loss: 756.7630 - val_accuracy: 0.5959\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 971.6536 - accuracy: 0.4597 - val_loss: 741.7776 - val_accuracy: 0.5875\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 961.0685 - accuracy: 0.4702 - val_loss: 734.8162 - val_accuracy: 0.6016\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 957.1760 - accuracy: 0.4728 - val_loss: 743.4807 - val_accuracy: 0.5988\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 948.7218 - accuracy: 0.4887 - val_loss: 730.0117 - val_accuracy: 0.5692\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 942.1064 - accuracy: 0.5531 - val_loss: 715.5230 - val_accuracy: 0.5903\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 932.7361 - accuracy: 0.6046 - val_loss: 712.8294 - val_accuracy: 0.6718\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 927.6538 - accuracy: 0.6233 - val_loss: 703.1486 - val_accuracy: 0.6795\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 922.9340 - accuracy: 0.6234 - val_loss: 697.0231 - val_accuracy: 0.6466\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 915.6392 - accuracy: 0.6358 - val_loss: 705.6796 - val_accuracy: 0.6950\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 920.4950 - accuracy: 0.6340 - val_loss: 694.1290 - val_accuracy: 0.7182\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 910.5549 - accuracy: 0.6347 - val_loss: 699.1122 - val_accuracy: 0.7002\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 905.8108 - accuracy: 0.6287 - val_loss: 685.8250 - val_accuracy: 0.7145\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 900.8578 - accuracy: 0.6315 - val_loss: 683.5001 - val_accuracy: 0.7126\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 900.2490 - accuracy: 0.6345 - val_loss: 674.9831 - val_accuracy: 0.7082\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 896.4932 - accuracy: 0.6375 - val_loss: 675.5975 - val_accuracy: 0.7040\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 892.0405 - accuracy: 0.6384 - val_loss: 673.4909 - val_accuracy: 0.6905\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 890.9470 - accuracy: 0.6407 - val_loss: 670.1144 - val_accuracy: 0.7088\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 886.2572 - accuracy: 0.6436 - val_loss: 668.2190 - val_accuracy: 0.6885\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 885.1842 - accuracy: 0.6364 - val_loss: 666.0844 - val_accuracy: 0.6959\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 881.1406 - accuracy: 0.6431 - val_loss: 669.3776 - val_accuracy: 0.7052\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 881.1293 - accuracy: 0.6424 - val_loss: 663.2347 - val_accuracy: 0.6961\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 876.9178 - accuracy: 0.6433 - val_loss: 662.8502 - val_accuracy: 0.6889\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 876.5746 - accuracy: 0.6458 - val_loss: 659.9839 - val_accuracy: 0.7082\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 874.2794 - accuracy: 0.6413 - val_loss: 659.2906 - val_accuracy: 0.7100\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 873.4479 - accuracy: 0.6405 - val_loss: 657.6042 - val_accuracy: 0.7180\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 870.3164 - accuracy: 0.6484 - val_loss: 655.5131 - val_accuracy: 0.7153\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 869.0167 - accuracy: 0.6518 - val_loss: 654.3943 - val_accuracy: 0.7210\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 866.7664 - accuracy: 0.6488 - val_loss: 652.3130 - val_accuracy: 0.7170\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 864.4776 - accuracy: 0.6468 - val_loss: 654.4135 - val_accuracy: 0.7201\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 863.8939 - accuracy: 0.6471 - val_loss: 651.5192 - val_accuracy: 0.7192\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 861.8962 - accuracy: 0.6493 - val_loss: 653.7309 - val_accuracy: 0.7258\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 863.3341 - accuracy: 0.6480 - val_loss: 649.5352 - val_accuracy: 0.7140\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 860.6423 - accuracy: 0.6464 - val_loss: 648.5863 - val_accuracy: 0.7144\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 856.5034 - accuracy: 0.6568 - val_loss: 651.9389 - val_accuracy: 0.7083\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 856.4235 - accuracy: 0.6439 - val_loss: 645.4415 - val_accuracy: 0.7359\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 854.1860 - accuracy: 0.6554 - val_loss: 648.5863 - val_accuracy: 0.7235\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 857.1725 - accuracy: 0.6573 - val_loss: 651.8544 - val_accuracy: 0.7201\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 853.3950 - accuracy: 0.6474 - val_loss: 642.1491 - val_accuracy: 0.7344\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 851.6920 - accuracy: 0.6573 - val_loss: 643.0614 - val_accuracy: 0.7284\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 848.6287 - accuracy: 0.6565 - val_loss: 643.0872 - val_accuracy: 0.7441\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 847.8884 - accuracy: 0.6578 - val_loss: 642.9634 - val_accuracy: 0.7440\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 846.3671 - accuracy: 0.6604 - val_loss: 640.2673 - val_accuracy: 0.7354\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 847.9291 - accuracy: 0.6531 - val_loss: 642.2373 - val_accuracy: 0.7509\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 844.0830 - accuracy: 0.6601 - val_loss: 639.6564 - val_accuracy: 0.7427\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 843.6147 - accuracy: 0.6593 - val_loss: 642.6086 - val_accuracy: 0.7390\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 843.6404 - accuracy: 0.6635 - val_loss: 639.8581 - val_accuracy: 0.7384\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 843.2730 - accuracy: 0.6621 - val_loss: 638.1858 - val_accuracy: 0.7395\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 840.6135 - accuracy: 0.6640 - val_loss: 641.5893 - val_accuracy: 0.7311\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 841.1819 - accuracy: 0.6661 - val_loss: 637.0222 - val_accuracy: 0.7444\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 841.2399 - accuracy: 0.6606 - val_loss: 636.9957 - val_accuracy: 0.7370\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 838.0096 - accuracy: 0.6556 - val_loss: 638.3896 - val_accuracy: 0.7436\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 836.5828 - accuracy: 0.6657 - val_loss: 638.2263 - val_accuracy: 0.7446\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 840.2369 - accuracy: 0.6657 - val_loss: 636.5178 - val_accuracy: 0.7273\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 838.6793 - accuracy: 0.6623 - val_loss: 640.8097 - val_accuracy: 0.7470\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 835.5172 - accuracy: 0.6673 - val_loss: 635.2123 - val_accuracy: 0.7403\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 832.7626 - accuracy: 0.6624 - val_loss: 639.0256 - val_accuracy: 0.7397\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 833.8303 - accuracy: 0.6682 - val_loss: 633.3975 - val_accuracy: 0.7459\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 832.9998 - accuracy: 0.6614 - val_loss: 636.1242 - val_accuracy: 0.7410\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 837.5273 - accuracy: 0.6670 - val_loss: 632.3773 - val_accuracy: 0.7459\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 832.8848 - accuracy: 0.6678 - val_loss: 630.3409 - val_accuracy: 0.7440\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 831.1309 - accuracy: 0.6689 - val_loss: 631.3087 - val_accuracy: 0.7519\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 827.9077 - accuracy: 0.6695 - val_loss: 629.2269 - val_accuracy: 0.7483\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 827.3746 - accuracy: 0.6725 - val_loss: 628.2481 - val_accuracy: 0.7506\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 825.5691 - accuracy: 0.6703 - val_loss: 629.5485 - val_accuracy: 0.7472\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 827.5341 - accuracy: 0.6710 - val_loss: 629.0037 - val_accuracy: 0.7445\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 827.2893 - accuracy: 0.6704 - val_loss: 628.9849 - val_accuracy: 0.7446\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 826.8121 - accuracy: 0.6680 - val_loss: 629.0720 - val_accuracy: 0.7554\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 825.9908 - accuracy: 0.6674 - val_loss: 633.5029 - val_accuracy: 0.7443\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 829.2103 - accuracy: 0.6771 - val_loss: 630.3561 - val_accuracy: 0.7499\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 825.6959 - accuracy: 0.6724 - val_loss: 629.0726 - val_accuracy: 0.7464\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 823.3025 - accuracy: 0.6685 - val_loss: 632.5785 - val_accuracy: 0.7476\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 824.2250 - accuracy: 0.6705 - val_loss: 627.7346 - val_accuracy: 0.7483\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 821.9205 - accuracy: 0.6736 - val_loss: 627.5555 - val_accuracy: 0.7434\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 821.5837 - accuracy: 0.6775 - val_loss: 627.1432 - val_accuracy: 0.7453\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 820.4219 - accuracy: 0.6750 - val_loss: 625.5341 - val_accuracy: 0.7442\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 820.0148 - accuracy: 0.6779 - val_loss: 624.0496 - val_accuracy: 0.7507\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 820.7845 - accuracy: 0.6748 - val_loss: 626.1208 - val_accuracy: 0.7528\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 22ms/step - loss: 818.9036 - accuracy: 0.6728 - val_loss: 623.9382 - val_accuracy: 0.7459\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 23ms/step - loss: 820.0010 - accuracy: 0.6752 - val_loss: 624.7823 - val_accuracy: 0.7484\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "upsample = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Define the output layer\n",
        "output_layer = layers.Add()([output_layer1, output_layer2 ])\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], output_layer)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=None, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1ycNa_ZDGBa"
      },
      "source": [
        "# **changes in best model results in good accuracy further**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCy1gB1-_iGw",
        "outputId": "0d32dc24-ca28-4d44-8d59-b75744f48615"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 9015.2920 - accuracy: 0.0108 - val_loss: 6434.7471 - val_accuracy: 0.0270\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 7698.9165 - accuracy: 0.0356 - val_loss: 5437.1763 - val_accuracy: 0.1158\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 6388.4409 - accuracy: 0.0358 - val_loss: 4667.2422 - val_accuracy: 0.1163\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 5330.7432 - accuracy: 0.0545 - val_loss: 3811.0042 - val_accuracy: 0.1128\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 4120.4038 - accuracy: 0.0495 - val_loss: 3124.5527 - val_accuracy: 0.0529\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3317.0000 - accuracy: 0.1070 - val_loss: 2732.7810 - val_accuracy: 0.1077\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2836.0415 - accuracy: 0.1284 - val_loss: 2420.2708 - val_accuracy: 0.0769\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 2569.3333 - accuracy: 0.1413 - val_loss: 2184.6096 - val_accuracy: 0.0942\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2350.8201 - accuracy: 0.2705 - val_loss: 2007.2369 - val_accuracy: 0.1237\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2211.7407 - accuracy: 0.3003 - val_loss: 1860.0815 - val_accuracy: 0.1250\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2059.9651 - accuracy: 0.2506 - val_loss: 1594.2943 - val_accuracy: 0.0490\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1772.4486 - accuracy: 0.0960 - val_loss: 1274.7982 - val_accuracy: 0.0396\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1609.2681 - accuracy: 0.0764 - val_loss: 1124.8899 - val_accuracy: 0.0825\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1462.1110 - accuracy: 0.1111 - val_loss: 1048.9475 - val_accuracy: 0.2035\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1385.6770 - accuracy: 0.1621 - val_loss: 1002.7465 - val_accuracy: 0.1786\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1337.9062 - accuracy: 0.2684 - val_loss: 981.5914 - val_accuracy: 0.2434\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1304.7388 - accuracy: 0.2678 - val_loss: 964.5543 - val_accuracy: 0.3991\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1279.5022 - accuracy: 0.3890 - val_loss: 957.0308 - val_accuracy: 0.5434\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1241.2983 - accuracy: 0.3740 - val_loss: 810.1370 - val_accuracy: 0.5679\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1092.3075 - accuracy: 0.3939 - val_loss: 868.3812 - val_accuracy: 0.5789\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1010.2445 - accuracy: 0.3978 - val_loss: 814.3142 - val_accuracy: 0.5710\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 947.7896 - accuracy: 0.4162 - val_loss: 735.8375 - val_accuracy: 0.5990\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 918.2171 - accuracy: 0.4504 - val_loss: 717.9507 - val_accuracy: 0.5738\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 899.4007 - accuracy: 0.4634 - val_loss: 716.3380 - val_accuracy: 0.5716\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 886.3826 - accuracy: 0.4709 - val_loss: 695.5929 - val_accuracy: 0.5720\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 881.8432 - accuracy: 0.4583 - val_loss: 683.4839 - val_accuracy: 0.5643\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 867.0501 - accuracy: 0.4824 - val_loss: 672.3400 - val_accuracy: 0.5817\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 856.5864 - accuracy: 0.4750 - val_loss: 669.9128 - val_accuracy: 0.5810\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 855.7720 - accuracy: 0.4833 - val_loss: 659.4153 - val_accuracy: 0.5952\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 849.2757 - accuracy: 0.5172 - val_loss: 650.4601 - val_accuracy: 0.6094\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 839.1003 - accuracy: 0.5256 - val_loss: 644.7554 - val_accuracy: 0.6193\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 838.5732 - accuracy: 0.5463 - val_loss: 642.6640 - val_accuracy: 0.6295\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 829.9297 - accuracy: 0.5332 - val_loss: 644.1813 - val_accuracy: 0.6337\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 825.0382 - accuracy: 0.5528 - val_loss: 646.8822 - val_accuracy: 0.6344\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 822.0546 - accuracy: 0.5623 - val_loss: 632.1595 - val_accuracy: 0.6339\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 816.0513 - accuracy: 0.5470 - val_loss: 623.4112 - val_accuracy: 0.6384\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 814.6560 - accuracy: 0.5486 - val_loss: 622.4476 - val_accuracy: 0.6344\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 808.1741 - accuracy: 0.5508 - val_loss: 617.7712 - val_accuracy: 0.6379\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 799.5742 - accuracy: 0.5478 - val_loss: 619.3021 - val_accuracy: 0.6342\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 793.5489 - accuracy: 0.5869 - val_loss: 613.0104 - val_accuracy: 0.6363\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 793.5898 - accuracy: 0.6223 - val_loss: 620.1063 - val_accuracy: 0.6415\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 790.4092 - accuracy: 0.6511 - val_loss: 613.9349 - val_accuracy: 0.6481\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 788.5142 - accuracy: 0.6629 - val_loss: 618.1892 - val_accuracy: 0.6508\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 786.2906 - accuracy: 0.6602 - val_loss: 609.1887 - val_accuracy: 0.6608\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 781.9990 - accuracy: 0.6664 - val_loss: 607.7252 - val_accuracy: 0.6720\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 776.3600 - accuracy: 0.6768 - val_loss: 605.1628 - val_accuracy: 0.6728\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 779.9211 - accuracy: 0.6738 - val_loss: 605.8158 - val_accuracy: 0.6799\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 777.1766 - accuracy: 0.6753 - val_loss: 602.4470 - val_accuracy: 0.6915\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 779.6484 - accuracy: 0.6813 - val_loss: 604.4438 - val_accuracy: 0.6968\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 770.3231 - accuracy: 0.6742 - val_loss: 605.6752 - val_accuracy: 0.7212\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 770.4848 - accuracy: 0.6930 - val_loss: 600.6945 - val_accuracy: 0.7167\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 773.6660 - accuracy: 0.6783 - val_loss: 617.0825 - val_accuracy: 0.7106\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 773.8711 - accuracy: 0.6890 - val_loss: 597.5746 - val_accuracy: 0.7071\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 767.5057 - accuracy: 0.6894 - val_loss: 593.4509 - val_accuracy: 0.7238\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 764.1171 - accuracy: 0.6954 - val_loss: 597.5191 - val_accuracy: 0.7570\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 763.7913 - accuracy: 0.6898 - val_loss: 595.7225 - val_accuracy: 0.7359\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.2202 - accuracy: 0.7003 - val_loss: 591.0275 - val_accuracy: 0.7247\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 754.4436 - accuracy: 0.6988 - val_loss: 585.9181 - val_accuracy: 0.7269\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 755.2426 - accuracy: 0.7024 - val_loss: 584.1576 - val_accuracy: 0.7431\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 752.8344 - accuracy: 0.7078 - val_loss: 583.5008 - val_accuracy: 0.7460\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 750.2004 - accuracy: 0.7067 - val_loss: 592.4802 - val_accuracy: 0.7431\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.9574 - accuracy: 0.7085 - val_loss: 584.1512 - val_accuracy: 0.7768\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.6436 - accuracy: 0.7080 - val_loss: 583.6791 - val_accuracy: 0.7668\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 748.8505 - accuracy: 0.7142 - val_loss: 583.0240 - val_accuracy: 0.7581\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 748.0049 - accuracy: 0.7158 - val_loss: 580.8334 - val_accuracy: 0.7744\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.1992 - accuracy: 0.6974 - val_loss: 585.7756 - val_accuracy: 0.7612\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.8391 - accuracy: 0.7164 - val_loss: 591.1812 - val_accuracy: 0.7722\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.7975 - accuracy: 0.7166 - val_loss: 580.2079 - val_accuracy: 0.7845\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 739.9241 - accuracy: 0.7202 - val_loss: 574.3546 - val_accuracy: 0.7801\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.7424 - accuracy: 0.7116 - val_loss: 574.9013 - val_accuracy: 0.7812\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.8140 - accuracy: 0.7190 - val_loss: 577.9814 - val_accuracy: 0.7867\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 737.0720 - accuracy: 0.7238 - val_loss: 578.2426 - val_accuracy: 0.7796\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 738.3925 - accuracy: 0.7197 - val_loss: 576.9055 - val_accuracy: 0.7789\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 737.6243 - accuracy: 0.7247 - val_loss: 577.9785 - val_accuracy: 0.7881\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 736.1865 - accuracy: 0.7226 - val_loss: 571.4665 - val_accuracy: 0.7871\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 736.7915 - accuracy: 0.7212 - val_loss: 576.9448 - val_accuracy: 0.7767\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 735.4653 - accuracy: 0.7226 - val_loss: 584.8370 - val_accuracy: 0.7790\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.8725 - accuracy: 0.7139 - val_loss: 574.7307 - val_accuracy: 0.7824\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 737.7792 - accuracy: 0.7189 - val_loss: 572.4667 - val_accuracy: 0.7847\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.5810 - accuracy: 0.7172 - val_loss: 571.5487 - val_accuracy: 0.7774\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.1080 - accuracy: 0.7144 - val_loss: 571.9575 - val_accuracy: 0.7796\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.0616 - accuracy: 0.7245 - val_loss: 570.9023 - val_accuracy: 0.7809\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.7257 - accuracy: 0.7125 - val_loss: 567.5522 - val_accuracy: 0.7844\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 727.3063 - accuracy: 0.7259 - val_loss: 568.1617 - val_accuracy: 0.7810\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.1630 - accuracy: 0.7240 - val_loss: 567.7531 - val_accuracy: 0.7835\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.1183 - accuracy: 0.7268 - val_loss: 567.9799 - val_accuracy: 0.7907\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.5432 - accuracy: 0.7278 - val_loss: 567.2858 - val_accuracy: 0.7881\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.5292 - accuracy: 0.7144 - val_loss: 574.2560 - val_accuracy: 0.7884\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 731.0518 - accuracy: 0.7259 - val_loss: 582.3182 - val_accuracy: 0.7828\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.0198 - accuracy: 0.7196 - val_loss: 566.1893 - val_accuracy: 0.7870\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.8146 - accuracy: 0.7255 - val_loss: 566.3010 - val_accuracy: 0.7875\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.0137 - accuracy: 0.7279 - val_loss: 566.3031 - val_accuracy: 0.7840\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.0065 - accuracy: 0.7267 - val_loss: 565.2396 - val_accuracy: 0.7886\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.8892 - accuracy: 0.7267 - val_loss: 561.4769 - val_accuracy: 0.7893\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.8680 - accuracy: 0.7270 - val_loss: 568.9511 - val_accuracy: 0.7844\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 720.1673 - accuracy: 0.7252 - val_loss: 561.3983 - val_accuracy: 0.7847\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.9407 - accuracy: 0.7294 - val_loss: 561.5783 - val_accuracy: 0.7885\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.1596 - accuracy: 0.7283 - val_loss: 558.8411 - val_accuracy: 0.7858\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.2107 - accuracy: 0.7271 - val_loss: 561.7570 - val_accuracy: 0.7841\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 717.8058 - accuracy: 0.7340 - val_loss: 556.8820 - val_accuracy: 0.7866\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=None, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQROJE0bDOPJ"
      },
      "source": [
        "# **further changes didn't improved accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIf0ZUVDBzLC",
        "outputId": "52746aef-59c3-4092-a32f-fe10f7468ace"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 9020.1914 - accuracy: 0.0038 - val_loss: 6582.3486 - val_accuracy: 8.9518e-04\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 7681.2290 - accuracy: 0.0115 - val_loss: 5724.2363 - val_accuracy: 5.5067e-04\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 6499.2666 - accuracy: 0.0096 - val_loss: 4983.2207 - val_accuracy: 4.2318e-04\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 5519.1216 - accuracy: 0.0056 - val_loss: 3978.2222 - val_accuracy: 0.0073\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 4697.6978 - accuracy: 0.0505 - val_loss: 3236.0945 - val_accuracy: 0.3952\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3955.9768 - accuracy: 0.1193 - val_loss: 2611.1912 - val_accuracy: 0.0911\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 3204.9204 - accuracy: 0.0792 - val_loss: 2317.3296 - val_accuracy: 0.1639\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2731.8418 - accuracy: 0.2722 - val_loss: 2115.1868 - val_accuracy: 0.1667\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2372.7378 - accuracy: 0.1999 - val_loss: 1816.6011 - val_accuracy: 0.1743\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2071.6091 - accuracy: 0.2106 - val_loss: 1575.4388 - val_accuracy: 0.1759\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1835.4680 - accuracy: 0.1707 - val_loss: 1394.7783 - val_accuracy: 0.0640\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1674.3950 - accuracy: 0.1400 - val_loss: 1251.7657 - val_accuracy: 0.0796\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1568.9005 - accuracy: 0.1253 - val_loss: 1152.0206 - val_accuracy: 0.0970\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1490.1370 - accuracy: 0.1502 - val_loss: 1099.5636 - val_accuracy: 0.1741\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1428.7018 - accuracy: 0.2559 - val_loss: 1067.7366 - val_accuracy: 0.2537\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1379.4409 - accuracy: 0.4106 - val_loss: 1038.5918 - val_accuracy: 0.3217\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1344.3042 - accuracy: 0.5093 - val_loss: 1026.7103 - val_accuracy: 0.3504\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1319.7760 - accuracy: 0.5196 - val_loss: 995.8983 - val_accuracy: 0.3698\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1291.9976 - accuracy: 0.5393 - val_loss: 993.1511 - val_accuracy: 0.3812\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1273.2902 - accuracy: 0.5497 - val_loss: 981.9815 - val_accuracy: 0.4144\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1260.5790 - accuracy: 0.5344 - val_loss: 960.0568 - val_accuracy: 0.4254\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1238.4983 - accuracy: 0.5647 - val_loss: 939.9965 - val_accuracy: 0.3607\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1221.4348 - accuracy: 0.5679 - val_loss: 926.2628 - val_accuracy: 0.3883\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1207.7841 - accuracy: 0.5630 - val_loss: 905.8551 - val_accuracy: 0.4000\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1190.9613 - accuracy: 0.5791 - val_loss: 899.6605 - val_accuracy: 0.5371\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1187.4866 - accuracy: 0.5979 - val_loss: 897.2611 - val_accuracy: 0.6451\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1174.4758 - accuracy: 0.5920 - val_loss: 885.5683 - val_accuracy: 0.6328\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1160.9438 - accuracy: 0.6212 - val_loss: 863.3927 - val_accuracy: 0.6778\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 1151.5597 - accuracy: 0.6463 - val_loss: 868.8174 - val_accuracy: 0.6792\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1160.5585 - accuracy: 0.6433 - val_loss: 862.5726 - val_accuracy: 0.6707\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 1143.8784 - accuracy: 0.6572 - val_loss: 838.0054 - val_accuracy: 0.7147\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1132.8613 - accuracy: 0.6648 - val_loss: 828.0465 - val_accuracy: 0.7159\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1130.3998 - accuracy: 0.6628 - val_loss: 821.8456 - val_accuracy: 0.7130\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1128.4404 - accuracy: 0.6682 - val_loss: 819.5298 - val_accuracy: 0.7263\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1122.4491 - accuracy: 0.6656 - val_loss: 811.7202 - val_accuracy: 0.7212\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1112.0051 - accuracy: 0.6720 - val_loss: 808.1571 - val_accuracy: 0.7200\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1105.4449 - accuracy: 0.6754 - val_loss: 803.4835 - val_accuracy: 0.7181\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1103.8322 - accuracy: 0.6733 - val_loss: 797.9546 - val_accuracy: 0.7321\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1099.4407 - accuracy: 0.6738 - val_loss: 794.1531 - val_accuracy: 0.7302\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1093.8868 - accuracy: 0.6768 - val_loss: 796.1048 - val_accuracy: 0.7270\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1094.0396 - accuracy: 0.6774 - val_loss: 791.1334 - val_accuracy: 0.7314\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1047.0723 - accuracy: 0.6669 - val_loss: 676.6263 - val_accuracy: 0.7317\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 894.9431 - accuracy: 0.6615 - val_loss: 742.2260 - val_accuracy: 0.7348\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 829.4457 - accuracy: 0.6932 - val_loss: 640.6334 - val_accuracy: 0.7518\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 791.1104 - accuracy: 0.6890 - val_loss: 630.0234 - val_accuracy: 0.7401\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 780.2324 - accuracy: 0.6731 - val_loss: 619.3369 - val_accuracy: 0.7490\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 776.5950 - accuracy: 0.6723 - val_loss: 620.4576 - val_accuracy: 0.7559\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 774.0547 - accuracy: 0.6835 - val_loss: 618.7158 - val_accuracy: 0.7588\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 770.3489 - accuracy: 0.6842 - val_loss: 610.3549 - val_accuracy: 0.7517\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 769.7820 - accuracy: 0.6863 - val_loss: 609.1284 - val_accuracy: 0.7534\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 762.1449 - accuracy: 0.6886 - val_loss: 607.1459 - val_accuracy: 0.7518\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 758.9769 - accuracy: 0.6913 - val_loss: 602.5928 - val_accuracy: 0.7465\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 754.6141 - accuracy: 0.6947 - val_loss: 608.1262 - val_accuracy: 0.7540\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 758.8083 - accuracy: 0.6941 - val_loss: 597.2137 - val_accuracy: 0.7534\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 757.0176 - accuracy: 0.6881 - val_loss: 592.4058 - val_accuracy: 0.7484\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 751.4741 - accuracy: 0.6964 - val_loss: 591.9055 - val_accuracy: 0.7556\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 745.6084 - accuracy: 0.7007 - val_loss: 589.2578 - val_accuracy: 0.7523\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 746.7584 - accuracy: 0.7045 - val_loss: 588.2740 - val_accuracy: 0.7570\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 743.3742 - accuracy: 0.7016 - val_loss: 589.3438 - val_accuracy: 0.7612\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.0101 - accuracy: 0.7055 - val_loss: 587.1588 - val_accuracy: 0.7598\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.8622 - accuracy: 0.7071 - val_loss: 582.2560 - val_accuracy: 0.7585\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.3561 - accuracy: 0.7026 - val_loss: 581.2062 - val_accuracy: 0.7565\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 736.4385 - accuracy: 0.7121 - val_loss: 583.9182 - val_accuracy: 0.7569\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.9513 - accuracy: 0.7095 - val_loss: 581.1570 - val_accuracy: 0.7573\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 734.4942 - accuracy: 0.7097 - val_loss: 581.4037 - val_accuracy: 0.7657\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 735.3887 - accuracy: 0.7106 - val_loss: 579.2891 - val_accuracy: 0.7626\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.0383 - accuracy: 0.7040 - val_loss: 575.3925 - val_accuracy: 0.7628\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.1211 - accuracy: 0.7112 - val_loss: 580.7237 - val_accuracy: 0.7608\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 730.6664 - accuracy: 0.7102 - val_loss: 585.2106 - val_accuracy: 0.7630\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.0596 - accuracy: 0.7072 - val_loss: 575.2597 - val_accuracy: 0.7594\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 728.6832 - accuracy: 0.7091 - val_loss: 572.2794 - val_accuracy: 0.7629\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 726.2636 - accuracy: 0.7112 - val_loss: 576.3511 - val_accuracy: 0.7593\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.4672 - accuracy: 0.7099 - val_loss: 571.8990 - val_accuracy: 0.7615\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 725.9285 - accuracy: 0.7131 - val_loss: 577.3870 - val_accuracy: 0.7586\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 727.5955 - accuracy: 0.7122 - val_loss: 569.0987 - val_accuracy: 0.7596\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.5179 - accuracy: 0.7155 - val_loss: 570.2013 - val_accuracy: 0.7675\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.3176 - accuracy: 0.7133 - val_loss: 573.1892 - val_accuracy: 0.7637\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.7598 - accuracy: 0.7194 - val_loss: 568.0124 - val_accuracy: 0.7659\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 721.8278 - accuracy: 0.7099 - val_loss: 577.0732 - val_accuracy: 0.7618\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 722.1036 - accuracy: 0.7170 - val_loss: 563.8412 - val_accuracy: 0.7714\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.0917 - accuracy: 0.7119 - val_loss: 564.1572 - val_accuracy: 0.7649\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.9238 - accuracy: 0.7160 - val_loss: 569.8381 - val_accuracy: 0.7653\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.5477 - accuracy: 0.7125 - val_loss: 564.9580 - val_accuracy: 0.7630\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.6133 - accuracy: 0.7149 - val_loss: 562.9144 - val_accuracy: 0.7684\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.6005 - accuracy: 0.7162 - val_loss: 565.4448 - val_accuracy: 0.7671\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 715.3998 - accuracy: 0.7163 - val_loss: 563.4618 - val_accuracy: 0.7722\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 716.9470 - accuracy: 0.7146 - val_loss: 560.6385 - val_accuracy: 0.7648\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 713.5710 - accuracy: 0.7181 - val_loss: 565.3948 - val_accuracy: 0.7773\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 715.1284 - accuracy: 0.7197 - val_loss: 563.0666 - val_accuracy: 0.7692\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 719.0822 - accuracy: 0.7180 - val_loss: 560.8670 - val_accuracy: 0.7671\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 717.3586 - accuracy: 0.7182 - val_loss: 562.9206 - val_accuracy: 0.7758\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 714.4111 - accuracy: 0.7192 - val_loss: 559.6667 - val_accuracy: 0.7708\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 709.1194 - accuracy: 0.7177 - val_loss: 556.2343 - val_accuracy: 0.7688\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 709.7281 - accuracy: 0.7211 - val_loss: 557.6885 - val_accuracy: 0.7729\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 709.4971 - accuracy: 0.7136 - val_loss: 556.2911 - val_accuracy: 0.7733\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 708.5222 - accuracy: 0.7193 - val_loss: 558.6743 - val_accuracy: 0.7758\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 707.0391 - accuracy: 0.7175 - val_loss: 554.6541 - val_accuracy: 0.7706\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 706.3856 - accuracy: 0.7220 - val_loss: 552.7746 - val_accuracy: 0.7745\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 704.8443 - accuracy: 0.7198 - val_loss: 556.0956 - val_accuracy: 0.7751\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 705.7056 - accuracy: 0.7188 - val_loss: 554.6622 - val_accuracy: 0.7750\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "#upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(input_layer1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=None, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gagW9I4C4za",
        "outputId": "4a894448-d986-44c1-9ae2-6c934097b0e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "12/12 [==============================] - 2s 68ms/step - loss: 8189.6548 - accuracy: 0.0017 - val_loss: 5442.4761 - val_accuracy: 2.0345e-04\n",
            "Epoch 2/100\n",
            "12/12 [==============================] - 1s 42ms/step - loss: 6495.2793 - accuracy: 0.0014 - val_loss: 4090.0132 - val_accuracy: 0.0015\n",
            "Epoch 3/100\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 5210.4731 - accuracy: 0.0033 - val_loss: 3463.8577 - val_accuracy: 0.0111\n",
            "Epoch 4/100\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 4061.3093 - accuracy: 0.0139 - val_loss: 2723.0181 - val_accuracy: 0.0222\n",
            "Epoch 5/100\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 3049.5471 - accuracy: 0.0346 - val_loss: 2159.9426 - val_accuracy: 0.0280\n",
            "Epoch 6/100\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 2409.0508 - accuracy: 0.0370 - val_loss: 1854.2448 - val_accuracy: 0.0315\n",
            "Epoch 7/100\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 2067.4775 - accuracy: 0.1045 - val_loss: 1649.0531 - val_accuracy: 0.1543\n",
            "Epoch 8/100\n",
            "12/12 [==============================] - 0s 41ms/step - loss: 1822.2849 - accuracy: 0.2301 - val_loss: 1481.4073 - val_accuracy: 0.2290\n",
            "Epoch 9/100\n",
            "12/12 [==============================] - 1s 44ms/step - loss: 1632.3976 - accuracy: 0.2826 - val_loss: 1335.5958 - val_accuracy: 0.2418\n",
            "Epoch 10/100\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1488.9091 - accuracy: 0.3090 - val_loss: 1204.4041 - val_accuracy: 0.2781\n",
            "Epoch 11/100\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 1359.6866 - accuracy: 0.4551 - val_loss: 1090.2084 - val_accuracy: 0.4390\n",
            "Epoch 12/100\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 1256.7094 - accuracy: 0.4832 - val_loss: 980.1733 - val_accuracy: 0.4729\n",
            "Epoch 13/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 1163.3157 - accuracy: 0.5083 - val_loss: 916.2540 - val_accuracy: 0.4958\n",
            "Epoch 14/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 1087.0050 - accuracy: 0.5268 - val_loss: 872.0927 - val_accuracy: 0.4857\n",
            "Epoch 15/100\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 1033.9248 - accuracy: 0.5510 - val_loss: 834.5405 - val_accuracy: 0.4604\n",
            "Epoch 16/100\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1000.9128 - accuracy: 0.5503 - val_loss: 824.5291 - val_accuracy: 0.5020\n",
            "Epoch 17/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 976.8522 - accuracy: 0.5445 - val_loss: 810.8530 - val_accuracy: 0.5104\n",
            "Epoch 18/100\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 954.2446 - accuracy: 0.5420 - val_loss: 776.0397 - val_accuracy: 0.5272\n",
            "Epoch 19/100\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 927.6940 - accuracy: 0.5604 - val_loss: 748.1500 - val_accuracy: 0.5606\n",
            "Epoch 20/100\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 906.8053 - accuracy: 0.5675 - val_loss: 731.6462 - val_accuracy: 0.5844\n",
            "Epoch 21/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 891.3583 - accuracy: 0.5763 - val_loss: 714.8489 - val_accuracy: 0.5779\n",
            "Epoch 22/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 878.0020 - accuracy: 0.5631 - val_loss: 692.2001 - val_accuracy: 0.5991\n",
            "Epoch 23/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 861.7288 - accuracy: 0.5985 - val_loss: 679.4001 - val_accuracy: 0.5983\n",
            "Epoch 24/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 848.8680 - accuracy: 0.6083 - val_loss: 668.4870 - val_accuracy: 0.6307\n",
            "Epoch 25/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 836.7676 - accuracy: 0.6085 - val_loss: 663.1671 - val_accuracy: 0.6428\n",
            "Epoch 26/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 828.7192 - accuracy: 0.6138 - val_loss: 658.0524 - val_accuracy: 0.6535\n",
            "Epoch 27/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 822.6669 - accuracy: 0.6127 - val_loss: 641.9517 - val_accuracy: 0.6520\n",
            "Epoch 28/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 816.1750 - accuracy: 0.6221 - val_loss: 639.9562 - val_accuracy: 0.6743\n",
            "Epoch 29/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 809.0566 - accuracy: 0.6231 - val_loss: 642.6807 - val_accuracy: 0.6603\n",
            "Epoch 30/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 813.7429 - accuracy: 0.6261 - val_loss: 631.2925 - val_accuracy: 0.6715\n",
            "Epoch 31/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 809.5041 - accuracy: 0.6216 - val_loss: 626.2708 - val_accuracy: 0.7040\n",
            "Epoch 32/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 797.6928 - accuracy: 0.6296 - val_loss: 618.9335 - val_accuracy: 0.6780\n",
            "Epoch 33/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 792.0626 - accuracy: 0.6272 - val_loss: 617.3662 - val_accuracy: 0.6873\n",
            "Epoch 34/100\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 796.7020 - accuracy: 0.6411 - val_loss: 619.5274 - val_accuracy: 0.6700\n",
            "Epoch 35/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 792.5623 - accuracy: 0.6402 - val_loss: 625.6593 - val_accuracy: 0.6850\n",
            "Epoch 36/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 787.8918 - accuracy: 0.6403 - val_loss: 624.1735 - val_accuracy: 0.7113\n",
            "Epoch 37/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 782.7992 - accuracy: 0.6428 - val_loss: 603.5648 - val_accuracy: 0.6945\n",
            "Epoch 38/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 779.1910 - accuracy: 0.6456 - val_loss: 608.9643 - val_accuracy: 0.6891\n",
            "Epoch 39/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 779.2400 - accuracy: 0.6402 - val_loss: 604.0057 - val_accuracy: 0.6909\n",
            "Epoch 40/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 775.3577 - accuracy: 0.6423 - val_loss: 604.5641 - val_accuracy: 0.6993\n",
            "Epoch 41/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 773.2488 - accuracy: 0.6522 - val_loss: 596.1689 - val_accuracy: 0.6999\n",
            "Epoch 42/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 770.3456 - accuracy: 0.6493 - val_loss: 601.9529 - val_accuracy: 0.7184\n",
            "Epoch 43/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 771.5701 - accuracy: 0.6570 - val_loss: 596.7006 - val_accuracy: 0.7017\n",
            "Epoch 44/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 772.7493 - accuracy: 0.6495 - val_loss: 596.2181 - val_accuracy: 0.7116\n",
            "Epoch 45/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 766.1458 - accuracy: 0.6567 - val_loss: 592.4591 - val_accuracy: 0.7228\n",
            "Epoch 46/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 765.0631 - accuracy: 0.6568 - val_loss: 596.2498 - val_accuracy: 0.7260\n",
            "Epoch 47/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 766.4858 - accuracy: 0.6543 - val_loss: 600.4022 - val_accuracy: 0.7137\n",
            "Epoch 48/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 771.9319 - accuracy: 0.6489 - val_loss: 595.6749 - val_accuracy: 0.7097\n",
            "Epoch 49/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 767.2106 - accuracy: 0.6590 - val_loss: 594.7829 - val_accuracy: 0.7334\n",
            "Epoch 50/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 762.4278 - accuracy: 0.6598 - val_loss: 599.3811 - val_accuracy: 0.7147\n",
            "Epoch 51/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 763.7397 - accuracy: 0.6597 - val_loss: 591.9412 - val_accuracy: 0.7255\n",
            "Epoch 52/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 759.2907 - accuracy: 0.6612 - val_loss: 587.5801 - val_accuracy: 0.7469\n",
            "Epoch 53/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 753.9219 - accuracy: 0.6668 - val_loss: 584.3731 - val_accuracy: 0.7339\n",
            "Epoch 54/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.8910 - accuracy: 0.6635 - val_loss: 582.4263 - val_accuracy: 0.7431\n",
            "Epoch 55/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.7418 - accuracy: 0.6714 - val_loss: 587.1422 - val_accuracy: 0.7323\n",
            "Epoch 56/100\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 753.8867 - accuracy: 0.6661 - val_loss: 591.4000 - val_accuracy: 0.7369\n",
            "Epoch 57/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.0013 - accuracy: 0.6665 - val_loss: 584.8259 - val_accuracy: 0.7408\n",
            "Epoch 58/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 747.4023 - accuracy: 0.6673 - val_loss: 588.4722 - val_accuracy: 0.7489\n",
            "Epoch 59/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 751.5007 - accuracy: 0.6720 - val_loss: 589.1562 - val_accuracy: 0.7460\n",
            "Epoch 60/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.8848 - accuracy: 0.6739 - val_loss: 581.9353 - val_accuracy: 0.7520\n",
            "Epoch 61/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 746.7528 - accuracy: 0.6727 - val_loss: 580.7125 - val_accuracy: 0.7443\n",
            "Epoch 62/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 746.1152 - accuracy: 0.6729 - val_loss: 586.0168 - val_accuracy: 0.7409\n",
            "Epoch 63/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 754.0007 - accuracy: 0.6756 - val_loss: 597.9777 - val_accuracy: 0.7416\n",
            "Epoch 64/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 753.0617 - accuracy: 0.6759 - val_loss: 580.6248 - val_accuracy: 0.7611\n",
            "Epoch 65/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 741.5814 - accuracy: 0.6812 - val_loss: 580.2405 - val_accuracy: 0.7564\n",
            "Epoch 66/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.9472 - accuracy: 0.6735 - val_loss: 577.1778 - val_accuracy: 0.7514\n",
            "Epoch 67/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.2706 - accuracy: 0.6758 - val_loss: 575.0090 - val_accuracy: 0.7449\n",
            "Epoch 68/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.1016 - accuracy: 0.6769 - val_loss: 574.2067 - val_accuracy: 0.7631\n",
            "Epoch 69/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.2632 - accuracy: 0.6781 - val_loss: 574.7260 - val_accuracy: 0.7553\n",
            "Epoch 70/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.0197 - accuracy: 0.6782 - val_loss: 576.8918 - val_accuracy: 0.7648\n",
            "Epoch 71/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 738.8803 - accuracy: 0.6768 - val_loss: 577.8360 - val_accuracy: 0.7523\n",
            "Epoch 72/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.8546 - accuracy: 0.6790 - val_loss: 578.5424 - val_accuracy: 0.7606\n",
            "Epoch 73/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 734.8830 - accuracy: 0.6834 - val_loss: 574.7025 - val_accuracy: 0.7537\n",
            "Epoch 74/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.4451 - accuracy: 0.6819 - val_loss: 569.3016 - val_accuracy: 0.7570\n",
            "Epoch 75/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.4282 - accuracy: 0.6805 - val_loss: 572.7336 - val_accuracy: 0.7685\n",
            "Epoch 76/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.8405 - accuracy: 0.6854 - val_loss: 568.4868 - val_accuracy: 0.7711\n",
            "Epoch 77/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.1943 - accuracy: 0.6840 - val_loss: 569.4412 - val_accuracy: 0.7584\n",
            "Epoch 78/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.2907 - accuracy: 0.6789 - val_loss: 576.3839 - val_accuracy: 0.7635\n",
            "Epoch 79/100\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 737.2219 - accuracy: 0.6798 - val_loss: 572.7323 - val_accuracy: 0.7427\n",
            "Epoch 80/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.6355 - accuracy: 0.6798 - val_loss: 571.5674 - val_accuracy: 0.7685\n",
            "Epoch 81/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.5692 - accuracy: 0.6831 - val_loss: 568.5031 - val_accuracy: 0.7600\n",
            "Epoch 82/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.4286 - accuracy: 0.6854 - val_loss: 572.4705 - val_accuracy: 0.7618\n",
            "Epoch 83/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 733.6478 - accuracy: 0.6894 - val_loss: 581.5121 - val_accuracy: 0.7781\n",
            "Epoch 84/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 731.7582 - accuracy: 0.6880 - val_loss: 569.7820 - val_accuracy: 0.7579\n",
            "Epoch 85/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 731.4456 - accuracy: 0.6853 - val_loss: 570.9087 - val_accuracy: 0.7763\n",
            "Epoch 86/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 732.2809 - accuracy: 0.6897 - val_loss: 566.0269 - val_accuracy: 0.7805\n",
            "Epoch 87/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 733.4659 - accuracy: 0.6901 - val_loss: 579.8261 - val_accuracy: 0.7697\n",
            "Epoch 88/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.3754 - accuracy: 0.6865 - val_loss: 584.7447 - val_accuracy: 0.7638\n",
            "Epoch 89/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 734.8941 - accuracy: 0.6907 - val_loss: 576.8728 - val_accuracy: 0.7816\n",
            "Epoch 90/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 736.7718 - accuracy: 0.6953 - val_loss: 565.0952 - val_accuracy: 0.7791\n",
            "Epoch 91/100\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 732.5967 - accuracy: 0.6896 - val_loss: 568.7303 - val_accuracy: 0.7747\n",
            "Epoch 92/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.6025 - accuracy: 0.6944 - val_loss: 562.6715 - val_accuracy: 0.7726\n",
            "Epoch 93/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.2581 - accuracy: 0.6965 - val_loss: 565.7075 - val_accuracy: 0.7810\n",
            "Epoch 94/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.8850 - accuracy: 0.6973 - val_loss: 563.4150 - val_accuracy: 0.7748\n",
            "Epoch 95/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 722.6213 - accuracy: 0.6963 - val_loss: 563.7638 - val_accuracy: 0.7875\n",
            "Epoch 96/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 721.4269 - accuracy: 0.6994 - val_loss: 565.6740 - val_accuracy: 0.7848\n",
            "Epoch 97/100\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 720.8533 - accuracy: 0.6986 - val_loss: 560.7662 - val_accuracy: 0.7820\n",
            "Epoch 98/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.8130 - accuracy: 0.7017 - val_loss: 562.0251 - val_accuracy: 0.7832\n",
            "Epoch 99/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 722.2894 - accuracy: 0.6997 - val_loss: 562.2858 - val_accuracy: 0.7651\n",
            "Epoch 100/100\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 720.0207 - accuracy: 0.6964 - val_loss: 569.5663 - val_accuracy: 0.7934\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "#upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(input_layer1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwBvIbMvC7JZ",
        "outputId": "79819ca1-dc1e-4a71-f0cb-fcfe82d5cfbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 117ms/step - loss: 8554.9678 - accuracy: 0.0570 - val_loss: 6086.7725 - val_accuracy: 0.0372\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 7581.4570 - accuracy: 0.0569 - val_loss: 5347.8047 - val_accuracy: 0.0370\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 6592.8467 - accuracy: 0.0567 - val_loss: 4814.7319 - val_accuracy: 0.0372\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 5699.9492 - accuracy: 0.0566 - val_loss: 4466.7979 - val_accuracy: 0.0373\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 5075.6714 - accuracy: 0.0560 - val_loss: 4028.3281 - val_accuracy: 0.0350\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 4501.9419 - accuracy: 0.0447 - val_loss: 3523.8923 - val_accuracy: 0.0025\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 3878.8396 - accuracy: 0.0290 - val_loss: 3062.2236 - val_accuracy: 0.0172\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 3391.6848 - accuracy: 0.0086 - val_loss: 2706.5146 - val_accuracy: 0.0167\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 2951.5483 - accuracy: 0.0058 - val_loss: 2364.1360 - val_accuracy: 0.0170\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 2607.1267 - accuracy: 0.0068 - val_loss: 2070.3162 - val_accuracy: 0.0187\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 2363.5454 - accuracy: 0.0164 - val_loss: 1876.0256 - val_accuracy: 0.0816\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 2151.8423 - accuracy: 0.0592 - val_loss: 1732.9277 - val_accuracy: 0.1022\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 1990.2236 - accuracy: 0.0595 - val_loss: 1644.9650 - val_accuracy: 0.1768\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 1880.7142 - accuracy: 0.1786 - val_loss: 1564.7734 - val_accuracy: 0.1934\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 1762.1639 - accuracy: 0.1917 - val_loss: 1473.8281 - val_accuracy: 0.2089\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 1670.4119 - accuracy: 0.2130 - val_loss: 1395.9974 - val_accuracy: 0.2271\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 1598.1785 - accuracy: 0.2282 - val_loss: 1333.6222 - val_accuracy: 0.2338\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 1537.2997 - accuracy: 0.2307 - val_loss: 1289.6400 - val_accuracy: 0.2400\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 1478.9103 - accuracy: 0.2354 - val_loss: 1244.9866 - val_accuracy: 0.2936\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 1427.1268 - accuracy: 0.2489 - val_loss: 1193.6552 - val_accuracy: 0.3601\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 1377.1415 - accuracy: 0.2795 - val_loss: 1145.9917 - val_accuracy: 0.4216\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 1326.9421 - accuracy: 0.2948 - val_loss: 1103.2467 - val_accuracy: 0.4084\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 1280.1981 - accuracy: 0.2999 - val_loss: 1058.6377 - val_accuracy: 0.4667\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 1233.6727 - accuracy: 0.3424 - val_loss: 1015.4086 - val_accuracy: 0.5093\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 1185.9330 - accuracy: 0.3960 - val_loss: 983.7177 - val_accuracy: 0.5401\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 1137.0251 - accuracy: 0.4442 - val_loss: 943.0242 - val_accuracy: 0.5521\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 1091.9070 - accuracy: 0.4733 - val_loss: 912.8387 - val_accuracy: 0.5720\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 1051.9680 - accuracy: 0.5494 - val_loss: 886.5801 - val_accuracy: 0.5893\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 1018.5984 - accuracy: 0.5519 - val_loss: 865.0056 - val_accuracy: 0.6035\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 997.5179 - accuracy: 0.5791 - val_loss: 840.6182 - val_accuracy: 0.5871\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 982.2424 - accuracy: 0.5280 - val_loss: 821.5854 - val_accuracy: 0.5890\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 964.2843 - accuracy: 0.4999 - val_loss: 807.9493 - val_accuracy: 0.5796\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 950.0040 - accuracy: 0.4755 - val_loss: 795.7971 - val_accuracy: 0.5838\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 936.1105 - accuracy: 0.4912 - val_loss: 787.5425 - val_accuracy: 0.5861\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 920.8408 - accuracy: 0.4752 - val_loss: 773.2172 - val_accuracy: 0.5976\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 910.0395 - accuracy: 0.5001 - val_loss: 754.3328 - val_accuracy: 0.5740\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 904.2556 - accuracy: 0.4962 - val_loss: 742.0627 - val_accuracy: 0.5787\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 893.4797 - accuracy: 0.5018 - val_loss: 735.9429 - val_accuracy: 0.5953\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 881.6483 - accuracy: 0.4983 - val_loss: 720.7744 - val_accuracy: 0.5828\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 873.0352 - accuracy: 0.5027 - val_loss: 705.5421 - val_accuracy: 0.5767\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 864.9537 - accuracy: 0.5091 - val_loss: 691.7621 - val_accuracy: 0.5721\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 858.5314 - accuracy: 0.5120 - val_loss: 683.2548 - val_accuracy: 0.5817\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 852.4291 - accuracy: 0.5156 - val_loss: 673.3799 - val_accuracy: 0.5598\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 846.9528 - accuracy: 0.5093 - val_loss: 665.8451 - val_accuracy: 0.5957\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 841.8898 - accuracy: 0.5123 - val_loss: 662.2367 - val_accuracy: 0.6084\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 836.7225 - accuracy: 0.5247 - val_loss: 651.9346 - val_accuracy: 0.6059\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 832.6219 - accuracy: 0.5180 - val_loss: 653.1631 - val_accuracy: 0.6255\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 826.9863 - accuracy: 0.5196 - val_loss: 645.8994 - val_accuracy: 0.6241\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 823.4886 - accuracy: 0.5246 - val_loss: 642.9514 - val_accuracy: 0.6175\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 73ms/step - loss: 820.1209 - accuracy: 0.5270 - val_loss: 636.7740 - val_accuracy: 0.6129\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 814.1075 - accuracy: 0.5379 - val_loss: 634.6005 - val_accuracy: 0.6220\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 809.6009 - accuracy: 0.5306 - val_loss: 631.5123 - val_accuracy: 0.6286\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 807.3029 - accuracy: 0.5345 - val_loss: 632.1057 - val_accuracy: 0.6302\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 805.0177 - accuracy: 0.5393 - val_loss: 624.9602 - val_accuracy: 0.6190\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 802.0461 - accuracy: 0.5467 - val_loss: 627.2042 - val_accuracy: 0.6214\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 800.2683 - accuracy: 0.5677 - val_loss: 620.5043 - val_accuracy: 0.6384\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 796.4313 - accuracy: 0.6130 - val_loss: 618.9489 - val_accuracy: 0.6560\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 795.4413 - accuracy: 0.6600 - val_loss: 620.8414 - val_accuracy: 0.6856\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 791.3210 - accuracy: 0.6633 - val_loss: 618.2432 - val_accuracy: 0.6757\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 789.1209 - accuracy: 0.6745 - val_loss: 611.1723 - val_accuracy: 0.6876\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 785.0991 - accuracy: 0.6807 - val_loss: 613.1127 - val_accuracy: 0.6935\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 784.1419 - accuracy: 0.6751 - val_loss: 608.6600 - val_accuracy: 0.6970\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 780.4749 - accuracy: 0.6873 - val_loss: 607.2226 - val_accuracy: 0.6998\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 779.5202 - accuracy: 0.6826 - val_loss: 606.3361 - val_accuracy: 0.6896\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 778.1766 - accuracy: 0.6893 - val_loss: 605.7036 - val_accuracy: 0.6813\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 774.4442 - accuracy: 0.6925 - val_loss: 602.5284 - val_accuracy: 0.7060\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 771.3896 - accuracy: 0.6893 - val_loss: 599.0354 - val_accuracy: 0.7055\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 769.7258 - accuracy: 0.6946 - val_loss: 601.0942 - val_accuracy: 0.7223\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 770.3503 - accuracy: 0.6981 - val_loss: 595.5237 - val_accuracy: 0.7242\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 766.9966 - accuracy: 0.6983 - val_loss: 597.8412 - val_accuracy: 0.7154\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 763.8265 - accuracy: 0.6974 - val_loss: 592.1724 - val_accuracy: 0.7094\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 761.3861 - accuracy: 0.6995 - val_loss: 595.8771 - val_accuracy: 0.7024\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 761.3622 - accuracy: 0.7032 - val_loss: 591.2035 - val_accuracy: 0.7177\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 759.3040 - accuracy: 0.7011 - val_loss: 589.5128 - val_accuracy: 0.7296\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 760.1844 - accuracy: 0.7020 - val_loss: 593.1632 - val_accuracy: 0.7299\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 760.0389 - accuracy: 0.7027 - val_loss: 585.8758 - val_accuracy: 0.7277\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 65ms/step - loss: 757.7099 - accuracy: 0.7089 - val_loss: 589.8782 - val_accuracy: 0.7302\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 755.4937 - accuracy: 0.7030 - val_loss: 587.7184 - val_accuracy: 0.7156\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 753.1647 - accuracy: 0.7128 - val_loss: 592.0449 - val_accuracy: 0.7171\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 751.5497 - accuracy: 0.6983 - val_loss: 586.0536 - val_accuracy: 0.7325\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 750.3871 - accuracy: 0.7092 - val_loss: 582.6210 - val_accuracy: 0.7396\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 748.4714 - accuracy: 0.7086 - val_loss: 582.2156 - val_accuracy: 0.7289\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 746.3356 - accuracy: 0.7102 - val_loss: 581.9256 - val_accuracy: 0.7259\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 746.1733 - accuracy: 0.7121 - val_loss: 579.7971 - val_accuracy: 0.7319\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 746.3903 - accuracy: 0.7055 - val_loss: 580.9709 - val_accuracy: 0.7385\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 746.4196 - accuracy: 0.7094 - val_loss: 579.6207 - val_accuracy: 0.7453\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 743.4903 - accuracy: 0.7113 - val_loss: 577.3663 - val_accuracy: 0.7398\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 61ms/step - loss: 740.7043 - accuracy: 0.7134 - val_loss: 577.1400 - val_accuracy: 0.7456\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 740.9131 - accuracy: 0.7139 - val_loss: 578.1115 - val_accuracy: 0.7398\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 741.2255 - accuracy: 0.7088 - val_loss: 580.8665 - val_accuracy: 0.7437\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 744.6462 - accuracy: 0.7144 - val_loss: 580.5526 - val_accuracy: 0.7386\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 741.0423 - accuracy: 0.7169 - val_loss: 583.6486 - val_accuracy: 0.7366\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 740.1075 - accuracy: 0.7123 - val_loss: 574.0442 - val_accuracy: 0.7370\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 735.7281 - accuracy: 0.7175 - val_loss: 573.2324 - val_accuracy: 0.7482\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 77ms/step - loss: 734.8207 - accuracy: 0.7122 - val_loss: 573.3545 - val_accuracy: 0.7505\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 736.4317 - accuracy: 0.7157 - val_loss: 572.4760 - val_accuracy: 0.7489\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 733.9157 - accuracy: 0.7154 - val_loss: 573.3004 - val_accuracy: 0.7434\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 731.9804 - accuracy: 0.7163 - val_loss: 572.1028 - val_accuracy: 0.7523\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 731.5471 - accuracy: 0.7157 - val_loss: 570.9648 - val_accuracy: 0.7546\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 733.5057 - accuracy: 0.7137 - val_loss: 574.3226 - val_accuracy: 0.7470\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "#upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(input_layer1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=64, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3H_YzT5XDgqo"
      },
      "source": [
        "# **now increase epochs in the best model created above**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tDrQriaDjqx",
        "outputId": "d7f7d200-e6ca-4bbf-e33f-3643c5870fac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 46ms/step - loss: 9016.2197 - accuracy: 0.0070 - val_loss: 6362.8599 - val_accuracy: 0.0157\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 7446.8994 - accuracy: 0.0071 - val_loss: 4861.0884 - val_accuracy: 0.0158\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 5627.5796 - accuracy: 0.0661 - val_loss: 4224.4951 - val_accuracy: 0.0107\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 4585.6616 - accuracy: 0.0478 - val_loss: 3573.6951 - val_accuracy: 0.0059\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 3770.9509 - accuracy: 0.0748 - val_loss: 2980.2979 - val_accuracy: 0.2936\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 3068.4468 - accuracy: 0.0894 - val_loss: 2423.1104 - val_accuracy: 0.1980\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 2494.5706 - accuracy: 0.0913 - val_loss: 2056.2009 - val_accuracy: 0.3545\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 2016.8743 - accuracy: 0.1352 - val_loss: 1678.9539 - val_accuracy: 0.3896\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 1693.7363 - accuracy: 0.2075 - val_loss: 1378.7174 - val_accuracy: 0.5352\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1452.7605 - accuracy: 0.3315 - val_loss: 1162.4142 - val_accuracy: 0.5249\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 1280.2339 - accuracy: 0.3804 - val_loss: 1033.1498 - val_accuracy: 0.5615\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 1170.0653 - accuracy: 0.3679 - val_loss: 956.3366 - val_accuracy: 0.5468\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 1100.2664 - accuracy: 0.3608 - val_loss: 894.2396 - val_accuracy: 0.5991\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 1058.0281 - accuracy: 0.3988 - val_loss: 868.0200 - val_accuracy: 0.5327\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 1034.0652 - accuracy: 0.4199 - val_loss: 850.3224 - val_accuracy: 0.5560\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 1007.2546 - accuracy: 0.4477 - val_loss: 814.7404 - val_accuracy: 0.5434\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 983.3064 - accuracy: 0.4489 - val_loss: 789.9947 - val_accuracy: 0.5391\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 959.6190 - accuracy: 0.4428 - val_loss: 766.0728 - val_accuracy: 0.5644\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 938.3508 - accuracy: 0.4327 - val_loss: 745.1110 - val_accuracy: 0.5312\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 921.6013 - accuracy: 0.4486 - val_loss: 728.9097 - val_accuracy: 0.5592\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 906.5849 - accuracy: 0.4455 - val_loss: 720.1396 - val_accuracy: 0.5447\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 896.1429 - accuracy: 0.4895 - val_loss: 705.2834 - val_accuracy: 0.5961\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 883.1149 - accuracy: 0.5454 - val_loss: 685.9660 - val_accuracy: 0.6005\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 870.0370 - accuracy: 0.5715 - val_loss: 683.0009 - val_accuracy: 0.6554\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 867.1871 - accuracy: 0.6137 - val_loss: 666.6217 - val_accuracy: 0.6723\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 856.6562 - accuracy: 0.6297 - val_loss: 661.6495 - val_accuracy: 0.6744\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 845.0693 - accuracy: 0.6321 - val_loss: 652.5229 - val_accuracy: 0.7068\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 834.2048 - accuracy: 0.6460 - val_loss: 641.1066 - val_accuracy: 0.7035\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 828.8856 - accuracy: 0.6442 - val_loss: 636.8116 - val_accuracy: 0.7158\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 820.2379 - accuracy: 0.6562 - val_loss: 626.8127 - val_accuracy: 0.7199\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 814.6412 - accuracy: 0.6552 - val_loss: 627.3430 - val_accuracy: 0.7242\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 812.8619 - accuracy: 0.6644 - val_loss: 623.4704 - val_accuracy: 0.7310\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 808.0411 - accuracy: 0.6611 - val_loss: 624.3250 - val_accuracy: 0.7391\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 808.6273 - accuracy: 0.6639 - val_loss: 625.1931 - val_accuracy: 0.7377\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 800.3036 - accuracy: 0.6692 - val_loss: 611.3395 - val_accuracy: 0.7359\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 795.2018 - accuracy: 0.6672 - val_loss: 617.4684 - val_accuracy: 0.7360\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 794.7324 - accuracy: 0.6771 - val_loss: 611.4941 - val_accuracy: 0.7345\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 794.3333 - accuracy: 0.6787 - val_loss: 614.9092 - val_accuracy: 0.7352\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 791.9113 - accuracy: 0.6772 - val_loss: 609.0889 - val_accuracy: 0.7350\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 787.5876 - accuracy: 0.6833 - val_loss: 605.1626 - val_accuracy: 0.7335\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 785.2350 - accuracy: 0.6842 - val_loss: 607.6168 - val_accuracy: 0.7371\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 788.8016 - accuracy: 0.6738 - val_loss: 605.0346 - val_accuracy: 0.7260\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 784.1015 - accuracy: 0.6866 - val_loss: 603.8456 - val_accuracy: 0.7174\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 778.7313 - accuracy: 0.6808 - val_loss: 613.1774 - val_accuracy: 0.7152\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 779.9763 - accuracy: 0.6887 - val_loss: 605.0295 - val_accuracy: 0.7244\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 773.5483 - accuracy: 0.6895 - val_loss: 598.3030 - val_accuracy: 0.7252\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 772.4153 - accuracy: 0.6791 - val_loss: 595.6909 - val_accuracy: 0.7189\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 771.2271 - accuracy: 0.6892 - val_loss: 595.8395 - val_accuracy: 0.7285\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 769.9352 - accuracy: 0.6871 - val_loss: 596.8902 - val_accuracy: 0.7279\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 767.9893 - accuracy: 0.6898 - val_loss: 598.1011 - val_accuracy: 0.7157\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 765.2491 - accuracy: 0.6966 - val_loss: 602.6326 - val_accuracy: 0.7302\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 776.0590 - accuracy: 0.6913 - val_loss: 596.0543 - val_accuracy: 0.7279\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 766.6261 - accuracy: 0.6921 - val_loss: 589.5791 - val_accuracy: 0.7228\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 762.3302 - accuracy: 0.6941 - val_loss: 591.8853 - val_accuracy: 0.7297\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 760.6121 - accuracy: 0.6953 - val_loss: 591.2781 - val_accuracy: 0.7144\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 767.8489 - accuracy: 0.6941 - val_loss: 592.4749 - val_accuracy: 0.7076\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 762.1494 - accuracy: 0.6900 - val_loss: 591.1248 - val_accuracy: 0.7160\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.4835 - accuracy: 0.7007 - val_loss: 591.1377 - val_accuracy: 0.7210\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 755.9373 - accuracy: 0.6957 - val_loss: 592.4318 - val_accuracy: 0.7264\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 756.5637 - accuracy: 0.7009 - val_loss: 593.7451 - val_accuracy: 0.7204\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 760.3264 - accuracy: 0.7002 - val_loss: 591.5082 - val_accuracy: 0.7124\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 755.7200 - accuracy: 0.6981 - val_loss: 597.2283 - val_accuracy: 0.7136\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 750.1990 - accuracy: 0.7057 - val_loss: 589.8148 - val_accuracy: 0.7216\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 752.8530 - accuracy: 0.6985 - val_loss: 590.0887 - val_accuracy: 0.7281\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.3010 - accuracy: 0.7014 - val_loss: 588.0995 - val_accuracy: 0.7298\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 749.6524 - accuracy: 0.7055 - val_loss: 583.4065 - val_accuracy: 0.7311\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 748.0068 - accuracy: 0.7094 - val_loss: 580.1599 - val_accuracy: 0.7286\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 746.9288 - accuracy: 0.7079 - val_loss: 579.9767 - val_accuracy: 0.7312\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 744.1987 - accuracy: 0.7089 - val_loss: 583.3616 - val_accuracy: 0.7303\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 750.2781 - accuracy: 0.7055 - val_loss: 580.3188 - val_accuracy: 0.7363\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 764.5820 - accuracy: 0.7010 - val_loss: 585.8926 - val_accuracy: 0.7333\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 751.5126 - accuracy: 0.7044 - val_loss: 582.3123 - val_accuracy: 0.7349\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 757.0302 - accuracy: 0.7111 - val_loss: 587.2068 - val_accuracy: 0.7318\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 748.3157 - accuracy: 0.7054 - val_loss: 575.9131 - val_accuracy: 0.7397\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 740.3145 - accuracy: 0.7121 - val_loss: 578.0372 - val_accuracy: 0.7335\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 743.7247 - accuracy: 0.7133 - val_loss: 577.5893 - val_accuracy: 0.7378\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 740.5088 - accuracy: 0.7151 - val_loss: 576.8721 - val_accuracy: 0.7398\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 739.0645 - accuracy: 0.7146 - val_loss: 573.9080 - val_accuracy: 0.7384\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.2175 - accuracy: 0.7117 - val_loss: 573.8578 - val_accuracy: 0.7339\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 738.4318 - accuracy: 0.7182 - val_loss: 575.0287 - val_accuracy: 0.7373\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 743.6137 - accuracy: 0.7065 - val_loss: 575.3670 - val_accuracy: 0.7445\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 740.5244 - accuracy: 0.7137 - val_loss: 572.7245 - val_accuracy: 0.7531\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 742.0737 - accuracy: 0.7162 - val_loss: 572.1530 - val_accuracy: 0.7469\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 737.2206 - accuracy: 0.7214 - val_loss: 571.7795 - val_accuracy: 0.7359\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 734.5262 - accuracy: 0.7141 - val_loss: 569.0635 - val_accuracy: 0.7431\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 732.6223 - accuracy: 0.7175 - val_loss: 572.1856 - val_accuracy: 0.7479\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 736.8275 - accuracy: 0.7123 - val_loss: 577.6377 - val_accuracy: 0.7392\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 735.9924 - accuracy: 0.7128 - val_loss: 572.0778 - val_accuracy: 0.7457\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 730.5489 - accuracy: 0.7199 - val_loss: 567.5483 - val_accuracy: 0.7445\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 729.0911 - accuracy: 0.7247 - val_loss: 570.0834 - val_accuracy: 0.7425\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.3752 - accuracy: 0.7136 - val_loss: 575.5330 - val_accuracy: 0.7452\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 728.8795 - accuracy: 0.7165 - val_loss: 566.1011 - val_accuracy: 0.7360\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 726.7360 - accuracy: 0.7164 - val_loss: 564.6141 - val_accuracy: 0.7483\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 726.0670 - accuracy: 0.7189 - val_loss: 568.8886 - val_accuracy: 0.7469\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.2699 - accuracy: 0.7245 - val_loss: 567.9810 - val_accuracy: 0.7611\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 729.2460 - accuracy: 0.7209 - val_loss: 565.2791 - val_accuracy: 0.7506\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.3461 - accuracy: 0.7204 - val_loss: 563.1833 - val_accuracy: 0.7521\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.7825 - accuracy: 0.7168 - val_loss: 568.0700 - val_accuracy: 0.7562\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 723.5840 - accuracy: 0.7178 - val_loss: 565.4462 - val_accuracy: 0.7568\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 722.7110 - accuracy: 0.7234 - val_loss: 569.3862 - val_accuracy: 0.7484\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 724.0142 - accuracy: 0.7195 - val_loss: 564.8491 - val_accuracy: 0.7506\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.9965 - accuracy: 0.7226 - val_loss: 561.9926 - val_accuracy: 0.7537\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.7275 - accuracy: 0.7236 - val_loss: 564.9297 - val_accuracy: 0.7554\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.0526 - accuracy: 0.7233 - val_loss: 561.8619 - val_accuracy: 0.7563\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.2465 - accuracy: 0.7205 - val_loss: 563.2062 - val_accuracy: 0.7465\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.3525 - accuracy: 0.7230 - val_loss: 562.4945 - val_accuracy: 0.7534\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 720.1777 - accuracy: 0.7217 - val_loss: 564.0315 - val_accuracy: 0.7505\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 718.5204 - accuracy: 0.7254 - val_loss: 567.5721 - val_accuracy: 0.7503\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 717.6385 - accuracy: 0.7232 - val_loss: 561.8177 - val_accuracy: 0.7486\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.3419 - accuracy: 0.7252 - val_loss: 572.4423 - val_accuracy: 0.7608\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 718.2780 - accuracy: 0.7197 - val_loss: 565.4194 - val_accuracy: 0.7529\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 716.7825 - accuracy: 0.7264 - val_loss: 562.3665 - val_accuracy: 0.7586\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 713.5405 - accuracy: 0.7262 - val_loss: 557.7382 - val_accuracy: 0.7622\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.0400 - accuracy: 0.7277 - val_loss: 561.0543 - val_accuracy: 0.7636\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.0465 - accuracy: 0.7277 - val_loss: 557.3822 - val_accuracy: 0.7700\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 716.2980 - accuracy: 0.7255 - val_loss: 559.8261 - val_accuracy: 0.7558\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 711.7438 - accuracy: 0.7268 - val_loss: 556.7444 - val_accuracy: 0.7601\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 711.3151 - accuracy: 0.7251 - val_loss: 557.3613 - val_accuracy: 0.7666\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 719.2422 - accuracy: 0.7279 - val_loss: 554.4063 - val_accuracy: 0.7562\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.2762 - accuracy: 0.7321 - val_loss: 562.5680 - val_accuracy: 0.7582\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 718.6805 - accuracy: 0.7254 - val_loss: 562.0355 - val_accuracy: 0.7604\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 714.3559 - accuracy: 0.7247 - val_loss: 557.6891 - val_accuracy: 0.7567\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 712.0410 - accuracy: 0.7256 - val_loss: 555.2217 - val_accuracy: 0.7636\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 709.7480 - accuracy: 0.7315 - val_loss: 556.5659 - val_accuracy: 0.7639\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 708.3145 - accuracy: 0.7308 - val_loss: 554.4059 - val_accuracy: 0.7620\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 707.1144 - accuracy: 0.7295 - val_loss: 553.2875 - val_accuracy: 0.7579\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 706.4820 - accuracy: 0.7333 - val_loss: 557.9999 - val_accuracy: 0.7621\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 709.2175 - accuracy: 0.7313 - val_loss: 552.8167 - val_accuracy: 0.7677\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 704.9420 - accuracy: 0.7330 - val_loss: 555.9583 - val_accuracy: 0.7684\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 703.9493 - accuracy: 0.7328 - val_loss: 553.9323 - val_accuracy: 0.7681\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 704.2758 - accuracy: 0.7313 - val_loss: 557.1328 - val_accuracy: 0.7597\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 705.7626 - accuracy: 0.7332 - val_loss: 550.9755 - val_accuracy: 0.7630\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 704.3454 - accuracy: 0.7296 - val_loss: 551.9963 - val_accuracy: 0.7763\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 702.7448 - accuracy: 0.7357 - val_loss: 551.7191 - val_accuracy: 0.7725\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 702.7710 - accuracy: 0.7309 - val_loss: 550.5325 - val_accuracy: 0.7688\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 700.7733 - accuracy: 0.7346 - val_loss: 548.8582 - val_accuracy: 0.7725\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 703.8734 - accuracy: 0.7342 - val_loss: 551.8130 - val_accuracy: 0.7674\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 702.7054 - accuracy: 0.7328 - val_loss: 549.3193 - val_accuracy: 0.7734\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 700.5665 - accuracy: 0.7353 - val_loss: 555.6942 - val_accuracy: 0.7659\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 698.5405 - accuracy: 0.7359 - val_loss: 545.6729 - val_accuracy: 0.7708\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 698.4149 - accuracy: 0.7359 - val_loss: 552.8983 - val_accuracy: 0.7741\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 702.5037 - accuracy: 0.7331 - val_loss: 548.3873 - val_accuracy: 0.7709\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 700.1335 - accuracy: 0.7309 - val_loss: 549.0195 - val_accuracy: 0.7778\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 698.2589 - accuracy: 0.7323 - val_loss: 549.0804 - val_accuracy: 0.7622\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 697.7460 - accuracy: 0.7326 - val_loss: 548.4459 - val_accuracy: 0.7710\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 698.4204 - accuracy: 0.7363 - val_loss: 546.3935 - val_accuracy: 0.7676\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 696.6563 - accuracy: 0.7379 - val_loss: 544.8209 - val_accuracy: 0.7753\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 696.6182 - accuracy: 0.7395 - val_loss: 546.2439 - val_accuracy: 0.7732\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 694.9110 - accuracy: 0.7366 - val_loss: 545.6052 - val_accuracy: 0.7740\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 696.5060 - accuracy: 0.7372 - val_loss: 548.7335 - val_accuracy: 0.7738\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 698.3471 - accuracy: 0.7373 - val_loss: 544.3600 - val_accuracy: 0.7690\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 697.3571 - accuracy: 0.7365 - val_loss: 547.3008 - val_accuracy: 0.7714\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 694.4232 - accuracy: 0.7396 - val_loss: 544.6994 - val_accuracy: 0.7806\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 693.4778 - accuracy: 0.7377 - val_loss: 546.4710 - val_accuracy: 0.7761\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 692.2930 - accuracy: 0.7418 - val_loss: 542.9619 - val_accuracy: 0.7783\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 691.8363 - accuracy: 0.7406 - val_loss: 543.5609 - val_accuracy: 0.7715\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 693.5543 - accuracy: 0.7396 - val_loss: 541.3665 - val_accuracy: 0.7764\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 695.6113 - accuracy: 0.7405 - val_loss: 545.2336 - val_accuracy: 0.7716\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 700.7250 - accuracy: 0.7353 - val_loss: 546.0909 - val_accuracy: 0.7548\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 691.4566 - accuracy: 0.7389 - val_loss: 543.5342 - val_accuracy: 0.7735\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 690.1556 - accuracy: 0.7396 - val_loss: 546.5809 - val_accuracy: 0.7754\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 690.9227 - accuracy: 0.7408 - val_loss: 542.8300 - val_accuracy: 0.7789\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 689.7365 - accuracy: 0.7397 - val_loss: 540.0362 - val_accuracy: 0.7845\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 688.5292 - accuracy: 0.7400 - val_loss: 541.1078 - val_accuracy: 0.7767\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 686.0380 - accuracy: 0.7413 - val_loss: 540.7665 - val_accuracy: 0.7781\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 687.6444 - accuracy: 0.7410 - val_loss: 540.5771 - val_accuracy: 0.7809\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 685.5780 - accuracy: 0.7403 - val_loss: 539.0140 - val_accuracy: 0.7775\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 688.3239 - accuracy: 0.7415 - val_loss: 549.1456 - val_accuracy: 0.7769\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 702.7258 - accuracy: 0.7392 - val_loss: 542.6075 - val_accuracy: 0.7704\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 692.2361 - accuracy: 0.7357 - val_loss: 544.5135 - val_accuracy: 0.7838\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 691.1377 - accuracy: 0.7413 - val_loss: 540.0067 - val_accuracy: 0.7800\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 686.4615 - accuracy: 0.7403 - val_loss: 536.1013 - val_accuracy: 0.7874\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 684.1067 - accuracy: 0.7416 - val_loss: 537.7128 - val_accuracy: 0.7833\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 683.1787 - accuracy: 0.7441 - val_loss: 538.8257 - val_accuracy: 0.7884\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 685.2966 - accuracy: 0.7394 - val_loss: 539.2923 - val_accuracy: 0.7797\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 687.0613 - accuracy: 0.7423 - val_loss: 537.1108 - val_accuracy: 0.7807\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 682.6100 - accuracy: 0.7423 - val_loss: 535.1660 - val_accuracy: 0.7837\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 681.5267 - accuracy: 0.7440 - val_loss: 535.4622 - val_accuracy: 0.7812\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 681.6846 - accuracy: 0.7432 - val_loss: 535.3038 - val_accuracy: 0.7826\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 683.4177 - accuracy: 0.7392 - val_loss: 539.6846 - val_accuracy: 0.7840\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 683.4313 - accuracy: 0.7424 - val_loss: 534.8099 - val_accuracy: 0.7811\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 681.8249 - accuracy: 0.7438 - val_loss: 532.6651 - val_accuracy: 0.7849\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 681.7086 - accuracy: 0.7431 - val_loss: 534.0701 - val_accuracy: 0.7837\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 681.6334 - accuracy: 0.7446 - val_loss: 535.9424 - val_accuracy: 0.7883\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 682.7783 - accuracy: 0.7425 - val_loss: 533.2464 - val_accuracy: 0.7833\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 680.0361 - accuracy: 0.7429 - val_loss: 535.9150 - val_accuracy: 0.7834\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 680.1857 - accuracy: 0.7425 - val_loss: 532.0402 - val_accuracy: 0.7855\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 678.3536 - accuracy: 0.7443 - val_loss: 537.6222 - val_accuracy: 0.7869\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 681.3987 - accuracy: 0.7410 - val_loss: 534.1050 - val_accuracy: 0.7849\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 684.5244 - accuracy: 0.7396 - val_loss: 543.7812 - val_accuracy: 0.7716\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 685.1951 - accuracy: 0.7445 - val_loss: 533.3660 - val_accuracy: 0.7890\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 680.6843 - accuracy: 0.7414 - val_loss: 539.7140 - val_accuracy: 0.7883\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 684.6203 - accuracy: 0.7421 - val_loss: 537.7683 - val_accuracy: 0.7909\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 679.7601 - accuracy: 0.7433 - val_loss: 531.8461 - val_accuracy: 0.7854\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 677.3545 - accuracy: 0.7450 - val_loss: 533.2880 - val_accuracy: 0.7877\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 675.3365 - accuracy: 0.7449 - val_loss: 530.2650 - val_accuracy: 0.7852\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 676.5549 - accuracy: 0.7431 - val_loss: 529.8854 - val_accuracy: 0.7874\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 675.7809 - accuracy: 0.7460 - val_loss: 540.1644 - val_accuracy: 0.7917\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 678.7297 - accuracy: 0.7446 - val_loss: 531.9652 - val_accuracy: 0.7895\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 677.3315 - accuracy: 0.7447 - val_loss: 528.6401 - val_accuracy: 0.7878\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 675.4460 - accuracy: 0.7431 - val_loss: 530.7836 - val_accuracy: 0.7881\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 674.7283 - accuracy: 0.7461 - val_loss: 529.1144 - val_accuracy: 0.7900\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 673.4982 - accuracy: 0.7471 - val_loss: 533.3453 - val_accuracy: 0.7847\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 673.5169 - accuracy: 0.7436 - val_loss: 526.3847 - val_accuracy: 0.7928\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 672.0699 - accuracy: 0.7448 - val_loss: 526.4876 - val_accuracy: 0.7921\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 671.4818 - accuracy: 0.7453 - val_loss: 531.8218 - val_accuracy: 0.7879\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 673.8786 - accuracy: 0.7466 - val_loss: 535.1628 - val_accuracy: 0.7961\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 673.4150 - accuracy: 0.7464 - val_loss: 530.0134 - val_accuracy: 0.7906\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 677.1287 - accuracy: 0.7443 - val_loss: 546.0078 - val_accuracy: 0.7858\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 688.0770 - accuracy: 0.7435 - val_loss: 539.4819 - val_accuracy: 0.7965\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 691.2864 - accuracy: 0.7440 - val_loss: 536.5835 - val_accuracy: 0.7896\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 678.0668 - accuracy: 0.7466 - val_loss: 533.7487 - val_accuracy: 0.7887\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 674.3975 - accuracy: 0.7416 - val_loss: 534.8411 - val_accuracy: 0.7899\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 677.5546 - accuracy: 0.7464 - val_loss: 532.3518 - val_accuracy: 0.7970\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 673.7630 - accuracy: 0.7461 - val_loss: 527.1774 - val_accuracy: 0.7936\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 669.1002 - accuracy: 0.7452 - val_loss: 525.0223 - val_accuracy: 0.7905\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 668.5202 - accuracy: 0.7467 - val_loss: 525.0412 - val_accuracy: 0.7919\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 668.1293 - accuracy: 0.7475 - val_loss: 524.0447 - val_accuracy: 0.7955\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 669.0103 - accuracy: 0.7464 - val_loss: 524.5923 - val_accuracy: 0.7965\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 670.3458 - accuracy: 0.7456 - val_loss: 527.8779 - val_accuracy: 0.7958\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 670.6803 - accuracy: 0.7472 - val_loss: 527.3450 - val_accuracy: 0.7950\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 671.3716 - accuracy: 0.7447 - val_loss: 524.7275 - val_accuracy: 0.7927\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 668.2806 - accuracy: 0.7461 - val_loss: 524.5192 - val_accuracy: 0.7958\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 668.4986 - accuracy: 0.7476 - val_loss: 525.3822 - val_accuracy: 0.7940\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 668.5740 - accuracy: 0.7460 - val_loss: 521.8773 - val_accuracy: 0.7942\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 667.5974 - accuracy: 0.7461 - val_loss: 522.6220 - val_accuracy: 0.7947\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 668.3555 - accuracy: 0.7462 - val_loss: 522.1589 - val_accuracy: 0.7947\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 669.4285 - accuracy: 0.7466 - val_loss: 528.5084 - val_accuracy: 0.7898\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 669.0228 - accuracy: 0.7450 - val_loss: 523.8144 - val_accuracy: 0.7963\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 668.1110 - accuracy: 0.7469 - val_loss: 527.4933 - val_accuracy: 0.7970\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 668.7592 - accuracy: 0.7446 - val_loss: 522.8623 - val_accuracy: 0.7928\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 665.9659 - accuracy: 0.7455 - val_loss: 523.0836 - val_accuracy: 0.7951\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 664.2123 - accuracy: 0.7494 - val_loss: 519.6884 - val_accuracy: 0.7918\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 666.0662 - accuracy: 0.7449 - val_loss: 522.2197 - val_accuracy: 0.7940\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 663.6699 - accuracy: 0.7488 - val_loss: 520.3619 - val_accuracy: 0.7934\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 663.7873 - accuracy: 0.7464 - val_loss: 521.8636 - val_accuracy: 0.7901\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 664.8620 - accuracy: 0.7486 - val_loss: 522.7486 - val_accuracy: 0.7940\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 666.1524 - accuracy: 0.7457 - val_loss: 521.6053 - val_accuracy: 0.7937\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 663.3543 - accuracy: 0.7480 - val_loss: 520.5662 - val_accuracy: 0.7941\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 662.1804 - accuracy: 0.7488 - val_loss: 518.3076 - val_accuracy: 0.7930\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 661.7828 - accuracy: 0.7477 - val_loss: 520.2685 - val_accuracy: 0.7896\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 662.6956 - accuracy: 0.7464 - val_loss: 520.5518 - val_accuracy: 0.7929\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 662.6880 - accuracy: 0.7477 - val_loss: 518.5156 - val_accuracy: 0.7891\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 663.1670 - accuracy: 0.7455 - val_loss: 519.9642 - val_accuracy: 0.7968\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 661.6146 - accuracy: 0.7464 - val_loss: 523.3248 - val_accuracy: 0.7940\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 660.6289 - accuracy: 0.7463 - val_loss: 518.2789 - val_accuracy: 0.7951\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 659.3810 - accuracy: 0.7493 - val_loss: 518.6574 - val_accuracy: 0.7947\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 660.4703 - accuracy: 0.7491 - val_loss: 519.1486 - val_accuracy: 0.7938\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 658.6377 - accuracy: 0.7491 - val_loss: 517.6063 - val_accuracy: 0.7942\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 658.9137 - accuracy: 0.7470 - val_loss: 519.6258 - val_accuracy: 0.7902\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 662.1674 - accuracy: 0.7466 - val_loss: 521.0131 - val_accuracy: 0.7963\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 659.2765 - accuracy: 0.7470 - val_loss: 519.3190 - val_accuracy: 0.7948\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 659.3857 - accuracy: 0.7482 - val_loss: 518.1671 - val_accuracy: 0.7969\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 658.1306 - accuracy: 0.7478 - val_loss: 518.0511 - val_accuracy: 0.7932\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 657.4697 - accuracy: 0.7487 - val_loss: 517.2429 - val_accuracy: 0.7893\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 658.0141 - accuracy: 0.7492 - val_loss: 516.8671 - val_accuracy: 0.7951\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 659.2556 - accuracy: 0.7490 - val_loss: 519.3798 - val_accuracy: 0.7908\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 661.7228 - accuracy: 0.7451 - val_loss: 516.8383 - val_accuracy: 0.7961\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 660.7115 - accuracy: 0.7480 - val_loss: 517.1946 - val_accuracy: 0.7921\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 657.1854 - accuracy: 0.7482 - val_loss: 515.7153 - val_accuracy: 0.7941\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 658.5040 - accuracy: 0.7470 - val_loss: 517.5656 - val_accuracy: 0.7946\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 659.8404 - accuracy: 0.7493 - val_loss: 518.1953 - val_accuracy: 0.7933\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 665.6321 - accuracy: 0.7476 - val_loss: 517.0539 - val_accuracy: 0.7962\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 660.4332 - accuracy: 0.7448 - val_loss: 516.4683 - val_accuracy: 0.7948\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 659.8596 - accuracy: 0.7474 - val_loss: 522.0411 - val_accuracy: 0.7935\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 657.1880 - accuracy: 0.7481 - val_loss: 517.4667 - val_accuracy: 0.7937\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 658.0587 - accuracy: 0.7496 - val_loss: 517.3438 - val_accuracy: 0.7876\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 657.8656 - accuracy: 0.7476 - val_loss: 517.7546 - val_accuracy: 0.7927\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 655.0744 - accuracy: 0.7489 - val_loss: 514.1027 - val_accuracy: 0.7973\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 654.3593 - accuracy: 0.7500 - val_loss: 514.5569 - val_accuracy: 0.7968\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 653.0941 - accuracy: 0.7492 - val_loss: 517.0238 - val_accuracy: 0.7962\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 654.8355 - accuracy: 0.7483 - val_loss: 521.4637 - val_accuracy: 0.7911\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 655.3671 - accuracy: 0.7476 - val_loss: 513.7755 - val_accuracy: 0.7941\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 653.8600 - accuracy: 0.7479 - val_loss: 513.8278 - val_accuracy: 0.7937\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 655.2073 - accuracy: 0.7475 - val_loss: 514.8857 - val_accuracy: 0.7960\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 655.5104 - accuracy: 0.7485 - val_loss: 515.2597 - val_accuracy: 0.7956\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 654.6060 - accuracy: 0.7475 - val_loss: 512.3561 - val_accuracy: 0.7959\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 656.5473 - accuracy: 0.7456 - val_loss: 523.0514 - val_accuracy: 0.7920\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 662.0679 - accuracy: 0.7447 - val_loss: 518.4248 - val_accuracy: 0.7925\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 668.0515 - accuracy: 0.7427 - val_loss: 523.8746 - val_accuracy: 0.7923\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 664.4946 - accuracy: 0.7448 - val_loss: 527.1641 - val_accuracy: 0.7925\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 659.1970 - accuracy: 0.7456 - val_loss: 517.0800 - val_accuracy: 0.7949\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 662.2526 - accuracy: 0.7439 - val_loss: 519.7919 - val_accuracy: 0.7924\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 657.9492 - accuracy: 0.7489 - val_loss: 516.4651 - val_accuracy: 0.7956\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 651.9377 - accuracy: 0.7477 - val_loss: 515.0339 - val_accuracy: 0.7902\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 651.6130 - accuracy: 0.7487 - val_loss: 512.6696 - val_accuracy: 0.7930\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 651.8568 - accuracy: 0.7474 - val_loss: 510.2871 - val_accuracy: 0.7895\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 650.8447 - accuracy: 0.7462 - val_loss: 511.0296 - val_accuracy: 0.7924\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 652.3741 - accuracy: 0.7493 - val_loss: 510.1878 - val_accuracy: 0.7940\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 652.9145 - accuracy: 0.7468 - val_loss: 513.9594 - val_accuracy: 0.7892\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 652.6826 - accuracy: 0.7471 - val_loss: 513.2889 - val_accuracy: 0.7962\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 650.6830 - accuracy: 0.7455 - val_loss: 511.3159 - val_accuracy: 0.7909\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 654.2428 - accuracy: 0.7479 - val_loss: 526.4881 - val_accuracy: 0.7935\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 659.0861 - accuracy: 0.7457 - val_loss: 525.5611 - val_accuracy: 0.7899\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 661.3871 - accuracy: 0.7463 - val_loss: 514.9052 - val_accuracy: 0.7927\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 655.7602 - accuracy: 0.7459 - val_loss: 516.8081 - val_accuracy: 0.7940\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 653.2065 - accuracy: 0.7448 - val_loss: 510.1947 - val_accuracy: 0.7898\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 649.8930 - accuracy: 0.7486 - val_loss: 511.6143 - val_accuracy: 0.7922\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 651.2026 - accuracy: 0.7478 - val_loss: 514.3459 - val_accuracy: 0.7911\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 649.5165 - accuracy: 0.7480 - val_loss: 513.0378 - val_accuracy: 0.7907\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 649.3237 - accuracy: 0.7474 - val_loss: 513.7296 - val_accuracy: 0.7928\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 648.2549 - accuracy: 0.7475 - val_loss: 512.1974 - val_accuracy: 0.7925\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 647.8351 - accuracy: 0.7472 - val_loss: 509.1753 - val_accuracy: 0.7950\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 647.0540 - accuracy: 0.7502 - val_loss: 512.0395 - val_accuracy: 0.7941\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 647.7029 - accuracy: 0.7494 - val_loss: 511.4537 - val_accuracy: 0.7939\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 648.2070 - accuracy: 0.7469 - val_loss: 509.1147 - val_accuracy: 0.7947\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 647.7993 - accuracy: 0.7476 - val_loss: 512.3561 - val_accuracy: 0.7903\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 646.7252 - accuracy: 0.7469 - val_loss: 510.5265 - val_accuracy: 0.7937\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 646.3722 - accuracy: 0.7492 - val_loss: 507.4047 - val_accuracy: 0.7928\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 646.3964 - accuracy: 0.7478 - val_loss: 510.3552 - val_accuracy: 0.7893\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 649.5073 - accuracy: 0.7468 - val_loss: 511.7712 - val_accuracy: 0.7912\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 647.3041 - accuracy: 0.7460 - val_loss: 513.8004 - val_accuracy: 0.7920\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 649.6846 - accuracy: 0.7469 - val_loss: 509.0066 - val_accuracy: 0.7922\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 649.7457 - accuracy: 0.7478 - val_loss: 510.1431 - val_accuracy: 0.7974\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 648.3022 - accuracy: 0.7479 - val_loss: 512.9144 - val_accuracy: 0.7899\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 646.8497 - accuracy: 0.7481 - val_loss: 510.8111 - val_accuracy: 0.7918\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 646.7936 - accuracy: 0.7472 - val_loss: 509.7480 - val_accuracy: 0.7892\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 646.3621 - accuracy: 0.7465 - val_loss: 510.0868 - val_accuracy: 0.7928\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 647.5311 - accuracy: 0.7501 - val_loss: 510.8124 - val_accuracy: 0.7930\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 647.6855 - accuracy: 0.7466 - val_loss: 510.5461 - val_accuracy: 0.7926\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 646.0587 - accuracy: 0.7460 - val_loss: 509.9774 - val_accuracy: 0.7926\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 645.3657 - accuracy: 0.7491 - val_loss: 514.6906 - val_accuracy: 0.7919\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 645.9459 - accuracy: 0.7471 - val_loss: 508.7687 - val_accuracy: 0.7953\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 644.1578 - accuracy: 0.7486 - val_loss: 511.4509 - val_accuracy: 0.7925\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 645.1279 - accuracy: 0.7493 - val_loss: 508.6337 - val_accuracy: 0.7882\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 644.1584 - accuracy: 0.7491 - val_loss: 510.2590 - val_accuracy: 0.7890\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 644.2726 - accuracy: 0.7489 - val_loss: 507.8440 - val_accuracy: 0.7893\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 643.4094 - accuracy: 0.7485 - val_loss: 508.6975 - val_accuracy: 0.7919\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 644.1196 - accuracy: 0.7492 - val_loss: 508.6721 - val_accuracy: 0.7897\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 645.2343 - accuracy: 0.7474 - val_loss: 507.6388 - val_accuracy: 0.7901\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 644.4732 - accuracy: 0.7488 - val_loss: 508.0719 - val_accuracy: 0.7893\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 646.2731 - accuracy: 0.7427 - val_loss: 506.4620 - val_accuracy: 0.7883\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 647.1387 - accuracy: 0.7487 - val_loss: 511.5116 - val_accuracy: 0.7884\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 645.3541 - accuracy: 0.7474 - val_loss: 506.6772 - val_accuracy: 0.7932\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 644.1379 - accuracy: 0.7495 - val_loss: 506.8267 - val_accuracy: 0.7904\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 644.4340 - accuracy: 0.7467 - val_loss: 513.7325 - val_accuracy: 0.7894\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 646.2233 - accuracy: 0.7498 - val_loss: 508.8531 - val_accuracy: 0.7872\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 645.0745 - accuracy: 0.7470 - val_loss: 510.7172 - val_accuracy: 0.7882\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 646.1807 - accuracy: 0.7475 - val_loss: 516.3991 - val_accuracy: 0.7927\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 651.9834 - accuracy: 0.7468 - val_loss: 511.8583 - val_accuracy: 0.7911\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 651.6548 - accuracy: 0.7452 - val_loss: 510.9552 - val_accuracy: 0.7950\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 644.8065 - accuracy: 0.7488 - val_loss: 505.7304 - val_accuracy: 0.7940\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 642.3173 - accuracy: 0.7498 - val_loss: 507.2825 - val_accuracy: 0.7918\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 643.4393 - accuracy: 0.7492 - val_loss: 506.9222 - val_accuracy: 0.7934\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 642.0825 - accuracy: 0.7483 - val_loss: 507.7473 - val_accuracy: 0.7916\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 642.1042 - accuracy: 0.7495 - val_loss: 509.9961 - val_accuracy: 0.7888\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 643.0081 - accuracy: 0.7480 - val_loss: 508.2115 - val_accuracy: 0.7947\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 641.8191 - accuracy: 0.7486 - val_loss: 507.9579 - val_accuracy: 0.7927\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 641.8687 - accuracy: 0.7487 - val_loss: 505.6707 - val_accuracy: 0.7908\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 641.3112 - accuracy: 0.7496 - val_loss: 510.2201 - val_accuracy: 0.7913\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 642.0946 - accuracy: 0.7499 - val_loss: 507.2520 - val_accuracy: 0.7913\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 646.9146 - accuracy: 0.7475 - val_loss: 509.9080 - val_accuracy: 0.7883\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 645.5620 - accuracy: 0.7462 - val_loss: 508.9136 - val_accuracy: 0.7870\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 642.3549 - accuracy: 0.7479 - val_loss: 507.0366 - val_accuracy: 0.7925\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 643.1074 - accuracy: 0.7458 - val_loss: 510.9147 - val_accuracy: 0.7946\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 641.7744 - accuracy: 0.7500 - val_loss: 509.6968 - val_accuracy: 0.7880\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 647.8997 - accuracy: 0.7481 - val_loss: 511.4120 - val_accuracy: 0.7921\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 653.0849 - accuracy: 0.7479 - val_loss: 543.2692 - val_accuracy: 0.7926\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 653.2635 - accuracy: 0.7486 - val_loss: 527.0350 - val_accuracy: 0.7921\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 645.8909 - accuracy: 0.7493 - val_loss: 512.2514 - val_accuracy: 0.7863\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 643.2952 - accuracy: 0.7496 - val_loss: 507.9300 - val_accuracy: 0.7931\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 642.3487 - accuracy: 0.7495 - val_loss: 506.4925 - val_accuracy: 0.7911\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 641.0351 - accuracy: 0.7469 - val_loss: 508.6697 - val_accuracy: 0.7880\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 640.8616 - accuracy: 0.7484 - val_loss: 509.2173 - val_accuracy: 0.7928\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 639.7751 - accuracy: 0.7490 - val_loss: 505.8325 - val_accuracy: 0.7914\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 639.6169 - accuracy: 0.7485 - val_loss: 505.6612 - val_accuracy: 0.7944\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 640.2305 - accuracy: 0.7519 - val_loss: 508.2396 - val_accuracy: 0.7936\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 641.3406 - accuracy: 0.7479 - val_loss: 505.1532 - val_accuracy: 0.7929\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 651.6989 - accuracy: 0.7501 - val_loss: 517.4167 - val_accuracy: 0.7917\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 651.0163 - accuracy: 0.7473 - val_loss: 521.9033 - val_accuracy: 0.7952\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 649.0003 - accuracy: 0.7488 - val_loss: 512.1859 - val_accuracy: 0.7970\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 641.8624 - accuracy: 0.7512 - val_loss: 507.0267 - val_accuracy: 0.7907\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 640.5408 - accuracy: 0.7461 - val_loss: 506.1999 - val_accuracy: 0.7908\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 639.0050 - accuracy: 0.7522 - val_loss: 507.2017 - val_accuracy: 0.7915\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 639.0493 - accuracy: 0.7502 - val_loss: 506.7481 - val_accuracy: 0.7915\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 638.7209 - accuracy: 0.7488 - val_loss: 509.7044 - val_accuracy: 0.7925\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 640.5580 - accuracy: 0.7504 - val_loss: 510.2682 - val_accuracy: 0.7936\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 640.8757 - accuracy: 0.7484 - val_loss: 505.2566 - val_accuracy: 0.7925\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 640.3904 - accuracy: 0.7493 - val_loss: 506.7362 - val_accuracy: 0.7949\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 640.2508 - accuracy: 0.7503 - val_loss: 505.4664 - val_accuracy: 0.7911\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 639.6932 - accuracy: 0.7491 - val_loss: 508.4655 - val_accuracy: 0.7939\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 639.4988 - accuracy: 0.7501 - val_loss: 504.8216 - val_accuracy: 0.7909\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 640.0198 - accuracy: 0.7492 - val_loss: 514.1244 - val_accuracy: 0.7916\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 639.3496 - accuracy: 0.7497 - val_loss: 505.8283 - val_accuracy: 0.7952\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 640.0148 - accuracy: 0.7499 - val_loss: 507.4698 - val_accuracy: 0.7962\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 637.7097 - accuracy: 0.7459 - val_loss: 506.6697 - val_accuracy: 0.7941\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 637.3989 - accuracy: 0.7512 - val_loss: 505.3817 - val_accuracy: 0.7927\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 638.3876 - accuracy: 0.7503 - val_loss: 507.8879 - val_accuracy: 0.7925\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 644.8459 - accuracy: 0.7513 - val_loss: 520.9661 - val_accuracy: 0.7936\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 655.0569 - accuracy: 0.7473 - val_loss: 523.6373 - val_accuracy: 0.7926\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 644.9164 - accuracy: 0.7510 - val_loss: 505.5613 - val_accuracy: 0.7932\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 642.2274 - accuracy: 0.7485 - val_loss: 507.2095 - val_accuracy: 0.7931\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 638.2419 - accuracy: 0.7500 - val_loss: 504.4033 - val_accuracy: 0.7931\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 640.6976 - accuracy: 0.7458 - val_loss: 507.7852 - val_accuracy: 0.7920\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 641.4091 - accuracy: 0.7487 - val_loss: 506.8045 - val_accuracy: 0.7890\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 639.4229 - accuracy: 0.7484 - val_loss: 508.1262 - val_accuracy: 0.7951\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 640.2277 - accuracy: 0.7475 - val_loss: 509.2929 - val_accuracy: 0.7947\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 639.7470 - accuracy: 0.7496 - val_loss: 507.7007 - val_accuracy: 0.7917\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 639.8385 - accuracy: 0.7485 - val_loss: 510.5530 - val_accuracy: 0.7896\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 639.1752 - accuracy: 0.7507 - val_loss: 505.2783 - val_accuracy: 0.7971\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 637.1702 - accuracy: 0.7521 - val_loss: 506.7961 - val_accuracy: 0.7937\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 636.1670 - accuracy: 0.7478 - val_loss: 506.7693 - val_accuracy: 0.7941\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 636.1960 - accuracy: 0.7514 - val_loss: 504.7480 - val_accuracy: 0.7922\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 636.6960 - accuracy: 0.7496 - val_loss: 505.6570 - val_accuracy: 0.7963\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 637.4341 - accuracy: 0.7487 - val_loss: 506.7045 - val_accuracy: 0.7928\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 639.1096 - accuracy: 0.7494 - val_loss: 507.6711 - val_accuracy: 0.7915\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 637.8877 - accuracy: 0.7519 - val_loss: 508.5227 - val_accuracy: 0.7944\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 639.1136 - accuracy: 0.7489 - val_loss: 506.1245 - val_accuracy: 0.7914\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 635.4365 - accuracy: 0.7516 - val_loss: 504.8425 - val_accuracy: 0.7911\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 637.7211 - accuracy: 0.7522 - val_loss: 506.0694 - val_accuracy: 0.7950\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 643.7161 - accuracy: 0.7501 - val_loss: 512.0127 - val_accuracy: 0.7938\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 640.5363 - accuracy: 0.7488 - val_loss: 506.4802 - val_accuracy: 0.7907\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 637.3300 - accuracy: 0.7496 - val_loss: 503.1014 - val_accuracy: 0.7933\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 636.6674 - accuracy: 0.7494 - val_loss: 503.4455 - val_accuracy: 0.7956\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 635.7954 - accuracy: 0.7531 - val_loss: 505.6329 - val_accuracy: 0.7973\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 634.0635 - accuracy: 0.7507 - val_loss: 504.2480 - val_accuracy: 0.7905\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 634.5323 - accuracy: 0.7515 - val_loss: 503.9928 - val_accuracy: 0.7925\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 634.9968 - accuracy: 0.7521 - val_loss: 502.7884 - val_accuracy: 0.7940\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 634.4679 - accuracy: 0.7524 - val_loss: 504.2678 - val_accuracy: 0.7920\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 635.0941 - accuracy: 0.7513 - val_loss: 506.1373 - val_accuracy: 0.7936\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 638.0827 - accuracy: 0.7507 - val_loss: 504.9449 - val_accuracy: 0.7955\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 636.6707 - accuracy: 0.7497 - val_loss: 504.2734 - val_accuracy: 0.7943\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 636.7039 - accuracy: 0.7522 - val_loss: 504.9883 - val_accuracy: 0.7918\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 635.4539 - accuracy: 0.7522 - val_loss: 504.5711 - val_accuracy: 0.7938\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 636.3285 - accuracy: 0.7518 - val_loss: 506.3549 - val_accuracy: 0.7945\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 638.4008 - accuracy: 0.7514 - val_loss: 502.7953 - val_accuracy: 0.7923\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 634.6799 - accuracy: 0.7512 - val_loss: 506.1137 - val_accuracy: 0.7927\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 637.2770 - accuracy: 0.7500 - val_loss: 504.3943 - val_accuracy: 0.7943\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 636.0219 - accuracy: 0.7509 - val_loss: 507.8806 - val_accuracy: 0.7928\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 634.5701 - accuracy: 0.7532 - val_loss: 503.6928 - val_accuracy: 0.7907\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 635.5460 - accuracy: 0.7504 - val_loss: 504.5742 - val_accuracy: 0.7934\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 642.5719 - accuracy: 0.7508 - val_loss: 508.0347 - val_accuracy: 0.7946\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 639.6838 - accuracy: 0.7501 - val_loss: 508.8070 - val_accuracy: 0.7916\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 637.3980 - accuracy: 0.7508 - val_loss: 503.0160 - val_accuracy: 0.7917\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 636.2315 - accuracy: 0.7492 - val_loss: 503.4064 - val_accuracy: 0.7956\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 634.9965 - accuracy: 0.7507 - val_loss: 502.1356 - val_accuracy: 0.7920\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 633.9169 - accuracy: 0.7509 - val_loss: 504.4864 - val_accuracy: 0.7950\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 634.4361 - accuracy: 0.7542 - val_loss: 507.3602 - val_accuracy: 0.7971\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 635.0191 - accuracy: 0.7532 - val_loss: 510.2486 - val_accuracy: 0.7957\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 639.7918 - accuracy: 0.7510 - val_loss: 510.9854 - val_accuracy: 0.7917\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 637.5738 - accuracy: 0.7525 - val_loss: 506.0368 - val_accuracy: 0.7928\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 638.8423 - accuracy: 0.7527 - val_loss: 507.9499 - val_accuracy: 0.7947\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 640.2533 - accuracy: 0.7491 - val_loss: 504.8735 - val_accuracy: 0.7936\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 634.7707 - accuracy: 0.7508 - val_loss: 506.0220 - val_accuracy: 0.7914\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 633.4205 - accuracy: 0.7518 - val_loss: 503.6577 - val_accuracy: 0.7926\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 633.4063 - accuracy: 0.7526 - val_loss: 502.6874 - val_accuracy: 0.7965\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 633.4991 - accuracy: 0.7540 - val_loss: 507.6144 - val_accuracy: 0.7927\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 635.1277 - accuracy: 0.7513 - val_loss: 505.1954 - val_accuracy: 0.7934\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 637.8479 - accuracy: 0.7524 - val_loss: 503.1350 - val_accuracy: 0.7944\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 636.7009 - accuracy: 0.7493 - val_loss: 505.7894 - val_accuracy: 0.7914\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 634.1003 - accuracy: 0.7514 - val_loss: 505.1771 - val_accuracy: 0.7909\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 636.5314 - accuracy: 0.7534 - val_loss: 503.5040 - val_accuracy: 0.7914\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 633.7700 - accuracy: 0.7528 - val_loss: 502.2921 - val_accuracy: 0.7938\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 634.4202 - accuracy: 0.7510 - val_loss: 504.7343 - val_accuracy: 0.7940\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 634.3464 - accuracy: 0.7511 - val_loss: 504.1697 - val_accuracy: 0.7915\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 632.8956 - accuracy: 0.7515 - val_loss: 502.1973 - val_accuracy: 0.7929\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 632.5050 - accuracy: 0.7547 - val_loss: 504.2117 - val_accuracy: 0.7941\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 632.5394 - accuracy: 0.7509 - val_loss: 506.2464 - val_accuracy: 0.7920\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 633.8959 - accuracy: 0.7522 - val_loss: 503.3174 - val_accuracy: 0.7912\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 634.6940 - accuracy: 0.7527 - val_loss: 501.5512 - val_accuracy: 0.7939\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 634.7847 - accuracy: 0.7529 - val_loss: 509.9110 - val_accuracy: 0.7936\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 636.5724 - accuracy: 0.7501 - val_loss: 501.0052 - val_accuracy: 0.7936\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 631.7983 - accuracy: 0.7538 - val_loss: 502.0013 - val_accuracy: 0.7920\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 632.6255 - accuracy: 0.7524 - val_loss: 502.5964 - val_accuracy: 0.7932\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 634.1693 - accuracy: 0.7524 - val_loss: 500.7390 - val_accuracy: 0.7930\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 633.4440 - accuracy: 0.7519 - val_loss: 506.6480 - val_accuracy: 0.7933\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 637.7286 - accuracy: 0.7501 - val_loss: 505.3176 - val_accuracy: 0.7926\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 637.6398 - accuracy: 0.7510 - val_loss: 502.3576 - val_accuracy: 0.7920\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 636.9574 - accuracy: 0.7541 - val_loss: 504.0387 - val_accuracy: 0.7946\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 632.2526 - accuracy: 0.7526 - val_loss: 503.7789 - val_accuracy: 0.7924\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.7207 - accuracy: 0.7532 - val_loss: 501.8777 - val_accuracy: 0.7922\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 631.6182 - accuracy: 0.7514 - val_loss: 500.0398 - val_accuracy: 0.7926\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 633.8760 - accuracy: 0.7521 - val_loss: 502.2146 - val_accuracy: 0.7916\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 632.8381 - accuracy: 0.7539 - val_loss: 502.0529 - val_accuracy: 0.7936\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 631.2061 - accuracy: 0.7523 - val_loss: 500.9992 - val_accuracy: 0.7953\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 631.4807 - accuracy: 0.7542 - val_loss: 500.6377 - val_accuracy: 0.7928\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 631.5247 - accuracy: 0.7534 - val_loss: 502.2949 - val_accuracy: 0.7941\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 633.7203 - accuracy: 0.7524 - val_loss: 505.5898 - val_accuracy: 0.7924\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 634.4837 - accuracy: 0.7524 - val_loss: 502.0247 - val_accuracy: 0.7941\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 634.5284 - accuracy: 0.7518 - val_loss: 506.2560 - val_accuracy: 0.7907\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 632.9505 - accuracy: 0.7519 - val_loss: 507.3843 - val_accuracy: 0.7931\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 632.6595 - accuracy: 0.7519 - val_loss: 502.2984 - val_accuracy: 0.7941\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 633.2601 - accuracy: 0.7554 - val_loss: 506.2554 - val_accuracy: 0.7910\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 634.5557 - accuracy: 0.7525 - val_loss: 501.0542 - val_accuracy: 0.7934\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 632.1147 - accuracy: 0.7547 - val_loss: 501.8827 - val_accuracy: 0.7941\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 633.6873 - accuracy: 0.7528 - val_loss: 504.3816 - val_accuracy: 0.7916\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 631.7029 - accuracy: 0.7532 - val_loss: 500.7246 - val_accuracy: 0.7937\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 633.0082 - accuracy: 0.7537 - val_loss: 500.4832 - val_accuracy: 0.7951\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 630.3232 - accuracy: 0.7553 - val_loss: 503.7201 - val_accuracy: 0.7937\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 630.0499 - accuracy: 0.7533 - val_loss: 500.6504 - val_accuracy: 0.7933\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 631.6379 - accuracy: 0.7550 - val_loss: 502.9297 - val_accuracy: 0.7928\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 631.8805 - accuracy: 0.7516 - val_loss: 504.4712 - val_accuracy: 0.7929\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 635.2140 - accuracy: 0.7528 - val_loss: 505.2587 - val_accuracy: 0.7915\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 639.2589 - accuracy: 0.7526 - val_loss: 508.5954 - val_accuracy: 0.7897\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 642.3002 - accuracy: 0.7504 - val_loss: 505.6486 - val_accuracy: 0.7914\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 633.3223 - accuracy: 0.7535 - val_loss: 504.1243 - val_accuracy: 0.7887\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 637.3047 - accuracy: 0.7522 - val_loss: 503.6495 - val_accuracy: 0.7911\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 632.9965 - accuracy: 0.7529 - val_loss: 502.3932 - val_accuracy: 0.7933\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 631.2456 - accuracy: 0.7546 - val_loss: 500.5752 - val_accuracy: 0.7915\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.1038 - accuracy: 0.7518 - val_loss: 501.6961 - val_accuracy: 0.7938\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 633.1213 - accuracy: 0.7550 - val_loss: 499.7768 - val_accuracy: 0.7934\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.0284 - accuracy: 0.7540 - val_loss: 501.0992 - val_accuracy: 0.7930\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.9087 - accuracy: 0.7559 - val_loss: 500.7548 - val_accuracy: 0.7949\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.8665 - accuracy: 0.7552 - val_loss: 503.7221 - val_accuracy: 0.7932\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 631.2717 - accuracy: 0.7541 - val_loss: 500.3993 - val_accuracy: 0.7928\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 629.7668 - accuracy: 0.7543 - val_loss: 501.4406 - val_accuracy: 0.7942\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 632.1071 - accuracy: 0.7551 - val_loss: 502.8231 - val_accuracy: 0.7940\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 633.4128 - accuracy: 0.7534 - val_loss: 505.6533 - val_accuracy: 0.7929\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 632.6825 - accuracy: 0.7573 - val_loss: 499.9604 - val_accuracy: 0.7920\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 631.1890 - accuracy: 0.7545 - val_loss: 503.0221 - val_accuracy: 0.7947\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 630.6179 - accuracy: 0.7554 - val_loss: 501.9834 - val_accuracy: 0.7927\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.7741 - accuracy: 0.7536 - val_loss: 501.2868 - val_accuracy: 0.7954\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.7269 - accuracy: 0.7541 - val_loss: 500.5905 - val_accuracy: 0.7954\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 629.2605 - accuracy: 0.7550 - val_loss: 500.7536 - val_accuracy: 0.7927\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.9861 - accuracy: 0.7552 - val_loss: 500.0670 - val_accuracy: 0.7952\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 634.2453 - accuracy: 0.7545 - val_loss: 519.3768 - val_accuracy: 0.7946\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 24ms/step - loss: 638.3840 - accuracy: 0.7517 - val_loss: 503.3728 - val_accuracy: 0.7931\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 632.1783 - accuracy: 0.7543 - val_loss: 501.3315 - val_accuracy: 0.7927\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 634.7270 - accuracy: 0.7559 - val_loss: 500.7622 - val_accuracy: 0.7944\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 633.8387 - accuracy: 0.7538 - val_loss: 502.0339 - val_accuracy: 0.7963\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.5587 - accuracy: 0.7538 - val_loss: 501.4753 - val_accuracy: 0.7956\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.0436 - accuracy: 0.7553 - val_loss: 503.6305 - val_accuracy: 0.7922\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 633.5047 - accuracy: 0.7549 - val_loss: 507.7751 - val_accuracy: 0.7932\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 634.9705 - accuracy: 0.7509 - val_loss: 500.8923 - val_accuracy: 0.7921\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 632.9423 - accuracy: 0.7540 - val_loss: 501.0547 - val_accuracy: 0.7944\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 635.1279 - accuracy: 0.7536 - val_loss: 502.6320 - val_accuracy: 0.7950\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 632.4420 - accuracy: 0.7535 - val_loss: 504.3089 - val_accuracy: 0.7932\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.0872 - accuracy: 0.7538 - val_loss: 498.4637 - val_accuracy: 0.7953\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 629.4590 - accuracy: 0.7565 - val_loss: 497.8625 - val_accuracy: 0.7951\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 629.8168 - accuracy: 0.7560 - val_loss: 503.9815 - val_accuracy: 0.7947\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.5824 - accuracy: 0.7551 - val_loss: 505.6558 - val_accuracy: 0.7946\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 633.0837 - accuracy: 0.7559 - val_loss: 498.5540 - val_accuracy: 0.7946\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.1734 - accuracy: 0.7566 - val_loss: 501.6924 - val_accuracy: 0.7959\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 629.1237 - accuracy: 0.7564 - val_loss: 500.1172 - val_accuracy: 0.7934\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 629.9095 - accuracy: 0.7560 - val_loss: 502.3138 - val_accuracy: 0.7936\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 630.2745 - accuracy: 0.7556 - val_loss: 499.1260 - val_accuracy: 0.7946\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.0929 - accuracy: 0.7565 - val_loss: 500.1477 - val_accuracy: 0.7947\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.2236 - accuracy: 0.7563 - val_loss: 502.6876 - val_accuracy: 0.7949\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.5029 - accuracy: 0.7560 - val_loss: 501.2953 - val_accuracy: 0.7948\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 630.2737 - accuracy: 0.7551 - val_loss: 499.3442 - val_accuracy: 0.7942\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.5710 - accuracy: 0.7568 - val_loss: 499.3732 - val_accuracy: 0.7951\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 628.9564 - accuracy: 0.7568 - val_loss: 500.0163 - val_accuracy: 0.7953\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 628.7214 - accuracy: 0.7572 - val_loss: 500.9831 - val_accuracy: 0.7958\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.1295 - accuracy: 0.7565 - val_loss: 501.4923 - val_accuracy: 0.7934\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 628.4589 - accuracy: 0.7567 - val_loss: 499.6494 - val_accuracy: 0.7928\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 627.9624 - accuracy: 0.7558 - val_loss: 497.7654 - val_accuracy: 0.7947\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 627.3198 - accuracy: 0.7568 - val_loss: 504.8789 - val_accuracy: 0.7938\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 632.6338 - accuracy: 0.7541 - val_loss: 508.5687 - val_accuracy: 0.7935\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 632.4066 - accuracy: 0.7537 - val_loss: 501.5142 - val_accuracy: 0.7914\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 628.3333 - accuracy: 0.7539 - val_loss: 502.0330 - val_accuracy: 0.7941\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 629.5239 - accuracy: 0.7548 - val_loss: 501.0664 - val_accuracy: 0.7932\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.1475 - accuracy: 0.7548 - val_loss: 504.2991 - val_accuracy: 0.7935\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 628.6456 - accuracy: 0.7536 - val_loss: 498.8829 - val_accuracy: 0.7957\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 33ms/step - loss: 627.3759 - accuracy: 0.7554 - val_loss: 499.5879 - val_accuracy: 0.7948\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 627.5342 - accuracy: 0.7575 - val_loss: 500.7542 - val_accuracy: 0.7955\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 627.8820 - accuracy: 0.7557 - val_loss: 500.3105 - val_accuracy: 0.7939\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 632.1077 - accuracy: 0.7545 - val_loss: 502.9461 - val_accuracy: 0.7979\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 629.6022 - accuracy: 0.7570 - val_loss: 500.5629 - val_accuracy: 0.7953\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 36ms/step - loss: 629.2478 - accuracy: 0.7544 - val_loss: 500.5991 - val_accuracy: 0.7954\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 40ms/step - loss: 629.1578 - accuracy: 0.7556 - val_loss: 507.9757 - val_accuracy: 0.7925\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 42ms/step - loss: 631.5053 - accuracy: 0.7551 - val_loss: 500.3280 - val_accuracy: 0.7927\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 627.2517 - accuracy: 0.7556 - val_loss: 499.6962 - val_accuracy: 0.7956\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 631.2059 - accuracy: 0.7552 - val_loss: 501.2202 - val_accuracy: 0.7954\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 631.6735 - accuracy: 0.7543 - val_loss: 500.4478 - val_accuracy: 0.7958\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 1s 48ms/step - loss: 632.8268 - accuracy: 0.7575 - val_loss: 504.9557 - val_accuracy: 0.7957\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 39ms/step - loss: 630.8738 - accuracy: 0.7551 - val_loss: 502.5399 - val_accuracy: 0.7930\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 38ms/step - loss: 631.5367 - accuracy: 0.7554 - val_loss: 498.9301 - val_accuracy: 0.7940\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 34ms/step - loss: 633.9944 - accuracy: 0.7545 - val_loss: 519.0151 - val_accuracy: 0.7942\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 35ms/step - loss: 635.8943 - accuracy: 0.7578 - val_loss: 505.9270 - val_accuracy: 0.7958\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 37ms/step - loss: 632.7650 - accuracy: 0.7566 - val_loss: 498.9703 - val_accuracy: 0.7933\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 630.4442 - accuracy: 0.7549 - val_loss: 501.2496 - val_accuracy: 0.7943\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.7364 - accuracy: 0.7538 - val_loss: 500.5437 - val_accuracy: 0.7937\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 628.4062 - accuracy: 0.7581 - val_loss: 498.3775 - val_accuracy: 0.7935\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 627.2775 - accuracy: 0.7566 - val_loss: 498.7146 - val_accuracy: 0.7922\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 626.1444 - accuracy: 0.7571 - val_loss: 499.6521 - val_accuracy: 0.7952\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.2941 - accuracy: 0.7544 - val_loss: 503.9702 - val_accuracy: 0.7945\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 632.1846 - accuracy: 0.7575 - val_loss: 506.4671 - val_accuracy: 0.7935\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.7592 - accuracy: 0.7565 - val_loss: 499.2508 - val_accuracy: 0.7968\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 627.7072 - accuracy: 0.7577 - val_loss: 499.6125 - val_accuracy: 0.7973\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 627.0085 - accuracy: 0.7584 - val_loss: 498.0548 - val_accuracy: 0.7959\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 629.5182 - accuracy: 0.7562 - val_loss: 498.4027 - val_accuracy: 0.7933\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 627.3824 - accuracy: 0.7599 - val_loss: 498.0183 - val_accuracy: 0.7942\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.1047 - accuracy: 0.7555 - val_loss: 499.7339 - val_accuracy: 0.7939\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 626.8531 - accuracy: 0.7576 - val_loss: 498.2756 - val_accuracy: 0.7945\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.4340 - accuracy: 0.7577 - val_loss: 502.2325 - val_accuracy: 0.7937\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 632.6488 - accuracy: 0.7566 - val_loss: 512.5755 - val_accuracy: 0.7969\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 632.8926 - accuracy: 0.7565 - val_loss: 508.3268 - val_accuracy: 0.7961\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 642.9659 - accuracy: 0.7573 - val_loss: 506.2041 - val_accuracy: 0.7959\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 642.5480 - accuracy: 0.7580 - val_loss: 500.6389 - val_accuracy: 0.7927\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 637.4382 - accuracy: 0.7569 - val_loss: 499.8671 - val_accuracy: 0.7940\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 630.9556 - accuracy: 0.7545 - val_loss: 498.9331 - val_accuracy: 0.7936\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 627.3354 - accuracy: 0.7582 - val_loss: 497.3538 - val_accuracy: 0.7932\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.5202 - accuracy: 0.7574 - val_loss: 500.6046 - val_accuracy: 0.7958\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.2402 - accuracy: 0.7604 - val_loss: 499.6895 - val_accuracy: 0.7962\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.0555 - accuracy: 0.7582 - val_loss: 500.5981 - val_accuracy: 0.7920\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 627.8119 - accuracy: 0.7575 - val_loss: 500.3820 - val_accuracy: 0.7948\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 628.3817 - accuracy: 0.7593 - val_loss: 498.9071 - val_accuracy: 0.7949\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 629.5893 - accuracy: 0.7570 - val_loss: 503.3653 - val_accuracy: 0.7955\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.0855 - accuracy: 0.7550 - val_loss: 500.2493 - val_accuracy: 0.7952\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 632.2672 - accuracy: 0.7582 - val_loss: 502.0543 - val_accuracy: 0.7935\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.0204 - accuracy: 0.7575 - val_loss: 500.7863 - val_accuracy: 0.7926\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.3170 - accuracy: 0.7568 - val_loss: 500.8340 - val_accuracy: 0.7938\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.9072 - accuracy: 0.7575 - val_loss: 498.3333 - val_accuracy: 0.7954\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.0849 - accuracy: 0.7577 - val_loss: 498.8900 - val_accuracy: 0.7951\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.3799 - accuracy: 0.7569 - val_loss: 500.4801 - val_accuracy: 0.7937\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 626.8318 - accuracy: 0.7600 - val_loss: 499.7655 - val_accuracy: 0.7949\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 626.1331 - accuracy: 0.7594 - val_loss: 501.9794 - val_accuracy: 0.7942\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 627.3337 - accuracy: 0.7574 - val_loss: 499.4527 - val_accuracy: 0.7937\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.3880 - accuracy: 0.7591 - val_loss: 496.7628 - val_accuracy: 0.7937\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 626.1841 - accuracy: 0.7595 - val_loss: 499.0368 - val_accuracy: 0.7953\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.7910 - accuracy: 0.7594 - val_loss: 498.6667 - val_accuracy: 0.7934\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 625.6069 - accuracy: 0.7592 - val_loss: 500.6179 - val_accuracy: 0.7941\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 627.1203 - accuracy: 0.7603 - val_loss: 498.3149 - val_accuracy: 0.7959\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 628.2477 - accuracy: 0.7596 - val_loss: 499.3461 - val_accuracy: 0.7950\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 629.3762 - accuracy: 0.7581 - val_loss: 498.8609 - val_accuracy: 0.7972\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.3577 - accuracy: 0.7584 - val_loss: 502.8358 - val_accuracy: 0.7948\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.9557 - accuracy: 0.7560 - val_loss: 500.2059 - val_accuracy: 0.7953\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.0939 - accuracy: 0.7569 - val_loss: 498.6786 - val_accuracy: 0.7928\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 630.3647 - accuracy: 0.7591 - val_loss: 508.7837 - val_accuracy: 0.7933\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 629.8345 - accuracy: 0.7572 - val_loss: 501.5356 - val_accuracy: 0.7931\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 627.8392 - accuracy: 0.7573 - val_loss: 499.8471 - val_accuracy: 0.7928\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 627.2278 - accuracy: 0.7592 - val_loss: 503.5716 - val_accuracy: 0.7928\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 628.9089 - accuracy: 0.7592 - val_loss: 501.5616 - val_accuracy: 0.7929\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.4639 - accuracy: 0.7582 - val_loss: 498.7076 - val_accuracy: 0.7968\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 626.5411 - accuracy: 0.7614 - val_loss: 499.0935 - val_accuracy: 0.7957\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 626.7363 - accuracy: 0.7584 - val_loss: 498.2949 - val_accuracy: 0.7972\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 628.6218 - accuracy: 0.7594 - val_loss: 498.0499 - val_accuracy: 0.7958\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 626.4690 - accuracy: 0.7611 - val_loss: 499.5338 - val_accuracy: 0.7962\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 632.7912 - accuracy: 0.7598 - val_loss: 501.8304 - val_accuracy: 0.7989\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 634.2785 - accuracy: 0.7599 - val_loss: 497.9962 - val_accuracy: 0.7968\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 630.9655 - accuracy: 0.7579 - val_loss: 498.8918 - val_accuracy: 0.7955\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 1s 47ms/step - loss: 633.2184 - accuracy: 0.7607 - val_loss: 498.0889 - val_accuracy: 0.7959\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.6235 - accuracy: 0.7597 - val_loss: 501.6839 - val_accuracy: 0.7961\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 626.6000 - accuracy: 0.7600 - val_loss: 496.6884 - val_accuracy: 0.7979\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 625.4155 - accuracy: 0.7606 - val_loss: 497.5165 - val_accuracy: 0.7966\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.7132 - accuracy: 0.7593 - val_loss: 497.2565 - val_accuracy: 0.7960\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.3563 - accuracy: 0.7564 - val_loss: 497.5483 - val_accuracy: 0.7960\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.2079 - accuracy: 0.7603 - val_loss: 511.3762 - val_accuracy: 0.7981\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.4727 - accuracy: 0.7594 - val_loss: 501.0312 - val_accuracy: 0.7976\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 627.8414 - accuracy: 0.7594 - val_loss: 513.3379 - val_accuracy: 0.7972\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 640.5919 - accuracy: 0.7571 - val_loss: 514.2997 - val_accuracy: 0.7970\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 630.8021 - accuracy: 0.7591 - val_loss: 500.4641 - val_accuracy: 0.7943\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.3231 - accuracy: 0.7555 - val_loss: 505.1102 - val_accuracy: 0.7945\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 632.5427 - accuracy: 0.7617 - val_loss: 504.0159 - val_accuracy: 0.7967\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.2768 - accuracy: 0.7602 - val_loss: 500.8094 - val_accuracy: 0.7982\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.3201 - accuracy: 0.7604 - val_loss: 497.3279 - val_accuracy: 0.7956\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.1293 - accuracy: 0.7599 - val_loss: 500.2074 - val_accuracy: 0.7954\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.5535 - accuracy: 0.7581 - val_loss: 497.7971 - val_accuracy: 0.7949\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 625.8259 - accuracy: 0.7599 - val_loss: 496.7522 - val_accuracy: 0.7938\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.4218 - accuracy: 0.7603 - val_loss: 498.0550 - val_accuracy: 0.7948\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 629.8105 - accuracy: 0.7613 - val_loss: 498.2738 - val_accuracy: 0.7966\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.5665 - accuracy: 0.7597 - val_loss: 495.9333 - val_accuracy: 0.7953\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 624.6472 - accuracy: 0.7604 - val_loss: 497.5915 - val_accuracy: 0.7949\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.9970 - accuracy: 0.7602 - val_loss: 498.7628 - val_accuracy: 0.7971\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 624.9028 - accuracy: 0.7615 - val_loss: 496.1286 - val_accuracy: 0.7931\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.7054 - accuracy: 0.7614 - val_loss: 496.7252 - val_accuracy: 0.7946\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 624.2056 - accuracy: 0.7628 - val_loss: 497.4422 - val_accuracy: 0.7956\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 625.0934 - accuracy: 0.7605 - val_loss: 500.4780 - val_accuracy: 0.7959\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 627.6901 - accuracy: 0.7610 - val_loss: 495.8775 - val_accuracy: 0.7970\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 628.2146 - accuracy: 0.7600 - val_loss: 495.4665 - val_accuracy: 0.7954\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 624.3076 - accuracy: 0.7586 - val_loss: 497.8307 - val_accuracy: 0.7977\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 625.5347 - accuracy: 0.7617 - val_loss: 498.2675 - val_accuracy: 0.7974\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 627.6522 - accuracy: 0.7615 - val_loss: 499.4782 - val_accuracy: 0.7945\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 627.9622 - accuracy: 0.7609 - val_loss: 497.6768 - val_accuracy: 0.7966\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 624.3661 - accuracy: 0.7586 - val_loss: 496.3236 - val_accuracy: 0.7949\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 624.7971 - accuracy: 0.7612 - val_loss: 496.4749 - val_accuracy: 0.7968\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 624.1965 - accuracy: 0.7628 - val_loss: 497.3233 - val_accuracy: 0.7933\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.4515 - accuracy: 0.7608 - val_loss: 496.5525 - val_accuracy: 0.7958\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 624.9570 - accuracy: 0.7615 - val_loss: 501.7296 - val_accuracy: 0.7914\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.1432 - accuracy: 0.7618 - val_loss: 498.4255 - val_accuracy: 0.7949\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 626.1495 - accuracy: 0.7600 - val_loss: 499.0933 - val_accuracy: 0.7963\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 625.2141 - accuracy: 0.7579 - val_loss: 497.5498 - val_accuracy: 0.7974\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.4169 - accuracy: 0.7616 - val_loss: 505.1263 - val_accuracy: 0.7969\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.8066 - accuracy: 0.7599 - val_loss: 503.3694 - val_accuracy: 0.7970\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.9763 - accuracy: 0.7608 - val_loss: 496.0169 - val_accuracy: 0.7969\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.8464 - accuracy: 0.7608 - val_loss: 499.8515 - val_accuracy: 0.7961\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 624.4020 - accuracy: 0.7624 - val_loss: 495.3888 - val_accuracy: 0.7988\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 626.2599 - accuracy: 0.7619 - val_loss: 505.5057 - val_accuracy: 0.7974\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 626.7488 - accuracy: 0.7625 - val_loss: 500.0480 - val_accuracy: 0.7960\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.7896 - accuracy: 0.7603 - val_loss: 515.4763 - val_accuracy: 0.7984\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.2519 - accuracy: 0.7595 - val_loss: 498.2503 - val_accuracy: 0.7977\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 639.6907 - accuracy: 0.7599 - val_loss: 502.9406 - val_accuracy: 0.7959\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 630.0679 - accuracy: 0.7591 - val_loss: 498.6306 - val_accuracy: 0.7992\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 626.8685 - accuracy: 0.7622 - val_loss: 495.4915 - val_accuracy: 0.7969\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 625.2179 - accuracy: 0.7622 - val_loss: 494.3823 - val_accuracy: 0.7970\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 625.0553 - accuracy: 0.7612 - val_loss: 494.8055 - val_accuracy: 0.7994\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.5177 - accuracy: 0.7608 - val_loss: 496.5171 - val_accuracy: 0.7988\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 624.7842 - accuracy: 0.7625 - val_loss: 498.9260 - val_accuracy: 0.7975\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.0801 - accuracy: 0.7616 - val_loss: 494.9171 - val_accuracy: 0.7981\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 623.2194 - accuracy: 0.7612 - val_loss: 496.7821 - val_accuracy: 0.7971\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 625.5659 - accuracy: 0.7624 - val_loss: 499.3089 - val_accuracy: 0.7966\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 624.6367 - accuracy: 0.7617 - val_loss: 496.5903 - val_accuracy: 0.7971\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.0141 - accuracy: 0.7610 - val_loss: 495.7017 - val_accuracy: 0.7980\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 622.5955 - accuracy: 0.7627 - val_loss: 496.3762 - val_accuracy: 0.7971\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.7251 - accuracy: 0.7609 - val_loss: 496.0390 - val_accuracy: 0.7985\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.1591 - accuracy: 0.7612 - val_loss: 494.8354 - val_accuracy: 0.7979\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.4613 - accuracy: 0.7620 - val_loss: 495.5008 - val_accuracy: 0.7980\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 622.9686 - accuracy: 0.7613 - val_loss: 498.3876 - val_accuracy: 0.7988\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 624.1180 - accuracy: 0.7602 - val_loss: 496.3870 - val_accuracy: 0.7990\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.8134 - accuracy: 0.7622 - val_loss: 495.7523 - val_accuracy: 0.7989\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 622.4409 - accuracy: 0.7630 - val_loss: 495.2100 - val_accuracy: 0.7969\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 622.2224 - accuracy: 0.7630 - val_loss: 498.1768 - val_accuracy: 0.7967\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 623.6848 - accuracy: 0.7627 - val_loss: 496.1048 - val_accuracy: 0.7971\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.1940 - accuracy: 0.7635 - val_loss: 496.2870 - val_accuracy: 0.7976\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.3319 - accuracy: 0.7615 - val_loss: 495.8204 - val_accuracy: 0.7985\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 622.2974 - accuracy: 0.7642 - val_loss: 498.2479 - val_accuracy: 0.8006\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 622.7735 - accuracy: 0.7633 - val_loss: 494.0618 - val_accuracy: 0.7992\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 623.5836 - accuracy: 0.7629 - val_loss: 497.7037 - val_accuracy: 0.7982\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 625.1468 - accuracy: 0.7616 - val_loss: 497.3756 - val_accuracy: 0.7982\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 622.9343 - accuracy: 0.7623 - val_loss: 495.3736 - val_accuracy: 0.7969\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.4622 - accuracy: 0.7633 - val_loss: 495.9082 - val_accuracy: 0.7974\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 623.0839 - accuracy: 0.7621 - val_loss: 495.6186 - val_accuracy: 0.7993\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.4255 - accuracy: 0.7627 - val_loss: 495.3022 - val_accuracy: 0.7978\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 623.4773 - accuracy: 0.7627 - val_loss: 497.1673 - val_accuracy: 0.7979\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.8275 - accuracy: 0.7630 - val_loss: 494.6247 - val_accuracy: 0.7983\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 624.6392 - accuracy: 0.7629 - val_loss: 497.5530 - val_accuracy: 0.7963\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.0254 - accuracy: 0.7623 - val_loss: 492.7087 - val_accuracy: 0.7969\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 626.2295 - accuracy: 0.7617 - val_loss: 499.0937 - val_accuracy: 0.7993\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 627.2912 - accuracy: 0.7621 - val_loss: 497.0862 - val_accuracy: 0.7959\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.5707 - accuracy: 0.7620 - val_loss: 498.3538 - val_accuracy: 0.7981\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.3821 - accuracy: 0.7633 - val_loss: 495.9321 - val_accuracy: 0.7976\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.2378 - accuracy: 0.7628 - val_loss: 497.7764 - val_accuracy: 0.7973\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.5302 - accuracy: 0.7613 - val_loss: 496.8713 - val_accuracy: 0.7991\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.0482 - accuracy: 0.7638 - val_loss: 495.6860 - val_accuracy: 0.7964\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.2183 - accuracy: 0.7635 - val_loss: 494.8347 - val_accuracy: 0.7974\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.6660 - accuracy: 0.7632 - val_loss: 502.7625 - val_accuracy: 0.7978\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 624.7135 - accuracy: 0.7603 - val_loss: 496.4348 - val_accuracy: 0.7986\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.1000 - accuracy: 0.7629 - val_loss: 495.3267 - val_accuracy: 0.7980\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 623.6028 - accuracy: 0.7634 - val_loss: 496.1175 - val_accuracy: 0.7978\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.5065 - accuracy: 0.7640 - val_loss: 496.1458 - val_accuracy: 0.7994\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.3459 - accuracy: 0.7634 - val_loss: 501.2795 - val_accuracy: 0.7934\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 625.6661 - accuracy: 0.7626 - val_loss: 494.5886 - val_accuracy: 0.7993\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.9610 - accuracy: 0.7624 - val_loss: 495.7806 - val_accuracy: 0.7974\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.0527 - accuracy: 0.7626 - val_loss: 495.0127 - val_accuracy: 0.7990\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.8102 - accuracy: 0.7636 - val_loss: 495.2430 - val_accuracy: 0.7991\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 622.0554 - accuracy: 0.7631 - val_loss: 496.2801 - val_accuracy: 0.7976\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.3637 - accuracy: 0.7637 - val_loss: 496.3616 - val_accuracy: 0.7983\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 622.2422 - accuracy: 0.7635 - val_loss: 491.9047 - val_accuracy: 0.7992\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.6641 - accuracy: 0.7626 - val_loss: 496.3806 - val_accuracy: 0.7979\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 621.7288 - accuracy: 0.7631 - val_loss: 493.9837 - val_accuracy: 0.7981\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.8427 - accuracy: 0.7616 - val_loss: 494.9941 - val_accuracy: 0.7993\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 622.4702 - accuracy: 0.7639 - val_loss: 495.6557 - val_accuracy: 0.7995\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.7656 - accuracy: 0.7630 - val_loss: 493.4052 - val_accuracy: 0.7976\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.9214 - accuracy: 0.7619 - val_loss: 494.6375 - val_accuracy: 0.7983\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.6127 - accuracy: 0.7632 - val_loss: 494.0645 - val_accuracy: 0.7984\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 627.8909 - accuracy: 0.7625 - val_loss: 505.5227 - val_accuracy: 0.7982\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 630.3088 - accuracy: 0.7628 - val_loss: 500.2182 - val_accuracy: 0.7980\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 627.9111 - accuracy: 0.7611 - val_loss: 495.9330 - val_accuracy: 0.7950\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 623.0775 - accuracy: 0.7645 - val_loss: 497.9258 - val_accuracy: 0.7985\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 634.6833 - accuracy: 0.7604 - val_loss: 514.7760 - val_accuracy: 0.7968\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 633.8716 - accuracy: 0.7605 - val_loss: 497.4710 - val_accuracy: 0.7995\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 632.6227 - accuracy: 0.7614 - val_loss: 496.1429 - val_accuracy: 0.8012\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 629.0986 - accuracy: 0.7622 - val_loss: 505.0544 - val_accuracy: 0.7987\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 628.1923 - accuracy: 0.7634 - val_loss: 498.4597 - val_accuracy: 0.7994\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 625.9932 - accuracy: 0.7626 - val_loss: 493.7824 - val_accuracy: 0.7987\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.1819 - accuracy: 0.7655 - val_loss: 494.8301 - val_accuracy: 0.7995\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.3779 - accuracy: 0.7634 - val_loss: 499.1665 - val_accuracy: 0.7985\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 626.6195 - accuracy: 0.7621 - val_loss: 497.4871 - val_accuracy: 0.7997\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 25ms/step - loss: 624.4714 - accuracy: 0.7633 - val_loss: 497.0741 - val_accuracy: 0.7976\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 625.3679 - accuracy: 0.7640 - val_loss: 499.3290 - val_accuracy: 0.7976\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.3339 - accuracy: 0.7627 - val_loss: 501.1594 - val_accuracy: 0.7966\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.3820 - accuracy: 0.7628 - val_loss: 492.9047 - val_accuracy: 0.7967\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.8187 - accuracy: 0.7634 - val_loss: 494.8349 - val_accuracy: 0.7988\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.9208 - accuracy: 0.7631 - val_loss: 495.7853 - val_accuracy: 0.7993\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 622.5188 - accuracy: 0.7633 - val_loss: 494.8488 - val_accuracy: 0.7981\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.0959 - accuracy: 0.7624 - val_loss: 493.3896 - val_accuracy: 0.7984\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 621.3278 - accuracy: 0.7634 - val_loss: 493.5655 - val_accuracy: 0.7975\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.6312 - accuracy: 0.7638 - val_loss: 494.2090 - val_accuracy: 0.7976\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.0659 - accuracy: 0.7631 - val_loss: 493.1613 - val_accuracy: 0.8008\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.9862 - accuracy: 0.7646 - val_loss: 496.9612 - val_accuracy: 0.7982\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.0931 - accuracy: 0.7636 - val_loss: 496.3837 - val_accuracy: 0.7975\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.2432 - accuracy: 0.7640 - val_loss: 497.2581 - val_accuracy: 0.7973\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 622.7722 - accuracy: 0.7618 - val_loss: 498.0357 - val_accuracy: 0.8022\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 625.6752 - accuracy: 0.7638 - val_loss: 497.6495 - val_accuracy: 0.7990\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.6371 - accuracy: 0.7643 - val_loss: 494.5176 - val_accuracy: 0.7996\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 621.3078 - accuracy: 0.7641 - val_loss: 493.6814 - val_accuracy: 0.7973\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 626.8737 - accuracy: 0.7598 - val_loss: 495.9548 - val_accuracy: 0.7976\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 624.4113 - accuracy: 0.7630 - val_loss: 495.0486 - val_accuracy: 0.7981\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.4132 - accuracy: 0.7639 - val_loss: 499.1496 - val_accuracy: 0.7962\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 623.4487 - accuracy: 0.7631 - val_loss: 494.0629 - val_accuracy: 0.7984\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 623.8994 - accuracy: 0.7638 - val_loss: 494.7619 - val_accuracy: 0.7982\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.6454 - accuracy: 0.7629 - val_loss: 499.1631 - val_accuracy: 0.7979\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.7471 - accuracy: 0.7640 - val_loss: 497.2066 - val_accuracy: 0.7988\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.3066 - accuracy: 0.7639 - val_loss: 496.0544 - val_accuracy: 0.7973\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.5815 - accuracy: 0.7630 - val_loss: 494.0643 - val_accuracy: 0.7996\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 622.7263 - accuracy: 0.7634 - val_loss: 495.2707 - val_accuracy: 0.7995\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 622.4952 - accuracy: 0.7640 - val_loss: 493.6949 - val_accuracy: 0.7991\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 622.5150 - accuracy: 0.7620 - val_loss: 494.1484 - val_accuracy: 0.7995\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.1084 - accuracy: 0.7647 - val_loss: 493.2327 - val_accuracy: 0.7983\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 620.5085 - accuracy: 0.7628 - val_loss: 493.3819 - val_accuracy: 0.7997\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 621.3936 - accuracy: 0.7645 - val_loss: 494.5193 - val_accuracy: 0.7989\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 621.6335 - accuracy: 0.7645 - val_loss: 499.1978 - val_accuracy: 0.7984\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.2774 - accuracy: 0.7643 - val_loss: 494.2465 - val_accuracy: 0.7989\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 622.8724 - accuracy: 0.7637 - val_loss: 495.5424 - val_accuracy: 0.7975\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 621.1204 - accuracy: 0.7659 - val_loss: 496.1582 - val_accuracy: 0.7980\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 621.4946 - accuracy: 0.7628 - val_loss: 494.2734 - val_accuracy: 0.8012\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.9048 - accuracy: 0.7658 - val_loss: 496.9065 - val_accuracy: 0.7966\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.6395 - accuracy: 0.7636 - val_loss: 492.9731 - val_accuracy: 0.7993\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 621.4186 - accuracy: 0.7648 - val_loss: 492.4652 - val_accuracy: 0.7984\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.2396 - accuracy: 0.7651 - val_loss: 494.4705 - val_accuracy: 0.7989\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 620.7610 - accuracy: 0.7640 - val_loss: 495.4124 - val_accuracy: 0.7979\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.3808 - accuracy: 0.7638 - val_loss: 495.1097 - val_accuracy: 0.7990\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 631.5522 - accuracy: 0.7644 - val_loss: 498.5838 - val_accuracy: 0.7996\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.6454 - accuracy: 0.7616 - val_loss: 495.9191 - val_accuracy: 0.7983\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.4261 - accuracy: 0.7652 - val_loss: 496.5316 - val_accuracy: 0.7984\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.2724 - accuracy: 0.7648 - val_loss: 493.7558 - val_accuracy: 0.7986\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 621.8350 - accuracy: 0.7630 - val_loss: 494.2943 - val_accuracy: 0.7985\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.0961 - accuracy: 0.7649 - val_loss: 495.2050 - val_accuracy: 0.7985\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 620.5404 - accuracy: 0.7642 - val_loss: 495.1353 - val_accuracy: 0.7995\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 623.5020 - accuracy: 0.7619 - val_loss: 505.7982 - val_accuracy: 0.8009\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 623.2879 - accuracy: 0.7634 - val_loss: 494.1907 - val_accuracy: 0.7985\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.6415 - accuracy: 0.7639 - val_loss: 500.9178 - val_accuracy: 0.7998\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 627.0651 - accuracy: 0.7633 - val_loss: 496.8672 - val_accuracy: 0.8009\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 623.5225 - accuracy: 0.7632 - val_loss: 491.7747 - val_accuracy: 0.7991\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.5516 - accuracy: 0.7623 - val_loss: 493.2036 - val_accuracy: 0.8004\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.5853 - accuracy: 0.7648 - val_loss: 494.4737 - val_accuracy: 0.7989\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.6191 - accuracy: 0.7643 - val_loss: 492.5285 - val_accuracy: 0.7994\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 619.7752 - accuracy: 0.7651 - val_loss: 492.8722 - val_accuracy: 0.7984\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 619.5970 - accuracy: 0.7656 - val_loss: 492.0500 - val_accuracy: 0.8006\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.6804 - accuracy: 0.7654 - val_loss: 496.2342 - val_accuracy: 0.7984\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.0582 - accuracy: 0.7646 - val_loss: 495.4713 - val_accuracy: 0.7990\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.5113 - accuracy: 0.7649 - val_loss: 507.8868 - val_accuracy: 0.8008\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.5906 - accuracy: 0.7659 - val_loss: 499.4915 - val_accuracy: 0.7999\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.3964 - accuracy: 0.7640 - val_loss: 495.5725 - val_accuracy: 0.7996\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.3285 - accuracy: 0.7641 - val_loss: 495.5879 - val_accuracy: 0.7973\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.7698 - accuracy: 0.7631 - val_loss: 496.6977 - val_accuracy: 0.7986\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 625.1775 - accuracy: 0.7649 - val_loss: 497.1593 - val_accuracy: 0.8006\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 622.3691 - accuracy: 0.7658 - val_loss: 498.3101 - val_accuracy: 0.7971\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 622.5463 - accuracy: 0.7642 - val_loss: 499.2544 - val_accuracy: 0.8006\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 623.0968 - accuracy: 0.7670 - val_loss: 494.1302 - val_accuracy: 0.8005\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 619.7701 - accuracy: 0.7655 - val_loss: 492.5417 - val_accuracy: 0.7992\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.9690 - accuracy: 0.7654 - val_loss: 492.2660 - val_accuracy: 0.8002\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.1701 - accuracy: 0.7665 - val_loss: 494.2643 - val_accuracy: 0.8016\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 620.5165 - accuracy: 0.7658 - val_loss: 493.7924 - val_accuracy: 0.7961\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 622.7808 - accuracy: 0.7651 - val_loss: 495.5882 - val_accuracy: 0.7999\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 622.9011 - accuracy: 0.7650 - val_loss: 497.5660 - val_accuracy: 0.7990\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 621.8026 - accuracy: 0.7654 - val_loss: 493.4621 - val_accuracy: 0.8002\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 620.1988 - accuracy: 0.7629 - val_loss: 494.9996 - val_accuracy: 0.8015\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 619.5020 - accuracy: 0.7665 - val_loss: 493.6386 - val_accuracy: 0.8011\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.9131 - accuracy: 0.7646 - val_loss: 493.3174 - val_accuracy: 0.7990\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.7640 - accuracy: 0.7647 - val_loss: 492.9090 - val_accuracy: 0.8002\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 619.5941 - accuracy: 0.7660 - val_loss: 494.7521 - val_accuracy: 0.7997\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.7857 - accuracy: 0.7648 - val_loss: 493.1196 - val_accuracy: 0.8008\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 619.4763 - accuracy: 0.7659 - val_loss: 492.6536 - val_accuracy: 0.7996\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 619.3647 - accuracy: 0.7653 - val_loss: 493.7169 - val_accuracy: 0.7991\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 621.8940 - accuracy: 0.7651 - val_loss: 494.3129 - val_accuracy: 0.7998\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.6544 - accuracy: 0.7667 - val_loss: 494.2415 - val_accuracy: 0.7979\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 622.0378 - accuracy: 0.7650 - val_loss: 495.1540 - val_accuracy: 0.7992\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.5166 - accuracy: 0.7673 - val_loss: 494.1759 - val_accuracy: 0.7999\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 619.7239 - accuracy: 0.7654 - val_loss: 494.7978 - val_accuracy: 0.8003\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 619.3010 - accuracy: 0.7669 - val_loss: 492.9428 - val_accuracy: 0.7989\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.4543 - accuracy: 0.7655 - val_loss: 495.3649 - val_accuracy: 0.7999\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.6896 - accuracy: 0.7648 - val_loss: 493.1035 - val_accuracy: 0.8016\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.6413 - accuracy: 0.7662 - val_loss: 492.5977 - val_accuracy: 0.8002\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 620.2762 - accuracy: 0.7671 - val_loss: 497.5714 - val_accuracy: 0.7997\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.2354 - accuracy: 0.7651 - val_loss: 494.1477 - val_accuracy: 0.7976\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 623.4818 - accuracy: 0.7647 - val_loss: 503.4428 - val_accuracy: 0.7974\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.5023 - accuracy: 0.7651 - val_loss: 501.8243 - val_accuracy: 0.8016\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.4861 - accuracy: 0.7638 - val_loss: 493.5750 - val_accuracy: 0.7978\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 625.4340 - accuracy: 0.7666 - val_loss: 495.2717 - val_accuracy: 0.7991\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 624.0331 - accuracy: 0.7631 - val_loss: 494.5780 - val_accuracy: 0.7984\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 625.9589 - accuracy: 0.7642 - val_loss: 494.4327 - val_accuracy: 0.8005\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.6113 - accuracy: 0.7658 - val_loss: 507.5461 - val_accuracy: 0.7989\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.8643 - accuracy: 0.7642 - val_loss: 492.9826 - val_accuracy: 0.7995\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.1854 - accuracy: 0.7656 - val_loss: 493.9321 - val_accuracy: 0.8000\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.3347 - accuracy: 0.7667 - val_loss: 493.6595 - val_accuracy: 0.7996\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.7070 - accuracy: 0.7641 - val_loss: 491.4675 - val_accuracy: 0.8007\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 618.8355 - accuracy: 0.7678 - val_loss: 491.4183 - val_accuracy: 0.8004\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.3232 - accuracy: 0.7666 - val_loss: 492.1840 - val_accuracy: 0.8005\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 619.4050 - accuracy: 0.7659 - val_loss: 494.5638 - val_accuracy: 0.8019\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.9089 - accuracy: 0.7617 - val_loss: 494.0106 - val_accuracy: 0.8017\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 628.4980 - accuracy: 0.7625 - val_loss: 497.5433 - val_accuracy: 0.8011\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 627.8369 - accuracy: 0.7626 - val_loss: 498.2763 - val_accuracy: 0.8006\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 625.9374 - accuracy: 0.7638 - val_loss: 493.0773 - val_accuracy: 0.8000\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.4938 - accuracy: 0.7653 - val_loss: 490.0325 - val_accuracy: 0.8023\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 619.4509 - accuracy: 0.7671 - val_loss: 492.8786 - val_accuracy: 0.8015\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.3240 - accuracy: 0.7662 - val_loss: 493.1141 - val_accuracy: 0.8010\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.5019 - accuracy: 0.7668 - val_loss: 493.0035 - val_accuracy: 0.8005\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 619.5363 - accuracy: 0.7661 - val_loss: 492.0270 - val_accuracy: 0.8003\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 620.2142 - accuracy: 0.7670 - val_loss: 495.1265 - val_accuracy: 0.8009\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.7696 - accuracy: 0.7658 - val_loss: 496.3803 - val_accuracy: 0.8021\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 619.7080 - accuracy: 0.7660 - val_loss: 492.4338 - val_accuracy: 0.8004\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 619.8739 - accuracy: 0.7661 - val_loss: 493.9032 - val_accuracy: 0.7992\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.1442 - accuracy: 0.7664 - val_loss: 494.1010 - val_accuracy: 0.8017\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.1424 - accuracy: 0.7654 - val_loss: 490.9502 - val_accuracy: 0.8000\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 618.6225 - accuracy: 0.7664 - val_loss: 494.4041 - val_accuracy: 0.7996\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 618.8635 - accuracy: 0.7672 - val_loss: 494.4324 - val_accuracy: 0.8007\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 619.5740 - accuracy: 0.7671 - val_loss: 492.7543 - val_accuracy: 0.8007\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 619.6416 - accuracy: 0.7661 - val_loss: 492.0799 - val_accuracy: 0.7997\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 619.9097 - accuracy: 0.7681 - val_loss: 493.6724 - val_accuracy: 0.8010\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 621.5948 - accuracy: 0.7654 - val_loss: 496.6130 - val_accuracy: 0.8011\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.4026 - accuracy: 0.7666 - val_loss: 494.3532 - val_accuracy: 0.7992\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 624.3618 - accuracy: 0.7652 - val_loss: 495.7957 - val_accuracy: 0.7979\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 621.5211 - accuracy: 0.7665 - val_loss: 492.3270 - val_accuracy: 0.8001\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 619.5256 - accuracy: 0.7677 - val_loss: 491.2220 - val_accuracy: 0.8006\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.5627 - accuracy: 0.7657 - val_loss: 491.9612 - val_accuracy: 0.8004\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.8850 - accuracy: 0.7673 - val_loss: 491.9251 - val_accuracy: 0.8014\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 618.7984 - accuracy: 0.7674 - val_loss: 492.2918 - val_accuracy: 0.8022\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 618.6440 - accuracy: 0.7674 - val_loss: 495.0977 - val_accuracy: 0.8018\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.4738 - accuracy: 0.7674 - val_loss: 491.5612 - val_accuracy: 0.8004\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 617.8962 - accuracy: 0.7671 - val_loss: 492.0993 - val_accuracy: 0.8010\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 618.8617 - accuracy: 0.7672 - val_loss: 493.0380 - val_accuracy: 0.8021\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.2517 - accuracy: 0.7665 - val_loss: 492.0699 - val_accuracy: 0.7991\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.8193 - accuracy: 0.7662 - val_loss: 492.3454 - val_accuracy: 0.8006\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.0044 - accuracy: 0.7673 - val_loss: 494.1444 - val_accuracy: 0.8007\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 618.8689 - accuracy: 0.7661 - val_loss: 493.2301 - val_accuracy: 0.8002\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 618.4305 - accuracy: 0.7674 - val_loss: 491.3777 - val_accuracy: 0.8023\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 617.8700 - accuracy: 0.7659 - val_loss: 489.5974 - val_accuracy: 0.8006\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.2975 - accuracy: 0.7680 - val_loss: 494.1831 - val_accuracy: 0.8029\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 619.0076 - accuracy: 0.7680 - val_loss: 490.2388 - val_accuracy: 0.7992\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 617.6894 - accuracy: 0.7657 - val_loss: 494.2238 - val_accuracy: 0.8005\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 619.3313 - accuracy: 0.7673 - val_loss: 493.1334 - val_accuracy: 0.7989\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.2178 - accuracy: 0.7662 - val_loss: 491.8382 - val_accuracy: 0.8013\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.5028 - accuracy: 0.7665 - val_loss: 491.9995 - val_accuracy: 0.8011\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.8822 - accuracy: 0.7669 - val_loss: 494.0555 - val_accuracy: 0.8032\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 617.5909 - accuracy: 0.7675 - val_loss: 490.9807 - val_accuracy: 0.8014\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.5721 - accuracy: 0.7685 - val_loss: 493.9176 - val_accuracy: 0.8042\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 619.7069 - accuracy: 0.7677 - val_loss: 491.5761 - val_accuracy: 0.8027\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 617.9652 - accuracy: 0.7672 - val_loss: 489.4576 - val_accuracy: 0.8040\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 617.4023 - accuracy: 0.7689 - val_loss: 492.5016 - val_accuracy: 0.8004\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 618.7029 - accuracy: 0.7682 - val_loss: 490.2488 - val_accuracy: 0.8024\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 619.4651 - accuracy: 0.7668 - val_loss: 492.7034 - val_accuracy: 0.8001\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.9101 - accuracy: 0.7678 - val_loss: 494.4065 - val_accuracy: 0.7997\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.7842 - accuracy: 0.7670 - val_loss: 492.2697 - val_accuracy: 0.8005\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.9555 - accuracy: 0.7663 - val_loss: 493.0881 - val_accuracy: 0.7996\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.0073 - accuracy: 0.7677 - val_loss: 494.9650 - val_accuracy: 0.7995\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 621.1328 - accuracy: 0.7667 - val_loss: 506.1286 - val_accuracy: 0.8018\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 623.9745 - accuracy: 0.7674 - val_loss: 497.0868 - val_accuracy: 0.7995\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 620.9487 - accuracy: 0.7668 - val_loss: 498.5462 - val_accuracy: 0.8012\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 622.0942 - accuracy: 0.7685 - val_loss: 492.8799 - val_accuracy: 0.8009\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.1177 - accuracy: 0.7665 - val_loss: 493.4559 - val_accuracy: 0.8010\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.5484 - accuracy: 0.7688 - val_loss: 492.6388 - val_accuracy: 0.8002\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 619.2059 - accuracy: 0.7670 - val_loss: 497.9741 - val_accuracy: 0.7990\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 625.2941 - accuracy: 0.7672 - val_loss: 493.8679 - val_accuracy: 0.8001\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 622.8395 - accuracy: 0.7678 - val_loss: 493.0720 - val_accuracy: 0.8028\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.4735 - accuracy: 0.7665 - val_loss: 494.1728 - val_accuracy: 0.8009\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 620.6766 - accuracy: 0.7686 - val_loss: 492.0778 - val_accuracy: 0.8025\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.5023 - accuracy: 0.7676 - val_loss: 489.9909 - val_accuracy: 0.8028\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 617.7719 - accuracy: 0.7682 - val_loss: 493.9792 - val_accuracy: 0.8015\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.0295 - accuracy: 0.7676 - val_loss: 495.7608 - val_accuracy: 0.7995\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.2609 - accuracy: 0.7697 - val_loss: 490.3112 - val_accuracy: 0.8017\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.3367 - accuracy: 0.7678 - val_loss: 490.7289 - val_accuracy: 0.8016\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 618.1414 - accuracy: 0.7686 - val_loss: 491.2456 - val_accuracy: 0.8005\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 617.8472 - accuracy: 0.7670 - val_loss: 491.6114 - val_accuracy: 0.8022\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 617.7377 - accuracy: 0.7694 - val_loss: 496.3592 - val_accuracy: 0.7995\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.4922 - accuracy: 0.7674 - val_loss: 489.9579 - val_accuracy: 0.8016\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 617.6003 - accuracy: 0.7676 - val_loss: 492.0835 - val_accuracy: 0.8008\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.6960 - accuracy: 0.7680 - val_loss: 492.3897 - val_accuracy: 0.8020\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.4375 - accuracy: 0.7676 - val_loss: 492.7882 - val_accuracy: 0.7997\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 617.9460 - accuracy: 0.7708 - val_loss: 491.0367 - val_accuracy: 0.8017\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 618.0809 - accuracy: 0.7656 - val_loss: 492.7668 - val_accuracy: 0.8033\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.1613 - accuracy: 0.7673 - val_loss: 490.1280 - val_accuracy: 0.8032\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 622.2365 - accuracy: 0.7684 - val_loss: 494.9662 - val_accuracy: 0.7993\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 624.0483 - accuracy: 0.7655 - val_loss: 498.5573 - val_accuracy: 0.8005\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 630.3068 - accuracy: 0.7667 - val_loss: 494.8266 - val_accuracy: 0.8017\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.6573 - accuracy: 0.7678 - val_loss: 496.8337 - val_accuracy: 0.8025\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 620.3965 - accuracy: 0.7686 - val_loss: 491.9255 - val_accuracy: 0.8006\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.1339 - accuracy: 0.7665 - val_loss: 491.6692 - val_accuracy: 0.8008\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 617.6247 - accuracy: 0.7677 - val_loss: 493.1193 - val_accuracy: 0.8027\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 617.3683 - accuracy: 0.7679 - val_loss: 491.5497 - val_accuracy: 0.8030\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.0294 - accuracy: 0.7683 - val_loss: 491.2851 - val_accuracy: 0.8028\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 617.4503 - accuracy: 0.7686 - val_loss: 489.7857 - val_accuracy: 0.8016\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 616.9239 - accuracy: 0.7686 - val_loss: 490.1344 - val_accuracy: 0.8026\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 617.8514 - accuracy: 0.7676 - val_loss: 491.1642 - val_accuracy: 0.8013\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 617.6783 - accuracy: 0.7683 - val_loss: 490.8687 - val_accuracy: 0.8010\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 618.7650 - accuracy: 0.7690 - val_loss: 494.4023 - val_accuracy: 0.7999\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 619.2709 - accuracy: 0.7666 - val_loss: 491.6608 - val_accuracy: 0.8003\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.8936 - accuracy: 0.7679 - val_loss: 490.7752 - val_accuracy: 0.8028\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 618.6039 - accuracy: 0.7692 - val_loss: 490.9121 - val_accuracy: 0.8003\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 617.0453 - accuracy: 0.7680 - val_loss: 489.8451 - val_accuracy: 0.8027\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 616.8699 - accuracy: 0.7692 - val_loss: 492.0686 - val_accuracy: 0.8020\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.8307 - accuracy: 0.7679 - val_loss: 489.5698 - val_accuracy: 0.8028\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 618.9399 - accuracy: 0.7681 - val_loss: 491.9328 - val_accuracy: 0.8026\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.2358 - accuracy: 0.7673 - val_loss: 492.1513 - val_accuracy: 0.8020\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 621.1367 - accuracy: 0.7700 - val_loss: 491.1964 - val_accuracy: 0.8018\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.3587 - accuracy: 0.7685 - val_loss: 491.9702 - val_accuracy: 0.8026\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.5841 - accuracy: 0.7688 - val_loss: 492.0288 - val_accuracy: 0.8023\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 619.8597 - accuracy: 0.7670 - val_loss: 490.6511 - val_accuracy: 0.8008\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.1866 - accuracy: 0.7678 - val_loss: 492.5685 - val_accuracy: 0.8018\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 618.4428 - accuracy: 0.7676 - val_loss: 491.4913 - val_accuracy: 0.8012\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 619.1403 - accuracy: 0.7685 - val_loss: 491.8913 - val_accuracy: 0.8008\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 32ms/step - loss: 619.4988 - accuracy: 0.7676 - val_loss: 495.1335 - val_accuracy: 0.8024\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 623.9499 - accuracy: 0.7680 - val_loss: 493.8155 - val_accuracy: 0.8053\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.1084 - accuracy: 0.7668 - val_loss: 492.2600 - val_accuracy: 0.8050\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 30ms/step - loss: 619.3285 - accuracy: 0.7685 - val_loss: 491.8605 - val_accuracy: 0.8032\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 617.6500 - accuracy: 0.7703 - val_loss: 491.5251 - val_accuracy: 0.8014\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 617.3738 - accuracy: 0.7663 - val_loss: 498.3996 - val_accuracy: 0.7995\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 31ms/step - loss: 621.5486 - accuracy: 0.7683 - val_loss: 491.9684 - val_accuracy: 0.8017\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 618.8435 - accuracy: 0.7668 - val_loss: 489.0361 - val_accuracy: 0.8023\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 620.4349 - accuracy: 0.7691 - val_loss: 494.9358 - val_accuracy: 0.8020\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 619.1249 - accuracy: 0.7695 - val_loss: 491.7654 - val_accuracy: 0.8014\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 617.6694 - accuracy: 0.7691 - val_loss: 492.6465 - val_accuracy: 0.8017\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 617.6707 - accuracy: 0.7691 - val_loss: 492.6374 - val_accuracy: 0.8032\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 617.1973 - accuracy: 0.7692 - val_loss: 491.5432 - val_accuracy: 0.8026\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 619.9859 - accuracy: 0.7699 - val_loss: 493.6521 - val_accuracy: 0.8020\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 29ms/step - loss: 623.7965 - accuracy: 0.7670 - val_loss: 497.2352 - val_accuracy: 0.7989\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 28ms/step - loss: 620.2487 - accuracy: 0.7677 - val_loss: 490.5915 - val_accuracy: 0.8038\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 619.3624 - accuracy: 0.7699 - val_loss: 492.5129 - val_accuracy: 0.8023\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 27ms/step - loss: 618.0716 - accuracy: 0.7675 - val_loss: 491.0960 - val_accuracy: 0.8005\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 26ms/step - loss: 620.8095 - accuracy: 0.7677 - val_loss: 494.7066 - val_accuracy: 0.8019\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=1000, batch_size=None, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTUs5o2kF38o"
      },
      "source": [
        "# **increased sample per epoch and learning rate **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w07kaaXFZtL",
        "outputId": "74566363-8fec-4375-b37d-1cc9967936d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "50/50 [==============================] - 2s 17ms/step - loss: 790.0027 - accuracy: 0.7299 - val_loss: 544.1195 - val_accuracy: 0.7846\n",
            "Epoch 2/100\n",
            "50/50 [==============================] - 1s 10ms/step - loss: 686.8332 - accuracy: 0.7354 - val_loss: 526.5968 - val_accuracy: 0.7820\n",
            "Epoch 3/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 659.8004 - accuracy: 0.7473 - val_loss: 571.0972 - val_accuracy: 0.7907\n",
            "Epoch 4/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 717.9963 - accuracy: 0.7327 - val_loss: 583.6807 - val_accuracy: 0.7856\n",
            "Epoch 5/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 668.5257 - accuracy: 0.7457 - val_loss: 539.8849 - val_accuracy: 0.7902\n",
            "Epoch 6/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 740.3493 - accuracy: 0.7197 - val_loss: 590.8100 - val_accuracy: 0.7878\n",
            "Epoch 7/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 677.6529 - accuracy: 0.7486 - val_loss: 564.0380 - val_accuracy: 0.7809\n",
            "Epoch 8/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 700.3636 - accuracy: 0.7402 - val_loss: 549.7684 - val_accuracy: 0.7775\n",
            "Epoch 9/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 692.4288 - accuracy: 0.7324 - val_loss: 545.8067 - val_accuracy: 0.7812\n",
            "Epoch 10/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 670.6811 - accuracy: 0.7414 - val_loss: 548.0834 - val_accuracy: 0.7722\n",
            "Epoch 11/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 674.1761 - accuracy: 0.7360 - val_loss: 555.5469 - val_accuracy: 0.7710\n",
            "Epoch 12/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 700.4866 - accuracy: 0.7381 - val_loss: 573.2881 - val_accuracy: 0.7794\n",
            "Epoch 13/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 737.9921 - accuracy: 0.7362 - val_loss: 590.0387 - val_accuracy: 0.7781\n",
            "Epoch 14/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 792.2075 - accuracy: 0.7329 - val_loss: 646.3618 - val_accuracy: 0.7544\n",
            "Epoch 15/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 712.1100 - accuracy: 0.7278 - val_loss: 591.4083 - val_accuracy: 0.7826\n",
            "Epoch 16/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 705.2975 - accuracy: 0.7371 - val_loss: 544.4189 - val_accuracy: 0.7900\n",
            "Epoch 17/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 654.3517 - accuracy: 0.7571 - val_loss: 535.8167 - val_accuracy: 0.7836\n",
            "Epoch 18/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 671.6895 - accuracy: 0.7450 - val_loss: 576.8798 - val_accuracy: 0.7853\n",
            "Epoch 19/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 686.9270 - accuracy: 0.7373 - val_loss: 531.1509 - val_accuracy: 0.7757\n",
            "Epoch 20/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 664.9581 - accuracy: 0.7536 - val_loss: 565.7773 - val_accuracy: 0.7869\n",
            "Epoch 21/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 717.4190 - accuracy: 0.7348 - val_loss: 552.4951 - val_accuracy: 0.7709\n",
            "Epoch 22/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 690.4682 - accuracy: 0.7368 - val_loss: 546.6362 - val_accuracy: 0.7635\n",
            "Epoch 23/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 638.0785 - accuracy: 0.7453 - val_loss: 524.0671 - val_accuracy: 0.7727\n",
            "Epoch 24/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 674.8432 - accuracy: 0.7464 - val_loss: 530.3176 - val_accuracy: 0.7821\n",
            "Epoch 25/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 665.6680 - accuracy: 0.7398 - val_loss: 541.5633 - val_accuracy: 0.7851\n",
            "Epoch 26/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 685.9969 - accuracy: 0.7490 - val_loss: 543.7988 - val_accuracy: 0.7801\n",
            "Epoch 27/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 693.0920 - accuracy: 0.7355 - val_loss: 529.1884 - val_accuracy: 0.7800\n",
            "Epoch 28/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 672.7450 - accuracy: 0.7483 - val_loss: 536.3315 - val_accuracy: 0.7785\n",
            "Epoch 29/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 736.8522 - accuracy: 0.7268 - val_loss: 570.1628 - val_accuracy: 0.7543\n",
            "Epoch 30/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 692.3829 - accuracy: 0.7545 - val_loss: 542.2661 - val_accuracy: 0.7639\n",
            "Epoch 31/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 726.4400 - accuracy: 0.7378 - val_loss: 591.3551 - val_accuracy: 0.7787\n",
            "Epoch 32/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 652.7065 - accuracy: 0.7479 - val_loss: 530.4053 - val_accuracy: 0.7864\n",
            "Epoch 33/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 702.7567 - accuracy: 0.7345 - val_loss: 534.5695 - val_accuracy: 0.7670\n",
            "Epoch 34/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 666.6209 - accuracy: 0.7546 - val_loss: 551.9560 - val_accuracy: 0.7887\n",
            "Epoch 35/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 764.1340 - accuracy: 0.7257 - val_loss: 583.3411 - val_accuracy: 0.7222\n",
            "Epoch 36/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 712.0552 - accuracy: 0.7346 - val_loss: 552.6036 - val_accuracy: 0.7731\n",
            "Epoch 37/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 690.4494 - accuracy: 0.7473 - val_loss: 587.4253 - val_accuracy: 0.7833\n",
            "Epoch 38/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 685.6624 - accuracy: 0.7393 - val_loss: 550.0767 - val_accuracy: 0.7640\n",
            "Epoch 39/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 680.7675 - accuracy: 0.7442 - val_loss: 542.8878 - val_accuracy: 0.7717\n",
            "Epoch 40/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 702.9125 - accuracy: 0.7385 - val_loss: 578.3401 - val_accuracy: 0.7657\n",
            "Epoch 41/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 746.9006 - accuracy: 0.7412 - val_loss: 549.1593 - val_accuracy: 0.7707\n",
            "Epoch 42/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 691.2761 - accuracy: 0.7290 - val_loss: 541.8954 - val_accuracy: 0.7742\n",
            "Epoch 43/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 666.2079 - accuracy: 0.7435 - val_loss: 524.7285 - val_accuracy: 0.7842\n",
            "Epoch 44/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 680.1273 - accuracy: 0.7470 - val_loss: 545.2250 - val_accuracy: 0.7815\n",
            "Epoch 45/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 699.4433 - accuracy: 0.7451 - val_loss: 576.5947 - val_accuracy: 0.7886\n",
            "Epoch 46/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 690.9465 - accuracy: 0.7486 - val_loss: 599.1877 - val_accuracy: 0.7581\n",
            "Epoch 47/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 712.9036 - accuracy: 0.7488 - val_loss: 563.3862 - val_accuracy: 0.7712\n",
            "Epoch 48/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 666.3132 - accuracy: 0.7455 - val_loss: 573.3573 - val_accuracy: 0.7877\n",
            "Epoch 49/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 684.4689 - accuracy: 0.7435 - val_loss: 519.0768 - val_accuracy: 0.7898\n",
            "Epoch 50/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 662.7197 - accuracy: 0.7483 - val_loss: 519.8988 - val_accuracy: 0.7872\n",
            "Epoch 51/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 643.9476 - accuracy: 0.7477 - val_loss: 527.9014 - val_accuracy: 0.7806\n",
            "Epoch 52/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 667.9869 - accuracy: 0.7434 - val_loss: 526.8214 - val_accuracy: 0.7900\n",
            "Epoch 53/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 670.0361 - accuracy: 0.7467 - val_loss: 544.8453 - val_accuracy: 0.7914\n",
            "Epoch 54/100\n",
            "50/50 [==============================] - 0s 7ms/step - loss: 679.5947 - accuracy: 0.7477 - val_loss: 553.8994 - val_accuracy: 0.7887\n",
            "Epoch 55/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 702.3314 - accuracy: 0.7473 - val_loss: 565.0401 - val_accuracy: 0.7750\n",
            "Epoch 56/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 657.6603 - accuracy: 0.7511 - val_loss: 518.9940 - val_accuracy: 0.7684\n",
            "Epoch 57/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 676.7531 - accuracy: 0.7413 - val_loss: 533.2314 - val_accuracy: 0.7848\n",
            "Epoch 58/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 728.6547 - accuracy: 0.7411 - val_loss: 564.7567 - val_accuracy: 0.7914\n",
            "Epoch 59/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 684.1554 - accuracy: 0.7511 - val_loss: 554.7604 - val_accuracy: 0.7542\n",
            "Epoch 60/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 649.3656 - accuracy: 0.7473 - val_loss: 534.5956 - val_accuracy: 0.7782\n",
            "Epoch 61/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 707.1803 - accuracy: 0.7512 - val_loss: 556.5648 - val_accuracy: 0.7669\n",
            "Epoch 62/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 713.1951 - accuracy: 0.7361 - val_loss: 535.3807 - val_accuracy: 0.7800\n",
            "Epoch 63/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 666.1635 - accuracy: 0.7514 - val_loss: 551.8350 - val_accuracy: 0.7910\n",
            "Epoch 64/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 692.8693 - accuracy: 0.7431 - val_loss: 522.9846 - val_accuracy: 0.7893\n",
            "Epoch 65/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 705.1156 - accuracy: 0.7491 - val_loss: 530.9930 - val_accuracy: 0.7886\n",
            "Epoch 66/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 664.6166 - accuracy: 0.7422 - val_loss: 538.9361 - val_accuracy: 0.7849\n",
            "Epoch 67/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 674.5801 - accuracy: 0.7427 - val_loss: 533.8871 - val_accuracy: 0.7872\n",
            "Epoch 68/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 686.7274 - accuracy: 0.7505 - val_loss: 567.2164 - val_accuracy: 0.7849\n",
            "Epoch 69/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 671.6429 - accuracy: 0.7483 - val_loss: 548.9421 - val_accuracy: 0.7892\n",
            "Epoch 70/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 699.9608 - accuracy: 0.7540 - val_loss: 559.0305 - val_accuracy: 0.7541\n",
            "Epoch 71/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 692.1209 - accuracy: 0.7446 - val_loss: 594.9670 - val_accuracy: 0.7910\n",
            "Epoch 72/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 810.4299 - accuracy: 0.7409 - val_loss: 552.1492 - val_accuracy: 0.7776\n",
            "Epoch 73/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 670.9124 - accuracy: 0.7437 - val_loss: 528.9773 - val_accuracy: 0.7843\n",
            "Epoch 74/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 705.1666 - accuracy: 0.7483 - val_loss: 682.4537 - val_accuracy: 0.7766\n",
            "Epoch 75/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 720.7893 - accuracy: 0.7443 - val_loss: 543.8190 - val_accuracy: 0.7694\n",
            "Epoch 76/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 684.6424 - accuracy: 0.7529 - val_loss: 527.9421 - val_accuracy: 0.7849\n",
            "Epoch 77/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 676.5316 - accuracy: 0.7535 - val_loss: 549.9125 - val_accuracy: 0.7910\n",
            "Epoch 78/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 671.7007 - accuracy: 0.7469 - val_loss: 515.7896 - val_accuracy: 0.7841\n",
            "Epoch 79/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 671.4320 - accuracy: 0.7524 - val_loss: 567.6559 - val_accuracy: 0.7910\n",
            "Epoch 80/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 683.3036 - accuracy: 0.7464 - val_loss: 526.2901 - val_accuracy: 0.7862\n",
            "Epoch 81/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 666.3734 - accuracy: 0.7540 - val_loss: 532.9739 - val_accuracy: 0.7775\n",
            "Epoch 82/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 722.9568 - accuracy: 0.7380 - val_loss: 553.8405 - val_accuracy: 0.7826\n",
            "Epoch 83/100\n",
            "50/50 [==============================] - 0s 8ms/step - loss: 672.3842 - accuracy: 0.7567 - val_loss: 527.7189 - val_accuracy: 0.7840\n",
            "Epoch 84/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 690.6438 - accuracy: 0.7421 - val_loss: 535.3290 - val_accuracy: 0.7872\n",
            "Epoch 85/100\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 699.4369 - accuracy: 0.7492 - val_loss: 558.8892 - val_accuracy: 0.7835\n",
            "Epoch 86/100\n",
            "50/50 [==============================] - 0s 9ms/step - loss: 711.6258 - accuracy: 0.7381 - val_loss: 544.0920 - val_accuracy: 0.7626\n",
            "Epoch 87/100\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 703.2682 - accuracy: 0.7435 - val_loss: 540.9926 - val_accuracy: 0.7766\n",
            "Epoch 88/100\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 668.6248 - accuracy: 0.7482 - val_loss: 517.6490 - val_accuracy: 0.7744\n",
            "Epoch 89/100\n",
            "50/50 [==============================] - 0s 10ms/step - loss: 681.7851 - accuracy: 0.7441 - val_loss: 581.4958 - val_accuracy: 0.7778\n",
            "Epoch 90/100\n",
            "50/50 [==============================] - 1s 11ms/step - loss: 679.5294 - accuracy: 0.7478 - val_loss: 536.6544 - val_accuracy: 0.7575\n",
            "Epoch 91/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 5000 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r50/50 [==============================] - 0s 3ms/step - loss: 679.5294 - accuracy: 0.7478 - val_loss: 536.6544 - val_accuracy: 0.7575\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "# Define the model\n",
        "model= tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model with a learning rate of 0.01 and 100 samples per epoch\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([HR_RGB, LRHSI], image_transposed, epochs=100, batch_size=None, validation_split=0.2, steps_per_epoch=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kF13K-QGSly"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "# Define the model\n",
        "model= tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model with a learning rate of 0.01 and 100 samples per epoch\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_absolute_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asgkYRyLuC1x"
      },
      "outputs": [],
      "source": [
        "a=HR_RGB/255\n",
        "b=LRHSI/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Q9EX7OwuQXq",
        "outputId": "da7b04a2-9c8d-4f7c-803e-8742eb3e0d4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64, 64, 3)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq1LzpuPuSS4",
        "outputId": "603346c4-7bab-4284-ac39-15b80f2ba533"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 8, 8, 31)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QGuSrDZuYn5"
      },
      "outputs": [],
      "source": [
        "c=image_transposed/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y1avQrAug7I",
        "outputId": "ea878f2b-bb39-4ef8-a223-9bed2dec932c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(64, 64, 64, 31)"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXSRz18Sby1H",
        "outputId": "12391294-4922-4a59-83db-15d808e72979"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 66ms/step - loss: 29.8242 - accuracy: 0.2470 - val_loss: 30.3128 - val_accuracy: 0.2013\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 27.9012 - accuracy: 0.2240 - val_loss: 27.4211 - val_accuracy: 0.2027\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 25.8470 - accuracy: 0.2321 - val_loss: 24.3627 - val_accuracy: 0.2043\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 23.7078 - accuracy: 0.2378 - val_loss: 21.3830 - val_accuracy: 0.2082\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 21.6791 - accuracy: 0.2400 - val_loss: 19.1234 - val_accuracy: 0.2150\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 20.4769 - accuracy: 0.2426 - val_loss: 17.7671 - val_accuracy: 0.2194\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.2592 - accuracy: 0.2451 - val_loss: 15.9886 - val_accuracy: 0.2232\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 17.8616 - accuracy: 0.2480 - val_loss: 14.1775 - val_accuracy: 0.2270\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 16.5471 - accuracy: 0.2525 - val_loss: 13.2345 - val_accuracy: 0.2327\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 15.8066 - accuracy: 0.2619 - val_loss: 12.3922 - val_accuracy: 0.2420\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.0768 - accuracy: 0.3008 - val_loss: 11.2082 - val_accuracy: 0.2690\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.4009 - accuracy: 0.3537 - val_loss: 10.4694 - val_accuracy: 0.4246\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.8590 - accuracy: 0.3962 - val_loss: 10.0602 - val_accuracy: 0.4476\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.6279 - accuracy: 0.2787 - val_loss: 10.1767 - val_accuracy: 0.4402\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 13.4176 - accuracy: 0.2882 - val_loss: 9.8699 - val_accuracy: 0.4152\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.0736 - accuracy: 0.3452 - val_loss: 9.5699 - val_accuracy: 0.5910\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.7305 - accuracy: 0.4397 - val_loss: 9.2433 - val_accuracy: 0.5899\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.3089 - accuracy: 0.4393 - val_loss: 9.0038 - val_accuracy: 0.5590\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.9452 - accuracy: 0.4139 - val_loss: 8.8258 - val_accuracy: 0.3211\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.5562 - accuracy: 0.4074 - val_loss: 8.4222 - val_accuracy: 0.3444\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.0461 - accuracy: 0.4458 - val_loss: 8.0075 - val_accuracy: 0.4445\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.6267 - accuracy: 0.3685 - val_loss: 7.7167 - val_accuracy: 0.1804\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.1218 - accuracy: 0.3470 - val_loss: 7.1482 - val_accuracy: 0.2323\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.3846 - accuracy: 0.5581 - val_loss: 6.6289 - val_accuracy: 0.4749\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8.6266 - accuracy: 0.6192 - val_loss: 6.4265 - val_accuracy: 0.1640\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 7.6295 - accuracy: 0.5964 - val_loss: 5.8964 - val_accuracy: 0.1708\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 6.6649 - accuracy: 0.6410 - val_loss: 4.8308 - val_accuracy: 0.2411\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.8980 - accuracy: 0.6467 - val_loss: 4.1433 - val_accuracy: 0.2442\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.4488 - accuracy: 0.6660 - val_loss: 3.2959 - val_accuracy: 0.5412\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0241 - accuracy: 0.6885 - val_loss: 2.7926 - val_accuracy: 0.5429\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.6630 - accuracy: 0.6939 - val_loss: 2.5973 - val_accuracy: 0.4681\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.4301 - accuracy: 0.6992 - val_loss: 2.1703 - val_accuracy: 0.5485\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.2168 - accuracy: 0.7013 - val_loss: 2.1080 - val_accuracy: 0.5609\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.0819 - accuracy: 0.7039 - val_loss: 1.9662 - val_accuracy: 0.5853\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.9940 - accuracy: 0.7050 - val_loss: 1.9029 - val_accuracy: 0.5964\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.9187 - accuracy: 0.7031 - val_loss: 1.8792 - val_accuracy: 0.6040\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.8611 - accuracy: 0.7030 - val_loss: 1.9904 - val_accuracy: 0.5972\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.8087 - accuracy: 0.7034 - val_loss: 1.8264 - val_accuracy: 0.6245\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.7562 - accuracy: 0.7052 - val_loss: 1.8295 - val_accuracy: 0.6253\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 3.7131 - accuracy: 0.7059 - val_loss: 1.9619 - val_accuracy: 0.6140\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.6807 - accuracy: 0.7078 - val_loss: 1.7723 - val_accuracy: 0.6228\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.6567 - accuracy: 0.7111 - val_loss: 1.8397 - val_accuracy: 0.6265\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.6073 - accuracy: 0.7145 - val_loss: 1.7958 - val_accuracy: 0.6338\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5771 - accuracy: 0.7148 - val_loss: 1.7503 - val_accuracy: 0.6419\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5512 - accuracy: 0.7164 - val_loss: 1.8127 - val_accuracy: 0.6356\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5300 - accuracy: 0.7163 - val_loss: 1.8005 - val_accuracy: 0.6391\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5086 - accuracy: 0.7176 - val_loss: 1.7811 - val_accuracy: 0.6423\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4862 - accuracy: 0.7179 - val_loss: 1.7202 - val_accuracy: 0.6380\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4691 - accuracy: 0.7188 - val_loss: 1.7485 - val_accuracy: 0.6401\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4520 - accuracy: 0.7187 - val_loss: 1.7202 - val_accuracy: 0.6377\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4379 - accuracy: 0.7203 - val_loss: 1.7399 - val_accuracy: 0.6412\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4235 - accuracy: 0.7209 - val_loss: 1.7062 - val_accuracy: 0.6382\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4132 - accuracy: 0.7227 - val_loss: 1.6626 - val_accuracy: 0.6330\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4087 - accuracy: 0.7236 - val_loss: 1.7265 - val_accuracy: 0.6408\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4013 - accuracy: 0.7244 - val_loss: 1.8430 - val_accuracy: 0.6390\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3933 - accuracy: 0.7267 - val_loss: 1.7941 - val_accuracy: 0.6421\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3823 - accuracy: 0.7261 - val_loss: 1.6719 - val_accuracy: 0.6376\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3647 - accuracy: 0.7273 - val_loss: 1.6665 - val_accuracy: 0.6354\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3563 - accuracy: 0.7279 - val_loss: 1.7208 - val_accuracy: 0.6418\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3514 - accuracy: 0.7289 - val_loss: 1.7157 - val_accuracy: 0.6384\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3500 - accuracy: 0.7308 - val_loss: 1.6258 - val_accuracy: 0.6302\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3425 - accuracy: 0.7305 - val_loss: 1.6163 - val_accuracy: 0.6297\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3352 - accuracy: 0.7318 - val_loss: 1.6513 - val_accuracy: 0.6406\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3240 - accuracy: 0.7336 - val_loss: 1.6757 - val_accuracy: 0.6461\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3183 - accuracy: 0.7350 - val_loss: 1.6422 - val_accuracy: 0.6408\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3126 - accuracy: 0.7356 - val_loss: 1.6321 - val_accuracy: 0.6405\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3088 - accuracy: 0.7360 - val_loss: 1.6434 - val_accuracy: 0.6424\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3062 - accuracy: 0.7379 - val_loss: 1.6008 - val_accuracy: 0.6369\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3009 - accuracy: 0.7388 - val_loss: 1.5876 - val_accuracy: 0.6347\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 3.3000 - accuracy: 0.7396 - val_loss: 1.5756 - val_accuracy: 0.6342\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2979 - accuracy: 0.7396 - val_loss: 1.5599 - val_accuracy: 0.6299\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2932 - accuracy: 0.7413 - val_loss: 1.5701 - val_accuracy: 0.6387\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2905 - accuracy: 0.7423 - val_loss: 1.5948 - val_accuracy: 0.6463\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2867 - accuracy: 0.7411 - val_loss: 1.6598 - val_accuracy: 0.6583\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2847 - accuracy: 0.7435 - val_loss: 1.6334 - val_accuracy: 0.6578\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2776 - accuracy: 0.7433 - val_loss: 1.6144 - val_accuracy: 0.6568\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2741 - accuracy: 0.7449 - val_loss: 1.5586 - val_accuracy: 0.6446\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2740 - accuracy: 0.7459 - val_loss: 1.5273 - val_accuracy: 0.6329\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2783 - accuracy: 0.7452 - val_loss: 1.5292 - val_accuracy: 0.6257\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2809 - accuracy: 0.7440 - val_loss: 1.5841 - val_accuracy: 0.6570\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2616 - accuracy: 0.7465 - val_loss: 1.6306 - val_accuracy: 0.6638\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2639 - accuracy: 0.7486 - val_loss: 1.6393 - val_accuracy: 0.6675\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2635 - accuracy: 0.7477 - val_loss: 1.5665 - val_accuracy: 0.6584\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2544 - accuracy: 0.7481 - val_loss: 1.5113 - val_accuracy: 0.6488\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2571 - accuracy: 0.7493 - val_loss: 1.5031 - val_accuracy: 0.6466\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2527 - accuracy: 0.7496 - val_loss: 1.5074 - val_accuracy: 0.6563\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2451 - accuracy: 0.7502 - val_loss: 1.5161 - val_accuracy: 0.6563\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2416 - accuracy: 0.7507 - val_loss: 1.5197 - val_accuracy: 0.6565\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2407 - accuracy: 0.7507 - val_loss: 1.5407 - val_accuracy: 0.6642\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2374 - accuracy: 0.7512 - val_loss: 1.5100 - val_accuracy: 0.6581\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2362 - accuracy: 0.7509 - val_loss: 1.5390 - val_accuracy: 0.6703\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2355 - accuracy: 0.7503 - val_loss: 1.5396 - val_accuracy: 0.6730\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2364 - accuracy: 0.7510 - val_loss: 1.5498 - val_accuracy: 0.6781\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 3.2364 - accuracy: 0.7510 - val_loss: 1.5169 - val_accuracy: 0.6732\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2331 - accuracy: 0.7509 - val_loss: 1.5271 - val_accuracy: 0.6777\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2299 - accuracy: 0.7512 - val_loss: 1.5540 - val_accuracy: 0.6843\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 3.2296 - accuracy: 0.7510 - val_loss: 1.5194 - val_accuracy: 0.6793\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2280 - accuracy: 0.7510 - val_loss: 1.5667 - val_accuracy: 0.6886\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2275 - accuracy: 0.7518 - val_loss: 1.5219 - val_accuracy: 0.6831\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2315 - accuracy: 0.7516 - val_loss: 1.4592 - val_accuracy: 0.6558\n"
          ]
        }
      ],
      "source": [
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=100, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upUKWM2gViPO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVviWubFu6xN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oae5sdP_u66F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "# Define the model\n",
        "model= tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model with a learning rate of 0.01 and 100 samples per epoch\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNNXO8UJvBe1",
        "outputId": "fee67606-d0d2-4dc5-9d00-854bfc84f424"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-b16d42a34b06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model and store the history object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    978\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m       _, _, filtered_flat_args = (\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[0;32m-> 2452\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2709\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_placeholder_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2711\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2712\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   2713\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2625\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2626\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2627\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2628\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1139\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m           \u001b[0;31m# TODO(mdan): Push this block higher in tf.function's call stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m           \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m             return autograph.converted_call(\n\u001b[0m\u001b[1;32m   1117\u001b[0m                 \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    329\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             run_step, jit_compile=True, reduce_retracing=True)\n\u001b[1;32m   1039\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m   1042\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1311\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1312\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2886\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2888\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2890\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3687\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3688\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3689\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3691\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1030\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1031\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_target_and_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \"\"\"\n\u001b[0;32m--> 537\u001b[0;31m     grads_and_vars = self._compute_gradients(\n\u001b[0m\u001b[1;32m    538\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     self._assert_valid_dtypes([\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    469\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_MeanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_MeanGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;34m\"\"\"Gradient for Mean.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m   \u001b[0msum_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SumGrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m   \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtile_scaling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m   \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"keep_dims\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, name, out_type)\u001b[0m\n\u001b[1;32m    655\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m   \"\"\"\n\u001b[0;32m--> 657\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[0;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[1;32m    696\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(input, out_type, name)\u001b[0m\n\u001b[1;32m   9363\u001b[0m     \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   9364\u001b[0m   \u001b[0mout_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"out_type\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 9365\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   9366\u001b[0m         \"Shape\", input=input, out_type=out_type, name=name)\n\u001b[1;32m   9367\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    798\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    692\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    695\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         compute_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3751\u001b[0m     \u001b[0;31m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3752\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3753\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3754\u001b[0m       ret = Operation(\n\u001b[1;32m   3755\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/lock_util.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/lock_util.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_another_group_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/lock_util.py\u001b[0m in \u001b[0;36m_another_group_active\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_another_group_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     return any(\n\u001b[0m\u001b[1;32m    107\u001b[0m         c > 0 for g, c in enumerate(self._group_member_counts) if g != group_id)\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=100, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq_5_ZXuvPPG",
        "outputId": "c1a73eff-4229-4544-fa8c-2a49f8746f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 60.8979 - accuracy: 0.6965 - val_loss: 11.0277 - val_accuracy: 0.6065\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 60.2229 - accuracy: 0.7057 - val_loss: 10.7109 - val_accuracy: 0.5817\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 59.7982 - accuracy: 0.6996 - val_loss: 10.4192 - val_accuracy: 0.5871\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 61.0584 - accuracy: 0.7025 - val_loss: 12.2807 - val_accuracy: 0.6267\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 59.7263 - accuracy: 0.6929 - val_loss: 10.3908 - val_accuracy: 0.6014\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 60.8203 - accuracy: 0.7076 - val_loss: 11.0130 - val_accuracy: 0.5852\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 60.0662 - accuracy: 0.7065 - val_loss: 11.5168 - val_accuracy: 0.6166\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 59.9416 - accuracy: 0.7017 - val_loss: 11.6715 - val_accuracy: 0.5943\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 59.6858 - accuracy: 0.7022 - val_loss: 11.1184 - val_accuracy: 0.5955\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 59.4354 - accuracy: 0.7045 - val_loss: 10.3983 - val_accuracy: 0.6335\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 59.2835 - accuracy: 0.7154 - val_loss: 10.6559 - val_accuracy: 0.6064\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.4205 - accuracy: 0.6960 - val_loss: 10.8577 - val_accuracy: 0.6364\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 59.6921 - accuracy: 0.7027 - val_loss: 10.9465 - val_accuracy: 0.5878\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 59.7392 - accuracy: 0.7116 - val_loss: 10.0404 - val_accuracy: 0.6003\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 59.0353 - accuracy: 0.7011 - val_loss: 11.0299 - val_accuracy: 0.5983\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 59.2242 - accuracy: 0.7107 - val_loss: 10.2116 - val_accuracy: 0.6188\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.9914 - accuracy: 0.7092 - val_loss: 10.6098 - val_accuracy: 0.6568\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.5649 - accuracy: 0.7161 - val_loss: 10.8189 - val_accuracy: 0.5789\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.2859 - accuracy: 0.6997 - val_loss: 10.3331 - val_accuracy: 0.6481\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 59.2217 - accuracy: 0.7047 - val_loss: 11.5512 - val_accuracy: 0.6444\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 59.0874 - accuracy: 0.7133 - val_loss: 10.4308 - val_accuracy: 0.6354\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 59.1556 - accuracy: 0.7152 - val_loss: 11.6017 - val_accuracy: 0.6119\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.9472 - accuracy: 0.7047 - val_loss: 10.0958 - val_accuracy: 0.6577\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 59.9831 - accuracy: 0.7065 - val_loss: 10.8274 - val_accuracy: 0.6787\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.8555 - accuracy: 0.7082 - val_loss: 10.0461 - val_accuracy: 0.5954\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.4962 - accuracy: 0.7189 - val_loss: 11.4405 - val_accuracy: 0.6075\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.5680 - accuracy: 0.7049 - val_loss: 10.0972 - val_accuracy: 0.6492\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.7134 - accuracy: 0.6939 - val_loss: 10.5625 - val_accuracy: 0.6900\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.8387 - accuracy: 0.7159 - val_loss: 10.2375 - val_accuracy: 0.6556\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 58.8489 - accuracy: 0.7146 - val_loss: 11.1796 - val_accuracy: 0.6647\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.4756 - accuracy: 0.6884 - val_loss: 10.5441 - val_accuracy: 0.6460\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 59.2373 - accuracy: 0.7247 - val_loss: 11.0329 - val_accuracy: 0.6466\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.5252 - accuracy: 0.7071 - val_loss: 13.1874 - val_accuracy: 0.7104\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.9428 - accuracy: 0.7174 - val_loss: 10.5932 - val_accuracy: 0.6774\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 60.1126 - accuracy: 0.7022 - val_loss: 10.3085 - val_accuracy: 0.6430\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.4109 - accuracy: 0.7208 - val_loss: 11.2379 - val_accuracy: 0.6609\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.5828 - accuracy: 0.7150 - val_loss: 10.3853 - val_accuracy: 0.6591\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.1703 - accuracy: 0.7072 - val_loss: 10.0824 - val_accuracy: 0.6714\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.6881 - accuracy: 0.7059 - val_loss: 11.4604 - val_accuracy: 0.6872\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.8240 - accuracy: 0.7141 - val_loss: 10.9658 - val_accuracy: 0.6289\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.8764 - accuracy: 0.7203 - val_loss: 10.7527 - val_accuracy: 0.6895\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.8329 - accuracy: 0.7085 - val_loss: 9.9877 - val_accuracy: 0.6481\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 58.5015 - accuracy: 0.7139 - val_loss: 10.8048 - val_accuracy: 0.6745\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.2581 - accuracy: 0.7116 - val_loss: 10.6199 - val_accuracy: 0.7061\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 59.1926 - accuracy: 0.7160 - val_loss: 10.3890 - val_accuracy: 0.6847\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.5413 - accuracy: 0.7129 - val_loss: 12.1217 - val_accuracy: 0.6445\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.4843 - accuracy: 0.6928 - val_loss: 10.0660 - val_accuracy: 0.6992\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.9146 - accuracy: 0.7173 - val_loss: 13.2161 - val_accuracy: 0.6760\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 60.1993 - accuracy: 0.7104 - val_loss: 10.6013 - val_accuracy: 0.6911\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 60.9432 - accuracy: 0.7103 - val_loss: 13.7943 - val_accuracy: 0.6941\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.8102 - accuracy: 0.7024 - val_loss: 9.8241 - val_accuracy: 0.6673\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 60.4319 - accuracy: 0.7278 - val_loss: 12.5276 - val_accuracy: 0.6800\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.9800 - accuracy: 0.7101 - val_loss: 9.9216 - val_accuracy: 0.6506\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 64.9043 - accuracy: 0.7068 - val_loss: 14.1897 - val_accuracy: 0.6209\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 65.0668 - accuracy: 0.6984 - val_loss: 10.8455 - val_accuracy: 0.7060\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 64.0665 - accuracy: 0.7033 - val_loss: 14.3521 - val_accuracy: 0.6541\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 69.7968 - accuracy: 0.6956 - val_loss: 11.6136 - val_accuracy: 0.7402\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 72.6847 - accuracy: 0.7085 - val_loss: 10.0087 - val_accuracy: 0.6877\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 62.9363 - accuracy: 0.6775 - val_loss: 13.1594 - val_accuracy: 0.6065\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 61.9893 - accuracy: 0.6839 - val_loss: 11.0672 - val_accuracy: 0.6509\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.4121 - accuracy: 0.7119 - val_loss: 10.5397 - val_accuracy: 0.6460\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 59.0793 - accuracy: 0.7126 - val_loss: 9.6628 - val_accuracy: 0.6638\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.0627 - accuracy: 0.6939 - val_loss: 10.3343 - val_accuracy: 0.6496\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.8961 - accuracy: 0.7109 - val_loss: 10.3564 - val_accuracy: 0.6272\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.9137 - accuracy: 0.7070 - val_loss: 10.2582 - val_accuracy: 0.7110\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.2070 - accuracy: 0.7269 - val_loss: 10.7303 - val_accuracy: 0.6870\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 58.4451 - accuracy: 0.7217 - val_loss: 9.7472 - val_accuracy: 0.6954\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 59.0715 - accuracy: 0.7013 - val_loss: 10.4751 - val_accuracy: 0.6836\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.1773 - accuracy: 0.7158 - val_loss: 10.6632 - val_accuracy: 0.6990\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.7262 - accuracy: 0.7125 - val_loss: 11.6247 - val_accuracy: 0.6802\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.3636 - accuracy: 0.7197 - val_loss: 10.7749 - val_accuracy: 0.6912\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.5895 - accuracy: 0.7039 - val_loss: 10.7663 - val_accuracy: 0.7004\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.7591 - accuracy: 0.7235 - val_loss: 10.1189 - val_accuracy: 0.7092\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.2322 - accuracy: 0.7088 - val_loss: 10.4593 - val_accuracy: 0.6991\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.8528 - accuracy: 0.7109 - val_loss: 9.9930 - val_accuracy: 0.6943\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.1947 - accuracy: 0.7296 - val_loss: 10.4754 - val_accuracy: 0.7158\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.6258 - accuracy: 0.7151 - val_loss: 10.4139 - val_accuracy: 0.7174\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.2313 - accuracy: 0.7231 - val_loss: 10.2114 - val_accuracy: 0.7037\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.4050 - accuracy: 0.7257 - val_loss: 10.7107 - val_accuracy: 0.7093\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.9941 - accuracy: 0.7097 - val_loss: 10.8697 - val_accuracy: 0.7072\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 58.2561 - accuracy: 0.7272 - val_loss: 9.9912 - val_accuracy: 0.7254\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.2127 - accuracy: 0.7163 - val_loss: 11.1467 - val_accuracy: 0.7153\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.3255 - accuracy: 0.7307 - val_loss: 10.0526 - val_accuracy: 0.7115\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.4195 - accuracy: 0.7001 - val_loss: 10.2736 - val_accuracy: 0.7284\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.2507 - accuracy: 0.7245 - val_loss: 10.0723 - val_accuracy: 0.7356\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.2170 - accuracy: 0.7267 - val_loss: 10.3863 - val_accuracy: 0.7379\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.2535 - accuracy: 0.7213 - val_loss: 10.6296 - val_accuracy: 0.7396\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.9056 - accuracy: 0.7308 - val_loss: 10.6326 - val_accuracy: 0.7112\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 56.5473 - accuracy: 0.7262 - val_loss: 10.6235 - val_accuracy: 0.7486\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.2025 - accuracy: 0.7265 - val_loss: 11.4020 - val_accuracy: 0.7199\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.6060 - accuracy: 0.7250 - val_loss: 10.6517 - val_accuracy: 0.7335\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.2708 - accuracy: 0.7175 - val_loss: 9.8427 - val_accuracy: 0.7109\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.0331 - accuracy: 0.7226 - val_loss: 12.2209 - val_accuracy: 0.7436\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 57.7496 - accuracy: 0.7284 - val_loss: 10.0706 - val_accuracy: 0.7268\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.1954 - accuracy: 0.7197 - val_loss: 12.8612 - val_accuracy: 0.7393\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.2252 - accuracy: 0.7162 - val_loss: 10.9192 - val_accuracy: 0.7155\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 60.5216 - accuracy: 0.6850 - val_loss: 13.6526 - val_accuracy: 0.7318\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 61.7718 - accuracy: 0.7222 - val_loss: 10.3293 - val_accuracy: 0.7089\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.8533 - accuracy: 0.7173 - val_loss: 12.6296 - val_accuracy: 0.6967\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.0768 - accuracy: 0.7266 - val_loss: 9.9780 - val_accuracy: 0.7299\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.5369 - accuracy: 0.7303 - val_loss: 10.3182 - val_accuracy: 0.7353\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.7108 - accuracy: 0.7279 - val_loss: 10.0669 - val_accuracy: 0.7369\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.1905 - accuracy: 0.7207 - val_loss: 11.7679 - val_accuracy: 0.6535\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.7726 - accuracy: 0.7202 - val_loss: 10.8096 - val_accuracy: 0.7226\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.9963 - accuracy: 0.7235 - val_loss: 10.5807 - val_accuracy: 0.7393\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.6516 - accuracy: 0.7243 - val_loss: 10.0765 - val_accuracy: 0.7193\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.5415 - accuracy: 0.7314 - val_loss: 10.0811 - val_accuracy: 0.7356\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.3544 - accuracy: 0.7205 - val_loss: 10.8533 - val_accuracy: 0.7088\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.6481 - accuracy: 0.7287 - val_loss: 10.3431 - val_accuracy: 0.7269\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.0747 - accuracy: 0.7084 - val_loss: 10.3995 - val_accuracy: 0.7176\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.5561 - accuracy: 0.7285 - val_loss: 12.3167 - val_accuracy: 0.7243\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.0311 - accuracy: 0.7304 - val_loss: 10.3037 - val_accuracy: 0.7162\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.7935 - accuracy: 0.7117 - val_loss: 10.7428 - val_accuracy: 0.7327\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.0349 - accuracy: 0.7233 - val_loss: 10.4359 - val_accuracy: 0.7460\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.8676 - accuracy: 0.7340 - val_loss: 11.2611 - val_accuracy: 0.7310\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.3807 - accuracy: 0.7304 - val_loss: 10.2065 - val_accuracy: 0.7317\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.9227 - accuracy: 0.7278 - val_loss: 11.2008 - val_accuracy: 0.7202\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.3786 - accuracy: 0.7291 - val_loss: 10.3631 - val_accuracy: 0.7180\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.8617 - accuracy: 0.7223 - val_loss: 11.2839 - val_accuracy: 0.7352\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 63.0643 - accuracy: 0.6977 - val_loss: 13.2981 - val_accuracy: 0.6721\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.2396 - accuracy: 0.7162 - val_loss: 11.6267 - val_accuracy: 0.6309\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 74.0655 - accuracy: 0.7054 - val_loss: 12.0649 - val_accuracy: 0.6393\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 70.6645 - accuracy: 0.6879 - val_loss: 10.8910 - val_accuracy: 0.6340\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 66.0266 - accuracy: 0.6484 - val_loss: 11.1864 - val_accuracy: 0.5940\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 64.5031 - accuracy: 0.6932 - val_loss: 11.0201 - val_accuracy: 0.6154\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.7228 - accuracy: 0.7008 - val_loss: 11.7530 - val_accuracy: 0.5938\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.6820 - accuracy: 0.6842 - val_loss: 10.5241 - val_accuracy: 0.6563\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.8947 - accuracy: 0.7209 - val_loss: 10.2896 - val_accuracy: 0.6310\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 58.4554 - accuracy: 0.7068 - val_loss: 10.5784 - val_accuracy: 0.6803\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 56.4506 - accuracy: 0.7205 - val_loss: 10.4622 - val_accuracy: 0.6942\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 56.5449 - accuracy: 0.7305 - val_loss: 10.4421 - val_accuracy: 0.7199\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.2157 - accuracy: 0.7177 - val_loss: 10.1700 - val_accuracy: 0.7287\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.5937 - accuracy: 0.7285 - val_loss: 11.2328 - val_accuracy: 0.6771\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.9833 - accuracy: 0.7299 - val_loss: 10.5990 - val_accuracy: 0.6926\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 58.5885 - accuracy: 0.7205 - val_loss: 14.2532 - val_accuracy: 0.7284\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 62.1356 - accuracy: 0.7227 - val_loss: 11.4161 - val_accuracy: 0.6575\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.5852 - accuracy: 0.7201 - val_loss: 11.9240 - val_accuracy: 0.6403\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 56.9994 - accuracy: 0.7089 - val_loss: 10.4005 - val_accuracy: 0.7050\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.3549 - accuracy: 0.7255 - val_loss: 10.8127 - val_accuracy: 0.7139\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.2583 - accuracy: 0.7216 - val_loss: 10.7107 - val_accuracy: 0.7242\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.1413 - accuracy: 0.7265 - val_loss: 10.5628 - val_accuracy: 0.7068\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 56.7068 - accuracy: 0.7219 - val_loss: 10.6929 - val_accuracy: 0.6993\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.6703 - accuracy: 0.7250 - val_loss: 12.3002 - val_accuracy: 0.7345\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.5694 - accuracy: 0.7321 - val_loss: 11.0469 - val_accuracy: 0.6979\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 57.2015 - accuracy: 0.7324 - val_loss: 11.3313 - val_accuracy: 0.7067\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.9476 - accuracy: 0.7148 - val_loss: 11.1972 - val_accuracy: 0.7401\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.1121 - accuracy: 0.7390 - val_loss: 11.0583 - val_accuracy: 0.7259\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.4923 - accuracy: 0.7251 - val_loss: 10.8339 - val_accuracy: 0.7254\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.2684 - accuracy: 0.7303 - val_loss: 10.5161 - val_accuracy: 0.7176\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.4915 - accuracy: 0.7307 - val_loss: 10.6505 - val_accuracy: 0.7040\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.7399 - accuracy: 0.7400 - val_loss: 11.5360 - val_accuracy: 0.7052\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.6131 - accuracy: 0.7254 - val_loss: 11.9372 - val_accuracy: 0.7184\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.9452 - accuracy: 0.7421 - val_loss: 9.9930 - val_accuracy: 0.6876\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.4059 - accuracy: 0.7219 - val_loss: 12.1031 - val_accuracy: 0.7288\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 56.3793 - accuracy: 0.7425 - val_loss: 10.5669 - val_accuracy: 0.6684\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.9994 - accuracy: 0.7076 - val_loss: 12.7933 - val_accuracy: 0.7381\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 58.6476 - accuracy: 0.7346 - val_loss: 10.2802 - val_accuracy: 0.6990\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.9577 - accuracy: 0.7166 - val_loss: 10.1824 - val_accuracy: 0.6963\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.8689 - accuracy: 0.7336 - val_loss: 12.4761 - val_accuracy: 0.7140\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.3220 - accuracy: 0.7248 - val_loss: 10.5131 - val_accuracy: 0.7162\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.5166 - accuracy: 0.7227 - val_loss: 11.3159 - val_accuracy: 0.7083\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.3400 - accuracy: 0.7321 - val_loss: 10.8810 - val_accuracy: 0.7337\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.1839 - accuracy: 0.7222 - val_loss: 10.4823 - val_accuracy: 0.7204\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.9428 - accuracy: 0.7369 - val_loss: 10.9764 - val_accuracy: 0.7242\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 54.8494 - accuracy: 0.7371 - val_loss: 10.1798 - val_accuracy: 0.7111\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.9647 - accuracy: 0.7344 - val_loss: 10.9926 - val_accuracy: 0.7208\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.9746 - accuracy: 0.7347 - val_loss: 11.0778 - val_accuracy: 0.7047\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.2706 - accuracy: 0.7301 - val_loss: 10.3738 - val_accuracy: 0.7169\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.2767 - accuracy: 0.7374 - val_loss: 11.5399 - val_accuracy: 0.7198\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 55.6026 - accuracy: 0.7291 - val_loss: 10.1529 - val_accuracy: 0.7158\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.3147 - accuracy: 0.7342 - val_loss: 11.1825 - val_accuracy: 0.6792\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.5091 - accuracy: 0.7210 - val_loss: 10.7760 - val_accuracy: 0.7042\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.7192 - accuracy: 0.7260 - val_loss: 11.2290 - val_accuracy: 0.7257\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 55.8447 - accuracy: 0.7299 - val_loss: 10.9088 - val_accuracy: 0.7162\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.4545 - accuracy: 0.7225 - val_loss: 10.3374 - val_accuracy: 0.7240\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.0971 - accuracy: 0.7345 - val_loss: 10.4541 - val_accuracy: 0.7372\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.4500 - accuracy: 0.7329 - val_loss: 11.6109 - val_accuracy: 0.7102\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.8326 - accuracy: 0.7281 - val_loss: 10.2147 - val_accuracy: 0.7188\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.0605 - accuracy: 0.7268 - val_loss: 12.5037 - val_accuracy: 0.7042\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.8930 - accuracy: 0.7379 - val_loss: 10.2929 - val_accuracy: 0.7173\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.4716 - accuracy: 0.7199 - val_loss: 11.8669 - val_accuracy: 0.7384\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 56.9278 - accuracy: 0.7286 - val_loss: 10.4613 - val_accuracy: 0.7089\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 60.2487 - accuracy: 0.7366 - val_loss: 17.7763 - val_accuracy: 0.7098\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.3545 - accuracy: 0.7306 - val_loss: 12.6509 - val_accuracy: 0.7100\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.0867 - accuracy: 0.7168 - val_loss: 12.5004 - val_accuracy: 0.7140\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 59.9816 - accuracy: 0.7170 - val_loss: 12.0361 - val_accuracy: 0.6678\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.6033 - accuracy: 0.7181 - val_loss: 10.7698 - val_accuracy: 0.7232\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.9053 - accuracy: 0.7268 - val_loss: 10.0951 - val_accuracy: 0.6964\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.3789 - accuracy: 0.7211 - val_loss: 10.2120 - val_accuracy: 0.7166\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.9111 - accuracy: 0.7341 - val_loss: 10.7245 - val_accuracy: 0.7161\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.7880 - accuracy: 0.7230 - val_loss: 9.9785 - val_accuracy: 0.7116\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 56.2065 - accuracy: 0.7391 - val_loss: 10.6659 - val_accuracy: 0.7331\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.6132 - accuracy: 0.7293 - val_loss: 10.6629 - val_accuracy: 0.7229\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.9267 - accuracy: 0.7331 - val_loss: 10.2821 - val_accuracy: 0.6942\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.0922 - accuracy: 0.7354 - val_loss: 10.3289 - val_accuracy: 0.7018\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 56.2679 - accuracy: 0.7353 - val_loss: 12.6290 - val_accuracy: 0.7097\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 55.2707 - accuracy: 0.7389 - val_loss: 10.5395 - val_accuracy: 0.7160\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.0606 - accuracy: 0.7354 - val_loss: 10.3775 - val_accuracy: 0.7192\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.7866 - accuracy: 0.7357 - val_loss: 10.2523 - val_accuracy: 0.7143\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 57.0022 - accuracy: 0.7359 - val_loss: 11.1122 - val_accuracy: 0.7322\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 60.3995 - accuracy: 0.7235 - val_loss: 14.5403 - val_accuracy: 0.7073\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 61.1229 - accuracy: 0.7204 - val_loss: 10.5790 - val_accuracy: 0.7171\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.7518 - accuracy: 0.7217 - val_loss: 10.0665 - val_accuracy: 0.7439\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 61.3357 - accuracy: 0.6902 - val_loss: 12.8608 - val_accuracy: 0.6731\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.0766 - accuracy: 0.7116 - val_loss: 11.7716 - val_accuracy: 0.7098\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 59.0992 - accuracy: 0.7186 - val_loss: 11.2164 - val_accuracy: 0.6576\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 57.5732 - accuracy: 0.7199 - val_loss: 10.8070 - val_accuracy: 0.6578\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.7413 - accuracy: 0.7188 - val_loss: 10.6095 - val_accuracy: 0.6736\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.6118 - accuracy: 0.7251 - val_loss: 11.1944 - val_accuracy: 0.6567\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.7544 - accuracy: 0.7191 - val_loss: 10.3410 - val_accuracy: 0.6334\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.0051 - accuracy: 0.7258 - val_loss: 12.2601 - val_accuracy: 0.6774\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.2260 - accuracy: 0.7174 - val_loss: 10.6887 - val_accuracy: 0.6897\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 57.1683 - accuracy: 0.7376 - val_loss: 11.7147 - val_accuracy: 0.6594\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.3959 - accuracy: 0.7269 - val_loss: 11.0196 - val_accuracy: 0.6582\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.1995 - accuracy: 0.7397 - val_loss: 11.0636 - val_accuracy: 0.7268\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.0346 - accuracy: 0.7297 - val_loss: 10.3435 - val_accuracy: 0.7040\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.7133 - accuracy: 0.7368 - val_loss: 11.5111 - val_accuracy: 0.7134\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.9591 - accuracy: 0.7336 - val_loss: 10.6726 - val_accuracy: 0.6981\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.7626 - accuracy: 0.7372 - val_loss: 11.1810 - val_accuracy: 0.7018\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.6595 - accuracy: 0.7365 - val_loss: 10.9932 - val_accuracy: 0.6947\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.6443 - accuracy: 0.7376 - val_loss: 11.6788 - val_accuracy: 0.6768\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.0245 - accuracy: 0.7404 - val_loss: 11.0888 - val_accuracy: 0.6963\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.9888 - accuracy: 0.7357 - val_loss: 11.2325 - val_accuracy: 0.6960\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.3774 - accuracy: 0.7400 - val_loss: 12.8111 - val_accuracy: 0.6846\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 54.9960 - accuracy: 0.7425 - val_loss: 11.4495 - val_accuracy: 0.6839\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.4438 - accuracy: 0.7357 - val_loss: 12.0031 - val_accuracy: 0.7095\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 55.9310 - accuracy: 0.7384 - val_loss: 12.4744 - val_accuracy: 0.7020\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 55.7359 - accuracy: 0.7374 - val_loss: 11.2163 - val_accuracy: 0.6608\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.1454 - accuracy: 0.7395 - val_loss: 11.2510 - val_accuracy: 0.7254\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.1459 - accuracy: 0.7315 - val_loss: 11.4193 - val_accuracy: 0.7104\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.6916 - accuracy: 0.7383 - val_loss: 11.0107 - val_accuracy: 0.7296\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.9467 - accuracy: 0.7137 - val_loss: 13.3090 - val_accuracy: 0.6741\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.5657 - accuracy: 0.7450 - val_loss: 11.9967 - val_accuracy: 0.6888\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.9456 - accuracy: 0.7355 - val_loss: 11.0944 - val_accuracy: 0.6929\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.4568 - accuracy: 0.7361 - val_loss: 11.1579 - val_accuracy: 0.6994\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.5595 - accuracy: 0.7404 - val_loss: 11.1617 - val_accuracy: 0.6977\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.5730 - accuracy: 0.7417 - val_loss: 11.7633 - val_accuracy: 0.6856\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 54.7985 - accuracy: 0.7436 - val_loss: 11.9412 - val_accuracy: 0.7112\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.8596 - accuracy: 0.7362 - val_loss: 11.2263 - val_accuracy: 0.6981\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 54.6298 - accuracy: 0.7400 - val_loss: 13.4671 - val_accuracy: 0.7058\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.4592 - accuracy: 0.7422 - val_loss: 11.6097 - val_accuracy: 0.6994\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 57.9844 - accuracy: 0.7327 - val_loss: 11.3629 - val_accuracy: 0.6766\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.3680 - accuracy: 0.7246 - val_loss: 11.6782 - val_accuracy: 0.7302\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 56.1577 - accuracy: 0.7382 - val_loss: 11.5777 - val_accuracy: 0.7083\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 55.9360 - accuracy: 0.7299 - val_loss: 11.3278 - val_accuracy: 0.6800\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.8972 - accuracy: 0.7438 - val_loss: 11.9627 - val_accuracy: 0.7068\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.6390 - accuracy: 0.7289 - val_loss: 11.2233 - val_accuracy: 0.7056\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 54.5855 - accuracy: 0.7410 - val_loss: 11.4001 - val_accuracy: 0.6635\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.1682 - accuracy: 0.7349 - val_loss: 11.5649 - val_accuracy: 0.7201\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.0066 - accuracy: 0.7403 - val_loss: 12.3452 - val_accuracy: 0.6817\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.6420 - accuracy: 0.7439 - val_loss: 11.6721 - val_accuracy: 0.6847\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.3995 - accuracy: 0.7431 - val_loss: 11.8479 - val_accuracy: 0.6929\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 57.0263 - accuracy: 0.7335 - val_loss: 13.0550 - val_accuracy: 0.7066\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 58.3185 - accuracy: 0.7354 - val_loss: 11.7619 - val_accuracy: 0.7165\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.1820 - accuracy: 0.7374 - val_loss: 15.4030 - val_accuracy: 0.7150\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 59.4678 - accuracy: 0.7358 - val_loss: 11.7353 - val_accuracy: 0.6829\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.3697 - accuracy: 0.7369 - val_loss: 15.6508 - val_accuracy: 0.6741\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.4014 - accuracy: 0.7304 - val_loss: 11.2516 - val_accuracy: 0.7001\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.4552 - accuracy: 0.7260 - val_loss: 13.3108 - val_accuracy: 0.7172\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.1085 - accuracy: 0.7314 - val_loss: 11.9965 - val_accuracy: 0.7014\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 58.0425 - accuracy: 0.7223 - val_loss: 12.6244 - val_accuracy: 0.6983\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 57.9947 - accuracy: 0.7447 - val_loss: 12.0467 - val_accuracy: 0.6953\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.3428 - accuracy: 0.7387 - val_loss: 13.7287 - val_accuracy: 0.6557\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.3880 - accuracy: 0.7355 - val_loss: 10.9333 - val_accuracy: 0.7104\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.5403 - accuracy: 0.7423 - val_loss: 11.2122 - val_accuracy: 0.7180\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.3789 - accuracy: 0.7350 - val_loss: 11.4891 - val_accuracy: 0.6853\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.0765 - accuracy: 0.7430 - val_loss: 12.2395 - val_accuracy: 0.6870\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.3279 - accuracy: 0.7462 - val_loss: 11.7104 - val_accuracy: 0.6689\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.0619 - accuracy: 0.7377 - val_loss: 11.9858 - val_accuracy: 0.7222\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 55.5047 - accuracy: 0.7426 - val_loss: 11.2547 - val_accuracy: 0.6629\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.6718 - accuracy: 0.7312 - val_loss: 13.0548 - val_accuracy: 0.7221\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.7031 - accuracy: 0.7495 - val_loss: 12.1889 - val_accuracy: 0.6741\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 58.1890 - accuracy: 0.7402 - val_loss: 16.6261 - val_accuracy: 0.7236\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 67.3081 - accuracy: 0.7357 - val_loss: 14.5160 - val_accuracy: 0.6978\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 81.5274 - accuracy: 0.7116 - val_loss: 15.1938 - val_accuracy: 0.6296\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 73.2243 - accuracy: 0.6945 - val_loss: 14.6880 - val_accuracy: 0.6546\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 69.8591 - accuracy: 0.6985 - val_loss: 12.7170 - val_accuracy: 0.6654\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 67.2072 - accuracy: 0.6835 - val_loss: 13.1202 - val_accuracy: 0.6931\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 64.6560 - accuracy: 0.6681 - val_loss: 13.6966 - val_accuracy: 0.6936\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 62.1589 - accuracy: 0.7186 - val_loss: 12.1254 - val_accuracy: 0.6295\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 59.6069 - accuracy: 0.7097 - val_loss: 10.9981 - val_accuracy: 0.6756\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.0775 - accuracy: 0.7060 - val_loss: 11.7307 - val_accuracy: 0.7032\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 57.4661 - accuracy: 0.7234 - val_loss: 12.6838 - val_accuracy: 0.6622\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 56.7395 - accuracy: 0.7218 - val_loss: 11.0575 - val_accuracy: 0.6603\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.5882 - accuracy: 0.7257 - val_loss: 11.7539 - val_accuracy: 0.6958\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.0150 - accuracy: 0.7357 - val_loss: 11.7803 - val_accuracy: 0.6922\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 55.4320 - accuracy: 0.7374 - val_loss: 11.2316 - val_accuracy: 0.6875\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 55.3388 - accuracy: 0.7340 - val_loss: 12.3407 - val_accuracy: 0.7009\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.0885 - accuracy: 0.7353 - val_loss: 11.7193 - val_accuracy: 0.6932\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 54.4789 - accuracy: 0.7356 - val_loss: 11.5718 - val_accuracy: 0.6747\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.3819 - accuracy: 0.7422 - val_loss: 11.3246 - val_accuracy: 0.7096\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.7763 - accuracy: 0.7412 - val_loss: 11.5787 - val_accuracy: 0.7103\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 55.5068 - accuracy: 0.7353 - val_loss: 10.9518 - val_accuracy: 0.7118\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 55.0332 - accuracy: 0.7456 - val_loss: 12.9169 - val_accuracy: 0.6913\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 54.7905 - accuracy: 0.7457 - val_loss: 11.9564 - val_accuracy: 0.7027\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.2814 - accuracy: 0.7354 - val_loss: 11.3137 - val_accuracy: 0.7157\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.1047 - accuracy: 0.7385 - val_loss: 11.9112 - val_accuracy: 0.6973\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.0560 - accuracy: 0.7482 - val_loss: 11.8914 - val_accuracy: 0.6928\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.8113 - accuracy: 0.7442 - val_loss: 11.2452 - val_accuracy: 0.6814\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.7601 - accuracy: 0.7432 - val_loss: 11.5769 - val_accuracy: 0.6913\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.7004 - accuracy: 0.7504 - val_loss: 11.1524 - val_accuracy: 0.7034\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.1898 - accuracy: 0.7452 - val_loss: 12.9005 - val_accuracy: 0.7037\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.3474 - accuracy: 0.7486 - val_loss: 11.9855 - val_accuracy: 0.6875\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 54.2987 - accuracy: 0.7432 - val_loss: 11.5733 - val_accuracy: 0.6982\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 54.0741 - accuracy: 0.7431 - val_loss: 11.7459 - val_accuracy: 0.7099\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.9945 - accuracy: 0.7451 - val_loss: 11.3367 - val_accuracy: 0.6881\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.1608 - accuracy: 0.7463 - val_loss: 12.4214 - val_accuracy: 0.6772\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.5326 - accuracy: 0.7473 - val_loss: 11.6952 - val_accuracy: 0.7081\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.1040 - accuracy: 0.7444 - val_loss: 11.0686 - val_accuracy: 0.7094\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.8888 - accuracy: 0.7403 - val_loss: 11.7498 - val_accuracy: 0.6968\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 54.2304 - accuracy: 0.7457 - val_loss: 12.1224 - val_accuracy: 0.7044\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 54.2610 - accuracy: 0.7453 - val_loss: 11.7990 - val_accuracy: 0.7161\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.1412 - accuracy: 0.7396 - val_loss: 11.6193 - val_accuracy: 0.6907\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 54.0666 - accuracy: 0.7471 - val_loss: 11.3743 - val_accuracy: 0.6850\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.5094 - accuracy: 0.7415 - val_loss: 13.7891 - val_accuracy: 0.6735\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.7999 - accuracy: 0.7452 - val_loss: 11.8955 - val_accuracy: 0.6953\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.6141 - accuracy: 0.7417 - val_loss: 13.9777 - val_accuracy: 0.7035\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 59.7558 - accuracy: 0.7335 - val_loss: 11.8475 - val_accuracy: 0.6881\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 63.1944 - accuracy: 0.7433 - val_loss: 13.9596 - val_accuracy: 0.7159\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 62.0737 - accuracy: 0.7232 - val_loss: 11.1629 - val_accuracy: 0.6931\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 67.1543 - accuracy: 0.7364 - val_loss: 15.9698 - val_accuracy: 0.6721\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 67.0586 - accuracy: 0.7210 - val_loss: 14.7387 - val_accuracy: 0.6327\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 61.9751 - accuracy: 0.7135 - val_loss: 11.8469 - val_accuracy: 0.7045\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 63.0481 - accuracy: 0.7112 - val_loss: 12.0948 - val_accuracy: 0.6858\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 63.6897 - accuracy: 0.7150 - val_loss: 11.2538 - val_accuracy: 0.6917\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 60.8533 - accuracy: 0.7237 - val_loss: 12.5029 - val_accuracy: 0.6963\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 62.9564 - accuracy: 0.7100 - val_loss: 10.4192 - val_accuracy: 0.6759\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.4216 - accuracy: 0.7067 - val_loss: 10.4924 - val_accuracy: 0.6701\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 58.6510 - accuracy: 0.7375 - val_loss: 11.1718 - val_accuracy: 0.6290\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 56.4907 - accuracy: 0.7295 - val_loss: 11.4774 - val_accuracy: 0.7129\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.4863 - accuracy: 0.7363 - val_loss: 11.2156 - val_accuracy: 0.6613\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 55.6221 - accuracy: 0.7445 - val_loss: 11.1422 - val_accuracy: 0.6851\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.4947 - accuracy: 0.7360 - val_loss: 10.6729 - val_accuracy: 0.6850\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.1647 - accuracy: 0.7456 - val_loss: 10.9321 - val_accuracy: 0.6526\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.9310 - accuracy: 0.7450 - val_loss: 11.0272 - val_accuracy: 0.6707\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 53.8230 - accuracy: 0.7406 - val_loss: 10.7893 - val_accuracy: 0.6662\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.0775 - accuracy: 0.7426 - val_loss: 10.7194 - val_accuracy: 0.6613\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.7128 - accuracy: 0.7484 - val_loss: 11.3338 - val_accuracy: 0.6757\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 53.6356 - accuracy: 0.7448 - val_loss: 10.5486 - val_accuracy: 0.6630\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.8835 - accuracy: 0.7461 - val_loss: 10.9231 - val_accuracy: 0.6812\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 54.1589 - accuracy: 0.7463 - val_loss: 10.7403 - val_accuracy: 0.6805\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.7127 - accuracy: 0.7480 - val_loss: 10.9369 - val_accuracy: 0.6708\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.3233 - accuracy: 0.7385 - val_loss: 11.1340 - val_accuracy: 0.6920\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.5149 - accuracy: 0.7488 - val_loss: 11.3905 - val_accuracy: 0.6819\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 54.5045 - accuracy: 0.7423 - val_loss: 10.8863 - val_accuracy: 0.6927\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.1602 - accuracy: 0.7416 - val_loss: 11.7790 - val_accuracy: 0.6984\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.2250 - accuracy: 0.7496 - val_loss: 11.9215 - val_accuracy: 0.6740\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.1046 - accuracy: 0.7475 - val_loss: 11.5304 - val_accuracy: 0.6862\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.8085 - accuracy: 0.7322 - val_loss: 10.9078 - val_accuracy: 0.7035\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.5609 - accuracy: 0.7412 - val_loss: 10.9504 - val_accuracy: 0.7020\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.6035 - accuracy: 0.7466 - val_loss: 11.9138 - val_accuracy: 0.7082\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 53.6746 - accuracy: 0.7446 - val_loss: 11.0735 - val_accuracy: 0.7095\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.2378 - accuracy: 0.7363 - val_loss: 12.5284 - val_accuracy: 0.6940\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.3924 - accuracy: 0.7492 - val_loss: 11.4583 - val_accuracy: 0.6900\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.8293 - accuracy: 0.7394 - val_loss: 10.7663 - val_accuracy: 0.7078\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 53.1501 - accuracy: 0.7461 - val_loss: 11.4382 - val_accuracy: 0.7127\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.3387 - accuracy: 0.7449 - val_loss: 12.2195 - val_accuracy: 0.7111\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.6264 - accuracy: 0.7505 - val_loss: 11.1412 - val_accuracy: 0.6852\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 53.3797 - accuracy: 0.7399 - val_loss: 11.5327 - val_accuracy: 0.7116\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.3938 - accuracy: 0.7509 - val_loss: 11.2010 - val_accuracy: 0.6956\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.8535 - accuracy: 0.7447 - val_loss: 12.0655 - val_accuracy: 0.7087\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 59.2521 - accuracy: 0.7369 - val_loss: 12.9160 - val_accuracy: 0.7084\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 57.6604 - accuracy: 0.7444 - val_loss: 11.9506 - val_accuracy: 0.7126\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.8114 - accuracy: 0.7429 - val_loss: 12.0494 - val_accuracy: 0.7060\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.9416 - accuracy: 0.7242 - val_loss: 11.7263 - val_accuracy: 0.7006\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.9751 - accuracy: 0.7493 - val_loss: 12.2544 - val_accuracy: 0.7113\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 53.8015 - accuracy: 0.7421 - val_loss: 11.4780 - val_accuracy: 0.6985\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 53.6394 - accuracy: 0.7374 - val_loss: 11.0087 - val_accuracy: 0.7106\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.1442 - accuracy: 0.7456 - val_loss: 10.9520 - val_accuracy: 0.7009\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.1372 - accuracy: 0.7478 - val_loss: 11.3506 - val_accuracy: 0.6885\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 54.2141 - accuracy: 0.7443 - val_loss: 11.8171 - val_accuracy: 0.6887\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.0849 - accuracy: 0.7505 - val_loss: 11.2390 - val_accuracy: 0.7077\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 53.4918 - accuracy: 0.7367 - val_loss: 10.9588 - val_accuracy: 0.7025\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.5724 - accuracy: 0.7489 - val_loss: 12.1756 - val_accuracy: 0.7103\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 54.0157 - accuracy: 0.7496 - val_loss: 11.3758 - val_accuracy: 0.7065\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.6731 - accuracy: 0.7456 - val_loss: 13.9659 - val_accuracy: 0.7267\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 58.8088 - accuracy: 0.7335 - val_loss: 12.0072 - val_accuracy: 0.6846\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 64.1725 - accuracy: 0.7285 - val_loss: 16.8329 - val_accuracy: 0.6977\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 69.8635 - accuracy: 0.7372 - val_loss: 11.9329 - val_accuracy: 0.7078\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 66.1808 - accuracy: 0.7016 - val_loss: 13.8363 - val_accuracy: 0.6833\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 64.0449 - accuracy: 0.7079 - val_loss: 11.2432 - val_accuracy: 0.7108\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 61.4190 - accuracy: 0.7059 - val_loss: 12.1644 - val_accuracy: 0.6969\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 59.9622 - accuracy: 0.7381 - val_loss: 11.8319 - val_accuracy: 0.6790\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 61.6929 - accuracy: 0.7254 - val_loss: 12.1211 - val_accuracy: 0.6936\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 58.9697 - accuracy: 0.7254 - val_loss: 11.6020 - val_accuracy: 0.7280\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.3552 - accuracy: 0.7364 - val_loss: 13.4750 - val_accuracy: 0.7191\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 60.2364 - accuracy: 0.7163 - val_loss: 10.7554 - val_accuracy: 0.6960\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 59.8886 - accuracy: 0.7336 - val_loss: 11.5294 - val_accuracy: 0.7004\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.4934 - accuracy: 0.7313 - val_loss: 10.9053 - val_accuracy: 0.7119\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 56.9698 - accuracy: 0.7390 - val_loss: 11.5387 - val_accuracy: 0.7239\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.6350 - accuracy: 0.7405 - val_loss: 11.9962 - val_accuracy: 0.7239\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.3444 - accuracy: 0.7378 - val_loss: 10.3291 - val_accuracy: 0.7356\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.2932 - accuracy: 0.7392 - val_loss: 11.8659 - val_accuracy: 0.7225\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.5798 - accuracy: 0.7451 - val_loss: 13.6776 - val_accuracy: 0.6949\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.1491 - accuracy: 0.7397 - val_loss: 10.9185 - val_accuracy: 0.7165\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.1225 - accuracy: 0.7415 - val_loss: 11.1832 - val_accuracy: 0.7092\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.2583 - accuracy: 0.7499 - val_loss: 11.9053 - val_accuracy: 0.7111\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.0197 - accuracy: 0.7486 - val_loss: 11.1354 - val_accuracy: 0.7098\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.8659 - accuracy: 0.7495 - val_loss: 11.3713 - val_accuracy: 0.7161\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.0463 - accuracy: 0.7509 - val_loss: 11.7618 - val_accuracy: 0.7200\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.7918 - accuracy: 0.7517 - val_loss: 11.2526 - val_accuracy: 0.7090\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 52.7313 - accuracy: 0.7523 - val_loss: 11.6650 - val_accuracy: 0.7125\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.0572 - accuracy: 0.7517 - val_loss: 12.7734 - val_accuracy: 0.7135\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.1783 - accuracy: 0.7503 - val_loss: 11.7693 - val_accuracy: 0.7151\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.2799 - accuracy: 0.7476 - val_loss: 11.6415 - val_accuracy: 0.7011\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 54.6396 - accuracy: 0.7531 - val_loss: 12.7552 - val_accuracy: 0.7176\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.4043 - accuracy: 0.7475 - val_loss: 11.4322 - val_accuracy: 0.6932\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 57.6308 - accuracy: 0.7415 - val_loss: 11.0715 - val_accuracy: 0.7267\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 55.7144 - accuracy: 0.7463 - val_loss: 13.6207 - val_accuracy: 0.7158\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 58.2056 - accuracy: 0.7396 - val_loss: 11.4225 - val_accuracy: 0.7133\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 57.1289 - accuracy: 0.7449 - val_loss: 11.0083 - val_accuracy: 0.7170\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.7434 - accuracy: 0.7417 - val_loss: 12.1125 - val_accuracy: 0.7103\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.5336 - accuracy: 0.7422 - val_loss: 11.2628 - val_accuracy: 0.7225\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 55.8918 - accuracy: 0.7361 - val_loss: 11.4809 - val_accuracy: 0.7226\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.6120 - accuracy: 0.7433 - val_loss: 12.3301 - val_accuracy: 0.7117\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.7798 - accuracy: 0.7433 - val_loss: 11.5069 - val_accuracy: 0.7085\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 54.4658 - accuracy: 0.7397 - val_loss: 11.1472 - val_accuracy: 0.7066\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.4505 - accuracy: 0.7489 - val_loss: 12.3401 - val_accuracy: 0.7077\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 53.8030 - accuracy: 0.7455 - val_loss: 12.8263 - val_accuracy: 0.7271\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.0033 - accuracy: 0.7397 - val_loss: 12.0746 - val_accuracy: 0.7281\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.8352 - accuracy: 0.7443 - val_loss: 11.1664 - val_accuracy: 0.6999\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.4350 - accuracy: 0.7462 - val_loss: 14.0117 - val_accuracy: 0.7146\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 54.3099 - accuracy: 0.7493 - val_loss: 12.0669 - val_accuracy: 0.7170\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 53.8382 - accuracy: 0.7447 - val_loss: 11.3713 - val_accuracy: 0.7042\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 55.2729 - accuracy: 0.7462 - val_loss: 14.3297 - val_accuracy: 0.7206\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.8522 - accuracy: 0.7506 - val_loss: 13.0168 - val_accuracy: 0.7099\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.7144 - accuracy: 0.7427 - val_loss: 11.5965 - val_accuracy: 0.7093\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.3003 - accuracy: 0.7436 - val_loss: 12.4781 - val_accuracy: 0.7061\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 52.7872 - accuracy: 0.7534 - val_loss: 11.9591 - val_accuracy: 0.7108\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.5884 - accuracy: 0.7476 - val_loss: 11.3634 - val_accuracy: 0.7140\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.1730 - accuracy: 0.7480 - val_loss: 11.4772 - val_accuracy: 0.7192\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 52.7339 - accuracy: 0.7542 - val_loss: 11.8095 - val_accuracy: 0.7156\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 52.6101 - accuracy: 0.7485 - val_loss: 12.2882 - val_accuracy: 0.7157\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.7395 - accuracy: 0.7506 - val_loss: 11.4205 - val_accuracy: 0.7173\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.4777 - accuracy: 0.7504 - val_loss: 12.0911 - val_accuracy: 0.7195\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.3203 - accuracy: 0.7556 - val_loss: 14.1473 - val_accuracy: 0.7052\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.4916 - accuracy: 0.7482 - val_loss: 13.5195 - val_accuracy: 0.6981\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 53.0616 - accuracy: 0.7475 - val_loss: 11.7140 - val_accuracy: 0.7058\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.9158 - accuracy: 0.7534 - val_loss: 11.7772 - val_accuracy: 0.7122\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.7445 - accuracy: 0.7463 - val_loss: 11.9873 - val_accuracy: 0.7256\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 52.6797 - accuracy: 0.7526 - val_loss: 12.2802 - val_accuracy: 0.7266\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.1705 - accuracy: 0.7485 - val_loss: 12.4757 - val_accuracy: 0.7086\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.4280 - accuracy: 0.7536 - val_loss: 12.1003 - val_accuracy: 0.7094\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 55.0141 - accuracy: 0.7458 - val_loss: 12.2435 - val_accuracy: 0.7186\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.8590 - accuracy: 0.7481 - val_loss: 12.6751 - val_accuracy: 0.7143\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 54.2179 - accuracy: 0.7441 - val_loss: 12.7747 - val_accuracy: 0.7274\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 55.4405 - accuracy: 0.7518 - val_loss: 12.2486 - val_accuracy: 0.7239\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.6892 - accuracy: 0.7409 - val_loss: 12.5521 - val_accuracy: 0.7174\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.0856 - accuracy: 0.7444 - val_loss: 12.1808 - val_accuracy: 0.7135\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 52.5056 - accuracy: 0.7469 - val_loss: 12.3956 - val_accuracy: 0.7136\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 52.7118 - accuracy: 0.7558 - val_loss: 11.9450 - val_accuracy: 0.7032\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 52.5736 - accuracy: 0.7488 - val_loss: 13.1534 - val_accuracy: 0.7253\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 52.2123 - accuracy: 0.7502 - val_loss: 11.9234 - val_accuracy: 0.7138\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 52.3572 - accuracy: 0.7520 - val_loss: 12.3049 - val_accuracy: 0.7230\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.5003 - accuracy: 0.7508 - val_loss: 12.2466 - val_accuracy: 0.7129\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 52.6688 - accuracy: 0.7523 - val_loss: 12.7686 - val_accuracy: 0.7183\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.0052 - accuracy: 0.7452 - val_loss: 12.1226 - val_accuracy: 0.7153\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.2497 - accuracy: 0.7529 - val_loss: 12.0766 - val_accuracy: 0.7109\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.0873 - accuracy: 0.7519 - val_loss: 15.9093 - val_accuracy: 0.7183\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.6139 - accuracy: 0.7514 - val_loss: 12.7375 - val_accuracy: 0.7151\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.8636 - accuracy: 0.7420 - val_loss: 11.9892 - val_accuracy: 0.7082\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.9186 - accuracy: 0.7490 - val_loss: 11.8599 - val_accuracy: 0.7131\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.9705 - accuracy: 0.7525 - val_loss: 12.4657 - val_accuracy: 0.7143\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 52.9937 - accuracy: 0.7531 - val_loss: 12.4614 - val_accuracy: 0.7190\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 52.6315 - accuracy: 0.7470 - val_loss: 13.1931 - val_accuracy: 0.7124\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.5071 - accuracy: 0.7576 - val_loss: 13.1710 - val_accuracy: 0.7103\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.2364 - accuracy: 0.7504 - val_loss: 12.4055 - val_accuracy: 0.7170\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.8692 - accuracy: 0.7575 - val_loss: 12.5957 - val_accuracy: 0.6948\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 54.2465 - accuracy: 0.7510 - val_loss: 12.2822 - val_accuracy: 0.7015\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.2302 - accuracy: 0.7497 - val_loss: 13.8980 - val_accuracy: 0.7263\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 53.3362 - accuracy: 0.7511 - val_loss: 12.2116 - val_accuracy: 0.7282\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.5243 - accuracy: 0.7512 - val_loss: 12.5823 - val_accuracy: 0.7265\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 52.4156 - accuracy: 0.7511 - val_loss: 12.5575 - val_accuracy: 0.7144\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 52.1743 - accuracy: 0.7567 - val_loss: 12.4172 - val_accuracy: 0.7176\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 51.9641 - accuracy: 0.7570 - val_loss: 12.4688 - val_accuracy: 0.7150\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 51.9507 - accuracy: 0.7487 - val_loss: 12.6223 - val_accuracy: 0.7246\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 52.0949 - accuracy: 0.7588 - val_loss: 12.1687 - val_accuracy: 0.7097\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 52.2059 - accuracy: 0.7560 - val_loss: 12.1420 - val_accuracy: 0.7152\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 52.2483 - accuracy: 0.7579 - val_loss: 12.8154 - val_accuracy: 0.7226\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.2083 - accuracy: 0.7535 - val_loss: 12.6183 - val_accuracy: 0.7192\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.4871 - accuracy: 0.7565 - val_loss: 13.7620 - val_accuracy: 0.7048\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.0211 - accuracy: 0.7560 - val_loss: 12.8170 - val_accuracy: 0.7263\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.6293 - accuracy: 0.7483 - val_loss: 13.1090 - val_accuracy: 0.7134\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 52.8383 - accuracy: 0.7511 - val_loss: 12.7785 - val_accuracy: 0.7196\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 52.9637 - accuracy: 0.7504 - val_loss: 13.1578 - val_accuracy: 0.7206\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.6349 - accuracy: 0.7529 - val_loss: 13.5500 - val_accuracy: 0.7038\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 54.2558 - accuracy: 0.7562 - val_loss: 13.4757 - val_accuracy: 0.7248\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 53.1923 - accuracy: 0.7405 - val_loss: 12.5704 - val_accuracy: 0.7125\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.6784 - accuracy: 0.7520 - val_loss: 11.9416 - val_accuracy: 0.7204\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.1907 - accuracy: 0.7537 - val_loss: 13.4225 - val_accuracy: 0.6961\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 52.4591 - accuracy: 0.7512 - val_loss: 13.4780 - val_accuracy: 0.7218\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 52.2989 - accuracy: 0.7485 - val_loss: 13.2278 - val_accuracy: 0.7118\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 52.4697 - accuracy: 0.7552 - val_loss: 12.6144 - val_accuracy: 0.7078\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 52.4155 - accuracy: 0.7516 - val_loss: 13.0786 - val_accuracy: 0.7153\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.2336 - accuracy: 0.7538 - val_loss: 14.3855 - val_accuracy: 0.7160\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 53.7083 - accuracy: 0.7520 - val_loss: 12.7739 - val_accuracy: 0.7295\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 52.7767 - accuracy: 0.7534 - val_loss: 13.3224 - val_accuracy: 0.7117\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.2530 - accuracy: 0.7439 - val_loss: 13.2189 - val_accuracy: 0.7152\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.2903 - accuracy: 0.7545 - val_loss: 12.4930 - val_accuracy: 0.7246\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 53.5416 - accuracy: 0.7549 - val_loss: 13.9933 - val_accuracy: 0.7043\n"
          ]
        }
      ],
      "source": [
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=500, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLLA-FJGvQ5A"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzhoDDwXv04m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "# Define the model\n",
        "model= tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model with a learning rate of 0.01 and 100 samples per epoch\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_absolute_error', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erd_5r4Dv5Ga",
        "outputId": "c45ed2ba-c6da-4652-e398-6a2cd727bd7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 1s 66ms/step - loss: 28.5877 - accuracy: 0.0513 - val_loss: 10.0629 - val_accuracy: 0.3710\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 18.5869 - accuracy: 0.1559 - val_loss: 6.9446 - val_accuracy: 3.6892e-04\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.3435 - accuracy: 0.2385 - val_loss: 5.1376 - val_accuracy: 0.4249\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.5589 - accuracy: 0.2074 - val_loss: 4.4122 - val_accuracy: 0.0051\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8.0257 - accuracy: 0.1922 - val_loss: 3.7780 - val_accuracy: 0.0578\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 7.1756 - accuracy: 0.1686 - val_loss: 3.2980 - val_accuracy: 0.0898\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 6.2574 - accuracy: 0.2174 - val_loss: 2.4587 - val_accuracy: 0.0283\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5.2777 - accuracy: 0.3038 - val_loss: 2.4092 - val_accuracy: 0.0762\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 4.8412 - accuracy: 0.3439 - val_loss: 2.1483 - val_accuracy: 0.2100\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.7790 - accuracy: 0.5032 - val_loss: 1.9131 - val_accuracy: 0.1902\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.4209 - accuracy: 0.5382 - val_loss: 1.7070 - val_accuracy: 0.5684\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.2081 - accuracy: 0.5742 - val_loss: 1.6734 - val_accuracy: 0.4981\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.5631 - accuracy: 0.6215 - val_loss: 1.5939 - val_accuracy: 0.5699\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 4.8758 - accuracy: 0.6443 - val_loss: 1.9073 - val_accuracy: 0.5385\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2274 - accuracy: 0.6802 - val_loss: 1.8147 - val_accuracy: 0.5311\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.7801 - accuracy: 0.6861 - val_loss: 1.9033 - val_accuracy: 0.4717\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.2654 - accuracy: 0.6467 - val_loss: 1.7097 - val_accuracy: 0.5377\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.3381 - accuracy: 0.6541 - val_loss: 1.7055 - val_accuracy: 0.5319\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.1459 - accuracy: 0.6502 - val_loss: 1.5660 - val_accuracy: 0.5936\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.9562 - accuracy: 0.6849 - val_loss: 1.7924 - val_accuracy: 0.5368\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.8848 - accuracy: 0.6911 - val_loss: 1.7367 - val_accuracy: 0.5424\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.8557 - accuracy: 0.6808 - val_loss: 1.6644 - val_accuracy: 0.5608\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7522 - accuracy: 0.6860 - val_loss: 1.5581 - val_accuracy: 0.5614\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.6937 - accuracy: 0.6799 - val_loss: 1.6565 - val_accuracy: 0.5713\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7296 - accuracy: 0.7035 - val_loss: 1.7615 - val_accuracy: 0.5622\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7739 - accuracy: 0.7122 - val_loss: 1.4646 - val_accuracy: 0.5676\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.6563 - accuracy: 0.6925 - val_loss: 1.7145 - val_accuracy: 0.5586\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.6825 - accuracy: 0.7172 - val_loss: 1.5324 - val_accuracy: 0.6038\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.6459 - accuracy: 0.7070 - val_loss: 1.4844 - val_accuracy: 0.6066\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.7971 - accuracy: 0.7186 - val_loss: 2.0650 - val_accuracy: 0.5410\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.9594 - accuracy: 0.7069 - val_loss: 1.8602 - val_accuracy: 0.5186\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.8588 - accuracy: 0.6873 - val_loss: 1.4908 - val_accuracy: 0.5644\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.9074 - accuracy: 0.6892 - val_loss: 1.8971 - val_accuracy: 0.6067\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7454 - accuracy: 0.7026 - val_loss: 1.6442 - val_accuracy: 0.6130\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.6925 - accuracy: 0.6952 - val_loss: 1.5807 - val_accuracy: 0.5938\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.8080 - accuracy: 0.7198 - val_loss: 1.7706 - val_accuracy: 0.5469\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.9829 - accuracy: 0.7227 - val_loss: 1.5924 - val_accuracy: 0.5854\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.9042 - accuracy: 0.6972 - val_loss: 2.0832 - val_accuracy: 0.6382\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.1833 - accuracy: 0.7035 - val_loss: 1.8091 - val_accuracy: 0.6096\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.9932 - accuracy: 0.7131 - val_loss: 1.5573 - val_accuracy: 0.5717\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.6439 - accuracy: 0.7062 - val_loss: 1.4009 - val_accuracy: 0.6404\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.6578 - accuracy: 0.7130 - val_loss: 1.8645 - val_accuracy: 0.5835\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.6625 - accuracy: 0.7041 - val_loss: 1.3942 - val_accuracy: 0.6268\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.7391 - accuracy: 0.6957 - val_loss: 1.7277 - val_accuracy: 0.6239\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7826 - accuracy: 0.7204 - val_loss: 1.4228 - val_accuracy: 0.6621\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.9379 - accuracy: 0.7014 - val_loss: 2.4706 - val_accuracy: 0.6283\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 4.2287 - accuracy: 0.6959 - val_loss: 1.4404 - val_accuracy: 0.6257\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.1677 - accuracy: 0.7180 - val_loss: 1.6372 - val_accuracy: 0.5663\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.9066 - accuracy: 0.6990 - val_loss: 1.5192 - val_accuracy: 0.6632\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.6882 - accuracy: 0.6872 - val_loss: 1.5138 - val_accuracy: 0.6526\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.6363 - accuracy: 0.7073 - val_loss: 1.3978 - val_accuracy: 0.6679\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.6108 - accuracy: 0.7091 - val_loss: 1.5294 - val_accuracy: 0.6415\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5197 - accuracy: 0.7207 - val_loss: 1.4712 - val_accuracy: 0.6601\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5064 - accuracy: 0.7234 - val_loss: 1.4849 - val_accuracy: 0.6679\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5257 - accuracy: 0.7245 - val_loss: 1.5132 - val_accuracy: 0.6733\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5802 - accuracy: 0.7228 - val_loss: 1.4809 - val_accuracy: 0.6413\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.6480 - accuracy: 0.7224 - val_loss: 1.4843 - val_accuracy: 0.6600\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.8850 - accuracy: 0.7246 - val_loss: 2.2653 - val_accuracy: 0.6420\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.1088 - accuracy: 0.7293 - val_loss: 1.3816 - val_accuracy: 0.6769\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.8298 - accuracy: 0.7061 - val_loss: 1.7393 - val_accuracy: 0.6049\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.7732 - accuracy: 0.7043 - val_loss: 1.8273 - val_accuracy: 0.6006\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.8076 - accuracy: 0.6838 - val_loss: 1.7760 - val_accuracy: 0.5826\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.6568 - accuracy: 0.6927 - val_loss: 1.4028 - val_accuracy: 0.6735\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.6198 - accuracy: 0.7082 - val_loss: 1.5805 - val_accuracy: 0.6801\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.5957 - accuracy: 0.7002 - val_loss: 1.6664 - val_accuracy: 0.5090\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.6285 - accuracy: 0.6831 - val_loss: 1.4683 - val_accuracy: 0.6555\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.5555 - accuracy: 0.7107 - val_loss: 1.4508 - val_accuracy: 0.6874\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5933 - accuracy: 0.6972 - val_loss: 1.5992 - val_accuracy: 0.6292\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.5074 - accuracy: 0.7214 - val_loss: 1.5795 - val_accuracy: 0.6653\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.5225 - accuracy: 0.7158 - val_loss: 1.3716 - val_accuracy: 0.6574\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5477 - accuracy: 0.7157 - val_loss: 1.9845 - val_accuracy: 0.6624\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.7318 - accuracy: 0.7078 - val_loss: 1.4276 - val_accuracy: 0.6189\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.5503 - accuracy: 0.7130 - val_loss: 1.5087 - val_accuracy: 0.6133\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5136 - accuracy: 0.6997 - val_loss: 1.4477 - val_accuracy: 0.6713\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5087 - accuracy: 0.7168 - val_loss: 1.5089 - val_accuracy: 0.6839\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.5233 - accuracy: 0.7133 - val_loss: 1.4082 - val_accuracy: 0.6697\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4477 - accuracy: 0.7153 - val_loss: 1.3463 - val_accuracy: 0.6856\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4815 - accuracy: 0.7192 - val_loss: 1.4054 - val_accuracy: 0.6910\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4153 - accuracy: 0.7191 - val_loss: 1.4836 - val_accuracy: 0.6788\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4076 - accuracy: 0.7241 - val_loss: 1.3446 - val_accuracy: 0.6823\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4595 - accuracy: 0.7163 - val_loss: 1.4612 - val_accuracy: 0.6708\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4460 - accuracy: 0.7204 - val_loss: 1.3814 - val_accuracy: 0.6841\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4210 - accuracy: 0.7275 - val_loss: 1.4417 - val_accuracy: 0.6898\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4122 - accuracy: 0.7236 - val_loss: 1.5011 - val_accuracy: 0.6813\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3655 - accuracy: 0.7215 - val_loss: 1.4771 - val_accuracy: 0.6821\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3919 - accuracy: 0.7250 - val_loss: 1.3334 - val_accuracy: 0.6903\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.4296 - accuracy: 0.7244 - val_loss: 1.3657 - val_accuracy: 0.6882\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3928 - accuracy: 0.7230 - val_loss: 1.4947 - val_accuracy: 0.6887\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3669 - accuracy: 0.7240 - val_loss: 1.5586 - val_accuracy: 0.6936\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3924 - accuracy: 0.7248 - val_loss: 1.5851 - val_accuracy: 0.6910\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.4253 - accuracy: 0.7265 - val_loss: 1.3250 - val_accuracy: 0.6811\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3992 - accuracy: 0.7233 - val_loss: 1.4180 - val_accuracy: 0.6839\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4356 - accuracy: 0.7112 - val_loss: 1.3546 - val_accuracy: 0.6992\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3971 - accuracy: 0.7229 - val_loss: 1.3698 - val_accuracy: 0.7062\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3813 - accuracy: 0.7297 - val_loss: 1.5884 - val_accuracy: 0.6921\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4152 - accuracy: 0.7266 - val_loss: 1.7353 - val_accuracy: 0.6720\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4495 - accuracy: 0.7222 - val_loss: 1.3826 - val_accuracy: 0.6893\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4001 - accuracy: 0.7217 - val_loss: 1.4555 - val_accuracy: 0.6969\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5120 - accuracy: 0.7267 - val_loss: 1.3398 - val_accuracy: 0.6886\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.6046 - accuracy: 0.7176 - val_loss: 1.3233 - val_accuracy: 0.7028\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.6790 - accuracy: 0.7421 - val_loss: 1.9489 - val_accuracy: 0.6884\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.9797 - accuracy: 0.7255 - val_loss: 1.4302 - val_accuracy: 0.6768\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.9776 - accuracy: 0.7085 - val_loss: 2.1010 - val_accuracy: 0.6268\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.1011 - accuracy: 0.7093 - val_loss: 1.7908 - val_accuracy: 0.6093\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.9983 - accuracy: 0.6988 - val_loss: 2.0997 - val_accuracy: 0.6142\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.6614 - accuracy: 0.7114 - val_loss: 1.3578 - val_accuracy: 0.7044\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5321 - accuracy: 0.6955 - val_loss: 1.5678 - val_accuracy: 0.6982\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4947 - accuracy: 0.7147 - val_loss: 1.3162 - val_accuracy: 0.6993\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4940 - accuracy: 0.7259 - val_loss: 1.8059 - val_accuracy: 0.7036\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5677 - accuracy: 0.7188 - val_loss: 1.4006 - val_accuracy: 0.6909\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5328 - accuracy: 0.7119 - val_loss: 1.3255 - val_accuracy: 0.7008\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4173 - accuracy: 0.7335 - val_loss: 1.3417 - val_accuracy: 0.6887\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4179 - accuracy: 0.7147 - val_loss: 1.5686 - val_accuracy: 0.7026\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4232 - accuracy: 0.7200 - val_loss: 1.6583 - val_accuracy: 0.6977\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5482 - accuracy: 0.7265 - val_loss: 1.3720 - val_accuracy: 0.7075\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7045 - accuracy: 0.7314 - val_loss: 1.6285 - val_accuracy: 0.6945\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.8763 - accuracy: 0.7090 - val_loss: 1.3795 - val_accuracy: 0.7022\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.8159 - accuracy: 0.7328 - val_loss: 1.5575 - val_accuracy: 0.6424\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5143 - accuracy: 0.7173 - val_loss: 1.3429 - val_accuracy: 0.6847\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4582 - accuracy: 0.7186 - val_loss: 1.3207 - val_accuracy: 0.6938\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4312 - accuracy: 0.7264 - val_loss: 1.7228 - val_accuracy: 0.7019\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4590 - accuracy: 0.7247 - val_loss: 1.3768 - val_accuracy: 0.7017\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.4176 - accuracy: 0.7186 - val_loss: 1.3632 - val_accuracy: 0.6960\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4746 - accuracy: 0.7310 - val_loss: 1.4870 - val_accuracy: 0.6968\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5235 - accuracy: 0.7177 - val_loss: 1.3836 - val_accuracy: 0.6938\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3719 - accuracy: 0.7282 - val_loss: 1.3376 - val_accuracy: 0.6985\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3035 - accuracy: 0.7248 - val_loss: 1.6256 - val_accuracy: 0.6947\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3171 - accuracy: 0.7406 - val_loss: 1.4549 - val_accuracy: 0.6990\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3337 - accuracy: 0.7349 - val_loss: 1.3781 - val_accuracy: 0.6948\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3384 - accuracy: 0.7336 - val_loss: 1.4040 - val_accuracy: 0.6708\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3868 - accuracy: 0.7339 - val_loss: 1.4873 - val_accuracy: 0.6787\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3756 - accuracy: 0.7175 - val_loss: 1.3972 - val_accuracy: 0.7012\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3160 - accuracy: 0.7335 - val_loss: 1.4547 - val_accuracy: 0.6975\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3274 - accuracy: 0.7289 - val_loss: 1.7219 - val_accuracy: 0.7084\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5088 - accuracy: 0.7315 - val_loss: 1.3468 - val_accuracy: 0.6911\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.7284 - accuracy: 0.7357 - val_loss: 2.1146 - val_accuracy: 0.7007\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 4.0279 - accuracy: 0.7377 - val_loss: 1.4269 - val_accuracy: 0.6844\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 3.6447 - accuracy: 0.7117 - val_loss: 1.3755 - val_accuracy: 0.6848\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3616 - accuracy: 0.7259 - val_loss: 1.5958 - val_accuracy: 0.6906\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4059 - accuracy: 0.7182 - val_loss: 1.5022 - val_accuracy: 0.6896\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3757 - accuracy: 0.7286 - val_loss: 1.3068 - val_accuracy: 0.6979\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3419 - accuracy: 0.7420 - val_loss: 1.5125 - val_accuracy: 0.6903\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.4055 - accuracy: 0.7336 - val_loss: 1.4902 - val_accuracy: 0.7062\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.3773 - accuracy: 0.7371 - val_loss: 1.3968 - val_accuracy: 0.6891\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3379 - accuracy: 0.7398 - val_loss: 1.4101 - val_accuracy: 0.6886\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3315 - accuracy: 0.7339 - val_loss: 1.6729 - val_accuracy: 0.6935\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4399 - accuracy: 0.7283 - val_loss: 1.3568 - val_accuracy: 0.7071\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4777 - accuracy: 0.7305 - val_loss: 1.4824 - val_accuracy: 0.6711\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.5162 - accuracy: 0.7265 - val_loss: 1.6257 - val_accuracy: 0.7045\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5054 - accuracy: 0.7286 - val_loss: 1.5027 - val_accuracy: 0.7087\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5114 - accuracy: 0.7376 - val_loss: 1.6852 - val_accuracy: 0.6894\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5195 - accuracy: 0.7160 - val_loss: 1.3465 - val_accuracy: 0.6911\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.7861 - accuracy: 0.7286 - val_loss: 1.5599 - val_accuracy: 0.7012\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.8662 - accuracy: 0.7250 - val_loss: 1.4469 - val_accuracy: 0.6761\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.7023 - accuracy: 0.7170 - val_loss: 1.7781 - val_accuracy: 0.6642\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.5819 - accuracy: 0.7191 - val_loss: 1.4179 - val_accuracy: 0.6784\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4529 - accuracy: 0.7242 - val_loss: 1.4925 - val_accuracy: 0.6702\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3534 - accuracy: 0.7202 - val_loss: 1.4370 - val_accuracy: 0.6881\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3523 - accuracy: 0.7391 - val_loss: 1.6992 - val_accuracy: 0.6884\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4376 - accuracy: 0.7316 - val_loss: 1.5457 - val_accuracy: 0.7230\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4145 - accuracy: 0.7257 - val_loss: 1.3508 - val_accuracy: 0.7250\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4609 - accuracy: 0.7339 - val_loss: 1.5179 - val_accuracy: 0.7286\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3745 - accuracy: 0.7282 - val_loss: 1.5950 - val_accuracy: 0.7213\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3956 - accuracy: 0.7113 - val_loss: 1.4046 - val_accuracy: 0.6716\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3882 - accuracy: 0.7359 - val_loss: 1.5245 - val_accuracy: 0.6935\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3562 - accuracy: 0.7464 - val_loss: 1.5227 - val_accuracy: 0.6996\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4381 - accuracy: 0.7302 - val_loss: 1.5134 - val_accuracy: 0.6149\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3126 - accuracy: 0.7405 - val_loss: 1.3822 - val_accuracy: 0.7015\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3214 - accuracy: 0.7382 - val_loss: 1.4447 - val_accuracy: 0.6926\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2988 - accuracy: 0.7365 - val_loss: 1.6088 - val_accuracy: 0.6848\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2820 - accuracy: 0.7437 - val_loss: 1.4485 - val_accuracy: 0.6909\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2800 - accuracy: 0.7375 - val_loss: 1.3563 - val_accuracy: 0.7143\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3866 - accuracy: 0.7487 - val_loss: 1.3263 - val_accuracy: 0.6922\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3407 - accuracy: 0.7496 - val_loss: 1.3864 - val_accuracy: 0.6862\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2676 - accuracy: 0.7421 - val_loss: 1.5010 - val_accuracy: 0.6937\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 3.3252 - accuracy: 0.7440 - val_loss: 1.5665 - val_accuracy: 0.6939\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2745 - accuracy: 0.7431 - val_loss: 1.3898 - val_accuracy: 0.6920\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.3310 - accuracy: 0.7451 - val_loss: 1.4163 - val_accuracy: 0.6822\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5413 - accuracy: 0.7284 - val_loss: 1.6575 - val_accuracy: 0.6927\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4557 - accuracy: 0.7460 - val_loss: 1.5294 - val_accuracy: 0.6865\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4261 - accuracy: 0.7431 - val_loss: 1.4673 - val_accuracy: 0.6800\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3926 - accuracy: 0.7260 - val_loss: 1.9252 - val_accuracy: 0.6921\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.3785 - accuracy: 0.7210 - val_loss: 1.5641 - val_accuracy: 0.6980\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3225 - accuracy: 0.7274 - val_loss: 1.3936 - val_accuracy: 0.7011\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2713 - accuracy: 0.7445 - val_loss: 1.4160 - val_accuracy: 0.6940\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3012 - accuracy: 0.7425 - val_loss: 1.3823 - val_accuracy: 0.6929\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.3971 - accuracy: 0.7367 - val_loss: 1.3804 - val_accuracy: 0.6905\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4286 - accuracy: 0.7277 - val_loss: 1.5039 - val_accuracy: 0.6938\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3376 - accuracy: 0.7402 - val_loss: 1.5888 - val_accuracy: 0.6922\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2567 - accuracy: 0.7461 - val_loss: 1.4983 - val_accuracy: 0.6843\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2649 - accuracy: 0.7401 - val_loss: 1.3695 - val_accuracy: 0.6755\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.3585 - accuracy: 0.7462 - val_loss: 1.3518 - val_accuracy: 0.6984\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2618 - accuracy: 0.7430 - val_loss: 1.5917 - val_accuracy: 0.6831\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2696 - accuracy: 0.7329 - val_loss: 1.3812 - val_accuracy: 0.7090\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3684 - accuracy: 0.7415 - val_loss: 1.3637 - val_accuracy: 0.7079\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.3945 - accuracy: 0.7415 - val_loss: 1.3762 - val_accuracy: 0.7006\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5652 - accuracy: 0.7418 - val_loss: 1.5959 - val_accuracy: 0.6702\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.9721 - accuracy: 0.7153 - val_loss: 2.1656 - val_accuracy: 0.7129\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.9052 - accuracy: 0.7175 - val_loss: 1.5511 - val_accuracy: 0.6748\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.8738 - accuracy: 0.7257 - val_loss: 1.4575 - val_accuracy: 0.6604\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.6599 - accuracy: 0.7065 - val_loss: 1.6180 - val_accuracy: 0.6465\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5261 - accuracy: 0.7189 - val_loss: 1.7872 - val_accuracy: 0.6621\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4566 - accuracy: 0.7327 - val_loss: 1.3234 - val_accuracy: 0.7205\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4882 - accuracy: 0.7255 - val_loss: 1.4141 - val_accuracy: 0.7126\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4630 - accuracy: 0.7279 - val_loss: 1.3842 - val_accuracy: 0.7095\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3577 - accuracy: 0.7511 - val_loss: 1.3114 - val_accuracy: 0.6880\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3230 - accuracy: 0.7450 - val_loss: 1.5091 - val_accuracy: 0.7163\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3021 - accuracy: 0.7377 - val_loss: 1.5442 - val_accuracy: 0.7050\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2459 - accuracy: 0.7503 - val_loss: 1.5222 - val_accuracy: 0.6998\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2422 - accuracy: 0.7454 - val_loss: 1.4287 - val_accuracy: 0.7105\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2655 - accuracy: 0.7477 - val_loss: 1.4171 - val_accuracy: 0.7077\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2480 - accuracy: 0.7359 - val_loss: 1.4211 - val_accuracy: 0.6856\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2793 - accuracy: 0.7458 - val_loss: 1.4538 - val_accuracy: 0.7066\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.4185 - accuracy: 0.7439 - val_loss: 1.4077 - val_accuracy: 0.7106\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.3248 - accuracy: 0.7469 - val_loss: 1.5153 - val_accuracy: 0.7108\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3957 - accuracy: 0.7451 - val_loss: 1.3099 - val_accuracy: 0.7000\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4523 - accuracy: 0.7368 - val_loss: 1.4214 - val_accuracy: 0.6857\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2992 - accuracy: 0.7496 - val_loss: 1.5983 - val_accuracy: 0.6772\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3240 - accuracy: 0.7423 - val_loss: 1.5270 - val_accuracy: 0.7034\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.3071 - accuracy: 0.7365 - val_loss: 1.3475 - val_accuracy: 0.6769\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3943 - accuracy: 0.7522 - val_loss: 1.3617 - val_accuracy: 0.7039\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3140 - accuracy: 0.7448 - val_loss: 1.5306 - val_accuracy: 0.6790\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2564 - accuracy: 0.7359 - val_loss: 1.3334 - val_accuracy: 0.7041\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2564 - accuracy: 0.7485 - val_loss: 1.4666 - val_accuracy: 0.7131\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2427 - accuracy: 0.7481 - val_loss: 1.3674 - val_accuracy: 0.6998\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2443 - accuracy: 0.7516 - val_loss: 1.5493 - val_accuracy: 0.7036\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2292 - accuracy: 0.7446 - val_loss: 1.5618 - val_accuracy: 0.7087\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2808 - accuracy: 0.7526 - val_loss: 1.3133 - val_accuracy: 0.7120\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2777 - accuracy: 0.7470 - val_loss: 1.3316 - val_accuracy: 0.6738\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1789 - accuracy: 0.7511 - val_loss: 1.4895 - val_accuracy: 0.6965\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2550 - accuracy: 0.7517 - val_loss: 1.6509 - val_accuracy: 0.7060\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3179 - accuracy: 0.7496 - val_loss: 1.3935 - val_accuracy: 0.6863\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3894 - accuracy: 0.7494 - val_loss: 1.4038 - val_accuracy: 0.6520\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4124 - accuracy: 0.7469 - val_loss: 1.3558 - val_accuracy: 0.6899\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3230 - accuracy: 0.7497 - val_loss: 1.5669 - val_accuracy: 0.6745\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2460 - accuracy: 0.7357 - val_loss: 1.5329 - val_accuracy: 0.7137\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 3.3150 - accuracy: 0.7563 - val_loss: 1.5016 - val_accuracy: 0.7155\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 3.3192 - accuracy: 0.7447 - val_loss: 1.3916 - val_accuracy: 0.7038\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 3.2854 - accuracy: 0.7455 - val_loss: 1.4306 - val_accuracy: 0.7145\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 3.3334 - accuracy: 0.7487 - val_loss: 1.4289 - val_accuracy: 0.7061\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 3.3535 - accuracy: 0.7383 - val_loss: 1.4017 - val_accuracy: 0.6880\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 3.2569 - accuracy: 0.7560 - val_loss: 1.4824 - val_accuracy: 0.6889\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 3.3549 - accuracy: 0.7464 - val_loss: 1.4157 - val_accuracy: 0.6785\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 3.2971 - accuracy: 0.7453 - val_loss: 1.4578 - val_accuracy: 0.7205\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 3.3544 - accuracy: 0.7526 - val_loss: 1.3870 - val_accuracy: 0.6952\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 3.2773 - accuracy: 0.7532 - val_loss: 1.4043 - val_accuracy: 0.7029\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 3.3087 - accuracy: 0.7540 - val_loss: 1.3868 - val_accuracy: 0.7117\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 3.2138 - accuracy: 0.7466 - val_loss: 1.4025 - val_accuracy: 0.6911\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 3.2431 - accuracy: 0.7512 - val_loss: 1.4662 - val_accuracy: 0.6997\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 3.2609 - accuracy: 0.7459 - val_loss: 1.3426 - val_accuracy: 0.7009\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 3.2857 - accuracy: 0.7473 - val_loss: 1.3676 - val_accuracy: 0.7014\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 3.2278 - accuracy: 0.7443 - val_loss: 1.3957 - val_accuracy: 0.7144\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 3.3337 - accuracy: 0.7416 - val_loss: 1.7470 - val_accuracy: 0.7150\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 3.3854 - accuracy: 0.7485 - val_loss: 1.5276 - val_accuracy: 0.7013\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 3.4899 - accuracy: 0.7294 - val_loss: 1.3445 - val_accuracy: 0.7121\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 3.4529 - accuracy: 0.7430 - val_loss: 1.6059 - val_accuracy: 0.7293\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 3.3515 - accuracy: 0.7292 - val_loss: 1.4791 - val_accuracy: 0.6946\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 3.4759 - accuracy: 0.7359 - val_loss: 1.9899 - val_accuracy: 0.7075\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 3.6555 - accuracy: 0.7317 - val_loss: 1.5370 - val_accuracy: 0.6806\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4748 - accuracy: 0.7529 - val_loss: 1.4493 - val_accuracy: 0.6834\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2848 - accuracy: 0.7424 - val_loss: 1.4338 - val_accuracy: 0.7150\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2814 - accuracy: 0.7545 - val_loss: 1.3594 - val_accuracy: 0.6811\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2335 - accuracy: 0.7465 - val_loss: 1.4186 - val_accuracy: 0.6830\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1974 - accuracy: 0.7610 - val_loss: 1.5697 - val_accuracy: 0.7158\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2892 - accuracy: 0.7486 - val_loss: 1.4164 - val_accuracy: 0.7197\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2467 - accuracy: 0.7481 - val_loss: 1.3038 - val_accuracy: 0.7132\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.2700 - accuracy: 0.7473 - val_loss: 1.5565 - val_accuracy: 0.6772\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3070 - accuracy: 0.7506 - val_loss: 1.3269 - val_accuracy: 0.7013\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.3507 - accuracy: 0.7433 - val_loss: 1.5214 - val_accuracy: 0.7096\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2409 - accuracy: 0.7468 - val_loss: 1.4831 - val_accuracy: 0.7132\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2065 - accuracy: 0.7566 - val_loss: 1.3649 - val_accuracy: 0.6951\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2320 - accuracy: 0.7492 - val_loss: 1.3100 - val_accuracy: 0.7192\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3254 - accuracy: 0.7534 - val_loss: 1.3335 - val_accuracy: 0.7141\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3051 - accuracy: 0.7414 - val_loss: 1.4856 - val_accuracy: 0.7367\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4570 - accuracy: 0.7588 - val_loss: 1.3269 - val_accuracy: 0.7018\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.5256 - accuracy: 0.7531 - val_loss: 1.5989 - val_accuracy: 0.7051\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5934 - accuracy: 0.7483 - val_loss: 1.3945 - val_accuracy: 0.6780\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5882 - accuracy: 0.7408 - val_loss: 1.6832 - val_accuracy: 0.6786\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4621 - accuracy: 0.7297 - val_loss: 1.6563 - val_accuracy: 0.7114\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2726 - accuracy: 0.7468 - val_loss: 1.4582 - val_accuracy: 0.7197\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3549 - accuracy: 0.7546 - val_loss: 1.4799 - val_accuracy: 0.7131\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3055 - accuracy: 0.7493 - val_loss: 1.7151 - val_accuracy: 0.7312\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2953 - accuracy: 0.7435 - val_loss: 1.3632 - val_accuracy: 0.7172\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2165 - accuracy: 0.7513 - val_loss: 1.3813 - val_accuracy: 0.7230\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1752 - accuracy: 0.7525 - val_loss: 1.5490 - val_accuracy: 0.7370\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2428 - accuracy: 0.7559 - val_loss: 1.3711 - val_accuracy: 0.7005\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2931 - accuracy: 0.7501 - val_loss: 1.2939 - val_accuracy: 0.7122\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3637 - accuracy: 0.7529 - val_loss: 1.3505 - val_accuracy: 0.7104\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4400 - accuracy: 0.7444 - val_loss: 1.5182 - val_accuracy: 0.6702\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2964 - accuracy: 0.7409 - val_loss: 1.3653 - val_accuracy: 0.7149\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2361 - accuracy: 0.7575 - val_loss: 1.3938 - val_accuracy: 0.7250\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1949 - accuracy: 0.7509 - val_loss: 1.3533 - val_accuracy: 0.7171\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1571 - accuracy: 0.7547 - val_loss: 1.3082 - val_accuracy: 0.6990\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 3.3951 - accuracy: 0.7583 - val_loss: 1.6689 - val_accuracy: 0.7149\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.5438 - accuracy: 0.7563 - val_loss: 1.4180 - val_accuracy: 0.6834\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.5551 - accuracy: 0.7587 - val_loss: 1.5731 - val_accuracy: 0.6851\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2910 - accuracy: 0.7539 - val_loss: 1.6750 - val_accuracy: 0.7276\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 3.3006 - accuracy: 0.7575 - val_loss: 1.3455 - val_accuracy: 0.6898\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3771 - accuracy: 0.7503 - val_loss: 1.3140 - val_accuracy: 0.7397\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2950 - accuracy: 0.7535 - val_loss: 1.3641 - val_accuracy: 0.7306\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.3073 - accuracy: 0.7602 - val_loss: 1.3706 - val_accuracy: 0.7028\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2721 - accuracy: 0.7446 - val_loss: 1.5410 - val_accuracy: 0.7119\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2785 - accuracy: 0.7533 - val_loss: 1.3094 - val_accuracy: 0.7271\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3009 - accuracy: 0.7586 - val_loss: 1.4985 - val_accuracy: 0.7081\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.6762 - accuracy: 0.7527 - val_loss: 1.5615 - val_accuracy: 0.6938\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.3704 - accuracy: 0.7501 - val_loss: 1.3547 - val_accuracy: 0.7188\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2342 - accuracy: 0.7492 - val_loss: 1.4677 - val_accuracy: 0.7267\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1610 - accuracy: 0.7546 - val_loss: 1.3977 - val_accuracy: 0.7354\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2500 - accuracy: 0.7604 - val_loss: 1.3520 - val_accuracy: 0.7075\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2319 - accuracy: 0.7545 - val_loss: 1.3499 - val_accuracy: 0.7443\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2401 - accuracy: 0.7571 - val_loss: 1.4269 - val_accuracy: 0.7336\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.1668 - accuracy: 0.7610 - val_loss: 1.4544 - val_accuracy: 0.7357\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.1795 - accuracy: 0.7582 - val_loss: 1.4571 - val_accuracy: 0.7337\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1464 - accuracy: 0.7614 - val_loss: 1.5131 - val_accuracy: 0.7317\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1535 - accuracy: 0.7581 - val_loss: 1.3690 - val_accuracy: 0.7518\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1443 - accuracy: 0.7620 - val_loss: 1.3676 - val_accuracy: 0.7305\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.1283 - accuracy: 0.7559 - val_loss: 1.3672 - val_accuracy: 0.7243\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2306 - accuracy: 0.7565 - val_loss: 1.3697 - val_accuracy: 0.7239\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3172 - accuracy: 0.7497 - val_loss: 1.6494 - val_accuracy: 0.7574\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4273 - accuracy: 0.7618 - val_loss: 1.3455 - val_accuracy: 0.7169\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3136 - accuracy: 0.7427 - val_loss: 1.3466 - val_accuracy: 0.7219\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2592 - accuracy: 0.7565 - val_loss: 1.4447 - val_accuracy: 0.7327\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2078 - accuracy: 0.7656 - val_loss: 1.3671 - val_accuracy: 0.7385\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 3.2239 - accuracy: 0.7614 - val_loss: 1.3308 - val_accuracy: 0.7342\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.3131 - accuracy: 0.7424 - val_loss: 1.6618 - val_accuracy: 0.7189\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2958 - accuracy: 0.7563 - val_loss: 1.5048 - val_accuracy: 0.7230\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2166 - accuracy: 0.7562 - val_loss: 1.3229 - val_accuracy: 0.7238\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1778 - accuracy: 0.7480 - val_loss: 1.3565 - val_accuracy: 0.7218\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3603 - accuracy: 0.7511 - val_loss: 1.7950 - val_accuracy: 0.7342\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4597 - accuracy: 0.7568 - val_loss: 1.3819 - val_accuracy: 0.7198\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3242 - accuracy: 0.7569 - val_loss: 1.4764 - val_accuracy: 0.7223\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.3484 - accuracy: 0.7476 - val_loss: 1.3898 - val_accuracy: 0.7080\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.3824 - accuracy: 0.7561 - val_loss: 1.3496 - val_accuracy: 0.7120\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3474 - accuracy: 0.7493 - val_loss: 1.5197 - val_accuracy: 0.7222\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.3287 - accuracy: 0.7486 - val_loss: 1.3674 - val_accuracy: 0.7234\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2374 - accuracy: 0.7560 - val_loss: 1.4318 - val_accuracy: 0.7334\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2421 - accuracy: 0.7545 - val_loss: 1.5104 - val_accuracy: 0.7290\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2398 - accuracy: 0.7508 - val_loss: 1.3544 - val_accuracy: 0.7347\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2502 - accuracy: 0.7489 - val_loss: 1.4035 - val_accuracy: 0.7485\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2684 - accuracy: 0.7557 - val_loss: 1.4223 - val_accuracy: 0.7358\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2231 - accuracy: 0.7543 - val_loss: 1.4205 - val_accuracy: 0.7389\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1968 - accuracy: 0.7498 - val_loss: 1.6278 - val_accuracy: 0.7290\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2409 - accuracy: 0.7552 - val_loss: 1.5393 - val_accuracy: 0.7525\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2650 - accuracy: 0.7520 - val_loss: 1.5332 - val_accuracy: 0.7385\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2569 - accuracy: 0.7532 - val_loss: 1.6199 - val_accuracy: 0.7437\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2854 - accuracy: 0.7529 - val_loss: 1.3498 - val_accuracy: 0.7429\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5183 - accuracy: 0.7570 - val_loss: 1.7787 - val_accuracy: 0.7391\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.5659 - accuracy: 0.7566 - val_loss: 1.3235 - val_accuracy: 0.7132\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.6271 - accuracy: 0.7652 - val_loss: 1.4453 - val_accuracy: 0.7285\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.8233 - accuracy: 0.7420 - val_loss: 1.6448 - val_accuracy: 0.6684\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.6306 - accuracy: 0.7486 - val_loss: 1.7943 - val_accuracy: 0.7272\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.6614 - accuracy: 0.7437 - val_loss: 1.4097 - val_accuracy: 0.7301\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4790 - accuracy: 0.7531 - val_loss: 1.5218 - val_accuracy: 0.7459\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4383 - accuracy: 0.7605 - val_loss: 1.4554 - val_accuracy: 0.7360\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2499 - accuracy: 0.7561 - val_loss: 1.5796 - val_accuracy: 0.7471\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2163 - accuracy: 0.7582 - val_loss: 1.3153 - val_accuracy: 0.7522\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2058 - accuracy: 0.7548 - val_loss: 1.4279 - val_accuracy: 0.7231\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1582 - accuracy: 0.7526 - val_loss: 1.3428 - val_accuracy: 0.7545\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1494 - accuracy: 0.7596 - val_loss: 1.3578 - val_accuracy: 0.7504\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.1769 - accuracy: 0.7658 - val_loss: 1.4795 - val_accuracy: 0.7328\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1493 - accuracy: 0.7608 - val_loss: 1.3381 - val_accuracy: 0.7552\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1457 - accuracy: 0.7575 - val_loss: 1.3220 - val_accuracy: 0.7549\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2066 - accuracy: 0.7665 - val_loss: 1.4681 - val_accuracy: 0.7540\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1780 - accuracy: 0.7611 - val_loss: 1.5493 - val_accuracy: 0.7430\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2905 - accuracy: 0.7665 - val_loss: 1.4832 - val_accuracy: 0.7617\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2716 - accuracy: 0.7625 - val_loss: 1.5236 - val_accuracy: 0.7416\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2660 - accuracy: 0.7568 - val_loss: 1.5367 - val_accuracy: 0.7432\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.1857 - accuracy: 0.7563 - val_loss: 1.3821 - val_accuracy: 0.7672\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.1456 - accuracy: 0.7644 - val_loss: 1.3605 - val_accuracy: 0.7536\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1415 - accuracy: 0.7675 - val_loss: 1.3580 - val_accuracy: 0.7540\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1206 - accuracy: 0.7663 - val_loss: 1.4676 - val_accuracy: 0.7476\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.0997 - accuracy: 0.7668 - val_loss: 1.4577 - val_accuracy: 0.7612\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.0981 - accuracy: 0.7661 - val_loss: 1.3498 - val_accuracy: 0.7580\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.0968 - accuracy: 0.7662 - val_loss: 1.3889 - val_accuracy: 0.7583\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.0908 - accuracy: 0.7666 - val_loss: 1.3555 - val_accuracy: 0.7579\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1504 - accuracy: 0.7639 - val_loss: 1.3882 - val_accuracy: 0.7574\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1438 - accuracy: 0.7683 - val_loss: 1.6025 - val_accuracy: 0.7571\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2412 - accuracy: 0.7609 - val_loss: 1.5744 - val_accuracy: 0.7547\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.5666 - accuracy: 0.7573 - val_loss: 1.4650 - val_accuracy: 0.7453\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4759 - accuracy: 0.7403 - val_loss: 1.3706 - val_accuracy: 0.7452\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3483 - accuracy: 0.7345 - val_loss: 1.7185 - val_accuracy: 0.6949\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3673 - accuracy: 0.7575 - val_loss: 1.3465 - val_accuracy: 0.7191\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.3524 - accuracy: 0.7573 - val_loss: 1.4212 - val_accuracy: 0.7519\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 3.3410 - accuracy: 0.7485 - val_loss: 1.4184 - val_accuracy: 0.7020\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2355 - accuracy: 0.7462 - val_loss: 1.3416 - val_accuracy: 0.7308\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2817 - accuracy: 0.7649 - val_loss: 1.4018 - val_accuracy: 0.7519\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2102 - accuracy: 0.7634 - val_loss: 1.4831 - val_accuracy: 0.7602\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1695 - accuracy: 0.7606 - val_loss: 1.3492 - val_accuracy: 0.7556\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2061 - accuracy: 0.7644 - val_loss: 1.3750 - val_accuracy: 0.7574\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2747 - accuracy: 0.7657 - val_loss: 1.4995 - val_accuracy: 0.7614\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2350 - accuracy: 0.7653 - val_loss: 1.3264 - val_accuracy: 0.7576\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.1503 - accuracy: 0.7600 - val_loss: 1.4198 - val_accuracy: 0.7424\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2015 - accuracy: 0.7615 - val_loss: 1.3319 - val_accuracy: 0.7539\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2705 - accuracy: 0.7459 - val_loss: 1.5586 - val_accuracy: 0.7388\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2858 - accuracy: 0.7504 - val_loss: 1.4347 - val_accuracy: 0.7571\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2508 - accuracy: 0.7618 - val_loss: 1.3654 - val_accuracy: 0.7564\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.1999 - accuracy: 0.7642 - val_loss: 1.7121 - val_accuracy: 0.7486\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.4099 - accuracy: 0.7617 - val_loss: 1.3461 - val_accuracy: 0.7329\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.4686 - accuracy: 0.7635 - val_loss: 1.3861 - val_accuracy: 0.7530\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 3.5999 - accuracy: 0.7546 - val_loss: 1.4244 - val_accuracy: 0.7192\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.4745 - accuracy: 0.7564 - val_loss: 1.4351 - val_accuracy: 0.7465\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.3440 - accuracy: 0.7519 - val_loss: 1.5952 - val_accuracy: 0.7480\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2543 - accuracy: 0.7549 - val_loss: 1.3965 - val_accuracy: 0.7392\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2713 - accuracy: 0.7590 - val_loss: 1.4527 - val_accuracy: 0.7265\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 3.2386 - accuracy: 0.7646 - val_loss: 1.4099 - val_accuracy: 0.7454\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1977 - accuracy: 0.7640 - val_loss: 1.4138 - val_accuracy: 0.7340\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2740 - accuracy: 0.7576 - val_loss: 1.6281 - val_accuracy: 0.7435\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2944 - accuracy: 0.7545 - val_loss: 1.3745 - val_accuracy: 0.7500\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2349 - accuracy: 0.7549 - val_loss: 1.3326 - val_accuracy: 0.7493\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.1931 - accuracy: 0.7659 - val_loss: 1.4021 - val_accuracy: 0.7299\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2155 - accuracy: 0.7650 - val_loss: 1.4142 - val_accuracy: 0.7569\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1965 - accuracy: 0.7599 - val_loss: 1.3912 - val_accuracy: 0.7318\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2494 - accuracy: 0.7627 - val_loss: 1.3825 - val_accuracy: 0.7528\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2058 - accuracy: 0.7655 - val_loss: 1.4551 - val_accuracy: 0.7548\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.1410 - accuracy: 0.7622 - val_loss: 1.4687 - val_accuracy: 0.7412\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.1352 - accuracy: 0.7610 - val_loss: 1.3954 - val_accuracy: 0.7465\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1271 - accuracy: 0.7630 - val_loss: 1.3767 - val_accuracy: 0.7444\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1033 - accuracy: 0.7677 - val_loss: 1.4018 - val_accuracy: 0.7650\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1005 - accuracy: 0.7669 - val_loss: 1.3759 - val_accuracy: 0.7545\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1368 - accuracy: 0.7715 - val_loss: 1.4656 - val_accuracy: 0.7449\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2219 - accuracy: 0.7661 - val_loss: 1.6838 - val_accuracy: 0.7588\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 3.2813 - accuracy: 0.7664 - val_loss: 1.3860 - val_accuracy: 0.7441\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2502 - accuracy: 0.7699 - val_loss: 1.4164 - val_accuracy: 0.7515\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2463 - accuracy: 0.7650 - val_loss: 1.4987 - val_accuracy: 0.7514\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1557 - accuracy: 0.7667 - val_loss: 1.3918 - val_accuracy: 0.7582\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.1894 - accuracy: 0.7582 - val_loss: 1.3735 - val_accuracy: 0.7414\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.1844 - accuracy: 0.7676 - val_loss: 1.3776 - val_accuracy: 0.7586\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1804 - accuracy: 0.7671 - val_loss: 1.3361 - val_accuracy: 0.7393\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 3.1646 - accuracy: 0.7581 - val_loss: 1.3681 - val_accuracy: 0.7483\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 3.1417 - accuracy: 0.7712 - val_loss: 1.3337 - val_accuracy: 0.7580\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 3.1782 - accuracy: 0.7618 - val_loss: 1.3974 - val_accuracy: 0.7120\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 3.1469 - accuracy: 0.7578 - val_loss: 1.5085 - val_accuracy: 0.7405\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.1737 - accuracy: 0.7616 - val_loss: 1.5009 - val_accuracy: 0.7613\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1747 - accuracy: 0.7633 - val_loss: 1.6107 - val_accuracy: 0.7509\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3160 - accuracy: 0.7640 - val_loss: 1.3775 - val_accuracy: 0.7481\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3574 - accuracy: 0.7595 - val_loss: 1.4036 - val_accuracy: 0.7592\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2796 - accuracy: 0.7515 - val_loss: 1.3712 - val_accuracy: 0.7412\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2000 - accuracy: 0.7560 - val_loss: 1.3270 - val_accuracy: 0.7432\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1452 - accuracy: 0.7545 - val_loss: 1.4382 - val_accuracy: 0.7490\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.1786 - accuracy: 0.7645 - val_loss: 1.4980 - val_accuracy: 0.7433\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 3.1874 - accuracy: 0.7627 - val_loss: 1.4610 - val_accuracy: 0.7429\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2056 - accuracy: 0.7611 - val_loss: 1.4047 - val_accuracy: 0.7532\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1769 - accuracy: 0.7705 - val_loss: 1.4472 - val_accuracy: 0.7614\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.1611 - accuracy: 0.7681 - val_loss: 1.3297 - val_accuracy: 0.7341\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3037 - accuracy: 0.7655 - val_loss: 1.4085 - val_accuracy: 0.7330\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.3013 - accuracy: 0.7668 - val_loss: 1.5978 - val_accuracy: 0.7567\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3019 - accuracy: 0.7550 - val_loss: 1.4304 - val_accuracy: 0.7241\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2373 - accuracy: 0.7556 - val_loss: 1.4814 - val_accuracy: 0.7526\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 3.1670 - accuracy: 0.7569 - val_loss: 1.3854 - val_accuracy: 0.7323\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.1410 - accuracy: 0.7633 - val_loss: 1.3963 - val_accuracy: 0.7360\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.1686 - accuracy: 0.7652 - val_loss: 1.4228 - val_accuracy: 0.7489\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 3.1649 - accuracy: 0.7637 - val_loss: 1.4055 - val_accuracy: 0.7471\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2229 - accuracy: 0.7622 - val_loss: 1.4686 - val_accuracy: 0.7253\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.3374 - accuracy: 0.7634 - val_loss: 1.4134 - val_accuracy: 0.7394\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2871 - accuracy: 0.7605 - val_loss: 1.3828 - val_accuracy: 0.7610\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.3941 - accuracy: 0.7530 - val_loss: 1.5967 - val_accuracy: 0.7541\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2785 - accuracy: 0.7619 - val_loss: 1.5798 - val_accuracy: 0.7498\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2336 - accuracy: 0.7566 - val_loss: 1.4471 - val_accuracy: 0.7544\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2018 - accuracy: 0.7570 - val_loss: 1.3371 - val_accuracy: 0.7373\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 3.1974 - accuracy: 0.7492 - val_loss: 1.3480 - val_accuracy: 0.7393\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.2230 - accuracy: 0.7624 - val_loss: 1.4150 - val_accuracy: 0.7427\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2637 - accuracy: 0.7615 - val_loss: 1.3714 - val_accuracy: 0.7486\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2090 - accuracy: 0.7589 - val_loss: 1.4786 - val_accuracy: 0.7373\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.1765 - accuracy: 0.7677 - val_loss: 1.4570 - val_accuracy: 0.7368\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.1778 - accuracy: 0.7588 - val_loss: 1.5846 - val_accuracy: 0.7496\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2456 - accuracy: 0.7597 - val_loss: 1.5885 - val_accuracy: 0.7482\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.2691 - accuracy: 0.7593 - val_loss: 1.4243 - val_accuracy: 0.7442\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2510 - accuracy: 0.7550 - val_loss: 1.8670 - val_accuracy: 0.7353\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3785 - accuracy: 0.7456 - val_loss: 1.6152 - val_accuracy: 0.7468\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2470 - accuracy: 0.7588 - val_loss: 1.4607 - val_accuracy: 0.7329\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4908 - accuracy: 0.7512 - val_loss: 1.6022 - val_accuracy: 0.7341\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.4258 - accuracy: 0.7691 - val_loss: 1.3361 - val_accuracy: 0.7544\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3012 - accuracy: 0.7621 - val_loss: 1.7119 - val_accuracy: 0.7403\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.2648 - accuracy: 0.7624 - val_loss: 1.5450 - val_accuracy: 0.7221\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.2047 - accuracy: 0.7603 - val_loss: 1.5737 - val_accuracy: 0.7523\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1644 - accuracy: 0.7628 - val_loss: 1.5417 - val_accuracy: 0.7441\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1763 - accuracy: 0.7598 - val_loss: 1.3574 - val_accuracy: 0.7422\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2862 - accuracy: 0.7481 - val_loss: 1.3607 - val_accuracy: 0.7437\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.2300 - accuracy: 0.7586 - val_loss: 1.3706 - val_accuracy: 0.7370\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 3.1794 - accuracy: 0.7563 - val_loss: 1.4038 - val_accuracy: 0.7497\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1665 - accuracy: 0.7636 - val_loss: 1.3325 - val_accuracy: 0.7459\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1293 - accuracy: 0.7627 - val_loss: 1.3549 - val_accuracy: 0.7393\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1307 - accuracy: 0.7668 - val_loss: 1.5025 - val_accuracy: 0.7408\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1214 - accuracy: 0.7730 - val_loss: 1.6015 - val_accuracy: 0.7425\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1755 - accuracy: 0.7667 - val_loss: 1.4663 - val_accuracy: 0.7262\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 3.1454 - accuracy: 0.7574 - val_loss: 1.3727 - val_accuracy: 0.7410\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1059 - accuracy: 0.7679 - val_loss: 1.3292 - val_accuracy: 0.7441\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 3.1135 - accuracy: 0.7685 - val_loss: 1.3759 - val_accuracy: 0.7273\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1605 - accuracy: 0.7669 - val_loss: 1.3462 - val_accuracy: 0.7238\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.1577 - accuracy: 0.7646 - val_loss: 1.3664 - val_accuracy: 0.7350\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.1388 - accuracy: 0.7626 - val_loss: 1.3301 - val_accuracy: 0.7430\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.1560 - accuracy: 0.7660 - val_loss: 1.4735 - val_accuracy: 0.7238\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 3.2378 - accuracy: 0.7664 - val_loss: 1.6907 - val_accuracy: 0.7094\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 3.3244 - accuracy: 0.7681 - val_loss: 1.5539 - val_accuracy: 0.7169\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 3.3138 - accuracy: 0.7646 - val_loss: 1.5897 - val_accuracy: 0.6797\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 3.2620 - accuracy: 0.7596 - val_loss: 1.4345 - val_accuracy: 0.7357\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 3.3352 - accuracy: 0.7555 - val_loss: 1.3282 - val_accuracy: 0.7059\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 3.3703 - accuracy: 0.7601 - val_loss: 1.6706 - val_accuracy: 0.6950\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 3.3803 - accuracy: 0.7372 - val_loss: 1.6473 - val_accuracy: 0.6864\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 3.3966 - accuracy: 0.7485 - val_loss: 1.5405 - val_accuracy: 0.6682\n"
          ]
        }
      ],
      "source": [
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=500, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Pj1wN-Swy6M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2uoc5QLwy_K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmJE_6oawzCu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gmXWYRGwzHA",
        "outputId": "af5b68a9-ea06-4926-c613-14f5805d5f00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 1s 76ms/step - loss: 33.6136 - accuracy: 0.0206 - val_loss: 12.3217 - val_accuracy: 0.0205\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 26.8445 - accuracy: 0.0173 - val_loss: 11.7136 - val_accuracy: 0.0048\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 22.4352 - accuracy: 0.0040 - val_loss: 10.7412 - val_accuracy: 0.0013\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 18.8510 - accuracy: 0.0020 - val_loss: 9.3640 - val_accuracy: 0.0093\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 16.5920 - accuracy: 0.0031 - val_loss: 8.8352 - val_accuracy: 0.0041\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.0297 - accuracy: 0.0877 - val_loss: 7.7956 - val_accuracy: 0.0429\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 13.6727 - accuracy: 0.1679 - val_loss: 7.0400 - val_accuracy: 0.0918\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.6402 - accuracy: 0.1886 - val_loss: 6.1846 - val_accuracy: 0.0238\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.8261 - accuracy: 0.1791 - val_loss: 6.1671 - val_accuracy: 0.0543\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.4352 - accuracy: 0.2529 - val_loss: 5.8975 - val_accuracy: 0.0339\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.0414 - accuracy: 0.3293 - val_loss: 5.5985 - val_accuracy: 0.0140\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.6339 - accuracy: 0.3241 - val_loss: 5.4312 - val_accuracy: 0.0143\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.3464 - accuracy: 0.3389 - val_loss: 5.4193 - val_accuracy: 0.0981\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.0298 - accuracy: 0.3534 - val_loss: 4.7309 - val_accuracy: 0.1145\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.7908 - accuracy: 0.3258 - val_loss: 4.6548 - val_accuracy: 0.1203\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.3557 - accuracy: 0.3813 - val_loss: 3.8487 - val_accuracy: 0.1265\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 8.6475 - accuracy: 0.3526 - val_loss: 3.3683 - val_accuracy: 0.1344\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 7.4732 - accuracy: 0.3360 - val_loss: 3.1288 - val_accuracy: 0.1273\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 7.1254 - accuracy: 0.3697 - val_loss: 3.1377 - val_accuracy: 0.1343\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 6.8460 - accuracy: 0.3943 - val_loss: 3.3020 - val_accuracy: 0.1591\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 6.7185 - accuracy: 0.3907 - val_loss: 3.0877 - val_accuracy: 0.2204\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 6.6824 - accuracy: 0.3600 - val_loss: 3.0116 - val_accuracy: 0.2004\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 6.7365 - accuracy: 0.4377 - val_loss: 2.9639 - val_accuracy: 0.1614\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 6.3218 - accuracy: 0.4190 - val_loss: 2.8806 - val_accuracy: 0.1653\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 6.3811 - accuracy: 0.4309 - val_loss: 2.9563 - val_accuracy: 0.3037\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 6.4543 - accuracy: 0.4111 - val_loss: 2.8379 - val_accuracy: 0.1719\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 6.2980 - accuracy: 0.4654 - val_loss: 2.8679 - val_accuracy: 0.2099\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 6.1995 - accuracy: 0.4664 - val_loss: 2.8784 - val_accuracy: 0.2007\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 6.2120 - accuracy: 0.4462 - val_loss: 2.9960 - val_accuracy: 0.5362\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 6.1658 - accuracy: 0.4442 - val_loss: 2.8582 - val_accuracy: 0.2645\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 6.0365 - accuracy: 0.4647 - val_loss: 2.8960 - val_accuracy: 0.1583\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 6.1754 - accuracy: 0.4859 - val_loss: 2.7001 - val_accuracy: 0.3833\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.9624 - accuracy: 0.4973 - val_loss: 2.6594 - val_accuracy: 0.2891\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 6.0782 - accuracy: 0.4948 - val_loss: 2.6751 - val_accuracy: 0.3108\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 6.0297 - accuracy: 0.4896 - val_loss: 2.6570 - val_accuracy: 0.4720\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.8684 - accuracy: 0.5315 - val_loss: 2.7062 - val_accuracy: 0.4623\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.9137 - accuracy: 0.5375 - val_loss: 2.7124 - val_accuracy: 0.4736\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 5.9926 - accuracy: 0.5054 - val_loss: 3.1355 - val_accuracy: 0.2199\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 6.0844 - accuracy: 0.5681 - val_loss: 2.7097 - val_accuracy: 0.3619\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.7433 - accuracy: 0.5400 - val_loss: 2.9686 - val_accuracy: 0.3315\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.9184 - accuracy: 0.5556 - val_loss: 2.9089 - val_accuracy: 0.2799\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.8514 - accuracy: 0.5484 - val_loss: 2.7045 - val_accuracy: 0.3398\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.6821 - accuracy: 0.5325 - val_loss: 2.5277 - val_accuracy: 0.4763\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.7595 - accuracy: 0.5743 - val_loss: 2.7995 - val_accuracy: 0.5120\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.9827 - accuracy: 0.5790 - val_loss: 2.4843 - val_accuracy: 0.4701\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.6895 - accuracy: 0.5593 - val_loss: 2.6136 - val_accuracy: 0.5116\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.8607 - accuracy: 0.5275 - val_loss: 2.4620 - val_accuracy: 0.4756\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.8257 - accuracy: 0.6005 - val_loss: 2.4697 - val_accuracy: 0.4536\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.8578 - accuracy: 0.6111 - val_loss: 2.5295 - val_accuracy: 0.4477\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.6634 - accuracy: 0.5393 - val_loss: 2.5014 - val_accuracy: 0.4484\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.6784 - accuracy: 0.5829 - val_loss: 3.1147 - val_accuracy: 0.2555\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.7527 - accuracy: 0.6087 - val_loss: 2.7309 - val_accuracy: 0.3565\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.6081 - accuracy: 0.5289 - val_loss: 2.6600 - val_accuracy: 0.2970\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.6292 - accuracy: 0.5933 - val_loss: 2.9214 - val_accuracy: 0.3311\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.7410 - accuracy: 0.5756 - val_loss: 2.7224 - val_accuracy: 0.4579\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.7147 - accuracy: 0.6093 - val_loss: 2.7129 - val_accuracy: 0.5013\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.5918 - accuracy: 0.5525 - val_loss: 2.7213 - val_accuracy: 0.4294\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.5979 - accuracy: 0.5699 - val_loss: 2.7487 - val_accuracy: 0.4368\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.6164 - accuracy: 0.5796 - val_loss: 2.6201 - val_accuracy: 0.4445\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.5882 - accuracy: 0.5458 - val_loss: 2.7811 - val_accuracy: 0.3021\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.8033 - accuracy: 0.6114 - val_loss: 2.6229 - val_accuracy: 0.4921\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.5903 - accuracy: 0.5868 - val_loss: 2.6398 - val_accuracy: 0.5457\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.6864 - accuracy: 0.5986 - val_loss: 2.4628 - val_accuracy: 0.5507\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.6379 - accuracy: 0.6385 - val_loss: 2.8819 - val_accuracy: 0.4695\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.5372 - accuracy: 0.6021 - val_loss: 2.8166 - val_accuracy: 0.5545\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.6471 - accuracy: 0.6152 - val_loss: 2.6268 - val_accuracy: 0.5919\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.5784 - accuracy: 0.6332 - val_loss: 2.8105 - val_accuracy: 0.5198\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.5797 - accuracy: 0.6197 - val_loss: 2.8628 - val_accuracy: 0.4886\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.5497 - accuracy: 0.6052 - val_loss: 2.9736 - val_accuracy: 0.3023\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.5606 - accuracy: 0.5806 - val_loss: 2.6577 - val_accuracy: 0.5629\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.5057 - accuracy: 0.6216 - val_loss: 2.6924 - val_accuracy: 0.4982\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.6609 - accuracy: 0.5947 - val_loss: 2.7228 - val_accuracy: 0.5370\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.4198 - accuracy: 0.6354 - val_loss: 2.5826 - val_accuracy: 0.5086\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.4814 - accuracy: 0.5504 - val_loss: 2.5255 - val_accuracy: 0.5836\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.5750 - accuracy: 0.5825 - val_loss: 2.7298 - val_accuracy: 0.5821\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.6310 - accuracy: 0.6187 - val_loss: 2.4555 - val_accuracy: 0.5698\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.4394 - accuracy: 0.6076 - val_loss: 2.4147 - val_accuracy: 0.5579\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.4211 - accuracy: 0.5999 - val_loss: 2.5041 - val_accuracy: 0.6317\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.4235 - accuracy: 0.6090 - val_loss: 2.4219 - val_accuracy: 0.5607\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.5128 - accuracy: 0.6188 - val_loss: 2.4985 - val_accuracy: 0.5838\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.5247 - accuracy: 0.5889 - val_loss: 2.4921 - val_accuracy: 0.6270\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.5638 - accuracy: 0.6557 - val_loss: 2.3675 - val_accuracy: 0.6393\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.5070 - accuracy: 0.5978 - val_loss: 2.3923 - val_accuracy: 0.6051\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.5961 - accuracy: 0.6244 - val_loss: 2.2516 - val_accuracy: 0.6432\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.4497 - accuracy: 0.6420 - val_loss: 2.3198 - val_accuracy: 0.6123\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.5245 - accuracy: 0.5986 - val_loss: 2.3017 - val_accuracy: 0.6387\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5.4559 - accuracy: 0.6275 - val_loss: 2.3760 - val_accuracy: 0.5928\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.4631 - accuracy: 0.6335 - val_loss: 2.3598 - val_accuracy: 0.6361\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.4090 - accuracy: 0.5587 - val_loss: 2.2921 - val_accuracy: 0.6376\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.3637 - accuracy: 0.6473 - val_loss: 2.3014 - val_accuracy: 0.6288\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.5721 - accuracy: 0.6329 - val_loss: 2.3441 - val_accuracy: 0.6267\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.3904 - accuracy: 0.6349 - val_loss: 2.4391 - val_accuracy: 0.6260\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 5.4199 - accuracy: 0.5897 - val_loss: 2.4637 - val_accuracy: 0.6527\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.4836 - accuracy: 0.6412 - val_loss: 2.4505 - val_accuracy: 0.5930\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 5.3163 - accuracy: 0.6064 - val_loss: 2.7095 - val_accuracy: 0.5854\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.3395 - accuracy: 0.6486 - val_loss: 2.6263 - val_accuracy: 0.6150\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.5142 - accuracy: 0.6207 - val_loss: 2.6336 - val_accuracy: 0.6367\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.5052 - accuracy: 0.6591 - val_loss: 2.6766 - val_accuracy: 0.6639\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.4155 - accuracy: 0.6595 - val_loss: 2.5299 - val_accuracy: 0.6629\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.3743 - accuracy: 0.6600 - val_loss: 2.6688 - val_accuracy: 0.6185\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.3745 - accuracy: 0.6090 - val_loss: 2.6652 - val_accuracy: 0.6542\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 5.3241 - accuracy: 0.6363 - val_loss: 2.5304 - val_accuracy: 0.6283\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.4108 - accuracy: 0.6179 - val_loss: 2.3909 - val_accuracy: 0.6184\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.4285 - accuracy: 0.6238 - val_loss: 2.5065 - val_accuracy: 0.6576\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.4096 - accuracy: 0.6597 - val_loss: 2.5361 - val_accuracy: 0.6481\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 5.3182 - accuracy: 0.6297 - val_loss: 2.4842 - val_accuracy: 0.6507\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 5.3221 - accuracy: 0.6613 - val_loss: 2.5644 - val_accuracy: 0.6417\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 5.4691 - accuracy: 0.6452 - val_loss: 2.5739 - val_accuracy: 0.6616\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.3205 - accuracy: 0.6511 - val_loss: 2.5669 - val_accuracy: 0.6582\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.4951 - accuracy: 0.6456 - val_loss: 2.6369 - val_accuracy: 0.6445\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.3923 - accuracy: 0.6759 - val_loss: 2.5365 - val_accuracy: 0.6551\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 5.2242 - accuracy: 0.6275 - val_loss: 2.4297 - val_accuracy: 0.6103\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.3121 - accuracy: 0.6010 - val_loss: 2.6599 - val_accuracy: 0.6513\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.4873 - accuracy: 0.6584 - val_loss: 2.3992 - val_accuracy: 0.6604\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.2710 - accuracy: 0.6653 - val_loss: 2.4323 - val_accuracy: 0.6221\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.3732 - accuracy: 0.5932 - val_loss: 2.4002 - val_accuracy: 0.6531\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.2625 - accuracy: 0.6549 - val_loss: 2.5279 - val_accuracy: 0.6572\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 5.2490 - accuracy: 0.6256 - val_loss: 2.4050 - val_accuracy: 0.6366\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 5.5628 - accuracy: 0.6701 - val_loss: 2.6178 - val_accuracy: 0.6608\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 5.4647 - accuracy: 0.6796 - val_loss: 2.4253 - val_accuracy: 0.6666\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 5.2096 - accuracy: 0.6636 - val_loss: 2.7414 - val_accuracy: 0.6741\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 5.4694 - accuracy: 0.6833 - val_loss: 2.4265 - val_accuracy: 0.6678\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.2925 - accuracy: 0.6704 - val_loss: 2.3163 - val_accuracy: 0.6525\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 5.2871 - accuracy: 0.6254 - val_loss: 2.2891 - val_accuracy: 0.6751\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 5.2231 - accuracy: 0.6359 - val_loss: 2.4588 - val_accuracy: 0.6381\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 5.6061 - accuracy: 0.6650 - val_loss: 2.3184 - val_accuracy: 0.6404\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 5.2954 - accuracy: 0.6867 - val_loss: 2.2422 - val_accuracy: 0.6762\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 5.1895 - accuracy: 0.6443 - val_loss: 2.3328 - val_accuracy: 0.6558\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.3518 - accuracy: 0.6611 - val_loss: 2.3203 - val_accuracy: 0.6686\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.4221 - accuracy: 0.6930 - val_loss: 2.3021 - val_accuracy: 0.6526\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.2473 - accuracy: 0.6674 - val_loss: 2.2764 - val_accuracy: 0.6327\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.3010 - accuracy: 0.6845 - val_loss: 2.3062 - val_accuracy: 0.6963\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.2462 - accuracy: 0.6532 - val_loss: 2.3542 - val_accuracy: 0.6728\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.2886 - accuracy: 0.6194 - val_loss: 2.7443 - val_accuracy: 0.6415\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.5003 - accuracy: 0.6938 - val_loss: 2.4286 - val_accuracy: 0.6681\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.2572 - accuracy: 0.6836 - val_loss: 2.2602 - val_accuracy: 0.6916\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.2597 - accuracy: 0.6752 - val_loss: 2.6299 - val_accuracy: 0.6609\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.3900 - accuracy: 0.6786 - val_loss: 2.4289 - val_accuracy: 0.6597\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.3962 - accuracy: 0.6853 - val_loss: 2.5348 - val_accuracy: 0.6824\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1869 - accuracy: 0.6612 - val_loss: 2.2990 - val_accuracy: 0.6739\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.3345 - accuracy: 0.6300 - val_loss: 2.2849 - val_accuracy: 0.6526\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.0768 - accuracy: 0.6184 - val_loss: 2.4315 - val_accuracy: 0.6577\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 5.4192 - accuracy: 0.6016 - val_loss: 2.2141 - val_accuracy: 0.6652\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2760 - accuracy: 0.6941 - val_loss: 2.2765 - val_accuracy: 0.6684\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1944 - accuracy: 0.6774 - val_loss: 2.4389 - val_accuracy: 0.7093\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.4431 - accuracy: 0.6980 - val_loss: 2.2717 - val_accuracy: 0.6700\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1838 - accuracy: 0.6683 - val_loss: 2.3447 - val_accuracy: 0.6685\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.2384 - accuracy: 0.6784 - val_loss: 2.3008 - val_accuracy: 0.6865\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.3860 - accuracy: 0.6674 - val_loss: 2.2729 - val_accuracy: 0.6799\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.1551 - accuracy: 0.6611 - val_loss: 2.2887 - val_accuracy: 0.6550\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.1784 - accuracy: 0.6636 - val_loss: 2.3432 - val_accuracy: 0.6392\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2292 - accuracy: 0.6412 - val_loss: 2.6088 - val_accuracy: 0.6250\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2072 - accuracy: 0.6223 - val_loss: 2.6496 - val_accuracy: 0.6328\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.3499 - accuracy: 0.6509 - val_loss: 2.7188 - val_accuracy: 0.6587\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.3435 - accuracy: 0.7153 - val_loss: 2.9322 - val_accuracy: 0.6700\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.2966 - accuracy: 0.7012 - val_loss: 2.8651 - val_accuracy: 0.6813\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2831 - accuracy: 0.7171 - val_loss: 2.4595 - val_accuracy: 0.6778\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.1383 - accuracy: 0.6747 - val_loss: 2.8313 - val_accuracy: 0.6787\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.3024 - accuracy: 0.6770 - val_loss: 2.5596 - val_accuracy: 0.6757\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0932 - accuracy: 0.6732 - val_loss: 2.5194 - val_accuracy: 0.7103\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.2325 - accuracy: 0.6585 - val_loss: 2.2101 - val_accuracy: 0.7228\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1068 - accuracy: 0.6194 - val_loss: 2.5470 - val_accuracy: 0.6813\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.4662 - accuracy: 0.7003 - val_loss: 2.7852 - val_accuracy: 0.6933\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2845 - accuracy: 0.6881 - val_loss: 2.4423 - val_accuracy: 0.6952\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.3419 - accuracy: 0.6932 - val_loss: 2.6230 - val_accuracy: 0.7068\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.3059 - accuracy: 0.6863 - val_loss: 2.7675 - val_accuracy: 0.6934\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2851 - accuracy: 0.6706 - val_loss: 2.3167 - val_accuracy: 0.7127\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0889 - accuracy: 0.6670 - val_loss: 2.3096 - val_accuracy: 0.7199\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1570 - accuracy: 0.6768 - val_loss: 2.3348 - val_accuracy: 0.7079\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.4378 - accuracy: 0.6995 - val_loss: 2.3565 - val_accuracy: 0.7076\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.3802 - accuracy: 0.7131 - val_loss: 2.2360 - val_accuracy: 0.6931\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1868 - accuracy: 0.6938 - val_loss: 2.2523 - val_accuracy: 0.7031\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2276 - accuracy: 0.7050 - val_loss: 2.4224 - val_accuracy: 0.6828\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1287 - accuracy: 0.6611 - val_loss: 2.4895 - val_accuracy: 0.6609\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1752 - accuracy: 0.6584 - val_loss: 2.4229 - val_accuracy: 0.6869\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.3480 - accuracy: 0.6975 - val_loss: 2.5274 - val_accuracy: 0.7109\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1665 - accuracy: 0.6810 - val_loss: 2.9313 - val_accuracy: 0.6965\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.3481 - accuracy: 0.7054 - val_loss: 2.6031 - val_accuracy: 0.7096\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0710 - accuracy: 0.6695 - val_loss: 2.4828 - val_accuracy: 0.7029\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.2677 - accuracy: 0.6711 - val_loss: 2.7622 - val_accuracy: 0.6925\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.4137 - accuracy: 0.7120 - val_loss: 2.2971 - val_accuracy: 0.7070\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0281 - accuracy: 0.6781 - val_loss: 2.4785 - val_accuracy: 0.6632\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.2139 - accuracy: 0.6706 - val_loss: 2.3520 - val_accuracy: 0.6756\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.3333 - accuracy: 0.6942 - val_loss: 2.2115 - val_accuracy: 0.7035\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.2414 - accuracy: 0.7050 - val_loss: 2.2131 - val_accuracy: 0.7039\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.1722 - accuracy: 0.7086 - val_loss: 2.3093 - val_accuracy: 0.7154\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 5.0447 - accuracy: 0.6915 - val_loss: 2.3593 - val_accuracy: 0.6408\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.1852 - accuracy: 0.6444 - val_loss: 2.4398 - val_accuracy: 0.6600\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.2239 - accuracy: 0.6589 - val_loss: 2.2248 - val_accuracy: 0.7171\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.3622 - accuracy: 0.6994 - val_loss: 2.2664 - val_accuracy: 0.6983\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 5.2784 - accuracy: 0.6955 - val_loss: 2.2562 - val_accuracy: 0.7124\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.1042 - accuracy: 0.7068 - val_loss: 2.2693 - val_accuracy: 0.7199\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2332 - accuracy: 0.7058 - val_loss: 2.2226 - val_accuracy: 0.7026\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.2770 - accuracy: 0.7040 - val_loss: 2.1683 - val_accuracy: 0.7015\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.0538 - accuracy: 0.6597 - val_loss: 2.3842 - val_accuracy: 0.6745\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1255 - accuracy: 0.6569 - val_loss: 2.2338 - val_accuracy: 0.7353\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.4379 - accuracy: 0.7155 - val_loss: 2.3452 - val_accuracy: 0.7237\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 5.1958 - accuracy: 0.7139 - val_loss: 2.3092 - val_accuracy: 0.7327\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.2342 - accuracy: 0.7119 - val_loss: 2.1958 - val_accuracy: 0.7095\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.0558 - accuracy: 0.6887 - val_loss: 2.2772 - val_accuracy: 0.7003\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1654 - accuracy: 0.6979 - val_loss: 2.2180 - val_accuracy: 0.7325\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.2405 - accuracy: 0.7157 - val_loss: 2.2290 - val_accuracy: 0.6975\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 5.1427 - accuracy: 0.6671 - val_loss: 2.3705 - val_accuracy: 0.6843\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.2340 - accuracy: 0.6584 - val_loss: 2.3696 - val_accuracy: 0.7238\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 5.1830 - accuracy: 0.7075 - val_loss: 2.2938 - val_accuracy: 0.7165\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.1822 - accuracy: 0.7015 - val_loss: 2.1984 - val_accuracy: 0.7184\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 5.0949 - accuracy: 0.7034 - val_loss: 2.2728 - val_accuracy: 0.6913\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 5.2801 - accuracy: 0.7093 - val_loss: 2.2844 - val_accuracy: 0.7349\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 5.2431 - accuracy: 0.7186 - val_loss: 2.2258 - val_accuracy: 0.7141\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 5.0459 - accuracy: 0.6812 - val_loss: 2.4606 - val_accuracy: 0.6688\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 5.0707 - accuracy: 0.6836 - val_loss: 2.4393 - val_accuracy: 0.6767\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.0018 - accuracy: 0.6688 - val_loss: 2.4575 - val_accuracy: 0.6593\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.2429 - accuracy: 0.6678 - val_loss: 2.3384 - val_accuracy: 0.7172\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.3548 - accuracy: 0.7065 - val_loss: 2.2625 - val_accuracy: 0.7236\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.1426 - accuracy: 0.7124 - val_loss: 2.2119 - val_accuracy: 0.7135\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.0821 - accuracy: 0.7076 - val_loss: 2.3413 - val_accuracy: 0.7009\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1991 - accuracy: 0.6963 - val_loss: 2.2189 - val_accuracy: 0.7414\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.0853 - accuracy: 0.6874 - val_loss: 2.2225 - val_accuracy: 0.7185\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.0258 - accuracy: 0.6527 - val_loss: 2.1880 - val_accuracy: 0.7490\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 5.0699 - accuracy: 0.6473 - val_loss: 2.4985 - val_accuracy: 0.7003\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.2954 - accuracy: 0.6743 - val_loss: 2.4497 - val_accuracy: 0.7132\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1674 - accuracy: 0.7135 - val_loss: 2.4372 - val_accuracy: 0.7138\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.2022 - accuracy: 0.7161 - val_loss: 2.3372 - val_accuracy: 0.7108\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1352 - accuracy: 0.7036 - val_loss: 2.5835 - val_accuracy: 0.7227\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1354 - accuracy: 0.7225 - val_loss: 2.5084 - val_accuracy: 0.7109\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1448 - accuracy: 0.7110 - val_loss: 2.5244 - val_accuracy: 0.7403\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 5.1782 - accuracy: 0.6982 - val_loss: 2.3478 - val_accuracy: 0.7094\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.0645 - accuracy: 0.6740 - val_loss: 2.3600 - val_accuracy: 0.7000\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.0226 - accuracy: 0.6874 - val_loss: 2.2384 - val_accuracy: 0.7183\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 5.2432 - accuracy: 0.7081 - val_loss: 2.7296 - val_accuracy: 0.7238\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.1621 - accuracy: 0.7085 - val_loss: 2.4636 - val_accuracy: 0.7289\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.1709 - accuracy: 0.7088 - val_loss: 2.5287 - val_accuracy: 0.7256\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 5.0370 - accuracy: 0.7172 - val_loss: 2.4379 - val_accuracy: 0.7157\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.2357 - accuracy: 0.7074 - val_loss: 2.7324 - val_accuracy: 0.7151\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.0527 - accuracy: 0.7102 - val_loss: 2.3123 - val_accuracy: 0.7275\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 5.0573 - accuracy: 0.6823 - val_loss: 2.2782 - val_accuracy: 0.7321\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9719 - accuracy: 0.6521 - val_loss: 2.2367 - val_accuracy: 0.7245\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.0388 - accuracy: 0.6317 - val_loss: 2.5677 - val_accuracy: 0.7258\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.4294 - accuracy: 0.6888 - val_loss: 2.2370 - val_accuracy: 0.7227\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.1955 - accuracy: 0.7253 - val_loss: 2.2609 - val_accuracy: 0.7272\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.2012 - accuracy: 0.7282 - val_loss: 2.1966 - val_accuracy: 0.7120\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.0034 - accuracy: 0.6948 - val_loss: 2.2398 - val_accuracy: 0.7204\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 5.1292 - accuracy: 0.6975 - val_loss: 2.1862 - val_accuracy: 0.7328\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 5.1717 - accuracy: 0.7143 - val_loss: 2.2724 - val_accuracy: 0.6843\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.1160 - accuracy: 0.7115 - val_loss: 2.4411 - val_accuracy: 0.7413\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 5.2766 - accuracy: 0.7119 - val_loss: 2.1696 - val_accuracy: 0.7196\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 5.0659 - accuracy: 0.6811 - val_loss: 2.3737 - val_accuracy: 0.6879\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.9485 - accuracy: 0.6594 - val_loss: 2.2774 - val_accuracy: 0.7072\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.0217 - accuracy: 0.6646 - val_loss: 2.6710 - val_accuracy: 0.7462\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 5.3909 - accuracy: 0.7185 - val_loss: 2.8919 - val_accuracy: 0.7136\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.1021 - accuracy: 0.7207 - val_loss: 2.3684 - val_accuracy: 0.7173\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.0502 - accuracy: 0.6807 - val_loss: 2.6682 - val_accuracy: 0.7151\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1011 - accuracy: 0.7104 - val_loss: 2.5112 - val_accuracy: 0.7107\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1582 - accuracy: 0.7235 - val_loss: 2.5866 - val_accuracy: 0.7186\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1708 - accuracy: 0.7233 - val_loss: 2.4388 - val_accuracy: 0.7199\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1621 - accuracy: 0.7175 - val_loss: 2.4743 - val_accuracy: 0.7313\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.0721 - accuracy: 0.7091 - val_loss: 2.7167 - val_accuracy: 0.7175\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0867 - accuracy: 0.7118 - val_loss: 2.9656 - val_accuracy: 0.7066\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0596 - accuracy: 0.7047 - val_loss: 2.4513 - val_accuracy: 0.7005\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1095 - accuracy: 0.6845 - val_loss: 2.3437 - val_accuracy: 0.6785\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0853 - accuracy: 0.6864 - val_loss: 2.1596 - val_accuracy: 0.7229\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 5.2649 - accuracy: 0.7156 - val_loss: 2.2141 - val_accuracy: 0.7325\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 5.1983 - accuracy: 0.7255 - val_loss: 2.1889 - val_accuracy: 0.7307\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 5.1988 - accuracy: 0.7265 - val_loss: 2.1825 - val_accuracy: 0.7301\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 5.0379 - accuracy: 0.6908 - val_loss: 2.2837 - val_accuracy: 0.7077\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 4.9825 - accuracy: 0.6925 - val_loss: 2.1673 - val_accuracy: 0.7366\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.2483 - accuracy: 0.7134 - val_loss: 2.1411 - val_accuracy: 0.7254\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 5.1053 - accuracy: 0.7207 - val_loss: 2.1862 - val_accuracy: 0.7315\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 4.9871 - accuracy: 0.6665 - val_loss: 2.2517 - val_accuracy: 0.7434\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.0007 - accuracy: 0.6801 - val_loss: 2.6381 - val_accuracy: 0.7059\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 5.3361 - accuracy: 0.7164 - val_loss: 2.1319 - val_accuracy: 0.7371\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 4.9518 - accuracy: 0.7214 - val_loss: 2.9682 - val_accuracy: 0.7176\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 5.1888 - accuracy: 0.7207 - val_loss: 2.7397 - val_accuracy: 0.7082\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 5.2041 - accuracy: 0.7145 - val_loss: 2.5082 - val_accuracy: 0.7232\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 5.0075 - accuracy: 0.7164 - val_loss: 2.5544 - val_accuracy: 0.7171\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.1290 - accuracy: 0.7014 - val_loss: 2.5213 - val_accuracy: 0.7239\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.0399 - accuracy: 0.7220 - val_loss: 2.6416 - val_accuracy: 0.7144\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.2892 - accuracy: 0.7160 - val_loss: 2.1862 - val_accuracy: 0.7243\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 4.8901 - accuracy: 0.6560 - val_loss: 2.8457 - val_accuracy: 0.6631\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.1160 - accuracy: 0.7069 - val_loss: 2.2250 - val_accuracy: 0.7090\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 5.1486 - accuracy: 0.7030 - val_loss: 2.2703 - val_accuracy: 0.7381\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.0652 - accuracy: 0.7167 - val_loss: 2.2583 - val_accuracy: 0.7284\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.2148 - accuracy: 0.7282 - val_loss: 2.2075 - val_accuracy: 0.7262\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 4.9825 - accuracy: 0.6929 - val_loss: 2.2479 - val_accuracy: 0.7230\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 4.8905 - accuracy: 0.6893 - val_loss: 2.8038 - val_accuracy: 0.6789\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.2289 - accuracy: 0.6524 - val_loss: 2.4183 - val_accuracy: 0.7367\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.1057 - accuracy: 0.7230 - val_loss: 2.4713 - val_accuracy: 0.7290\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.1058 - accuracy: 0.7224 - val_loss: 2.6949 - val_accuracy: 0.7277\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.1393 - accuracy: 0.7255 - val_loss: 2.4999 - val_accuracy: 0.7150\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.1051 - accuracy: 0.7202 - val_loss: 2.2797 - val_accuracy: 0.7132\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 4.9220 - accuracy: 0.6974 - val_loss: 2.5141 - val_accuracy: 0.6816\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.0215 - accuracy: 0.6891 - val_loss: 2.2928 - val_accuracy: 0.7062\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.0883 - accuracy: 0.7101 - val_loss: 2.2258 - val_accuracy: 0.7274\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0812 - accuracy: 0.7209 - val_loss: 2.2625 - val_accuracy: 0.7344\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0418 - accuracy: 0.7114 - val_loss: 2.1818 - val_accuracy: 0.7184\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0537 - accuracy: 0.7156 - val_loss: 2.2591 - val_accuracy: 0.7385\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.0629 - accuracy: 0.7178 - val_loss: 2.2417 - val_accuracy: 0.7259\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.1678 - accuracy: 0.7184 - val_loss: 2.1760 - val_accuracy: 0.7371\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0420 - accuracy: 0.7107 - val_loss: 2.2649 - val_accuracy: 0.7366\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0608 - accuracy: 0.6513 - val_loss: 2.3255 - val_accuracy: 0.7048\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.9730 - accuracy: 0.6861 - val_loss: 2.2804 - val_accuracy: 0.7135\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.2276 - accuracy: 0.7102 - val_loss: 2.7069 - val_accuracy: 0.7367\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0883 - accuracy: 0.7278 - val_loss: 2.7897 - val_accuracy: 0.7296\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0430 - accuracy: 0.7199 - val_loss: 2.7052 - val_accuracy: 0.7355\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.1846 - accuracy: 0.7222 - val_loss: 2.4336 - val_accuracy: 0.7233\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8722 - accuracy: 0.7185 - val_loss: 2.2888 - val_accuracy: 0.7178\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0263 - accuracy: 0.6866 - val_loss: 2.4290 - val_accuracy: 0.7308\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0029 - accuracy: 0.7141 - val_loss: 2.7259 - val_accuracy: 0.7118\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.2021 - accuracy: 0.7297 - val_loss: 2.2761 - val_accuracy: 0.7293\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.0309 - accuracy: 0.7212 - val_loss: 2.6119 - val_accuracy: 0.7399\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 5.1186 - accuracy: 0.7281 - val_loss: 2.3585 - val_accuracy: 0.7167\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 4.9567 - accuracy: 0.7204 - val_loss: 2.2901 - val_accuracy: 0.7162\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.0034 - accuracy: 0.7002 - val_loss: 2.5709 - val_accuracy: 0.7020\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.0640 - accuracy: 0.7179 - val_loss: 2.3949 - val_accuracy: 0.7455\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.1924 - accuracy: 0.6989 - val_loss: 2.5072 - val_accuracy: 0.7318\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 5.1439 - accuracy: 0.7329 - val_loss: 2.5416 - val_accuracy: 0.7311\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9201 - accuracy: 0.7212 - val_loss: 2.3025 - val_accuracy: 0.7162\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 4.9919 - accuracy: 0.6690 - val_loss: 2.3207 - val_accuracy: 0.7330\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 5.0749 - accuracy: 0.7040 - val_loss: 2.1685 - val_accuracy: 0.7389\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.1926 - accuracy: 0.7084 - val_loss: 2.1944 - val_accuracy: 0.7364\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0601 - accuracy: 0.7318 - val_loss: 2.2227 - val_accuracy: 0.7296\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 4.9862 - accuracy: 0.7200 - val_loss: 2.2449 - val_accuracy: 0.7205\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.1260 - accuracy: 0.7247 - val_loss: 2.2538 - val_accuracy: 0.7271\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 5.0160 - accuracy: 0.7281 - val_loss: 2.1648 - val_accuracy: 0.7159\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 4.9434 - accuracy: 0.7327 - val_loss: 2.1841 - val_accuracy: 0.7370\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 5.0012 - accuracy: 0.7007 - val_loss: 2.5236 - val_accuracy: 0.7198\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 4.9709 - accuracy: 0.6994 - val_loss: 2.8827 - val_accuracy: 0.7209\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 5.2023 - accuracy: 0.7261 - val_loss: 2.5627 - val_accuracy: 0.7169\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.0707 - accuracy: 0.7275 - val_loss: 2.4524 - val_accuracy: 0.7204\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.0033 - accuracy: 0.7281 - val_loss: 2.6511 - val_accuracy: 0.7249\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 5.1386 - accuracy: 0.7218 - val_loss: 2.2434 - val_accuracy: 0.7185\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 4.9120 - accuracy: 0.6865 - val_loss: 2.1984 - val_accuracy: 0.7101\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 5.1076 - accuracy: 0.6967 - val_loss: 2.2336 - val_accuracy: 0.7167\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 5.0783 - accuracy: 0.7218 - val_loss: 2.1556 - val_accuracy: 0.7342\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 5.1117 - accuracy: 0.7226 - val_loss: 2.1581 - val_accuracy: 0.7328\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 4.9104 - accuracy: 0.7309 - val_loss: 2.3147 - val_accuracy: 0.7402\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0604 - accuracy: 0.7216 - val_loss: 2.1894 - val_accuracy: 0.7310\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0647 - accuracy: 0.7302 - val_loss: 2.1471 - val_accuracy: 0.7279\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9661 - accuracy: 0.7020 - val_loss: 2.2074 - val_accuracy: 0.7352\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9697 - accuracy: 0.6927 - val_loss: 2.3710 - val_accuracy: 0.7351\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.0778 - accuracy: 0.7184 - val_loss: 2.6583 - val_accuracy: 0.7245\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0931 - accuracy: 0.7330 - val_loss: 2.3619 - val_accuracy: 0.7249\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0505 - accuracy: 0.7286 - val_loss: 2.4743 - val_accuracy: 0.7206\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0684 - accuracy: 0.7299 - val_loss: 2.5162 - val_accuracy: 0.7220\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 5.0001 - accuracy: 0.7097 - val_loss: 2.2781 - val_accuracy: 0.7359\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.0625 - accuracy: 0.7044 - val_loss: 2.6778 - val_accuracy: 0.7280\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8863 - accuracy: 0.7054 - val_loss: 2.4749 - val_accuracy: 0.6963\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.0258 - accuracy: 0.7052 - val_loss: 2.6637 - val_accuracy: 0.7269\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1375 - accuracy: 0.7288 - val_loss: 2.5894 - val_accuracy: 0.7290\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.9771 - accuracy: 0.7302 - val_loss: 2.5908 - val_accuracy: 0.7183\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.9623 - accuracy: 0.7318 - val_loss: 2.4337 - val_accuracy: 0.7150\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0036 - accuracy: 0.7061 - val_loss: 2.1814 - val_accuracy: 0.7264\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0694 - accuracy: 0.7084 - val_loss: 2.2632 - val_accuracy: 0.7302\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9972 - accuracy: 0.7279 - val_loss: 2.2008 - val_accuracy: 0.7251\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.1868 - accuracy: 0.7305 - val_loss: 2.1564 - val_accuracy: 0.7194\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9328 - accuracy: 0.7205 - val_loss: 2.2217 - val_accuracy: 0.7368\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0516 - accuracy: 0.7278 - val_loss: 2.2651 - val_accuracy: 0.7142\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0013 - accuracy: 0.7180 - val_loss: 2.3307 - val_accuracy: 0.7037\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0394 - accuracy: 0.7132 - val_loss: 2.5980 - val_accuracy: 0.7357\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0032 - accuracy: 0.7345 - val_loss: 2.6238 - val_accuracy: 0.7252\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9259 - accuracy: 0.7149 - val_loss: 2.3736 - val_accuracy: 0.7279\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 5.0892 - accuracy: 0.7110 - val_loss: 2.6546 - val_accuracy: 0.7239\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1734 - accuracy: 0.7284 - val_loss: 2.5057 - val_accuracy: 0.7297\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9157 - accuracy: 0.7288 - val_loss: 2.5070 - val_accuracy: 0.7216\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1347 - accuracy: 0.7239 - val_loss: 2.4479 - val_accuracy: 0.7225\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9377 - accuracy: 0.7245 - val_loss: 2.3843 - val_accuracy: 0.7065\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.8766 - accuracy: 0.7280 - val_loss: 2.5756 - val_accuracy: 0.6850\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9759 - accuracy: 0.7037 - val_loss: 2.4559 - val_accuracy: 0.7013\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2095 - accuracy: 0.7217 - val_loss: 2.1402 - val_accuracy: 0.7284\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0622 - accuracy: 0.7353 - val_loss: 2.1630 - val_accuracy: 0.7277\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9520 - accuracy: 0.7304 - val_loss: 2.2715 - val_accuracy: 0.7042\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.1063 - accuracy: 0.7228 - val_loss: 2.1454 - val_accuracy: 0.7417\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 4.7890 - accuracy: 0.7115 - val_loss: 2.4767 - val_accuracy: 0.6825\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9783 - accuracy: 0.7091 - val_loss: 2.1511 - val_accuracy: 0.7285\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2346 - accuracy: 0.7388 - val_loss: 2.1625 - val_accuracy: 0.7427\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9609 - accuracy: 0.7397 - val_loss: 2.1160 - val_accuracy: 0.7298\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0628 - accuracy: 0.7325 - val_loss: 2.1613 - val_accuracy: 0.7241\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9068 - accuracy: 0.7155 - val_loss: 2.2699 - val_accuracy: 0.6704\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.8857 - accuracy: 0.6804 - val_loss: 2.3302 - val_accuracy: 0.6521\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9536 - accuracy: 0.6818 - val_loss: 2.3379 - val_accuracy: 0.7049\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1005 - accuracy: 0.7114 - val_loss: 2.3216 - val_accuracy: 0.7256\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1095 - accuracy: 0.7384 - val_loss: 2.1323 - val_accuracy: 0.7268\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9224 - accuracy: 0.7290 - val_loss: 2.1561 - val_accuracy: 0.7159\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9535 - accuracy: 0.7339 - val_loss: 2.2139 - val_accuracy: 0.7208\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0831 - accuracy: 0.7378 - val_loss: 2.1398 - val_accuracy: 0.7350\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9426 - accuracy: 0.7352 - val_loss: 2.1666 - val_accuracy: 0.7385\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9796 - accuracy: 0.7313 - val_loss: 2.3716 - val_accuracy: 0.6927\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9401 - accuracy: 0.7101 - val_loss: 2.5251 - val_accuracy: 0.6830\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.0972 - accuracy: 0.7119 - val_loss: 2.7703 - val_accuracy: 0.7262\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0380 - accuracy: 0.7315 - val_loss: 2.2108 - val_accuracy: 0.7308\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9318 - accuracy: 0.7053 - val_loss: 2.2900 - val_accuracy: 0.7475\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1122 - accuracy: 0.7224 - val_loss: 2.5533 - val_accuracy: 0.7210\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9973 - accuracy: 0.7384 - val_loss: 2.3349 - val_accuracy: 0.7277\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9752 - accuracy: 0.7222 - val_loss: 2.4474 - val_accuracy: 0.7134\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0747 - accuracy: 0.7412 - val_loss: 2.4980 - val_accuracy: 0.7280\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0407 - accuracy: 0.7383 - val_loss: 2.3443 - val_accuracy: 0.7292\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.8557 - accuracy: 0.7191 - val_loss: 2.4356 - val_accuracy: 0.7085\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.8416 - accuracy: 0.6950 - val_loss: 2.2538 - val_accuracy: 0.7315\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9790 - accuracy: 0.7181 - val_loss: 2.4282 - val_accuracy: 0.7297\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0874 - accuracy: 0.7374 - val_loss: 2.3149 - val_accuracy: 0.7238\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0493 - accuracy: 0.7379 - val_loss: 2.3349 - val_accuracy: 0.7218\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 4.8533 - accuracy: 0.7303 - val_loss: 2.4456 - val_accuracy: 0.7110\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9703 - accuracy: 0.7331 - val_loss: 2.4213 - val_accuracy: 0.7212\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9690 - accuracy: 0.7254 - val_loss: 2.3079 - val_accuracy: 0.7095\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.9547 - accuracy: 0.7269 - val_loss: 2.8688 - val_accuracy: 0.7130\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1003 - accuracy: 0.7389 - val_loss: 2.4295 - val_accuracy: 0.7317\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.9801 - accuracy: 0.7359 - val_loss: 2.3497 - val_accuracy: 0.7138\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9846 - accuracy: 0.7309 - val_loss: 2.5113 - val_accuracy: 0.7180\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0405 - accuracy: 0.7420 - val_loss: 2.4171 - val_accuracy: 0.7268\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9029 - accuracy: 0.7304 - val_loss: 2.2836 - val_accuracy: 0.6975\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9161 - accuracy: 0.6993 - val_loss: 2.1409 - val_accuracy: 0.7288\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8891 - accuracy: 0.7116 - val_loss: 2.1942 - val_accuracy: 0.7219\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.2178 - accuracy: 0.7260 - val_loss: 2.1387 - val_accuracy: 0.7374\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.8889 - accuracy: 0.7354 - val_loss: 2.2303 - val_accuracy: 0.7276\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0021 - accuracy: 0.7419 - val_loss: 2.1037 - val_accuracy: 0.7236\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 4.8990 - accuracy: 0.7368 - val_loss: 2.2482 - val_accuracy: 0.7261\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0358 - accuracy: 0.7434 - val_loss: 2.1362 - val_accuracy: 0.7232\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9966 - accuracy: 0.7423 - val_loss: 2.1614 - val_accuracy: 0.7126\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9574 - accuracy: 0.7250 - val_loss: 2.1339 - val_accuracy: 0.7218\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9445 - accuracy: 0.7138 - val_loss: 2.3544 - val_accuracy: 0.7150\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9289 - accuracy: 0.7010 - val_loss: 2.3972 - val_accuracy: 0.7311\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.0468 - accuracy: 0.7270 - val_loss: 2.8774 - val_accuracy: 0.7242\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8610 - accuracy: 0.7420 - val_loss: 2.6601 - val_accuracy: 0.6945\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.1052 - accuracy: 0.7385 - val_loss: 2.4540 - val_accuracy: 0.7128\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0687 - accuracy: 0.7392 - val_loss: 2.5076 - val_accuracy: 0.7159\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9389 - accuracy: 0.7344 - val_loss: 2.5118 - val_accuracy: 0.6991\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.9284 - accuracy: 0.7187 - val_loss: 2.3524 - val_accuracy: 0.7287\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9021 - accuracy: 0.7326 - val_loss: 2.4001 - val_accuracy: 0.7097\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 4.9665 - accuracy: 0.7264 - val_loss: 2.9434 - val_accuracy: 0.6989\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 5.0669 - accuracy: 0.7429 - val_loss: 2.5225 - val_accuracy: 0.7062\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0857 - accuracy: 0.7418 - val_loss: 2.4373 - val_accuracy: 0.7052\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.8029 - accuracy: 0.7420 - val_loss: 2.4574 - val_accuracy: 0.6844\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0152 - accuracy: 0.7389 - val_loss: 2.4521 - val_accuracy: 0.7180\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0235 - accuracy: 0.7388 - val_loss: 2.2624 - val_accuracy: 0.6910\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9012 - accuracy: 0.7063 - val_loss: 2.2272 - val_accuracy: 0.7215\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.8270 - accuracy: 0.7258 - val_loss: 2.3254 - val_accuracy: 0.7116\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 5.1275 - accuracy: 0.7223 - val_loss: 2.2640 - val_accuracy: 0.7126\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9292 - accuracy: 0.7436 - val_loss: 2.2557 - val_accuracy: 0.7189\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9333 - accuracy: 0.7462 - val_loss: 2.5179 - val_accuracy: 0.7075\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 4.9844 - accuracy: 0.7466 - val_loss: 2.3488 - val_accuracy: 0.7053\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8769 - accuracy: 0.7365 - val_loss: 2.5623 - val_accuracy: 0.7145\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0574 - accuracy: 0.7352 - val_loss: 2.3935 - val_accuracy: 0.6874\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.8921 - accuracy: 0.7298 - val_loss: 2.3468 - val_accuracy: 0.7057\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9515 - accuracy: 0.7396 - val_loss: 2.3385 - val_accuracy: 0.7242\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9213 - accuracy: 0.7135 - val_loss: 2.4493 - val_accuracy: 0.7198\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.0728 - accuracy: 0.7468 - val_loss: 2.6024 - val_accuracy: 0.7113\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 4.9646 - accuracy: 0.7418 - val_loss: 2.5261 - val_accuracy: 0.7016\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9293 - accuracy: 0.7461 - val_loss: 2.5253 - val_accuracy: 0.7142\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9556 - accuracy: 0.7263 - val_loss: 2.4563 - val_accuracy: 0.6899\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.8652 - accuracy: 0.7196 - val_loss: 2.3357 - val_accuracy: 0.7154\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 5.0373 - accuracy: 0.7362 - val_loss: 2.5279 - val_accuracy: 0.7096\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.0631 - accuracy: 0.7468 - val_loss: 2.6253 - val_accuracy: 0.7184\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8358 - accuracy: 0.7440 - val_loss: 2.1818 - val_accuracy: 0.7121\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9465 - accuracy: 0.7212 - val_loss: 2.3893 - val_accuracy: 0.7068\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.8691 - accuracy: 0.7236 - val_loss: 2.2994 - val_accuracy: 0.7081\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9097 - accuracy: 0.7047 - val_loss: 2.2551 - val_accuracy: 0.7216\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 4.8395 - accuracy: 0.7059 - val_loss: 2.1553 - val_accuracy: 0.7110\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.1778 - accuracy: 0.7454 - val_loss: 2.1736 - val_accuracy: 0.6964\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.9737 - accuracy: 0.7459 - val_loss: 2.1272 - val_accuracy: 0.7112\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9123 - accuracy: 0.7469 - val_loss: 2.2748 - val_accuracy: 0.6961\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.8825 - accuracy: 0.7395 - val_loss: 2.1579 - val_accuracy: 0.7124\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9919 - accuracy: 0.7423 - val_loss: 2.1367 - val_accuracy: 0.7025\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9132 - accuracy: 0.7399 - val_loss: 2.1139 - val_accuracy: 0.7118\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9226 - accuracy: 0.7155 - val_loss: 2.3264 - val_accuracy: 0.6864\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8015 - accuracy: 0.7194 - val_loss: 2.2847 - val_accuracy: 0.6735\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9648 - accuracy: 0.7062 - val_loss: 2.4157 - val_accuracy: 0.6940\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.2339 - accuracy: 0.7432 - val_loss: 2.1335 - val_accuracy: 0.7046\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9112 - accuracy: 0.7452 - val_loss: 2.1406 - val_accuracy: 0.7055\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.9680 - accuracy: 0.7448 - val_loss: 2.1441 - val_accuracy: 0.7068\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.9700 - accuracy: 0.7450 - val_loss: 2.1463 - val_accuracy: 0.7118\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.8392 - accuracy: 0.7229 - val_loss: 2.4765 - val_accuracy: 0.6640\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 4.8595 - accuracy: 0.7253 - val_loss: 2.4011 - val_accuracy: 0.6977\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 5.2167 - accuracy: 0.7386 - val_loss: 2.2604 - val_accuracy: 0.6968\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.7886 - accuracy: 0.7129 - val_loss: 2.2523 - val_accuracy: 0.7006\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.8707 - accuracy: 0.7281 - val_loss: 2.6037 - val_accuracy: 0.7046\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0890 - accuracy: 0.7449 - val_loss: 2.3436 - val_accuracy: 0.6972\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 4.9498 - accuracy: 0.7372 - val_loss: 2.8399 - val_accuracy: 0.6954\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9446 - accuracy: 0.7277 - val_loss: 2.3361 - val_accuracy: 0.6848\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8244 - accuracy: 0.7293 - val_loss: 2.2003 - val_accuracy: 0.7025\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.7625 - accuracy: 0.7328 - val_loss: 2.1862 - val_accuracy: 0.6684\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.1560 - accuracy: 0.7251 - val_loss: 2.2222 - val_accuracy: 0.6975\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.8682 - accuracy: 0.7414 - val_loss: 2.1458 - val_accuracy: 0.7065\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.9524 - accuracy: 0.7456 - val_loss: 2.1031 - val_accuracy: 0.6942\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.8790 - accuracy: 0.7305 - val_loss: 2.2078 - val_accuracy: 0.6969\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 4.9648 - accuracy: 0.7394 - val_loss: 2.2315 - val_accuracy: 0.7120\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.9931 - accuracy: 0.7409 - val_loss: 2.1344 - val_accuracy: 0.7043\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8923 - accuracy: 0.7450 - val_loss: 2.1069 - val_accuracy: 0.6949\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.9368 - accuracy: 0.7401 - val_loss: 2.2018 - val_accuracy: 0.6775\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9817 - accuracy: 0.7364 - val_loss: 2.1418 - val_accuracy: 0.6953\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 4.8127 - accuracy: 0.7204 - val_loss: 2.1987 - val_accuracy: 0.6858\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 4.8580 - accuracy: 0.7206 - val_loss: 2.4686 - val_accuracy: 0.6820\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0679 - accuracy: 0.7430 - val_loss: 2.2239 - val_accuracy: 0.7041\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9112 - accuracy: 0.7427 - val_loss: 2.4000 - val_accuracy: 0.6890\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9279 - accuracy: 0.7468 - val_loss: 2.6822 - val_accuracy: 0.6899\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 5.0379 - accuracy: 0.7436 - val_loss: 2.2814 - val_accuracy: 0.6916\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 4.8012 - accuracy: 0.7298 - val_loss: 2.3535 - val_accuracy: 0.6984\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 4.8707 - accuracy: 0.7216 - val_loss: 2.6245 - val_accuracy: 0.6629\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 4.9991 - accuracy: 0.7402 - val_loss: 2.2761 - val_accuracy: 0.6908\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 5.0166 - accuracy: 0.7481 - val_loss: 2.2872 - val_accuracy: 0.6956\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 4.7777 - accuracy: 0.7384 - val_loss: 2.4873 - val_accuracy: 0.6890\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=8)(input_layer2)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample2)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer2)\n",
        "\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer2])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='RMSprop', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=500, batch_size=None, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xM6o5S8H0QZK",
        "outputId": "0d5b2bac-dd78-4adb-9b2c-0cd00dfae96d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(225, 64, 64, 3)\n",
            "(225, 8, 8, 31)\n",
            "(64, 64, 3)\n",
            "(8, 8, 31)\n"
          ]
        }
      ],
      "source": [
        "print(a.shape)\n",
        "print(b.shape)\n",
        "print(a[100].shape)\n",
        "print(b[100].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8El8J9ovz0VY",
        "outputId": "e66296b3-f34a-408e-a6d8-3ba22fb98fbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 6ms/step\n"
          ]
        }
      ],
      "source": [
        "gen_img=model.predict([a,b])\n",
        "gen_img=gen_img*255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeXMEDL11SaO",
        "outputId": "c1886603-96b2-474c-bf32-c8912416888f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(225, 64, 64, 31)\n",
            "(225, 64, 64, 31)\n"
          ]
        }
      ],
      "source": [
        "print(gen_img.shape)\n",
        "print(image_transposed.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "33IpMqXc2Mws",
        "outputId": "d70d6d31-e6e2-4b3a-8377-3be0dc6edf0e"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pic_no=150\n",
        "channel=30\n",
        "# Plot the first graph in the first subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(image_transposed[pic_no][:,:,channel])\n",
        "plt.title('original image')\n",
        "plt.show()\n",
        "\n",
        "# Plot the second graph in the second subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(gen_img[pic_no][:,:,channel])\n",
        "plt.title('Generated image from model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "WZmq1PAWEvZr",
        "outputId": "b9731a27-67fb-4b9e-a66f-7fbe581c4f1c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pic_no=150\n",
        "channel=30\n",
        "# Plot the first graph in the first subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(image_transposed[pic_no][:,:,channel])\n",
        "plt.title('original image')\n",
        "plt.show()\n",
        "\n",
        "# Plot the second graph in the second subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(gen_img[pic_no][:,:,channel])\n",
        "plt.title('Generated image from model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WQf6L0T1IfhN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvVOAYwqIful",
        "outputId": "0b52e2ea-9ef6-48cf-e33e-71ef6223dcb0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 9s 792ms/step - loss: 120.7829 - accuracy: 0.0185 - val_loss: 16.4956 - val_accuracy: 0.0598\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 36.2541 - accuracy: 0.0087 - val_loss: 13.1813 - val_accuracy: 0.0268\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 30.3341 - accuracy: 0.0252 - val_loss: 12.2016 - val_accuracy: 3.6892e-04\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 27.5434 - accuracy: 0.0053 - val_loss: 11.8658 - val_accuracy: 0.0014\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 25.4210 - accuracy: 0.0115 - val_loss: 11.2623 - val_accuracy: 0.0098\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 23.5692 - accuracy: 0.0071 - val_loss: 10.9309 - val_accuracy: 0.0075\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 23.0617 - accuracy: 0.0093 - val_loss: 11.2895 - val_accuracy: 0.0036\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 23.1585 - accuracy: 0.0194 - val_loss: 10.7877 - val_accuracy: 0.0053\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 22.0092 - accuracy: 0.0135 - val_loss: 10.6192 - val_accuracy: 0.0072\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 21.5656 - accuracy: 0.0252 - val_loss: 10.5886 - val_accuracy: 0.0081\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 20.8877 - accuracy: 0.0197 - val_loss: 10.5429 - val_accuracy: 0.0344\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 20.5373 - accuracy: 0.0415 - val_loss: 10.6267 - val_accuracy: 0.0171\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 20.5068 - accuracy: 0.1669 - val_loss: 10.3960 - val_accuracy: 0.0181\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 20.5635 - accuracy: 0.1704 - val_loss: 10.3219 - val_accuracy: 0.0413\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 20.4913 - accuracy: 0.0447 - val_loss: 10.0965 - val_accuracy: 0.0356\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 20.1800 - accuracy: 0.0411 - val_loss: 10.2928 - val_accuracy: 0.0359\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 19.5220 - accuracy: 0.0398 - val_loss: 9.8169 - val_accuracy: 0.0363\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 18.8978 - accuracy: 0.0419 - val_loss: 9.7120 - val_accuracy: 0.0384\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 18.9065 - accuracy: 0.1098 - val_loss: 9.5337 - val_accuracy: 0.0114\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 18.5416 - accuracy: 0.2352 - val_loss: 9.0110 - val_accuracy: 0.0052\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 17.9603 - accuracy: 0.2364 - val_loss: 8.8224 - val_accuracy: 0.0027\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 17.7872 - accuracy: 0.2481 - val_loss: 8.5650 - val_accuracy: 0.0056\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 17.5113 - accuracy: 0.2471 - val_loss: 8.5788 - val_accuracy: 2.2244e-04\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 17.5460 - accuracy: 0.2420 - val_loss: 8.4431 - val_accuracy: 2.5499e-04\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 17.5693 - accuracy: 0.2594 - val_loss: 8.1758 - val_accuracy: 0.0040\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 17.4367 - accuracy: 0.2903 - val_loss: 8.7552 - val_accuracy: 0.0196\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 18.4872 - accuracy: 0.2778 - val_loss: 8.3460 - val_accuracy: 0.0063\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 17.7848 - accuracy: 0.2871 - val_loss: 8.1114 - val_accuracy: 0.0100\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 17.8382 - accuracy: 0.2919 - val_loss: 8.4324 - val_accuracy: 0.0126\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 17.2589 - accuracy: 0.3072 - val_loss: 7.9249 - val_accuracy: 0.0294\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 16.6585 - accuracy: 0.3109 - val_loss: 7.7639 - val_accuracy: 0.0051\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 16.2906 - accuracy: 0.2774 - val_loss: 7.6611 - val_accuracy: 0.0049\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 16.1437 - accuracy: 0.2686 - val_loss: 12.0251 - val_accuracy: 0.0384\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 20.1131 - accuracy: 0.2624 - val_loss: 8.2597 - val_accuracy: 0.2042\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 16.7782 - accuracy: 0.2666 - val_loss: 7.5970 - val_accuracy: 0.0201\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 16.2246 - accuracy: 0.2980 - val_loss: 8.3846 - val_accuracy: 0.0095\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 16.8991 - accuracy: 0.2788 - val_loss: 8.1446 - val_accuracy: 0.0056\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 16.8922 - accuracy: 0.2731 - val_loss: 7.4928 - val_accuracy: 0.0099\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 16.4636 - accuracy: 0.2914 - val_loss: 7.3029 - val_accuracy: 0.3618\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 15.4720 - accuracy: 0.2067 - val_loss: 6.9102 - val_accuracy: 0.3653\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 14.8943 - accuracy: 0.1922 - val_loss: 6.6158 - val_accuracy: 0.3687\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 14.3544 - accuracy: 0.1995 - val_loss: 6.4040 - val_accuracy: 0.3980\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 14.3558 - accuracy: 0.2147 - val_loss: 6.5782 - val_accuracy: 0.4098\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 14.1255 - accuracy: 0.2197 - val_loss: 7.0938 - val_accuracy: 0.0440\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 15.2453 - accuracy: 0.2908 - val_loss: 7.7208 - val_accuracy: 0.0249\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 14.7249 - accuracy: 0.2865 - val_loss: 6.3574 - val_accuracy: 0.0080\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 13.9164 - accuracy: 0.2803 - val_loss: 5.8828 - val_accuracy: 0.0051\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 13.7528 - accuracy: 0.2835 - val_loss: 6.7883 - val_accuracy: 0.0146\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 14.1100 - accuracy: 0.2818 - val_loss: 5.8915 - val_accuracy: 0.0463\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 13.0450 - accuracy: 0.2984 - val_loss: 5.9485 - val_accuracy: 0.0542\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 12.8035 - accuracy: 0.3012 - val_loss: 6.4742 - val_accuracy: 0.0587\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 13.8834 - accuracy: 0.3016 - val_loss: 7.1834 - val_accuracy: 0.0538\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 14.1459 - accuracy: 0.2893 - val_loss: 5.9211 - val_accuracy: 0.0390\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 12.9557 - accuracy: 0.2778 - val_loss: 6.1496 - val_accuracy: 0.0560\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 13.0464 - accuracy: 0.2859 - val_loss: 5.9485 - val_accuracy: 0.0428\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 12.5376 - accuracy: 0.2875 - val_loss: 5.9197 - val_accuracy: 0.0515\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 12.1689 - accuracy: 0.3056 - val_loss: 5.9008 - val_accuracy: 0.0621\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 12.1619 - accuracy: 0.3010 - val_loss: 6.7792 - val_accuracy: 0.0550\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 12.5629 - accuracy: 0.2933 - val_loss: 5.9400 - val_accuracy: 0.0609\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 12.5977 - accuracy: 0.3042 - val_loss: 6.3902 - val_accuracy: 0.0673\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 12.5039 - accuracy: 0.3007 - val_loss: 5.9024 - val_accuracy: 0.0560\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 11.9478 - accuracy: 0.2522 - val_loss: 5.4225 - val_accuracy: 0.0517\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 11.6128 - accuracy: 0.2886 - val_loss: 5.2224 - val_accuracy: 0.0387\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 11.7033 - accuracy: 0.2967 - val_loss: 5.0753 - val_accuracy: 0.0233\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 11.1770 - accuracy: 0.2852 - val_loss: 4.7559 - val_accuracy: 0.0358\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 10.9121 - accuracy: 0.3067 - val_loss: 4.7918 - val_accuracy: 0.0487\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 11.4988 - accuracy: 0.2946 - val_loss: 10.9222 - val_accuracy: 0.0417\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 17.5245 - accuracy: 0.2127 - val_loss: 10.5490 - val_accuracy: 0.3952\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 16.6207 - accuracy: 0.1961 - val_loss: 6.3014 - val_accuracy: 0.3788\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 11.9241 - accuracy: 0.2108 - val_loss: 4.7840 - val_accuracy: 0.3779\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 11.6016 - accuracy: 0.1998 - val_loss: 5.4715 - val_accuracy: 0.1098\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 11.1786 - accuracy: 0.2749 - val_loss: 5.4975 - val_accuracy: 0.0488\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 10.9395 - accuracy: 0.2726 - val_loss: 5.0415 - val_accuracy: 0.3786\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 10.8291 - accuracy: 0.2109 - val_loss: 5.2591 - val_accuracy: 0.0592\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 10.9138 - accuracy: 0.2649 - val_loss: 4.8178 - val_accuracy: 0.0489\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 10.9445 - accuracy: 0.2931 - val_loss: 4.9475 - val_accuracy: 0.0479\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 10.3020 - accuracy: 0.2859 - val_loss: 5.2486 - val_accuracy: 0.0460\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 10.5579 - accuracy: 0.2489 - val_loss: 4.7029 - val_accuracy: 0.3590\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 10.6234 - accuracy: 0.2446 - val_loss: 5.4790 - val_accuracy: 0.0428\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 11.5286 - accuracy: 0.2924 - val_loss: 4.6433 - val_accuracy: 0.0447\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 10.5869 - accuracy: 0.2966 - val_loss: 4.6018 - val_accuracy: 0.3886\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 10.0634 - accuracy: 0.2185 - val_loss: 4.7397 - val_accuracy: 0.3488\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 10.2865 - accuracy: 0.2235 - val_loss: 4.9597 - val_accuracy: 0.0363\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 10.3810 - accuracy: 0.2856 - val_loss: 4.7599 - val_accuracy: 0.0431\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 10.2581 - accuracy: 0.2849 - val_loss: 4.9558 - val_accuracy: 0.0421\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.9697 - accuracy: 0.2898 - val_loss: 4.8253 - val_accuracy: 0.0512\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 10.2305 - accuracy: 0.2807 - val_loss: 4.8119 - val_accuracy: 0.0498\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 10.1505 - accuracy: 0.2695 - val_loss: 4.9497 - val_accuracy: 0.0490\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 10.2996 - accuracy: 0.2327 - val_loss: 4.7995 - val_accuracy: 0.0355\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.9658 - accuracy: 0.2663 - val_loss: 4.7190 - val_accuracy: 0.0484\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.8169 - accuracy: 0.2992 - val_loss: 4.6487 - val_accuracy: 0.0754\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.6596 - accuracy: 0.2969 - val_loss: 4.5903 - val_accuracy: 0.0494\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.7538 - accuracy: 0.2911 - val_loss: 4.5649 - val_accuracy: 0.0509\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.7278 - accuracy: 0.2956 - val_loss: 4.5714 - val_accuracy: 0.0467\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.5492 - accuracy: 0.2830 - val_loss: 4.5835 - val_accuracy: 0.0509\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 9.6685 - accuracy: 0.3009 - val_loss: 4.5545 - val_accuracy: 0.0517\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.5691 - accuracy: 0.3005 - val_loss: 4.5234 - val_accuracy: 0.0632\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.5678 - accuracy: 0.2698 - val_loss: 4.4794 - val_accuracy: 0.0681\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.5610 - accuracy: 0.2914 - val_loss: 4.4992 - val_accuracy: 0.0627\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.4809 - accuracy: 0.2998 - val_loss: 4.5192 - val_accuracy: 0.0927\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.5402 - accuracy: 0.2990 - val_loss: 4.5546 - val_accuracy: 0.0721\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.4908 - accuracy: 0.3071 - val_loss: 4.6266 - val_accuracy: 0.0849\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.4537 - accuracy: 0.3121 - val_loss: 4.5239 - val_accuracy: 0.1053\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.5029 - accuracy: 0.2971 - val_loss: 4.5651 - val_accuracy: 0.1060\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.5320 - accuracy: 0.3136 - val_loss: 4.4500 - val_accuracy: 0.0971\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.5204 - accuracy: 0.3138 - val_loss: 4.4660 - val_accuracy: 0.0999\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.6701 - accuracy: 0.3086 - val_loss: 4.5003 - val_accuracy: 0.1059\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.6345 - accuracy: 0.3007 - val_loss: 4.3868 - val_accuracy: 0.3847\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 9.4897 - accuracy: 0.3301 - val_loss: 4.4605 - val_accuracy: 0.1139\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 9.3516 - accuracy: 0.3205 - val_loss: 4.3018 - val_accuracy: 0.1272\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.3594 - accuracy: 0.2766 - val_loss: 4.4257 - val_accuracy: 0.1167\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.5770 - accuracy: 0.2872 - val_loss: 4.4513 - val_accuracy: 0.1114\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.5349 - accuracy: 0.3144 - val_loss: 4.4760 - val_accuracy: 0.2445\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.5349 - accuracy: 0.3239 - val_loss: 4.3094 - val_accuracy: 0.1107\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 9.3535 - accuracy: 0.3282 - val_loss: 4.2782 - val_accuracy: 0.1199\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.3319 - accuracy: 0.3011 - val_loss: 4.2984 - val_accuracy: 0.1396\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.2926 - accuracy: 0.3195 - val_loss: 4.2730 - val_accuracy: 0.1147\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.2634 - accuracy: 0.3333 - val_loss: 4.2995 - val_accuracy: 0.1218\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.3679 - accuracy: 0.3408 - val_loss: 4.3608 - val_accuracy: 0.1251\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.2690 - accuracy: 0.3398 - val_loss: 4.5885 - val_accuracy: 0.1220\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.3904 - accuracy: 0.3525 - val_loss: 4.3611 - val_accuracy: 0.1303\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.2774 - accuracy: 0.3461 - val_loss: 4.6092 - val_accuracy: 0.1426\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 9.4383 - accuracy: 0.3657 - val_loss: 4.4905 - val_accuracy: 0.1491\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 9.3046 - accuracy: 0.3522 - val_loss: 4.2698 - val_accuracy: 0.1583\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 9.1729 - accuracy: 0.3875 - val_loss: 4.5534 - val_accuracy: 0.1415\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 9.4370 - accuracy: 0.3833 - val_loss: 4.3612 - val_accuracy: 0.1372\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 9.5861 - accuracy: 0.3642 - val_loss: 4.3694 - val_accuracy: 0.1359\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 9.3846 - accuracy: 0.3776 - val_loss: 4.7705 - val_accuracy: 0.1530\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.7446 - accuracy: 0.3751 - val_loss: 4.5955 - val_accuracy: 0.1334\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.9728 - accuracy: 0.3865 - val_loss: 4.5686 - val_accuracy: 0.1548\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 9.9412 - accuracy: 0.3820 - val_loss: 4.6052 - val_accuracy: 0.1694\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.7344 - accuracy: 0.3873 - val_loss: 4.5363 - val_accuracy: 0.1693\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.4845 - accuracy: 0.4319 - val_loss: 4.9603 - val_accuracy: 0.1880\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.8859 - accuracy: 0.3826 - val_loss: 5.2686 - val_accuracy: 0.1775\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.8548 - accuracy: 0.4072 - val_loss: 4.4918 - val_accuracy: 0.1655\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.5211 - accuracy: 0.4409 - val_loss: 4.2930 - val_accuracy: 0.1674\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.2650 - accuracy: 0.4255 - val_loss: 4.3837 - val_accuracy: 0.1800\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.2611 - accuracy: 0.4260 - val_loss: 4.6645 - val_accuracy: 0.1554\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.8052 - accuracy: 0.4612 - val_loss: 4.2728 - val_accuracy: 0.1675\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.6295 - accuracy: 0.4147 - val_loss: 4.2758 - val_accuracy: 0.1736\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.8502 - accuracy: 0.4409 - val_loss: 4.4496 - val_accuracy: 0.1781\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.2600 - accuracy: 0.3645 - val_loss: 4.3859 - val_accuracy: 0.2451\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.6508 - accuracy: 0.4134 - val_loss: 4.5526 - val_accuracy: 0.1712\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.6276 - accuracy: 0.4463 - val_loss: 4.1864 - val_accuracy: 0.1965\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 9.2885 - accuracy: 0.4527 - val_loss: 4.5136 - val_accuracy: 0.1872\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 9.2551 - accuracy: 0.4484 - val_loss: 4.7475 - val_accuracy: 0.2618\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 9.3188 - accuracy: 0.4664 - val_loss: 4.3360 - val_accuracy: 0.1723\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.1479 - accuracy: 0.4989 - val_loss: 4.4482 - val_accuracy: 0.1905\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.2119 - accuracy: 0.4476 - val_loss: 4.5829 - val_accuracy: 0.1725\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 9.3977 - accuracy: 0.4596 - val_loss: 4.2949 - val_accuracy: 0.1695\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.2231 - accuracy: 0.4422 - val_loss: 4.6040 - val_accuracy: 0.1786\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 9.4540 - accuracy: 0.4379 - val_loss: 4.4412 - val_accuracy: 0.1835\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.1594 - accuracy: 0.4398 - val_loss: 4.2506 - val_accuracy: 0.1854\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.3184 - accuracy: 0.4713 - val_loss: 4.2922 - val_accuracy: 0.1951\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.1826 - accuracy: 0.4593 - val_loss: 4.2778 - val_accuracy: 0.1793\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.1316 - accuracy: 0.4655 - val_loss: 4.5579 - val_accuracy: 0.1802\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.5127 - accuracy: 0.4516 - val_loss: 4.2586 - val_accuracy: 0.1713\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.9470 - accuracy: 0.4499 - val_loss: 4.2545 - val_accuracy: 0.2154\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.9067 - accuracy: 0.4579 - val_loss: 4.2485 - val_accuracy: 0.1822\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.8580 - accuracy: 0.4792 - val_loss: 4.2498 - val_accuracy: 0.1827\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.8433 - accuracy: 0.4860 - val_loss: 4.2052 - val_accuracy: 0.1904\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 8.9714 - accuracy: 0.4706 - val_loss: 4.3232 - val_accuracy: 0.2248\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.9857 - accuracy: 0.4866 - val_loss: 4.2240 - val_accuracy: 0.1956\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.8888 - accuracy: 0.4692 - val_loss: 4.2916 - val_accuracy: 0.1995\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.8379 - accuracy: 0.4782 - val_loss: 4.2536 - val_accuracy: 0.1784\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.8327 - accuracy: 0.4771 - val_loss: 4.4400 - val_accuracy: 0.1848\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.0460 - accuracy: 0.4876 - val_loss: 4.3629 - val_accuracy: 0.1801\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.2681 - accuracy: 0.4802 - val_loss: 4.6068 - val_accuracy: 0.1911\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 9.8608 - accuracy: 0.4528 - val_loss: 4.3749 - val_accuracy: 0.2191\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.1122 - accuracy: 0.4675 - val_loss: 4.2024 - val_accuracy: 0.3146\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.0467 - accuracy: 0.4643 - val_loss: 4.4457 - val_accuracy: 0.1915\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.1058 - accuracy: 0.4831 - val_loss: 4.2274 - val_accuracy: 0.1949\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.8809 - accuracy: 0.4934 - val_loss: 4.4612 - val_accuracy: 0.2029\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.0878 - accuracy: 0.4743 - val_loss: 4.3340 - val_accuracy: 0.2426\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.8861 - accuracy: 0.4866 - val_loss: 4.2290 - val_accuracy: 0.3447\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.7660 - accuracy: 0.5100 - val_loss: 4.2591 - val_accuracy: 0.1987\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.7342 - accuracy: 0.4765 - val_loss: 4.2219 - val_accuracy: 0.2067\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.8257 - accuracy: 0.4751 - val_loss: 4.3934 - val_accuracy: 0.2082\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 8.9389 - accuracy: 0.4909 - val_loss: 4.3226 - val_accuracy: 0.3070\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.8778 - accuracy: 0.5111 - val_loss: 4.3683 - val_accuracy: 0.2120\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.8279 - accuracy: 0.4761 - val_loss: 4.4143 - val_accuracy: 0.1796\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.6918 - accuracy: 0.4911 - val_loss: 4.2593 - val_accuracy: 0.2176\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.6632 - accuracy: 0.5327 - val_loss: 4.2807 - val_accuracy: 0.2174\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.7150 - accuracy: 0.4969 - val_loss: 4.2827 - val_accuracy: 0.2098\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.7153 - accuracy: 0.4957 - val_loss: 4.2729 - val_accuracy: 0.2181\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.6808 - accuracy: 0.4867 - val_loss: 4.4035 - val_accuracy: 0.2104\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.8165 - accuracy: 0.4979 - val_loss: 4.2783 - val_accuracy: 0.2106\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.6570 - accuracy: 0.4997 - val_loss: 4.2882 - val_accuracy: 0.2207\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.6941 - accuracy: 0.5109 - val_loss: 4.1911 - val_accuracy: 0.2107\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.9643 - accuracy: 0.4935 - val_loss: 4.5024 - val_accuracy: 0.2127\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.0691 - accuracy: 0.5036 - val_loss: 4.8045 - val_accuracy: 0.2598\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.2821 - accuracy: 0.4967 - val_loss: 4.7711 - val_accuracy: 0.2064\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.9644 - accuracy: 0.5059 - val_loss: 4.7497 - val_accuracy: 0.3440\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.0444 - accuracy: 0.5582 - val_loss: 4.5136 - val_accuracy: 0.4080\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.2494 - accuracy: 0.4989 - val_loss: 4.2692 - val_accuracy: 0.3473\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.9567 - accuracy: 0.5503 - val_loss: 4.4727 - val_accuracy: 0.2181\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.1208 - accuracy: 0.5246 - val_loss: 4.6818 - val_accuracy: 0.2341\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.1314 - accuracy: 0.5397 - val_loss: 4.4924 - val_accuracy: 0.2386\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.9314 - accuracy: 0.5232 - val_loss: 4.3401 - val_accuracy: 0.2279\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.7541 - accuracy: 0.5417 - val_loss: 4.3248 - val_accuracy: 0.2236\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.5879 - accuracy: 0.5037 - val_loss: 4.4243 - val_accuracy: 0.2931\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.6625 - accuracy: 0.5663 - val_loss: 4.3151 - val_accuracy: 0.3402\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 8.7792 - accuracy: 0.5083 - val_loss: 4.2953 - val_accuracy: 0.2120\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.6500 - accuracy: 0.5272 - val_loss: 4.3386 - val_accuracy: 0.2951\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.5505 - accuracy: 0.5443 - val_loss: 4.4017 - val_accuracy: 0.2040\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.5600 - accuracy: 0.5051 - val_loss: 4.3683 - val_accuracy: 0.2155\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.5196 - accuracy: 0.5328 - val_loss: 4.2963 - val_accuracy: 0.3052\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.5004 - accuracy: 0.5336 - val_loss: 4.3166 - val_accuracy: 0.2096\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.5483 - accuracy: 0.5192 - val_loss: 4.2709 - val_accuracy: 0.2694\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.6296 - accuracy: 0.5573 - val_loss: 4.2156 - val_accuracy: 0.4003\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.4914 - accuracy: 0.5670 - val_loss: 4.2121 - val_accuracy: 0.2457\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 1s 178ms/step - loss: 8.4992 - accuracy: 0.5051 - val_loss: 4.2206 - val_accuracy: 0.3112\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.5376 - accuracy: 0.5734 - val_loss: 4.2978 - val_accuracy: 0.3767\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.4122 - accuracy: 0.5312 - val_loss: 4.2661 - val_accuracy: 0.2341\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.4770 - accuracy: 0.5333 - val_loss: 4.2287 - val_accuracy: 0.2900\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.4237 - accuracy: 0.5734 - val_loss: 4.3309 - val_accuracy: 0.3038\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.4289 - accuracy: 0.5538 - val_loss: 4.2895 - val_accuracy: 0.2182\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.5181 - accuracy: 0.5188 - val_loss: 4.5921 - val_accuracy: 0.2236\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.7964 - accuracy: 0.5488 - val_loss: 4.3244 - val_accuracy: 0.3243\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.5017 - accuracy: 0.5616 - val_loss: 4.2934 - val_accuracy: 0.2217\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.4061 - accuracy: 0.5194 - val_loss: 4.3269 - val_accuracy: 0.2664\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.4723 - accuracy: 0.5568 - val_loss: 4.2577 - val_accuracy: 0.2614\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.4155 - accuracy: 0.5431 - val_loss: 4.2823 - val_accuracy: 0.2714\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.3539 - accuracy: 0.5863 - val_loss: 4.2372 - val_accuracy: 0.3572\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.3665 - accuracy: 0.5997 - val_loss: 4.4562 - val_accuracy: 0.3372\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.5201 - accuracy: 0.5726 - val_loss: 4.2252 - val_accuracy: 0.3702\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.3127 - accuracy: 0.5801 - val_loss: 4.2119 - val_accuracy: 0.3166\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 8.3576 - accuracy: 0.5642 - val_loss: 4.2713 - val_accuracy: 0.3285\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 10.7394 - accuracy: 0.5363 - val_loss: 6.7762 - val_accuracy: 0.4472\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 11.3351 - accuracy: 0.5189 - val_loss: 5.7016 - val_accuracy: 0.2926\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.8536 - accuracy: 0.5704 - val_loss: 5.1390 - val_accuracy: 0.4538\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.6620 - accuracy: 0.5480 - val_loss: 4.3270 - val_accuracy: 0.2311\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.7521 - accuracy: 0.5193 - val_loss: 4.5081 - val_accuracy: 0.2143\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.6900 - accuracy: 0.5309 - val_loss: 4.3666 - val_accuracy: 0.2095\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.7070 - accuracy: 0.5488 - val_loss: 4.5445 - val_accuracy: 0.3471\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 8.7419 - accuracy: 0.5987 - val_loss: 4.3104 - val_accuracy: 0.2913\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.4804 - accuracy: 0.5907 - val_loss: 4.3381 - val_accuracy: 0.3017\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.4962 - accuracy: 0.5512 - val_loss: 4.2771 - val_accuracy: 0.3249\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.5885 - accuracy: 0.5837 - val_loss: 4.3170 - val_accuracy: 0.1960\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.4783 - accuracy: 0.5191 - val_loss: 4.2633 - val_accuracy: 0.4240\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.4772 - accuracy: 0.5790 - val_loss: 4.2053 - val_accuracy: 0.1971\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.5382 - accuracy: 0.5119 - val_loss: 4.3734 - val_accuracy: 0.2667\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.5153 - accuracy: 0.5667 - val_loss: 4.3035 - val_accuracy: 0.3401\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.7179 - accuracy: 0.5340 - val_loss: 4.6651 - val_accuracy: 0.2256\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.5315 - accuracy: 0.5682 - val_loss: 4.1836 - val_accuracy: 0.2474\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 8.4016 - accuracy: 0.5269 - val_loss: 4.2634 - val_accuracy: 0.2605\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.3782 - accuracy: 0.5789 - val_loss: 4.1642 - val_accuracy: 0.3820\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.3014 - accuracy: 0.5735 - val_loss: 4.8057 - val_accuracy: 0.4182\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 8.5784 - accuracy: 0.5990 - val_loss: 4.1534 - val_accuracy: 0.3548\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.4982 - accuracy: 0.5825 - val_loss: 4.4706 - val_accuracy: 0.4218\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.4126 - accuracy: 0.5367 - val_loss: 4.2494 - val_accuracy: 0.4083\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.2388 - accuracy: 0.5614 - val_loss: 4.2882 - val_accuracy: 0.2339\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.2197 - accuracy: 0.5658 - val_loss: 4.2561 - val_accuracy: 0.3425\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.2291 - accuracy: 0.5814 - val_loss: 4.2008 - val_accuracy: 0.4391\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.5322 - accuracy: 0.5633 - val_loss: 4.2481 - val_accuracy: 0.3386\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.6016 - accuracy: 0.5981 - val_loss: 4.7790 - val_accuracy: 0.4734\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.5227 - accuracy: 0.5897 - val_loss: 4.3744 - val_accuracy: 0.2916\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.3802 - accuracy: 0.5458 - val_loss: 4.3112 - val_accuracy: 0.2292\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.3040 - accuracy: 0.5940 - val_loss: 4.2218 - val_accuracy: 0.3700\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 8.3017 - accuracy: 0.5666 - val_loss: 4.2773 - val_accuracy: 0.4641\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.2928 - accuracy: 0.5652 - val_loss: 4.3331 - val_accuracy: 0.2450\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 8.4337 - accuracy: 0.5456 - val_loss: 4.5480 - val_accuracy: 0.3143\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.5958 - accuracy: 0.5761 - val_loss: 4.6146 - val_accuracy: 0.4054\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.6114 - accuracy: 0.5792 - val_loss: 4.3176 - val_accuracy: 0.2615\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 8.4271 - accuracy: 0.5235 - val_loss: 4.2567 - val_accuracy: 0.2496\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.5424 - accuracy: 0.5830 - val_loss: 4.3786 - val_accuracy: 0.3917\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 1s 158ms/step - loss: 8.7766 - accuracy: 0.5775 - val_loss: 4.7011 - val_accuracy: 0.3600\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.4694 - accuracy: 0.5713 - val_loss: 4.6494 - val_accuracy: 0.2266\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 8.4706 - accuracy: 0.5233 - val_loss: 4.2598 - val_accuracy: 0.2231\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.3522 - accuracy: 0.5622 - val_loss: 4.3314 - val_accuracy: 0.4402\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.4216 - accuracy: 0.5587 - val_loss: 4.6439 - val_accuracy: 0.3831\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.4315 - accuracy: 0.5773 - val_loss: 5.2356 - val_accuracy: 0.3542\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.9074 - accuracy: 0.5969 - val_loss: 4.2903 - val_accuracy: 0.3569\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.8475 - accuracy: 0.5847 - val_loss: 4.7965 - val_accuracy: 0.3752\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.3339 - accuracy: 0.5640 - val_loss: 5.1210 - val_accuracy: 0.4156\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.4755 - accuracy: 0.5359 - val_loss: 4.3673 - val_accuracy: 0.2070\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.2420 - accuracy: 0.5240 - val_loss: 4.3009 - val_accuracy: 0.2117\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.2139 - accuracy: 0.5579 - val_loss: 4.3586 - val_accuracy: 0.4236\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.1036 - accuracy: 0.5442 - val_loss: 4.3256 - val_accuracy: 0.2944\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.1282 - accuracy: 0.5855 - val_loss: 4.3418 - val_accuracy: 0.4623\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.2568 - accuracy: 0.5679 - val_loss: 4.4055 - val_accuracy: 0.4024\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.3534 - accuracy: 0.5855 - val_loss: 4.4481 - val_accuracy: 0.2307\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 8.2737 - accuracy: 0.5266 - val_loss: 4.3301 - val_accuracy: 0.2751\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.1256 - accuracy: 0.5987 - val_loss: 4.3094 - val_accuracy: 0.3831\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 8.0973 - accuracy: 0.6050 - val_loss: 4.2279 - val_accuracy: 0.4023\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.0549 - accuracy: 0.5920 - val_loss: 4.2753 - val_accuracy: 0.4413\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.0312 - accuracy: 0.5653 - val_loss: 4.3274 - val_accuracy: 0.4417\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.0565 - accuracy: 0.5890 - val_loss: 4.3056 - val_accuracy: 0.3993\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.1288 - accuracy: 0.5756 - val_loss: 4.3886 - val_accuracy: 0.3406\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.1014 - accuracy: 0.5471 - val_loss: 4.4272 - val_accuracy: 0.4378\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.0886 - accuracy: 0.5467 - val_loss: 4.3299 - val_accuracy: 0.2269\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 1s 149ms/step - loss: 8.1486 - accuracy: 0.5652 - val_loss: 4.3602 - val_accuracy: 0.2058\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.0754 - accuracy: 0.5448 - val_loss: 4.2943 - val_accuracy: 0.4029\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.1273 - accuracy: 0.5888 - val_loss: 4.2667 - val_accuracy: 0.2959\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 8.3691 - accuracy: 0.5903 - val_loss: 5.0767 - val_accuracy: 0.4689\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 9.6188 - accuracy: 0.5374 - val_loss: 4.6273 - val_accuracy: 0.3401\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 9.0265 - accuracy: 0.5564 - val_loss: 5.5298 - val_accuracy: 0.2128\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.9935 - accuracy: 0.5018 - val_loss: 4.5497 - val_accuracy: 0.1952\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 8.9506 - accuracy: 0.5495 - val_loss: 4.5113 - val_accuracy: 0.2387\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 9.0643 - accuracy: 0.5235 - val_loss: 4.7058 - val_accuracy: 0.1862\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 1s 158ms/step - loss: 8.8549 - accuracy: 0.5500 - val_loss: 4.4011 - val_accuracy: 0.2317\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.2920 - accuracy: 0.5240 - val_loss: 4.3199 - val_accuracy: 0.3115\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.1580 - accuracy: 0.5983 - val_loss: 4.2194 - val_accuracy: 0.4214\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.0357 - accuracy: 0.5603 - val_loss: 4.4154 - val_accuracy: 0.4632\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 8.3698 - accuracy: 0.5878 - val_loss: 4.4795 - val_accuracy: 0.2743\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.6801 - accuracy: 0.5647 - val_loss: 4.5741 - val_accuracy: 0.3787\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.4861 - accuracy: 0.5653 - val_loss: 4.3131 - val_accuracy: 0.3263\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.0654 - accuracy: 0.5617 - val_loss: 4.1545 - val_accuracy: 0.2740\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.9429 - accuracy: 0.5980 - val_loss: 4.4208 - val_accuracy: 0.3974\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.6559 - accuracy: 0.5561 - val_loss: 4.7244 - val_accuracy: 0.3696\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.5532 - accuracy: 0.5774 - val_loss: 4.2715 - val_accuracy: 0.3067\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 1s 150ms/step - loss: 8.3085 - accuracy: 0.6045 - val_loss: 4.4633 - val_accuracy: 0.4331\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.5971 - accuracy: 0.5771 - val_loss: 4.9816 - val_accuracy: 0.4570\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.3469 - accuracy: 0.5769 - val_loss: 4.2518 - val_accuracy: 0.1952\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.3065 - accuracy: 0.5262 - val_loss: 4.3433 - val_accuracy: 0.3660\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.1592 - accuracy: 0.5764 - val_loss: 4.2052 - val_accuracy: 0.3124\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.8709 - accuracy: 0.5930 - val_loss: 4.3525 - val_accuracy: 0.3865\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.8173 - accuracy: 0.6163 - val_loss: 4.2047 - val_accuracy: 0.3780\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.8987 - accuracy: 0.5671 - val_loss: 4.2461 - val_accuracy: 0.4328\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.8407 - accuracy: 0.5893 - val_loss: 4.2170 - val_accuracy: 0.3298\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.9471 - accuracy: 0.5963 - val_loss: 4.2057 - val_accuracy: 0.3816\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.8093 - accuracy: 0.5829 - val_loss: 4.2645 - val_accuracy: 0.3156\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.7789 - accuracy: 0.5963 - val_loss: 4.1923 - val_accuracy: 0.3601\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 7.8635 - accuracy: 0.6042 - val_loss: 4.3043 - val_accuracy: 0.3773\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.9023 - accuracy: 0.5935 - val_loss: 4.2978 - val_accuracy: 0.4554\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.0015 - accuracy: 0.5703 - val_loss: 4.4963 - val_accuracy: 0.3044\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 1s 174ms/step - loss: 8.0530 - accuracy: 0.5898 - val_loss: 4.3742 - val_accuracy: 0.3850\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 1s 158ms/step - loss: 8.0887 - accuracy: 0.5686 - val_loss: 4.4125 - val_accuracy: 0.4363\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 1s 161ms/step - loss: 8.3173 - accuracy: 0.5714 - val_loss: 4.3695 - val_accuracy: 0.3813\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 1s 160ms/step - loss: 8.0444 - accuracy: 0.5759 - val_loss: 4.2181 - val_accuracy: 0.1981\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 1s 164ms/step - loss: 7.9010 - accuracy: 0.5498 - val_loss: 4.3013 - val_accuracy: 0.4311\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 7.8647 - accuracy: 0.5813 - val_loss: 4.2271 - val_accuracy: 0.3950\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.8066 - accuracy: 0.5818 - val_loss: 4.2915 - val_accuracy: 0.4360\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.1038 - accuracy: 0.5828 - val_loss: 4.2542 - val_accuracy: 0.3781\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.1090 - accuracy: 0.5910 - val_loss: 4.8012 - val_accuracy: 0.4296\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 8.2130 - accuracy: 0.5736 - val_loss: 4.3667 - val_accuracy: 0.1964\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 8.1863 - accuracy: 0.5166 - val_loss: 4.1824 - val_accuracy: 0.1803\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 1s 166ms/step - loss: 8.2988 - accuracy: 0.5546 - val_loss: 4.2704 - val_accuracy: 0.4056\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.0615 - accuracy: 0.5592 - val_loss: 4.1031 - val_accuracy: 0.3935\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.9480 - accuracy: 0.5788 - val_loss: 4.2012 - val_accuracy: 0.3134\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.3105 - accuracy: 0.5740 - val_loss: 4.5154 - val_accuracy: 0.4616\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.6797 - accuracy: 0.5538 - val_loss: 5.7646 - val_accuracy: 0.4694\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 9.2459 - accuracy: 0.5184 - val_loss: 4.6810 - val_accuracy: 0.3945\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.3290 - accuracy: 0.5626 - val_loss: 4.2155 - val_accuracy: 0.4452\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 8.0500 - accuracy: 0.5794 - val_loss: 4.2753 - val_accuracy: 0.2095\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.8838 - accuracy: 0.5687 - val_loss: 4.1660 - val_accuracy: 0.4661\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.8308 - accuracy: 0.5718 - val_loss: 4.1638 - val_accuracy: 0.2744\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.8336 - accuracy: 0.5553 - val_loss: 4.1975 - val_accuracy: 0.4436\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.7935 - accuracy: 0.5898 - val_loss: 4.2149 - val_accuracy: 0.2493\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.7946 - accuracy: 0.5911 - val_loss: 4.1881 - val_accuracy: 0.4425\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.7622 - accuracy: 0.5725 - val_loss: 4.3476 - val_accuracy: 0.4220\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.7708 - accuracy: 0.5730 - val_loss: 4.3483 - val_accuracy: 0.3566\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 8.1332 - accuracy: 0.5891 - val_loss: 4.2630 - val_accuracy: 0.3600\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.1232 - accuracy: 0.5859 - val_loss: 4.4661 - val_accuracy: 0.4191\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 8.5802 - accuracy: 0.5610 - val_loss: 5.0816 - val_accuracy: 0.4723\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 8.6246 - accuracy: 0.5570 - val_loss: 4.3556 - val_accuracy: 0.3942\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.3136 - accuracy: 0.5860 - val_loss: 4.2210 - val_accuracy: 0.4135\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 8.0652 - accuracy: 0.5955 - val_loss: 4.2218 - val_accuracy: 0.2925\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 7.8567 - accuracy: 0.5879 - val_loss: 4.2026 - val_accuracy: 0.4283\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.7751 - accuracy: 0.5641 - val_loss: 4.2108 - val_accuracy: 0.3936\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.7061 - accuracy: 0.5677 - val_loss: 4.2958 - val_accuracy: 0.3813\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.7468 - accuracy: 0.5615 - val_loss: 4.1272 - val_accuracy: 0.4431\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.7201 - accuracy: 0.5312 - val_loss: 4.1641 - val_accuracy: 0.3497\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 1s 167ms/step - loss: 7.8219 - accuracy: 0.5446 - val_loss: 4.1615 - val_accuracy: 0.2229\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.7296 - accuracy: 0.5312 - val_loss: 4.1945 - val_accuracy: 0.4390\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6708 - accuracy: 0.5825 - val_loss: 4.1413 - val_accuracy: 0.2384\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6604 - accuracy: 0.5907 - val_loss: 4.1439 - val_accuracy: 0.4364\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6649 - accuracy: 0.5712 - val_loss: 4.1369 - val_accuracy: 0.4393\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.6826 - accuracy: 0.5688 - val_loss: 4.1386 - val_accuracy: 0.3753\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.8118 - accuracy: 0.5875 - val_loss: 4.2592 - val_accuracy: 0.4504\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.8597 - accuracy: 0.5659 - val_loss: 4.1669 - val_accuracy: 0.3573\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.9744 - accuracy: 0.5926 - val_loss: 4.2867 - val_accuracy: 0.3289\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 1s 168ms/step - loss: 7.8874 - accuracy: 0.5784 - val_loss: 4.2443 - val_accuracy: 0.4423\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.7448 - accuracy: 0.5655 - val_loss: 4.1220 - val_accuracy: 0.3176\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.6717 - accuracy: 0.5513 - val_loss: 4.1337 - val_accuracy: 0.2453\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 7.7284 - accuracy: 0.5762 - val_loss: 4.1668 - val_accuracy: 0.4306\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.7363 - accuracy: 0.5852 - val_loss: 4.1289 - val_accuracy: 0.3774\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6556 - accuracy: 0.5611 - val_loss: 4.1504 - val_accuracy: 0.4454\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.6102 - accuracy: 0.5947 - val_loss: 4.1108 - val_accuracy: 0.3537\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 7.6155 - accuracy: 0.5648 - val_loss: 4.2327 - val_accuracy: 0.4423\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.5901 - accuracy: 0.5837 - val_loss: 4.1462 - val_accuracy: 0.3302\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 7.5598 - accuracy: 0.5900 - val_loss: 4.1214 - val_accuracy: 0.4328\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.6222 - accuracy: 0.5697 - val_loss: 4.1529 - val_accuracy: 0.4314\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.6032 - accuracy: 0.5728 - val_loss: 4.1497 - val_accuracy: 0.3728\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.5979 - accuracy: 0.5904 - val_loss: 4.2209 - val_accuracy: 0.4494\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.0318 - accuracy: 0.5659 - val_loss: 4.1633 - val_accuracy: 0.4221\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.8685 - accuracy: 0.5693 - val_loss: 4.2925 - val_accuracy: 0.3787\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.7398 - accuracy: 0.5891 - val_loss: 4.2004 - val_accuracy: 0.3785\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.7733 - accuracy: 0.5821 - val_loss: 4.0824 - val_accuracy: 0.4379\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 7.7570 - accuracy: 0.5569 - val_loss: 4.1202 - val_accuracy: 0.4181\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.6901 - accuracy: 0.5731 - val_loss: 4.1640 - val_accuracy: 0.4320\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6081 - accuracy: 0.5721 - val_loss: 4.0798 - val_accuracy: 0.3919\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.6126 - accuracy: 0.5937 - val_loss: 4.1729 - val_accuracy: 0.3956\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.5580 - accuracy: 0.5718 - val_loss: 4.1469 - val_accuracy: 0.4087\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.5656 - accuracy: 0.5760 - val_loss: 4.1950 - val_accuracy: 0.4461\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6797 - accuracy: 0.5395 - val_loss: 4.1287 - val_accuracy: 0.4308\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6494 - accuracy: 0.5498 - val_loss: 4.2300 - val_accuracy: 0.2410\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.6465 - accuracy: 0.5538 - val_loss: 4.2254 - val_accuracy: 0.4509\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.6331 - accuracy: 0.5471 - val_loss: 4.3999 - val_accuracy: 0.3072\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.7093 - accuracy: 0.5844 - val_loss: 4.0761 - val_accuracy: 0.3976\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6518 - accuracy: 0.5439 - val_loss: 4.2088 - val_accuracy: 0.4232\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.9062 - accuracy: 0.5854 - val_loss: 4.8757 - val_accuracy: 0.2867\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.7671 - accuracy: 0.5717 - val_loss: 4.2134 - val_accuracy: 0.4399\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 8.5750 - accuracy: 0.5571 - val_loss: 4.6349 - val_accuracy: 0.3441\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 8.0404 - accuracy: 0.5908 - val_loss: 4.2594 - val_accuracy: 0.3945\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.6534 - accuracy: 0.5978 - val_loss: 4.0619 - val_accuracy: 0.3827\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.7871 - accuracy: 0.5631 - val_loss: 4.2422 - val_accuracy: 0.4254\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.9950 - accuracy: 0.5621 - val_loss: 4.2169 - val_accuracy: 0.3895\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 8.1022 - accuracy: 0.5693 - val_loss: 4.3888 - val_accuracy: 0.4185\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.1331 - accuracy: 0.5837 - val_loss: 4.7552 - val_accuracy: 0.4329\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 8.4409 - accuracy: 0.5623 - val_loss: 4.2955 - val_accuracy: 0.4295\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.9955 - accuracy: 0.5710 - val_loss: 4.1680 - val_accuracy: 0.3129\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.7038 - accuracy: 0.5856 - val_loss: 4.1494 - val_accuracy: 0.3377\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6071 - accuracy: 0.6034 - val_loss: 4.0520 - val_accuracy: 0.3811\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.5910 - accuracy: 0.5624 - val_loss: 4.2423 - val_accuracy: 0.4443\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 7.6654 - accuracy: 0.5839 - val_loss: 4.1322 - val_accuracy: 0.2896\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.8001 - accuracy: 0.5815 - val_loss: 4.1644 - val_accuracy: 0.4277\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.7199 - accuracy: 0.5675 - val_loss: 4.9698 - val_accuracy: 0.4612\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 8.1374 - accuracy: 0.5806 - val_loss: 4.2443 - val_accuracy: 0.3481\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.7733 - accuracy: 0.5877 - val_loss: 4.1603 - val_accuracy: 0.4372\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.7097 - accuracy: 0.5663 - val_loss: 4.1716 - val_accuracy: 0.3718\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.8887 - accuracy: 0.5715 - val_loss: 4.4308 - val_accuracy: 0.4134\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.7519 - accuracy: 0.5507 - val_loss: 4.0715 - val_accuracy: 0.4318\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 7.6631 - accuracy: 0.5469 - val_loss: 4.0924 - val_accuracy: 0.3432\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.6017 - accuracy: 0.5657 - val_loss: 4.2686 - val_accuracy: 0.4578\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.5884 - accuracy: 0.5793 - val_loss: 4.1083 - val_accuracy: 0.3539\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.4607 - accuracy: 0.5743 - val_loss: 4.1470 - val_accuracy: 0.4411\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.4039 - accuracy: 0.5802 - val_loss: 4.1570 - val_accuracy: 0.3333\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.4029 - accuracy: 0.5980 - val_loss: 4.0911 - val_accuracy: 0.4369\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.5194 - accuracy: 0.5592 - val_loss: 4.3174 - val_accuracy: 0.4179\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.5790 - accuracy: 0.6000 - val_loss: 4.0739 - val_accuracy: 0.3758\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.4895 - accuracy: 0.5803 - val_loss: 4.1154 - val_accuracy: 0.4370\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.3494 - accuracy: 0.5724 - val_loss: 4.0882 - val_accuracy: 0.4404\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.3665 - accuracy: 0.5951 - val_loss: 4.0423 - val_accuracy: 0.3578\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.5145 - accuracy: 0.5485 - val_loss: 4.4373 - val_accuracy: 0.4656\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.7041 - accuracy: 0.5607 - val_loss: 4.5118 - val_accuracy: 0.3177\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.9702 - accuracy: 0.5856 - val_loss: 4.3340 - val_accuracy: 0.4026\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.6845 - accuracy: 0.5646 - val_loss: 4.1960 - val_accuracy: 0.4295\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.6382 - accuracy: 0.5728 - val_loss: 4.0765 - val_accuracy: 0.4190\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.6541 - accuracy: 0.5675 - val_loss: 4.1581 - val_accuracy: 0.4489\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.3423 - accuracy: 0.5658 - val_loss: 4.1623 - val_accuracy: 0.4264\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.3445 - accuracy: 0.6019 - val_loss: 4.0592 - val_accuracy: 0.3556\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.3379 - accuracy: 0.5646 - val_loss: 4.1726 - val_accuracy: 0.4320\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.2997 - accuracy: 0.5911 - val_loss: 4.0943 - val_accuracy: 0.1840\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.3293 - accuracy: 0.5792 - val_loss: 4.0495 - val_accuracy: 0.4359\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.4059 - accuracy: 0.5720 - val_loss: 4.0459 - val_accuracy: 0.4370\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.3368 - accuracy: 0.5482 - val_loss: 4.2505 - val_accuracy: 0.4512\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.5368 - accuracy: 0.5847 - val_loss: 3.9946 - val_accuracy: 0.3392\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.4601 - accuracy: 0.5517 - val_loss: 4.2310 - val_accuracy: 0.4374\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.4373 - accuracy: 0.5772 - val_loss: 4.1115 - val_accuracy: 0.2474\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.4285 - accuracy: 0.5824 - val_loss: 4.4396 - val_accuracy: 0.4604\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.4395 - accuracy: 0.5288 - val_loss: 4.0465 - val_accuracy: 0.2680\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.4226 - accuracy: 0.5919 - val_loss: 4.1781 - val_accuracy: 0.4209\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 7.4803 - accuracy: 0.5546 - val_loss: 4.3177 - val_accuracy: 0.4179\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.5254 - accuracy: 0.5825 - val_loss: 4.0748 - val_accuracy: 0.3649\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.3980 - accuracy: 0.5839 - val_loss: 4.3587 - val_accuracy: 0.4486\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.5920 - accuracy: 0.5786 - val_loss: 4.1698 - val_accuracy: 0.3935\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.6681 - accuracy: 0.5707 - val_loss: 4.2152 - val_accuracy: 0.4158\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.6878 - accuracy: 0.5751 - val_loss: 4.6992 - val_accuracy: 0.3491\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.8743 - accuracy: 0.5753 - val_loss: 4.4305 - val_accuracy: 0.4121\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.8454 - accuracy: 0.5757 - val_loss: 4.3657 - val_accuracy: 0.3222\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.8066 - accuracy: 0.5891 - val_loss: 4.3546 - val_accuracy: 0.4402\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.6492 - accuracy: 0.5628 - val_loss: 4.3313 - val_accuracy: 0.4601\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 1s 169ms/step - loss: 7.7057 - accuracy: 0.5760 - val_loss: 4.3930 - val_accuracy: 0.4168\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.5098 - accuracy: 0.5781 - val_loss: 4.1350 - val_accuracy: 0.3251\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.3822 - accuracy: 0.6103 - val_loss: 4.1776 - val_accuracy: 0.3755\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.3592 - accuracy: 0.5813 - val_loss: 4.1229 - val_accuracy: 0.4423\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.3833 - accuracy: 0.5685 - val_loss: 4.0890 - val_accuracy: 0.3695\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.4120 - accuracy: 0.5990 - val_loss: 4.1433 - val_accuracy: 0.3710\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.3867 - accuracy: 0.5883 - val_loss: 4.0641 - val_accuracy: 0.4282\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 1s 170ms/step - loss: 7.3683 - accuracy: 0.5665 - val_loss: 4.4620 - val_accuracy: 0.4585\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.5577 - accuracy: 0.5917 - val_loss: 4.1880 - val_accuracy: 0.3130\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.4288 - accuracy: 0.5841 - val_loss: 4.2822 - val_accuracy: 0.4248\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.8373 - accuracy: 0.5655 - val_loss: 4.4544 - val_accuracy: 0.4163\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.7298 - accuracy: 0.5615 - val_loss: 4.2661 - val_accuracy: 0.4213\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.4182 - accuracy: 0.5829 - val_loss: 4.1438 - val_accuracy: 0.4387\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 1s 171ms/step - loss: 7.2606 - accuracy: 0.5927 - val_loss: 4.1603 - val_accuracy: 0.3703\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.1868 - accuracy: 0.5904 - val_loss: 4.1858 - val_accuracy: 0.4492\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.2348 - accuracy: 0.5832 - val_loss: 4.0855 - val_accuracy: 0.3726\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.2035 - accuracy: 0.5907 - val_loss: 4.1060 - val_accuracy: 0.4257\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.2474 - accuracy: 0.5764 - val_loss: 4.1059 - val_accuracy: 0.4436\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 1s 151ms/step - loss: 7.2657 - accuracy: 0.5678 - val_loss: 4.3002 - val_accuracy: 0.4484\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.2264 - accuracy: 0.5729 - val_loss: 4.1298 - val_accuracy: 0.4027\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.1671 - accuracy: 0.5936 - val_loss: 4.1334 - val_accuracy: 0.3373\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 1s 159ms/step - loss: 7.2174 - accuracy: 0.6002 - val_loss: 4.2707 - val_accuracy: 0.4541\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.2456 - accuracy: 0.5850 - val_loss: 4.0656 - val_accuracy: 0.4172\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.1514 - accuracy: 0.5763 - val_loss: 4.1018 - val_accuracy: 0.4430\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.1693 - accuracy: 0.5840 - val_loss: 4.1749 - val_accuracy: 0.4255\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.4151 - accuracy: 0.5753 - val_loss: 4.1716 - val_accuracy: 0.4371\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.3630 - accuracy: 0.5816 - val_loss: 4.1812 - val_accuracy: 0.4257\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 1s 158ms/step - loss: 7.3804 - accuracy: 0.5776 - val_loss: 4.2660 - val_accuracy: 0.4415\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 1s 152ms/step - loss: 7.3054 - accuracy: 0.5762 - val_loss: 4.1119 - val_accuracy: 0.4393\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.1319 - accuracy: 0.5955 - val_loss: 4.0356 - val_accuracy: 0.2779\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.1504 - accuracy: 0.6012 - val_loss: 4.1091 - val_accuracy: 0.4369\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.1259 - accuracy: 0.5751 - val_loss: 4.1213 - val_accuracy: 0.4391\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 1s 156ms/step - loss: 7.1317 - accuracy: 0.5789 - val_loss: 4.1103 - val_accuracy: 0.4344\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 1s 154ms/step - loss: 7.1693 - accuracy: 0.5921 - val_loss: 4.1378 - val_accuracy: 0.3449\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.1747 - accuracy: 0.5949 - val_loss: 4.1207 - val_accuracy: 0.4444\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 1s 155ms/step - loss: 7.0993 - accuracy: 0.5986 - val_loss: 4.0485 - val_accuracy: 0.3769\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 1s 153ms/step - loss: 7.1365 - accuracy: 0.5697 - val_loss: 4.1048 - val_accuracy: 0.4513\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=2)(input_layer2)\n",
        "upsample3 = layers.UpSampling2D(size=2)(upsample2)\n",
        "upsample4 = layers.UpSampling2D(size=2)(upsample3)\n",
        "upsample5 = layers.UpSampling2D(size=2)(upsample4)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=8, activation='relu')(upsample5)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=8, activation='relu')(conv_layer2)\n",
        "output_layer3 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer2)\n",
        "output_layer4 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer3)\n",
        "output_layer5 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer4)\n",
        "output_layer6 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer5)\n",
        "output_layer7 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer6)\n",
        "output_layer8 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer7)\n",
        "output_layer9 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer8)\n",
        "output_layer10 = layers.Conv2D(31, kernel_size=2, activation='relu')(output_layer9)\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer10])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='Adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=500, batch_size=32, validation_split=0.2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCiA7UJhNnL9",
        "outputId": "a125850a-2a5b-4a76-af5c-f864958e793c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 1s 67ms/step\n"
          ]
        }
      ],
      "source": [
        "gen_img=model.predict([a,b])\n",
        "gen_img=gen_img*255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "_5HPcSE0N1KQ",
        "outputId": "96398662-0a28-46c7-96d9-f51a41d0e9a2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pic_no=10\n",
        "channel=30\n",
        "# Plot the first graph in the first subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(image_transposed[pic_no][:,:,channel])\n",
        "plt.title('original image')\n",
        "plt.show()\n",
        "\n",
        "# Plot the second graph in the second subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(gen_img[pic_no][:,:,channel])\n",
        "plt.title('Generated image from model')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHPquFcHUY7M"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKG1fNe3OnSE",
        "outputId": "52dc2ce9-6e57-4709-c898-04776cc37036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 60s 22s/step - loss: 837578176.0000 - accuracy: 0.0058 - val_loss: 581.6852 - val_accuracy: 0.2634\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 57s 23s/step - loss: 696.9283 - accuracy: 0.1408 - val_loss: 14.8010 - val_accuracy: 0.1408\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 33.4239 - accuracy: 0.0236 - val_loss: 14.3678 - val_accuracy: 0.1413\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 32.2255 - accuracy: 0.0108 - val_loss: 14.0439 - val_accuracy: 0.1146\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 31.1911 - accuracy: 0.0268 - val_loss: 13.7047 - val_accuracy: 0.1015\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 30.2788 - accuracy: 0.0680 - val_loss: 13.1353 - val_accuracy: 0.1409\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 28.8156 - accuracy: 0.0360 - val_loss: 13.5028 - val_accuracy: 0.0029\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 58s 25s/step - loss: 27.9555 - accuracy: 0.0313 - val_loss: 12.2726 - val_accuracy: 0.0031\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 27.0911 - accuracy: 0.0032 - val_loss: 11.6469 - val_accuracy: 0.1011\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 26.2474 - accuracy: 0.0017 - val_loss: 11.2259 - val_accuracy: 0.1406\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 25.6082 - accuracy: 0.0233 - val_loss: 11.0591 - val_accuracy: 0.1408\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 25.4214 - accuracy: 0.0335 - val_loss: 10.8559 - val_accuracy: 0.1408\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 25.1016 - accuracy: 0.0312 - val_loss: 10.6437 - val_accuracy: 0.1148\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 24.6678 - accuracy: 0.0322 - val_loss: 10.4687 - val_accuracy: 0.1030\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 58s 26s/step - loss: 24.1276 - accuracy: 0.0210 - val_loss: 10.2268 - val_accuracy: 0.1054\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 23.5520 - accuracy: 0.0297 - val_loss: 9.9668 - val_accuracy: 0.2412\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 23.1299 - accuracy: 0.0851 - val_loss: 9.7367 - val_accuracy: 0.2653\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 22.8024 - accuracy: 0.0819 - val_loss: 9.5156 - val_accuracy: 0.2316\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 59s 22s/step - loss: 22.4791 - accuracy: 0.0740 - val_loss: 9.2406 - val_accuracy: 0.1815\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 22.1477 - accuracy: 0.0490 - val_loss: 9.0436 - val_accuracy: 0.1406\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 21.9168 - accuracy: 0.0553 - val_loss: 8.9318 - val_accuracy: 0.1537\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 58s 26s/step - loss: 21.5884 - accuracy: 0.0986 - val_loss: 8.8936 - val_accuracy: 0.1886\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 21.3227 - accuracy: 0.1632 - val_loss: 9.0009 - val_accuracy: 0.2321\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 21.1456 - accuracy: 0.1868 - val_loss: 9.0236 - val_accuracy: 0.2447\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 21.0862 - accuracy: 0.1786 - val_loss: 8.9980 - val_accuracy: 0.2221\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 20.8496 - accuracy: 0.1714 - val_loss: 8.9916 - val_accuracy: 0.2153\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 20.7077 - accuracy: 0.1845 - val_loss: 8.9363 - val_accuracy: 0.2237\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 20.6072 - accuracy: 0.1840 - val_loss: 8.7805 - val_accuracy: 0.2688\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 57s 25s/step - loss: 20.4514 - accuracy: 0.1904 - val_loss: 8.6987 - val_accuracy: 0.3003\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 55s 22s/step - loss: 20.3879 - accuracy: 0.2763 - val_loss: 8.7370 - val_accuracy: 0.3161\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 20.2866 - accuracy: 0.2136 - val_loss: 8.7216 - val_accuracy: 0.3164\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 19.9091 - accuracy: 0.1802 - val_loss: 8.4648 - val_accuracy: 0.3254\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 19.5239 - accuracy: 0.1749 - val_loss: 8.1295 - val_accuracy: 0.3073\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 19.2619 - accuracy: 0.1723 - val_loss: 8.1085 - val_accuracy: 0.2735\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 19.1559 - accuracy: 0.1919 - val_loss: 7.9898 - val_accuracy: 0.1871\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 19.1083 - accuracy: 0.1860 - val_loss: 7.6612 - val_accuracy: 0.0129\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 18.7832 - accuracy: 0.2694 - val_loss: 7.5983 - val_accuracy: 0.1372\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 18.3855 - accuracy: 0.2918 - val_loss: 7.5861 - val_accuracy: 0.1600\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 17.8526 - accuracy: 0.3832 - val_loss: 6.8496 - val_accuracy: 0.1701\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 57s 26s/step - loss: 17.4604 - accuracy: 0.2929 - val_loss: 6.8780 - val_accuracy: 0.2186\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 17.1189 - accuracy: 0.1671 - val_loss: 6.6878 - val_accuracy: 0.1179\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 16.7284 - accuracy: 0.0467 - val_loss: 6.7911 - val_accuracy: 0.0049\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 16.7313 - accuracy: 0.0838 - val_loss: 7.1084 - val_accuracy: 0.0320\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 16.5544 - accuracy: 0.2006 - val_loss: 7.0904 - val_accuracy: 0.1492\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 16.3111 - accuracy: 0.3946 - val_loss: 7.2829 - val_accuracy: 0.1502\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 16.0733 - accuracy: 0.4720 - val_loss: 6.7779 - val_accuracy: 0.1509\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 57s 26s/step - loss: 16.1666 - accuracy: 0.4813 - val_loss: 7.2498 - val_accuracy: 0.1577\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 16.1998 - accuracy: 0.4191 - val_loss: 6.7347 - val_accuracy: 0.1691\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 16.1134 - accuracy: 0.2367 - val_loss: 6.5754 - val_accuracy: 0.1888\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 15.7701 - accuracy: 0.3920 - val_loss: 7.0673 - val_accuracy: 0.2193\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 15.7514 - accuracy: 0.3984 - val_loss: 6.3901 - val_accuracy: 0.2475\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 15.8643 - accuracy: 0.4096 - val_loss: 6.7885 - val_accuracy: 0.2600\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 15.6062 - accuracy: 0.4592 - val_loss: 6.5477 - val_accuracy: 0.2696\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 15.4309 - accuracy: 0.4007 - val_loss: 6.0088 - val_accuracy: 0.2662\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 15.0846 - accuracy: 0.4026 - val_loss: 6.2196 - val_accuracy: 0.2727\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 15.0612 - accuracy: 0.4813 - val_loss: 6.0339 - val_accuracy: 0.2764\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 58s 26s/step - loss: 14.9400 - accuracy: 0.4465 - val_loss: 5.8550 - val_accuracy: 0.2784\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 14.8653 - accuracy: 0.3736 - val_loss: 6.1450 - val_accuracy: 0.2882\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 14.9217 - accuracy: 0.3595 - val_loss: 5.5736 - val_accuracy: 0.2839\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 14.7173 - accuracy: 0.4306 - val_loss: 5.5476 - val_accuracy: 0.2847\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 14.4265 - accuracy: 0.4799 - val_loss: 5.4597 - val_accuracy: 0.2669\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 14.0740 - accuracy: 0.4722 - val_loss: 5.1008 - val_accuracy: 0.3593\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 13.7249 - accuracy: 0.4591 - val_loss: 5.4291 - val_accuracy: 0.5280\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 58s 26s/step - loss: 13.5509 - accuracy: 0.3958 - val_loss: 5.5900 - val_accuracy: 0.4217\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 13.3245 - accuracy: 0.3229 - val_loss: 5.7421 - val_accuracy: 0.4111\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 13.0636 - accuracy: 0.3908 - val_loss: 5.5320 - val_accuracy: 0.4244\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 12.8406 - accuracy: 0.4456 - val_loss: 5.5501 - val_accuracy: 0.4678\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 12.7478 - accuracy: 0.4639 - val_loss: 5.2857 - val_accuracy: 0.4591\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 12.7118 - accuracy: 0.3959 - val_loss: 5.1094 - val_accuracy: 0.3965\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 12.6085 - accuracy: 0.3370 - val_loss: 5.0813 - val_accuracy: 0.4744\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 58s 26s/step - loss: 12.4292 - accuracy: 0.4304 - val_loss: 4.9851 - val_accuracy: 0.5019\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 12.1521 - accuracy: 0.5170 - val_loss: 5.0633 - val_accuracy: 0.5077\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 11.7264 - accuracy: 0.4795 - val_loss: 4.8497 - val_accuracy: 0.5096\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 11.2678 - accuracy: 0.4186 - val_loss: 5.0880 - val_accuracy: 0.5104\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 11.3102 - accuracy: 0.3625 - val_loss: 5.1713 - val_accuracy: 0.5136\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 11.4365 - accuracy: 0.3502 - val_loss: 5.0030 - val_accuracy: 0.5135\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 11.2946 - accuracy: 0.4192 - val_loss: 4.7999 - val_accuracy: 0.5110\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 11.0706 - accuracy: 0.5881 - val_loss: 4.4575 - val_accuracy: 0.5087\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 11.0174 - accuracy: 0.6041 - val_loss: 4.6784 - val_accuracy: 0.5157\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 11.1528 - accuracy: 0.5637 - val_loss: 4.5796 - val_accuracy: 0.5186\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 11.0197 - accuracy: 0.5669 - val_loss: 4.6934 - val_accuracy: 0.5198\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 10.9238 - accuracy: 0.5772 - val_loss: 4.6057 - val_accuracy: 0.5183\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.9632 - accuracy: 0.5651 - val_loss: 4.5741 - val_accuracy: 0.5095\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.9043 - accuracy: 0.5443 - val_loss: 4.4669 - val_accuracy: 0.4938\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.8398 - accuracy: 0.5845 - val_loss: 4.8459 - val_accuracy: 0.5169\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 10.9288 - accuracy: 0.6180 - val_loss: 4.2785 - val_accuracy: 0.5256\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.9680 - accuracy: 0.6095 - val_loss: 4.5205 - val_accuracy: 0.5267\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.8240 - accuracy: 0.6055 - val_loss: 4.3879 - val_accuracy: 0.5201\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 10.9672 - accuracy: 0.6144 - val_loss: 4.3761 - val_accuracy: 0.5205\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 10.8889 - accuracy: 0.6226 - val_loss: 4.4549 - val_accuracy: 0.5322\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.8732 - accuracy: 0.6261 - val_loss: 4.5392 - val_accuracy: 0.5350\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.7709 - accuracy: 0.6354 - val_loss: 4.2960 - val_accuracy: 0.5325\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 10.7859 - accuracy: 0.6243 - val_loss: 4.5376 - val_accuracy: 0.5415\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.6918 - accuracy: 0.6364 - val_loss: 4.2677 - val_accuracy: 0.5636\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.7996 - accuracy: 0.6353 - val_loss: 4.6024 - val_accuracy: 0.5631\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 57s 24s/step - loss: 10.8487 - accuracy: 0.6295 - val_loss: 4.3755 - val_accuracy: 0.5664\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.8073 - accuracy: 0.6386 - val_loss: 4.3306 - val_accuracy: 0.5685\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.7750 - accuracy: 0.6259 - val_loss: 4.2572 - val_accuracy: 0.5819\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 10.8694 - accuracy: 0.6406 - val_loss: 4.8066 - val_accuracy: 0.5860\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.9519 - accuracy: 0.6537 - val_loss: 4.2879 - val_accuracy: 0.5824\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 56s 25s/step - loss: 10.9271 - accuracy: 0.6461 - val_loss: 4.3554 - val_accuracy: 0.5821\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 10.7557 - accuracy: 0.6355 - val_loss: 4.2232 - val_accuracy: 0.5869\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 10.7663 - accuracy: 0.6364 - val_loss: 4.2089 - val_accuracy: 0.5947\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 57s 26s/step - loss: 10.7462 - accuracy: 0.5966 - val_loss: 4.7412 - val_accuracy: 0.6012\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.7479 - accuracy: 0.6348 - val_loss: 4.1870 - val_accuracy: 0.5893\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 11.1154 - accuracy: 0.6472 - val_loss: 4.4877 - val_accuracy: 0.6024\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 58s 26s/step - loss: 10.7695 - accuracy: 0.6398 - val_loss: 4.3863 - val_accuracy: 0.6027\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.6866 - accuracy: 0.6097 - val_loss: 4.2124 - val_accuracy: 0.6036\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.6484 - accuracy: 0.6243 - val_loss: 4.4021 - val_accuracy: 0.6124\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.7386 - accuracy: 0.6211 - val_loss: 4.2415 - val_accuracy: 0.6105\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 10.6205 - accuracy: 0.6083 - val_loss: 4.3375 - val_accuracy: 0.6093\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.6035 - accuracy: 0.6252 - val_loss: 4.1756 - val_accuracy: 0.6050\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.6212 - accuracy: 0.5979 - val_loss: 4.2072 - val_accuracy: 0.6018\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 56s 24s/step - loss: 10.5644 - accuracy: 0.5715 - val_loss: 4.2091 - val_accuracy: 0.6118\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 55s 22s/step - loss: 10.6253 - accuracy: 0.6214 - val_loss: 4.1106 - val_accuracy: 0.6120\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.5810 - accuracy: 0.6367 - val_loss: 4.1293 - val_accuracy: 0.6164\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.5345 - accuracy: 0.6118 - val_loss: 4.3858 - val_accuracy: 0.6128\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 57s 26s/step - loss: 10.3909 - accuracy: 0.6235 - val_loss: 4.2914 - val_accuracy: 0.6147\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.1015 - accuracy: 0.6314 - val_loss: 4.7387 - val_accuracy: 0.6120\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.9263 - accuracy: 0.6024 - val_loss: 4.9569 - val_accuracy: 0.5870\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 10.0737 - accuracy: 0.5401 - val_loss: 5.0267 - val_accuracy: 0.5781\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 9.9954 - accuracy: 0.4938 - val_loss: 4.6140 - val_accuracy: 0.5635\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.8140 - accuracy: 0.5665 - val_loss: 4.3095 - val_accuracy: 0.5711\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.7768 - accuracy: 0.6465 - val_loss: 4.3248 - val_accuracy: 0.5967\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 57s 26s/step - loss: 9.7186 - accuracy: 0.6163 - val_loss: 4.2694 - val_accuracy: 0.5918\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.7110 - accuracy: 0.5716 - val_loss: 4.1578 - val_accuracy: 0.5992\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.6475 - accuracy: 0.5641 - val_loss: 4.0646 - val_accuracy: 0.5928\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.6215 - accuracy: 0.6211 - val_loss: 4.3396 - val_accuracy: 0.5937\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 58s 26s/step - loss: 9.6040 - accuracy: 0.5742 - val_loss: 4.2932 - val_accuracy: 0.6052\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.5839 - accuracy: 0.6082 - val_loss: 4.0350 - val_accuracy: 0.6036\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.5734 - accuracy: 0.6439 - val_loss: 4.1467 - val_accuracy: 0.6018\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.6662 - accuracy: 0.5828 - val_loss: 3.9691 - val_accuracy: 0.5954\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 9.5262 - accuracy: 0.5608 - val_loss: 4.1941 - val_accuracy: 0.5818\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4786 - accuracy: 0.6247 - val_loss: 4.1662 - val_accuracy: 0.5780\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.5685 - accuracy: 0.6335 - val_loss: 4.1085 - val_accuracy: 0.5905\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4701 - accuracy: 0.6401 - val_loss: 3.9889 - val_accuracy: 0.5930\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 9.4240 - accuracy: 0.6409 - val_loss: 4.0060 - val_accuracy: 0.5848\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 9.4138 - accuracy: 0.6396 - val_loss: 4.0616 - val_accuracy: 0.5894\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4661 - accuracy: 0.6110 - val_loss: 3.9645 - val_accuracy: 0.5880\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 57s 25s/step - loss: 9.4033 - accuracy: 0.6110 - val_loss: 4.0752 - val_accuracy: 0.5925\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4249 - accuracy: 0.6283 - val_loss: 4.0192 - val_accuracy: 0.5950\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4209 - accuracy: 0.6180 - val_loss: 4.0726 - val_accuracy: 0.5917\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4159 - accuracy: 0.6315 - val_loss: 4.0150 - val_accuracy: 0.5992\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 57s 26s/step - loss: 9.4253 - accuracy: 0.6411 - val_loss: 4.0303 - val_accuracy: 0.5977\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.3829 - accuracy: 0.6275 - val_loss: 3.9479 - val_accuracy: 0.5922\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.3758 - accuracy: 0.6228 - val_loss: 3.9004 - val_accuracy: 0.5922\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.3747 - accuracy: 0.6428 - val_loss: 4.1567 - val_accuracy: 0.5908\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 57s 26s/step - loss: 9.3747 - accuracy: 0.6353 - val_loss: 3.9533 - val_accuracy: 0.5802\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.3731 - accuracy: 0.6419 - val_loss: 3.9846 - val_accuracy: 0.5908\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.3536 - accuracy: 0.6450 - val_loss: 3.9939 - val_accuracy: 0.5902\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.3638 - accuracy: 0.6373 - val_loss: 3.9609 - val_accuracy: 0.5915\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 9.3638 - accuracy: 0.6379 - val_loss: 3.8719 - val_accuracy: 0.5961\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4267 - accuracy: 0.6281 - val_loss: 3.9982 - val_accuracy: 0.5911\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.3477 - accuracy: 0.6299 - val_loss: 4.1828 - val_accuracy: 0.5881\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4265 - accuracy: 0.6450 - val_loss: 3.8472 - val_accuracy: 0.5813\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 58s 22s/step - loss: 9.4645 - accuracy: 0.6448 - val_loss: 4.1335 - val_accuracy: 0.5925\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.5306 - accuracy: 0.6389 - val_loss: 3.7864 - val_accuracy: 0.6040\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.4998 - accuracy: 0.6380 - val_loss: 4.1151 - val_accuracy: 0.6030\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 57s 22s/step - loss: 9.9355 - accuracy: 0.6048 - val_loss: 3.7211 - val_accuracy: 0.5901\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 9.6299 - accuracy: 0.6197 - val_loss: 3.7240 - val_accuracy: 0.5897\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 9.6455 - accuracy: 0.6285 - val_loss: 4.3651 - val_accuracy: 0.5986\n",
            "Epoch 162/500\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=2)(input_layer2)\n",
        "upsample3 = layers.UpSampling2D(size=2)(upsample2)\n",
        "upsample4 = layers.UpSampling2D(size=2)(upsample3)\n",
        "upsample5 = layers.UpSampling2D(size=2)(upsample4)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=8, activation='relu')(upsample5)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=8, activation='relu')(conv_layer2)\n",
        "output_layer3 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer2)\n",
        "output_layer4 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer3)\n",
        "output_layer5 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer4)\n",
        "output_layer6 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer5)\n",
        "output_layer7 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer6)\n",
        "output_layer8 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer7)\n",
        "output_layer9 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer8)\n",
        "output_layer10 = layers.Conv2D(31, kernel_size=2, activation='relu')(output_layer9)\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer10])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "max_pool_layer1 = layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(conv_layer3)\n",
        "max_pool_layer2 = layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(max_pool_layer1)\n",
        "max_pool_layer3 = layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(max_pool_layer2)\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], max_pool_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=500, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gTMvB6iGPxQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2iHCmkewP4i"
      },
      "outputs": [],
      "source": [
        "gen_img=model.predict([a,b])\n",
        "gen_img=gen_img*255\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Y2pJxS6xyqw",
        "outputId": "02f7b074-9296-47d6-e49b-5d7d4dbb332d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 64, 31)\n"
          ]
        }
      ],
      "source": [
        "print(gen_img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "GkSfduswDlTP",
        "outputId": "1c216ac7-16db-497e-f7ec-2bc72d2498e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 64, 31)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 64 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "patches=np.asarray(gt_data)\n",
        "print(patches.shape)\n",
        "plt.figure(figsize=(6,6))\n",
        "for i in range(64):\n",
        "  plt.subplot(8,8,i+1)\n",
        "  plt.imshow(patches[i,:,:,1])\n",
        "  plt.axis('off')\n",
        "plt.savefig('patches.png',dpi=400)\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "3rTO8JYID7pY",
        "outputId": "2f95d193-25ce-4d48-9d6d-0e89dc3fdb03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 64, 64, 31)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 64 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "patches_new=np.asarray(gen_img)\n",
        "print(patches_new.shape)\n",
        "\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.title('GENERATED IMAGE')\n",
        "for i in range(64):\n",
        "  plt.subplot(8,8,i+1)\n",
        "  plt.imshow(patches_new[i,:,:,1])\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-K-jvc2GiY2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlhwTqipGjzj"
      },
      "source": [
        "# **less epochs to reduce time**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9IeFabUAGrCB",
        "outputId": "a4692517-4dc9-46b5-f93d-71a6a975a613"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 60s 22s/step - loss: 327113440.0000 - accuracy: 0.0318 - val_loss: 1370.5588 - val_accuracy: 5.6340e-05\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 52s 21s/step - loss: 1591.2306 - accuracy: 0.0078 - val_loss: 16.5378 - val_accuracy: 0.2631\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 54s 23s/step - loss: 34.5327 - accuracy: 0.1130 - val_loss: 14.7244 - val_accuracy: 1.1268e-04\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 53s 21s/step - loss: 31.6489 - accuracy: 0.0013 - val_loss: 13.7943 - val_accuracy: 1.1268e-04\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 56s 21s/step - loss: 28.5088 - accuracy: 0.0012 - val_loss: 13.5640 - val_accuracy: 7.5120e-05\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 54s 23s/step - loss: 27.4559 - accuracy: 0.0023 - val_loss: 13.5019 - val_accuracy: 9.3900e-05\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 26.5727 - accuracy: 0.0052 - val_loss: 13.1540 - val_accuracy: 1.5024e-04\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 25.1475 - accuracy: 0.0014 - val_loss: 12.6929 - val_accuracy: 2.0658e-04\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 58s 27s/step - loss: 24.7299 - accuracy: 0.0017 - val_loss: 12.4075 - val_accuracy: 0.3514\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 24.9638 - accuracy: 0.1055 - val_loss: 12.2608 - val_accuracy: 0.3136\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 24.9889 - accuracy: 0.0811 - val_loss: 12.1533 - val_accuracy: 0.0521\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 52s 21s/step - loss: 24.7083 - accuracy: 0.1839 - val_loss: 12.1190 - val_accuracy: 8.8266e-04\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 53s 23s/step - loss: 24.3865 - accuracy: 0.2821 - val_loss: 12.0310 - val_accuracy: 0.0059\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 56s 25s/step - loss: 23.7168 - accuracy: 0.3100 - val_loss: 11.8836 - val_accuracy: 0.0041\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 60s 27s/step - loss: 23.1420 - accuracy: 0.2428 - val_loss: 11.9304 - val_accuracy: 0.0038\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 75s 28s/step - loss: 22.6748 - accuracy: 0.0370 - val_loss: 12.2044 - val_accuracy: 0.0052\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 54s 21s/step - loss: 22.2401 - accuracy: 0.0215 - val_loss: 12.4579 - val_accuracy: 0.0093\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 56s 21s/step - loss: 21.6996 - accuracy: 0.0189 - val_loss: 12.4768 - val_accuracy: 0.0266\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 54s 21s/step - loss: 21.0547 - accuracy: 0.0228 - val_loss: 12.2256 - val_accuracy: 0.1663\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 20.5897 - accuracy: 0.0673 - val_loss: 11.9628 - val_accuracy: 0.1453\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 20.3543 - accuracy: 0.0465 - val_loss: 11.6851 - val_accuracy: 0.1506\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 53s 22s/step - loss: 20.1517 - accuracy: 0.0549 - val_loss: 11.5065 - val_accuracy: 0.1644\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 56s 21s/step - loss: 20.0241 - accuracy: 0.0891 - val_loss: 11.3974 - val_accuracy: 0.1838\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 19.9030 - accuracy: 0.1343 - val_loss: 11.3097 - val_accuracy: 0.1981\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 61s 21s/step - loss: 19.8228 - accuracy: 0.1323 - val_loss: 11.1119 - val_accuracy: 0.2265\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 54s 23s/step - loss: 19.6027 - accuracy: 0.0915 - val_loss: 10.8939 - val_accuracy: 0.2363\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 55s 21s/step - loss: 19.2480 - accuracy: 0.1307 - val_loss: 10.6979 - val_accuracy: 0.2411\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 18.8459 - accuracy: 0.2040 - val_loss: 10.6045 - val_accuracy: 0.2395\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 57s 26s/step - loss: 18.4951 - accuracy: 0.2575 - val_loss: 10.5432 - val_accuracy: 0.1943\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 52s 21s/step - loss: 18.2490 - accuracy: 0.2581 - val_loss: 10.4881 - val_accuracy: 0.1698\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 56s 25s/step - loss: 17.9655 - accuracy: 0.1338 - val_loss: 10.4002 - val_accuracy: 0.1686\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 54s 23s/step - loss: 17.6883 - accuracy: 0.1384 - val_loss: 10.3780 - val_accuracy: 0.1582\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 52s 21s/step - loss: 17.3639 - accuracy: 0.2386 - val_loss: 10.4758 - val_accuracy: 0.0095\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 17.0849 - accuracy: 0.1844 - val_loss: 10.5729 - val_accuracy: 0.0045\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 52s 21s/step - loss: 16.9365 - accuracy: 0.1172 - val_loss: 10.6316 - val_accuracy: 0.0044\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 58s 21s/step - loss: 16.8478 - accuracy: 0.0214 - val_loss: 10.6392 - val_accuracy: 0.0044\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 52s 21s/step - loss: 16.7892 - accuracy: 0.0311 - val_loss: 10.6446 - val_accuracy: 0.0065\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 51s 21s/step - loss: 16.6546 - accuracy: 0.1158 - val_loss: 10.6374 - val_accuracy: 0.1346\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 54s 21s/step - loss: 16.3637 - accuracy: 0.1614 - val_loss: 10.4462 - val_accuracy: 0.1622\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 56s 21s/step - loss: 16.0443 - accuracy: 0.2045 - val_loss: 10.2188 - val_accuracy: 0.1759\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 52s 21s/step - loss: 15.8638 - accuracy: 0.1563 - val_loss: 9.9756 - val_accuracy: 0.1808\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 54s 22s/step - loss: 15.8393 - accuracy: 0.1562 - val_loss: 9.7944 - val_accuracy: 0.1817\n",
            "Epoch 43/500\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-a66ff06ce8c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Train the model and store the history object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=2)(input_layer2)\n",
        "upsample3 = layers.UpSampling2D(size=2)(upsample2)\n",
        "upsample4 = layers.UpSampling2D(size=2)(upsample3)\n",
        "upsample5 = layers.UpSampling2D(size=2)(upsample4)\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=8, activation='relu')(upsample5)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=8, activation='relu')(conv_layer2)\n",
        "output_layer3 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer2)\n",
        "output_layer4 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer3)\n",
        "output_layer5 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer4)\n",
        "output_layer6 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer5)\n",
        "output_layer7 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer6)\n",
        "output_layer8 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer7)\n",
        "output_layer9 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer8)\n",
        "output_layer10 = layers.Conv2D(31, kernel_size=2, activation='relu')(output_layer9)\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer10])\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "max_pool_layer1 = layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(conv_layer3)\n",
        "max_pool_layer2 = layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(max_pool_layer1)\n",
        "max_pool_layer3 = layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(max_pool_layer2)\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], max_pool_layer3)\n",
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_absolute_error', metrics=['accuracy'])\n",
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=500, batch_size=32, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvgGqesIIJ3N"
      },
      "outputs": [],
      "source": [
        "model.save((\"/content/drive/MyDrive/balloons_ms/64/super_res.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1f6xkGFIQOa"
      },
      "outputs": [],
      "source": [
        "model =  keras.models.load_model(\"/content/drive/MyDrive/balloons_ms/64/super_res.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giY4aw2mI6rz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_JyjkIcJMOz"
      },
      "outputs": [],
      "source": [
        "gen_img=model.predict([a,b])\n",
        "gen_img=gen_img*255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EOzMc7fJejU"
      },
      "outputs": [],
      "source": [
        "patches=np.asarray(gt_data)\n",
        "print(patches.shape)\n",
        "plt.figure(figsize=(6,6))\n",
        "for i in range(64):\n",
        "  plt.subplot(8,8,i+1)\n",
        "  plt.imshow(patches[i,:,:,1])\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ChRWF7iJipn"
      },
      "outputs": [],
      "source": [
        "patches=np.asarray(gen_img)\n",
        "print(patches.shape)\n",
        "plt.figure(figsize=(6,6))\n",
        "for i in range(64):\n",
        "  plt.subplot(8,8,i+1)\n",
        "  plt.imshow(patches[i,:,:,1])\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3tdHyYAKGyT"
      },
      "outputs": [],
      "source": [
        "# Extract the accuracy and loss values from the history object\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# Plot the first graph in the first subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(acc, label='Training accuracy')\n",
        "plt.plot(val_acc, label='Validation accuracy')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# Plot the second graph in the second subplot\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.plot(loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.title('Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRCF4KzzhJ6G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4fsm3mrDhKC4",
        "outputId": "d7031b36-5ebd-4b25-81d6-7c13f292575d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 59s 23s/step - loss: 44.8862 - accuracy: 0.0101 - val_loss: 16.7475 - val_accuracy: 1.3146e-04\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 38.4218 - accuracy: 0.0034 - val_loss: 16.7131 - val_accuracy: 1.3146e-04\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 52s 21s/step - loss: 38.2023 - accuracy: 0.0031 - val_loss: 16.3445 - val_accuracy: 5.6340e-05\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 52s 21s/step - loss: 35.6788 - accuracy: 0.0175 - val_loss: 18.8149 - val_accuracy: 5.6340e-05\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 57s 27s/step - loss: 34.6548 - accuracy: 0.0179 - val_loss: 14.0845 - val_accuracy: 3.7560e-05\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 30.9990 - accuracy: 0.0186 - val_loss: 13.9891 - val_accuracy: 2.0658e-04\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 52s 21s/step - loss: 28.9507 - accuracy: 0.0077 - val_loss: 14.7619 - val_accuracy: 2.8170e-04\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 27.4757 - accuracy: 0.0080 - val_loss: 13.2260 - val_accuracy: 2.4414e-04\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 53s 21s/step - loss: 27.4279 - accuracy: 0.0083 - val_loss: 13.0289 - val_accuracy: 2.0658e-04\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 56s 21s/step - loss: 25.8025 - accuracy: 0.0069 - val_loss: 12.7621 - val_accuracy: 0.0020\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 52s 21s/step - loss: 24.7813 - accuracy: 0.0123 - val_loss: 12.1109 - val_accuracy: 3.7560e-05\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 53s 21s/step - loss: 24.0715 - accuracy: 0.0169 - val_loss: 12.5312 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 24.1109 - accuracy: 0.0156 - val_loss: 11.9929 - val_accuracy: 7.5120e-05\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 23.3509 - accuracy: 0.0216 - val_loss: 12.0301 - val_accuracy: 3.7560e-05\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 58s 21s/step - loss: 22.8654 - accuracy: 0.0193 - val_loss: 11.9256 - val_accuracy: 3.0048e-04\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 52s 21s/step - loss: 22.2659 - accuracy: 0.0220 - val_loss: 11.8436 - val_accuracy: 1.5024e-04\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 52s 21s/step - loss: 21.5927 - accuracy: 0.0213 - val_loss: 12.4765 - val_accuracy: 3.7560e-05\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 52s 21s/step - loss: 21.9033 - accuracy: 0.0209 - val_loss: 11.6097 - val_accuracy: 7.5120e-05\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 56s 23s/step - loss: 21.2449 - accuracy: 0.0210 - val_loss: 11.6639 - val_accuracy: 7.5120e-05\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 54s 21s/step - loss: 20.4020 - accuracy: 0.0243 - val_loss: 11.6336 - val_accuracy: 7.5120e-05\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 20.2787 - accuracy: 0.0286 - val_loss: 11.8049 - val_accuracy: 3.7560e-05\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 54s 21s/step - loss: 20.5915 - accuracy: 0.0270 - val_loss: 11.4802 - val_accuracy: 2.6292e-04\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 52s 21s/step - loss: 20.0875 - accuracy: 0.0499 - val_loss: 12.0903 - val_accuracy: 0.0225\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 57s 26s/step - loss: 21.0968 - accuracy: 0.0610 - val_loss: 11.3408 - val_accuracy: 0.3253\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 53s 23s/step - loss: 21.2883 - accuracy: 0.0993 - val_loss: 11.1963 - val_accuracy: 0.3254\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 20.3609 - accuracy: 0.0827 - val_loss: 11.7747 - val_accuracy: 0.0519\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 20.0356 - accuracy: 0.0250 - val_loss: 11.1400 - val_accuracy: 4.1316e-04\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 20.7556 - accuracy: 0.0339 - val_loss: 11.2622 - val_accuracy: 2.6292e-04\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 19.5239 - accuracy: 0.0359 - val_loss: 11.4754 - val_accuracy: 2.6292e-04\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 57s 21s/step - loss: 19.4233 - accuracy: 0.0350 - val_loss: 10.9458 - val_accuracy: 0.0014\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 51s 21s/step - loss: 19.5046 - accuracy: 0.0594 - val_loss: 11.1122 - val_accuracy: 0.0074\n",
            "Epoch 32/200\n",
            "1/2 [==============>...............] - ETA: 30s - loss: 19.8945 - accuracy: 0.0445"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-c9d1131c6197>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Train the model and store the history object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the input layers\n",
        "input_layer1 = layers.Input(shape=(64, 64, 3))\n",
        "input_layer2 = layers.Input(shape=(8, 8, 31))\n",
        "\n",
        "# Upsample the first input image\n",
        "upsample1 = layers.UpSampling2D(size=1)(input_layer1)\n",
        "# Define the convolutional layer\n",
        "conv_layer1 = layers.Conv2D(64, kernel_size=1, activation='relu')(upsample1)\n",
        "output_layer1 = layers.Conv2D(31, kernel_size=1, activation='relu')(conv_layer1)\n",
        "\n",
        "# Upsample the second input image\n",
        "upsample2 = layers.UpSampling2D(size=2)(input_layer2)\n",
        "upsample3 = layers.UpSampling2D(size=2)(upsample2)\n",
        "upsample4 = layers.UpSampling2D(size=2)(upsample3)\n",
        "upsample5 = layers.UpSampling2D(size=2)(upsample4)\n",
        "\n",
        "# Define the convolutional layer\n",
        "conv_layer2 = layers.Conv2D(31, kernel_size=8, activation='relu')(upsample5)\n",
        "output_layer2 = layers.Conv2D(31, kernel_size=8, activation='relu')(conv_layer2)\n",
        "output_layer3 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer2)\n",
        "output_layer4 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer3)\n",
        "output_layer5 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer4)\n",
        "output_layer6 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer5)\n",
        "output_layer7 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer6)\n",
        "output_layer8 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer7)\n",
        "output_layer9 = layers.Conv2D(31, kernel_size=8, activation='relu')(output_layer8)\n",
        "output_layer10 = layers.Conv2D(31, kernel_size=2, activation='relu')(output_layer9)\n",
        "# Concatenate the two output layers\n",
        "concatenated = layers.Concatenate()([output_layer1, output_layer10])\n",
        "\n",
        "# Add a convolutional layer with 31 filters and a kernel size of 3\n",
        "conv_layer3 = layers.Conv2D(31, kernel_size=1, activation='relu')(concatenated)\n",
        "\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model([input_layer1, input_layer2], conv_layer3)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='Adam', loss='mean_absolute_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model and store the history object\n",
        "history = model.fit([a, b], c, epochs=200, batch_size=32, validation_split=0.2)\n",
        "\n",
        "\n",
        "model.save((\"/content/drive/MyDrive/balloons_ms/64/super_res.h5\"))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}